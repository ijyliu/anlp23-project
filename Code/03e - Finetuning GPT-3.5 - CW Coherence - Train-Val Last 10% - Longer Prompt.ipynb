{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning GPT-3.5 - CW Coherence.ipynb\n",
        "\n",
        "Sources: https://blog.futuresmart.ai/fine-tuning-gpt-35-a-step-by-step-guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Whether this notebook is first 10% or last 10%\n",
        "this_nb = 'last_10_LP'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_task_method</th>\n",
              "      <th>conversation_number</th>\n",
              "      <th>response</th>\n",
              "      <th>coherence_1_incoherent_10_very_coherent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>1</td>\n",
              "      <td>Learning to do a handstand is a fun activity f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>2</td>\n",
              "      <td>The hawk was used to hunting what he needed fo...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>3</td>\n",
              "      <td>I love the smell of roasting almonds in the ki...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>4</td>\n",
              "      <td>Ralph's bedroom was routinely filled up with s...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>5</td>\n",
              "      <td>Joe had a unique way of dealing with the hospi...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   model_task_method  conversation_number  \\\n",
              "0  td3_cw_direct_prompting_responses                    1   \n",
              "1  td3_cw_direct_prompting_responses                    2   \n",
              "2  td3_cw_direct_prompting_responses                    3   \n",
              "3  td3_cw_direct_prompting_responses                    4   \n",
              "4  td3_cw_direct_prompting_responses                    5   \n",
              "\n",
              "                                            response  \\\n",
              "0  Learning to do a handstand is a fun activity f...   \n",
              "1  The hawk was used to hunting what he needed fo...   \n",
              "2  I love the smell of roasting almonds in the ki...   \n",
              "3  Ralph's bedroom was routinely filled up with s...   \n",
              "4  Joe had a unique way of dealing with the hospi...   \n",
              "\n",
              "   coherence_1_incoherent_10_very_coherent  \n",
              "0                                        1  \n",
              "1                                        7  \n",
              "2                                        1  \n",
              "3                                       10  \n",
              "4                                        4  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "full_human_data = pd.read_csv(\"full_human_data.csv\")\n",
        "full_human_data.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This notebook: train and validate on first 10% of observations for each method\n",
        "# Get predictions on second 90% of observations for each method\n",
        "# Keep first 10% of observations for each model_task_method in dataset\n",
        "# Split on conversation_number LTE 10 and not\n",
        "if this_nb == 'first_10_LP':\n",
        "    this_notebook_train_validate = full_human_data[full_human_data['conversation_number'] <= 10]\n",
        "    this_notebook_predictions = full_human_data[full_human_data['conversation_number'] > 10]\n",
        "else:\n",
        "    this_notebook_train_validate = full_human_data[full_human_data['conversation_number'] > 90]\n",
        "    this_notebook_predictions = full_human_data[full_human_data['conversation_number'] <= 90]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save this notebook's predictions\n",
        "this_notebook_predictions.to_csv('items_to_predict_using_' + this_nb + '.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sarah had been trying to lose weight for months, but every time she stepped on the scale, it seemed like she wasn't making progress. Frustrated, she knew she couldn't continue eating three-egg omelets for breakfast every morning if she wanted to start slimming down. If eating three-egg omelets causes weight-gain, budgie eggs are a good substitute.\n",
            "She made her way to the park to clear her mind. Watching the ducks float on the pond, Sarah noticed a man in mirrored sunglasses and a leather jacket walking his Staffordshire Terrier. She wondered what his eyes were saying beneath his mirrored sunglasses.\n",
            "\n",
            "The hawk was very puzzled as to why the ground squirrels always ran away from him whenever he came around. After a few days of close observation, he noticed that they treated everyone the same way. It quickly became apparent that the ground squirrels weren't afraid of him, they just weren't looking for company. The hawk didn't understand why the ground squirrels didn't want to be his friend.\n",
            "John was a procrastinator for the entirety of his college career. He decided to start his research paper a week before it was due, but knew that he had to finish it within that week. With a few all-nighters, and some hard work, he managed to complete it. He turned in the research paper on Friday; otherwise, he would have not passed the class.\n",
            "\n",
            "Joe had been doing his daily commute, taking the same route to and from work for months now. One day, he noticed a traffic cone on the sidewalk and when he picked it up, was amazed to find his voice was amplified within the cone. Joe found that he could use it to project his speech to the passerby - like a megaphone. Joe discovered that traffic cones make excellent megaphones.\n",
            "Unexpectedly, a TV show in his hometown reached national acclaim and suddenly everyone was talking about it. People kept raving about the show but Joe didn't know anything about it - he hadn't watched it. Honestly, I didn't care much for the first season, so I didn't bother with the second.\n",
            "\n",
            "Television shows loving premiered every year, with high expectations of audience engagement and critical success. Every now and then, a show is born that shimmers brighter than others, its captivating story-line and compelling characters making it an instant success. A glittering gem is not enough, however, to sustain a show for multiple seasons; most eventually fall off the radar, returning to obscurity. Honestly, I didn't care much for the first season, so I didn't bother with the second. I prefer to move on to another show with some fresh ideas and new perspectives.\n",
            "\n",
            "I hadn't expected to like the new TV series, but I decided to give it a shot anyway. Honestly, I didn't care much for the first season, so I didn't bother with the second.\n",
            "She was an unforgettable sight - her white sundress billowing in the summer breeze and her hair was windswept as she rode in the black convertible. I could only envy her as she drove away into the horizon, completely free.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print responses for 5 observations\n",
        "for i in range(5):\n",
        "    print(this_notebook_train_validate.iloc[i, 2])\n",
        "    print('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She6a_yOnVsI"
      },
      "source": [
        "### Format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9ZLRixKjVMZ",
        "outputId": "5e60c152-4196-4f76-8268-2f81d13d4eed"
      },
      "outputs": [],
      "source": [
        "def convert_to_gpt35_format(dataset):\n",
        "    fine_tuning_data = []\n",
        "    for _, row in dataset.iterrows():\n",
        "        json_response = '{\"Score\": \"' + str(row['coherence_1_incoherent_10_very_coherent']) + '\"}'\n",
        "        fine_tuning_data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": row['response'] + \"\\nYour Task: Rate the coherence of the passage above on a scale of 1 to 10, 1 being incoherent and 10 being very coherent. If the passage is two unconnected pieces give it a score of 1. If it has sentences that seem to be randomly inserted, has abrupt change in characters, or has abrupt change in setting, give it a low score. If it has a continuous setting or characters and seems plausible, give it a high score. If it is as coherent as you believe is possible, give it a score of 10.\"},\n",
        "                {\"role\": \"assistant\", \"content\": json_response}\n",
        "            ]\n",
        "        })\n",
        "    return fine_tuning_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': \"Sarah had been trying to lose weight for months, but every time she stepped on the scale, it seemed like she wasn't making progress. Frustrated, she knew she couldn't continue eating three-egg omelets for breakfast every morning if she wanted to start slimming down. If eating three-egg omelets causes weight-gain, budgie eggs are a good substitute.\\nShe made her way to the park to clear her mind. Watching the ducks float on the pond, Sarah noticed a man in mirrored sunglasses and a leather jacket walking his Staffordshire Terrier. She wondered what his eyes were saying beneath his mirrored sunglasses.\\nYour Task: Rate the coherence of the passage above on a scale of 1 to 10, 1 being incoherent and 10 being very coherent. If the passage is two unconnected pieces give it a score of 1. If it has sentences that seem to be randomly inserted, has abrupt change in characters, or has abrupt change in setting, give it a low score. If it has a continuous setting or characters and seems plausible, give it a high score. If it is as coherent as you believe is possible, give it a score of 10.\"},\n",
              " {'role': 'assistant', 'content': '{\"Score\": \"6\"}'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert entire dataset\n",
        "dataset = this_notebook_train_validate\n",
        "converted_data = convert_to_gpt35_format(dataset)\n",
        "converted_data[0]['messages']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzOSh9ZOjh6P",
        "outputId": "0f954c17-e689-442e-9bae-7d77661f7de5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Score': '6'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "json.loads(converted_data[0]['messages'][-1]['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fM5yTsndjp"
      },
      "source": [
        "Create Train and Val Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['td3_cw_direct_prompting_responses',\n",
              "       'td3_cw_zero_shot_cot_responses',\n",
              "       'td3_cw_ape_zero_shot_cot_responses',\n",
              "       'td3_cw_least_to_most_responses',\n",
              "       'td3_cw_manual_few_shot_responses', 'td3_cw_manual_cot_responses',\n",
              "       'td3_cw_tree_of_thought_responses', 'td3_cw_self_refine_responses',\n",
              "       'gpt4_cw_direct_prompting_responses',\n",
              "       'gpt4_cw_zero_shot_cot_responses',\n",
              "       'gpt4_cw_ape_zero_shot_cot_responses',\n",
              "       'gpt4_cw_tree_of_thought_responses',\n",
              "       'gpt4_cw_self_refine_responses', 'gpt4_cw_least_to_most_responses',\n",
              "       'gpt4_cw_manual_few_shot_responses',\n",
              "       'gpt4_cw_manual_cot_responses'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print unique values of model_task_method\n",
        "this_notebook_train_validate['model_task_method'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jslTVNldj5Ml"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified splitting on model_task_method.\n",
        "train_data, val_data = train_test_split(\n",
        "    converted_data,\n",
        "    test_size=0.2,\n",
        "    stratify=this_notebook_train_validate['model_task_method'],\n",
        "    random_state=42  # for reproducibility\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_sf-jBwc5Y",
        "outputId": "45578907-f3b7-438b-aad3-322afb9004e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128\n",
            "32\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPNfP_GnrDq"
      },
      "source": [
        "Create JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "31vTBdJiitzX"
      },
      "outputs": [],
      "source": [
        "def write_to_jsonl(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for entry in data:\n",
        "            json.dump(entry, file)\n",
        "            file.write('\\n')\n",
        "\n",
        "\n",
        "training_file_name = \"train_\" + this_nb + \".jsonl\"\n",
        "validation_file_name = \"val_\" + this_nb + \".jsonl\"\n",
        "\n",
        "write_to_jsonl(train_data, training_file_name)\n",
        "write_to_jsonl(val_data, validation_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Get and set API key\n",
        "# with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "#     api_key = file.read()\n",
        "# openai.api_key = api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Get and set API key\n",
        "with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "    my_api_key = file.read()\n",
        "\n",
        "#from openai import OpenAI\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=my_api_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHIVr7BAnyjC"
      },
      "source": [
        "Upload Training and Validation File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpCsg8I2ZxLK",
        "outputId": "9ce65740-674b-446b-9829-b9c04c6097c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-xx0weewZiEHzMkn6et2LfLxf\n",
            "Validation file id: file-UBG4DDfaxNvmBmik74DXQHv8\n"
          ]
        }
      ],
      "source": [
        "training_file = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(\"Training file id:\", training_file.id)\n",
        "print(\"Validation file id:\", validation_file.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCwIEinan2il"
      },
      "source": [
        "Create Finetuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17X6KNaaIRJ",
        "outputId": "a66d283d-03f7-4ae3-f322-bd449042dfbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-gN3HZmStnyX37Et8jSkLmxFs', created_at=1701240131, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-MdSScMkbTK60fqqIP4cio0Kx', result_files=[], status='validating_files', trained_tokens=None, training_file='file-xx0weewZiEHzMkn6et2LfLxf', validation_file='file-UBG4DDfaxNvmBmik74DXQHv8')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "suffix_name = this_nb\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    validation_file=validation_file.id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "response\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
