{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Metrics and Conduct Inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import simpledorff\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Combined_Data.xlsx\n",
    "combined_data = pd.read_excel('Combined_Data.xlsx')\n",
    "\n",
    "# GSM8k data - limit to task = \"gsm8k\"\n",
    "gsm8k_data = combined_data[combined_data['task'] == 'gsm8k']\n",
    "\n",
    "# Creative writing data - limit to task = \"cw\"\n",
    "cw_data = combined_data[combined_data['task'] == 'cw']\n",
    "\n",
    "# Load direct_prompting_comparison.xlsx\n",
    "direct_prompting_comparison = pd.read_excel('direct_prompting_comparison.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A closer look at creative writing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coherence_1_incoherent_10_very_coherent  Prediction_Based_On_First_10  \\\n",
      "count                              1600.000000                   1440.000000   \n",
      "mean                                  4.974375                      5.403472   \n",
      "std                                   2.612563                      2.175833   \n",
      "min                                   1.000000                      1.000000   \n",
      "25%                                   3.000000                      3.000000   \n",
      "50%                                   5.000000                      7.000000   \n",
      "75%                                   7.000000                      7.000000   \n",
      "max                                  10.000000                      8.000000   \n",
      "\n",
      "       Prediction_Based_On_Last_10  Aggegated_Prediction  \n",
      "count                  1440.000000           1600.000000  \n",
      "mean                      4.066667              4.722500  \n",
      "std                       2.569885              2.265422  \n",
      "min                       1.000000              1.000000  \n",
      "25%                       2.000000              3.000000  \n",
      "50%                       3.000000              4.500000  \n",
      "75%                       7.000000              7.000000  \n",
      "max                       8.000000              8.000000  \n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for variables: coherence_1_incoherent_10_very_coherent, Prediction_Based_On_First_10, Prediction_Based_On_Last_10, Aggegated_Prediction\n",
    "print(cw_data[['coherence_1_incoherent_10_very_coherent', 'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10', 'Aggegated_Prediction']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=1600, minmax=(-7.0, 8.0), mean=0.251875, variance=5.838020247029392, skewness=-0.006411691981771768, kurtosis=0.18078123260822876)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  23.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  36.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  22.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  63.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  34.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  99.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  44.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 184.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,  76.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 221.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 101.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 190.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,  64.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0., 119.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,  45.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,  82.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,  25.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,  48.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,  15.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  49.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   9.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([-7.   , -6.985, -6.97 , ...,  7.97 ,  7.985,  8.   ]),\n",
       " <BarContainer object of 1000 artists>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Differences between coherence_1_incoherent_10_very_coherent and Aggregated_Prediction\n",
    "print(stats.describe(cw_data['coherence_1_incoherent_10_very_coherent'] - cw_data['Aggegated_Prediction']))\n",
    "\n",
    "# Histogram\n",
    "plt.hist(cw_data['coherence_1_incoherent_10_very_coherent'] - cw_data['Aggegated_Prediction'], bins = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_task_method', 'conversation_number',\n",
      "       'coherence_1_incoherent_10_very_coherent',\n",
      "       'task_constraints_followed_0_not_followed_1_followed',\n",
      "       'ease_of_review_1_easy_10_hard', 'correct',\n",
      "       'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10',\n",
      "       'Aggegated_Prediction', 'conversation_length', 'input_length',\n",
      "       'output_length', 'conversation_cost', 'gsm8k_question_index',\n",
      "       'gsm8k_answer', 'gsm8k_length_vs_provided',\n",
      "       'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences',\n",
      "       'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres',\n",
      "       'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts',\n",
      "       'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts',\n",
      "       'num_linebreaks_provided', 'num_sentences_provided',\n",
      "       'num_step_i_provided', 'num_1_dot_etc_provided', 'compliance',\n",
      "       'coherence_1_incoherent_10_very_coherent_compliance_adjusted', 'model',\n",
      "       'task', 'method', 'accuracy_quality',\n",
      "       'accuracy_quality_compliance_adjusted'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cw_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall KA\n",
      "0.10686929311619198\n",
      "no first 10 KA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3888\\1729583903.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cw_data['model_task_method_conversation_id'] = cw_data['model'] + '_' + cw_data['task'] + '_' + cw_data['method'] + '_' + cw_data['conversation_number'].astype(str)\n",
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3888\\1729583903.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cw_data['Human'] = cw_data['coherence_1_incoherent_10_very_coherent']\n",
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3888\\1729583903.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cw_data['GPT-3.5 - First 10'] = cw_data['Prediction_Based_On_First_10']\n",
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3888\\1729583903.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cw_data['GPT-3.5 - Last 10'] = cw_data['Prediction_Based_On_Last_10']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10782815485733388\n",
      "no last 10 KA\n",
      "0.11024510661584563\n",
      "no first and last 10 KA\n",
      "0.11158211702182685\n"
     ]
    }
   ],
   "source": [
    "# Krippendorff's alpha\n",
    "# I am using the simpledorff package\n",
    "# experiment_col should be the conversation (row of the dataframe) - create model_task_method_conversation_id\n",
    "# annotator_col should be 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'\n",
    "# class col should be the score from coherence_1_incoherent_10_very_coherent, Prediction_Based_On_First_10, Prediction_Based_On_Last_10\n",
    "\n",
    "# Manipulate and reshape dataframe\n",
    "cw_data['model_task_method_conversation_id'] = cw_data['model'] + '_' + cw_data['task'] + '_' + cw_data['method'] + '_' + cw_data['conversation_number'].astype(str)\n",
    "cw_data['Human'] = cw_data['coherence_1_incoherent_10_very_coherent']\n",
    "cw_data['GPT-3.5 - First 10'] = cw_data['Prediction_Based_On_First_10']\n",
    "cw_data['GPT-3.5 - Last 10'] = cw_data['Prediction_Based_On_Last_10']\n",
    "ka_data = cw_data[['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_melted = ka_data.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_melted = ka_data_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print('overall KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n",
    "\n",
    "# Version excluding first 10\n",
    "ka_data_no_first_10 = cw_data[cw_data['conversation_number'] > 10][['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_no_first_10_melted = ka_data_no_first_10.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_no_first_10_melted = ka_data_no_first_10_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('no first 10 KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_no_first_10_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n",
    "\n",
    "# Version excluding last 10\n",
    "ka_data_no_last_10 = cw_data[cw_data['conversation_number'] <= 90][['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_no_last_10_melted = ka_data_no_last_10.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_no_last_10_melted = ka_data_no_last_10_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('no last 10 KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_no_last_10_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n",
    "\n",
    "# Version excluding first and last 10\n",
    "ka_data_no_first_last_10 = cw_data[(cw_data['conversation_number'] > 10) & (cw_data['conversation_number'] <= 90)][['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_no_first_last_10_melted = ka_data_no_first_last_10.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_no_first_last_10_melted = ka_data_no_first_last_10_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('no first and last 10 KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_no_first_last_10_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregated predictions KA\n",
      "0.04803932294886726\n"
     ]
    }
   ],
   "source": [
    "# Try aggregated predictions\n",
    "ka_data_agg = cw_data[['model_task_method_conversation_id', 'Human', 'Aggegated_Prediction']]\n",
    "ka_data_agg_melted = ka_data_agg.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'Aggegated_Prediction'])\n",
    "ka_data_agg_melted = ka_data_agg_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('aggregated predictions KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_agg_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18525258256529475\n"
     ]
    }
   ],
   "source": [
    "# Try to demand less of the data - in ka_data_melted, bin 1-10 into 1-5\n",
    "# Divide by 2 and take the ceiling\n",
    "ka_data_melted['coherence_1_to_5'] = ka_data_melted.dropna()['coherence_score'].apply(lambda x: math.ceil(x/2))\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                       experiment_col='model_task_method_conversation_id',\n",
    "                                                       annotator_col='grader',\n",
    "                                                       class_col='coherence_1_to_5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2735720914000721\n"
     ]
    }
   ],
   "source": [
    "# Try coherence on a scale of 1 to 3\n",
    "ka_data_melted['coherence_1_to_3'] = ka_data_melted.dropna()['coherence_score'].apply(lambda x: math.ceil(x/3.33))\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                       experiment_col='model_task_method_conversation_id',\n",
    "                                                       annotator_col='grader',\n",
    "                                                       class_col='coherence_1_to_3'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4195238892015637\n"
     ]
    }
   ],
   "source": [
    "# Try coherence vs incoherence binary\n",
    "ka_data_melted['coherence_binary'] = ka_data_melted.dropna()['coherence_score'].apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                       experiment_col='model_task_method_conversation_id',\n",
    "                                                       annotator_col='grader',\n",
    "                                                       class_col='coherence_binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over cases where task = \"cw\" and output histograms of accuracy quality by model and method\n",
    "# Loop over models\n",
    "for model in cw_data['model'].unique():\n",
    "    # Loop over methods\n",
    "    for method in cw_data['method'].unique():\n",
    "        # Get data for this model and method\n",
    "        data = cw_data[(cw_data['model'] == model) & (cw_data['method'] == method)]\n",
    "        # Plot histogram\n",
    "        plt.hist(data['coherence_1_incoherent_10_very_coherent'], bins = 10)\n",
    "        # Ticks for values of 1, 2, ... 10\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.title(model + ' - ' + method)\n",
    "        plt.xlabel('Accuracy Quality')\n",
    "        plt.ylabel('Count')\n",
    "        # Save histogram\n",
    "        plt.savefig('../Output/cw_acc_qual_' + model + '_' + method + '.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy/Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>accuracy_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.210505</td>\n",
       "      <td>5.46 (6.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.065758</td>\n",
       "      <td>0.93 (0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>cw</td>\n",
       "      <td>5.71</td>\n",
       "      <td>7.298889</td>\n",
       "      <td>5.71 (7.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.199091</td>\n",
       "      <td>0.73 (0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>cw</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.907475</td>\n",
       "      <td>5.54 (5.91)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.95 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.33</td>\n",
       "      <td>5.193030</td>\n",
       "      <td>6.33 (5.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.065758</td>\n",
       "      <td>0.93 (0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.220101</td>\n",
       "      <td>6.11 (6.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.252424</td>\n",
       "      <td>0.49 (0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.04</td>\n",
       "      <td>7.412525</td>\n",
       "      <td>6.04 (7.41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.89 (0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5.012525</td>\n",
       "      <td>4.76 (5.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.4 (0.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.511010</td>\n",
       "      <td>6.29 (6.51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.95 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>3.9 (5.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.252424</td>\n",
       "      <td>0.49 (0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>td3</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.46</td>\n",
       "      <td>7.786263</td>\n",
       "      <td>4.46 (7.79)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>td3</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.178889</td>\n",
       "      <td>0.23 (0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.280303</td>\n",
       "      <td>4.45 (5.28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.950606</td>\n",
       "      <td>0.67 (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.889293</td>\n",
       "      <td>4.14 (4.89)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.6 (0.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.97</td>\n",
       "      <td>6.211212</td>\n",
       "      <td>4.97 (6.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.149091</td>\n",
       "      <td>0.18 (0.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.343434</td>\n",
       "      <td>4.2 (6.34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.2 (0.16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>cw</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4.114242</td>\n",
       "      <td>3.37 (4.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.178889</td>\n",
       "      <td>0.23 (0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>3.86</td>\n",
       "      <td>6.404444</td>\n",
       "      <td>3.86 (6.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.237980</td>\n",
       "      <td>0.62 (0.24)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model             method   task  mean       var accuracy_quality\n",
       "0   gpt4  ape_zero_shot_cot     cw  5.46  6.210505      5.46 (6.21)\n",
       "1   gpt4  ape_zero_shot_cot  gsm8k  0.93  0.065758      0.93 (0.07)\n",
       "2   gpt4   direct_prompting     cw  5.71  7.298889       5.71 (7.3)\n",
       "3   gpt4   direct_prompting  gsm8k  0.73  0.199091       0.73 (0.2)\n",
       "4   gpt4      least_to_most     cw  5.54  5.907475      5.54 (5.91)\n",
       "5   gpt4      least_to_most  gsm8k  0.95  0.047980      0.95 (0.05)\n",
       "6   gpt4         manual_cot     cw  6.33  5.193030      6.33 (5.19)\n",
       "7   gpt4         manual_cot  gsm8k  0.93  0.065758      0.93 (0.07)\n",
       "8   gpt4    manual_few_shot     cw  6.11  6.220101      6.11 (6.22)\n",
       "9   gpt4    manual_few_shot  gsm8k  0.49  0.252424      0.49 (0.25)\n",
       "10  gpt4        self_refine     cw  6.04  7.412525      6.04 (7.41)\n",
       "11  gpt4        self_refine  gsm8k  0.89  0.098889       0.89 (0.1)\n",
       "12  gpt4    tree_of_thought     cw  4.76  5.012525      4.76 (5.01)\n",
       "13  gpt4    tree_of_thought  gsm8k  0.40  0.242424       0.4 (0.24)\n",
       "14  gpt4      zero_shot_cot     cw  6.29  6.511010      6.29 (6.51)\n",
       "15  gpt4      zero_shot_cot  gsm8k  0.95  0.047980      0.95 (0.05)\n",
       "16   td3  ape_zero_shot_cot     cw  3.90  5.363636       3.9 (5.36)\n",
       "17   td3  ape_zero_shot_cot  gsm8k  0.49  0.252424      0.49 (0.25)\n",
       "18   td3   direct_prompting     cw  4.46  7.786263      4.46 (7.79)\n",
       "19   td3   direct_prompting  gsm8k  0.23  0.178889      0.23 (0.18)\n",
       "20   td3      least_to_most     cw  4.45  5.280303      4.45 (5.28)\n",
       "21   td3      least_to_most  gsm8k  0.67  0.950606      0.67 (0.95)\n",
       "22   td3         manual_cot     cw  4.14  4.889293      4.14 (4.89)\n",
       "23   td3         manual_cot  gsm8k  0.60  0.242424       0.6 (0.24)\n",
       "24   td3    manual_few_shot     cw  4.97  6.211212      4.97 (6.21)\n",
       "25   td3    manual_few_shot  gsm8k  0.18  0.149091      0.18 (0.15)\n",
       "26   td3        self_refine     cw  4.20  6.343434       4.2 (6.34)\n",
       "27   td3        self_refine  gsm8k  0.20  0.161616       0.2 (0.16)\n",
       "28   td3    tree_of_thought     cw  3.37  4.114242      3.37 (4.11)\n",
       "29   td3    tree_of_thought  gsm8k  0.23  0.178889      0.23 (0.18)\n",
       "30   td3      zero_shot_cot     cw  3.86  6.404444       3.86 (6.4)\n",
       "31   td3      zero_shot_cot  gsm8k  0.62  0.237980      0.62 (0.24)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average accuracy_quality by model, method, task\n",
    "# Also get variance\n",
    "avg_accuracy_quality_with_variance = combined_data[['model', 'method', 'task', 'accuracy_quality']].groupby(['model', 'method', 'task']).agg(['mean', 'var'])['accuracy_quality'].reset_index()\n",
    "\n",
    "# Combine mean and variance into one column that is a string with the mean and then the variance in parentheses\n",
    "avg_accuracy_quality_with_variance['accuracy_quality'] = avg_accuracy_quality_with_variance.apply(lambda row: str(round(row['mean'], 2)) + ' (' + str(round(row['var'], 2)) + ')', axis=1)\n",
    "\n",
    "avg_accuracy_quality_with_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(           'model',                  ''),\n",
      "            (            'task',                  ''),\n",
      "            ('accuracy_quality', 'ape_zero_shot_cot'),\n",
      "            ('accuracy_quality',  'direct_prompting'),\n",
      "            ('accuracy_quality',     'least_to_most'),\n",
      "            ('accuracy_quality',        'manual_cot'),\n",
      "            ('accuracy_quality',   'manual_few_shot'),\n",
      "            ('accuracy_quality',       'self_refine'),\n",
      "            ('accuracy_quality',   'tree_of_thought'),\n",
      "            ('accuracy_quality',     'zero_shot_cot')],\n",
      "           )\n",
      "  model   task ape_zero_shot_cot direct_prompting least_to_most   manual_cot  \\\n",
      "0  gpt4     cw       5.46 (6.21)       5.71 (7.3)   5.54 (5.91)  6.33 (5.19)   \n",
      "1   td3     cw        3.9 (5.36)      4.46 (7.79)   4.45 (5.28)  4.14 (4.89)   \n",
      "2  gpt4  gsm8k       0.93 (0.07)       0.73 (0.2)   0.95 (0.05)  0.93 (0.07)   \n",
      "3   td3  gsm8k       0.49 (0.25)      0.23 (0.18)   0.67 (0.95)   0.6 (0.24)   \n",
      "\n",
      "  manual_few_shot  self_refine tree_of_thought zero_shot_cot  \n",
      "0     6.11 (6.22)  6.04 (7.41)     4.76 (5.01)   6.29 (6.51)  \n",
      "1     4.97 (6.21)   4.2 (6.34)     3.37 (4.11)    3.86 (6.4)  \n",
      "2     0.49 (0.25)   0.89 (0.1)      0.4 (0.24)   0.95 (0.05)  \n",
      "3     0.18 (0.15)   0.2 (0.16)     0.23 (0.18)   0.62 (0.24)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3888\\280831353.py:10: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  avg_accuracy_quality_pivot = avg_accuracy_quality_pivot.sort_values(by=['task', 'model'], ascending=[True, True]).reset_index().drop(columns=['index'])\n"
     ]
    }
   ],
   "source": [
    "# Pivot table - column method should go wide\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_with_variance.drop(columns=['mean', 'var']).set_index(['model', 'task', 'method']).unstack()\n",
    "#pivot_table(index=['model', 'task'], columns='method', values='accuracy_quality').reset_index()\n",
    "\n",
    "# Fix axis\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_pivot.rename_axis([None, None], axis=1).reset_index()\n",
    "\n",
    "# Sort rows by task - gsm8k task first, then cw\n",
    "# Sort by model - text-davinci-003 first, then gpt4\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_pivot.sort_values(by=['task', 'model'], ascending=[True, True]).reset_index().drop(columns=['index'])\n",
    "\n",
    "print(avg_accuracy_quality_pivot.columns)\n",
    "\n",
    "flattened_cols = [''.join(col).strip().replace('accuracy_quality', '') for col in avg_accuracy_quality_pivot.columns.values]\n",
    "avg_accuracy_quality_pivot.columns = flattened_cols\n",
    "\n",
    "print(avg_accuracy_quality_pivot)\n",
    "\n",
    "# Order columns: direct_prompting, zero_shot_cot, ape_zero_shot_cot, tree_of_thought, self_refine, least_to_most, manual_few_shot, manual_cot\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_pivot[['model', 'task', 'direct_prompting', 'zero_shot_cot', 'ape_zero_shot_cot', 'tree_of_thought', 'self_refine', 'least_to_most', 'manual_few_shot', 'manual_cot']]\n",
    "\n",
    "# Output to LaTeX\n",
    "avg_accuracy_quality_pivot.to_latex('../Output/avg_accuracy_quality_pivot.tex', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding release date to accuracy quality table (optional version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      technique_name ss_publication_date   Prompt Engineering Method\n",
      "0  ape_zero_shot_cot          2022-11-03   Automatic Prompt Engineer\n",
      "1      least_to_most          2022-05-21     Least-to-Most Prompting\n",
      "2         manual_cot          2022-01-28  Chain-of-Thought Prompting\n",
      "3    manual_few_shot          2020-05-28           Few-Shot Learning\n",
      "4        self_refine          2023-03-30                 Self-Refine\n",
      "5    tree_of_thought          2023-05-15             Tree-of-Thought\n",
      "6      zero_shot_cot          2022-05-24  Zero-Shot Chain-of-Thought\n",
      "Index(['index', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='object')\n",
      "                       index      0      1                 2  \\\n",
      "0             technique_name  model   task  direct_prompting   \n",
      "1                          0   gpt4     cw        5.71 (7.3)   \n",
      "2                          1    td3     cw       4.46 (7.79)   \n",
      "3                          2   gpt4  gsm8k        0.73 (0.2)   \n",
      "4                          3    td3  gsm8k       0.23 (0.18)   \n",
      "5        ss_publication_date    NaN    NaN               NaN   \n",
      "6  Prompt Engineering Method    NaN    NaN               NaN   \n",
      "\n",
      "                            3                          4                5  \\\n",
      "0               zero_shot_cot          ape_zero_shot_cot  tree_of_thought   \n",
      "1                 6.29 (6.51)                5.46 (6.21)      4.76 (5.01)   \n",
      "2                  3.86 (6.4)                 3.9 (5.36)      3.37 (4.11)   \n",
      "3                 0.95 (0.05)                0.93 (0.07)       0.4 (0.24)   \n",
      "4                 0.62 (0.24)                0.49 (0.25)      0.23 (0.18)   \n",
      "5                  2022-05-24                 2022-11-03       2023-05-15   \n",
      "6  Zero-Shot Chain-of-Thought  Automatic Prompt Engineer  Tree-of-Thought   \n",
      "\n",
      "             6                        7                  8  \\\n",
      "0  self_refine            least_to_most    manual_few_shot   \n",
      "1  6.04 (7.41)              5.54 (5.91)        6.11 (6.22)   \n",
      "2   4.2 (6.34)              4.45 (5.28)        4.97 (6.21)   \n",
      "3   0.89 (0.1)              0.95 (0.05)        0.49 (0.25)   \n",
      "4   0.2 (0.16)              0.67 (0.95)        0.18 (0.15)   \n",
      "5   2023-03-30               2022-05-21         2020-05-28   \n",
      "6  Self-Refine  Least-to-Most Prompting  Few-Shot Learning   \n",
      "\n",
      "                            9  \n",
      "0                  manual_cot  \n",
      "1                 6.33 (5.19)  \n",
      "2                 4.14 (4.89)  \n",
      "3                 0.93 (0.07)  \n",
      "4                  0.6 (0.24)  \n",
      "5                  2022-01-28  \n",
      "6  Chain-of-Thought Prompting  \n"
     ]
    }
   ],
   "source": [
    "# Release date and gains versus direct prompting\n",
    "\n",
    "# Load Excel file \"..\\Selection of Prompt Engineering Methods\\Hand-Labeled Method and Implementation Considerations.xlsx\"\n",
    "hand_labeled_data = pd.read_excel('..\\Selection of Prompt Engineering Methods\\Hand-Labeled Method and Implementation Considerations.xlsx')\n",
    "\n",
    "# Keep columns ss_publication_date, \"Prompt Engineering Method\"\n",
    "hand_labeled_data = hand_labeled_data[['ss_publication_date', 'Prompt Engineering Method']]\n",
    "\n",
    "# Mapping names from this data to technqiue names\n",
    "# \"Few-Shot Learing\" -> \"manual_few_shot\"\n",
    "# \"Chain-of-Thought Prompting\" -> \"manual_cot\"\n",
    "# \"Zero-Shot Chain-of_Thought\" -> \"zero_shot_cot\"\n",
    "# \"Automatic Prompt Engineer\" -> \"ape_zero_shot_cot\"\n",
    "# \"Self-Refine\" -> \"self_refine\"\n",
    "# \"Least-to-Most Prompting\" -> \"least_to_most\"\n",
    "# \"Tree-of-Thought\" -> \"tree_of_thought\"\n",
    "# Set names in hand_labeled_data to these names\n",
    "hand_labeled_data['technique_name'] = hand_labeled_data['Prompt Engineering Method'].replace({'Few-Shot Learning': 'manual_few_shot', 'Chain-of-Thought Prompting': 'manual_cot', 'Zero-Shot Chain-of-Thought': 'zero_shot_cot', 'Automatic Prompt Engineer': 'ape_zero_shot_cot', 'Self-Refine': 'self_refine', 'Least-to-Most Prompting': 'least_to_most', 'Tree-of-Thought': 'tree_of_thought'})\n",
    "\n",
    "# Keep cases where technique_name is not 'Prompt Engineering Method'\n",
    "hand_labeled_data = hand_labeled_data[hand_labeled_data['technique_name'] != hand_labeled_data['Prompt Engineering Method']]\n",
    "\n",
    "# Convert ss_publication_date to \"YYYY-MM-DD\"\n",
    "hand_labeled_data['ss_publication_date'] = hand_labeled_data['ss_publication_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Drop the item with technique_name = 'tree_of_thought' that has the higher ss_publication_date\n",
    "# Just keep the row with min ss_publication_date for each technique_name\n",
    "hand_labeled_data = hand_labeled_data.groupby(['technique_name']).min().reset_index()\n",
    "print(hand_labeled_data)\n",
    "\n",
    "# Add ss_publication_date to avg_accuracy_quality_pivot\n",
    "# The value should be for each column, right below the column name\n",
    "# Transpose accuracy_quality_pivot\n",
    "avg_accuracy_quality_pivot_transposed = avg_accuracy_quality_pivot.transpose().reset_index()\n",
    "\n",
    "# Set name of first column to \"technique_name\"\n",
    "avg_accuracy_quality_pivot_transposed = avg_accuracy_quality_pivot_transposed.rename(columns={'index': 'technique_name'})\n",
    "\n",
    "# Left join hand_labeled_data to avg_accuracy_quality_pivot_transposed on technique_name\n",
    "avg_accuracy_quality_pivot_transposed = avg_accuracy_quality_pivot_transposed.merge(hand_labeled_data, on='technique_name', how='left')\n",
    "\n",
    "# Transpose back\n",
    "avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_transposed.transpose().reset_index()\n",
    "\n",
    "# # Set names to last row\n",
    "# avg_accuracy_quality_pivot_with_date.columns = avg_accuracy_quality_pivot_with_date.iloc[-1]\n",
    "# # Drop first row, reset index\n",
    "# avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date.drop([0]).reset_index().drop(columns=['index'])\n",
    "# # Drop row where technique_name is \"Prompt Engineering Method\"\n",
    "# #avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date[avg_accuracy_quality_pivot_with_date['technique_name'] != 'Prompt Engineering Method']\n",
    "# # In first column, set values of \"0\", \"1\", \"2\", \"3\" to blanks\n",
    "# #avg_accuracy_quality_pivot_with_date['technique_name'] = avg_accuracy_quality_pivot_with_date['technique_name'].replace({'0': '', '1': '', '2': '', '3': ''})\n",
    "# # Drop column tecnique_name\n",
    "# #avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date.drop(columns=['technique_name'])\n",
    "# # Drop first column\n",
    "# avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date.iloc[:, 1:]\n",
    "# # Set second column name to \"Model\"\n",
    "# avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date.rename(index={1: 'Model'})\n",
    "# # Set third column name to \"Task\"\n",
    "# avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date.rename(index={2: 'Task'})\n",
    "# avg_accuracy_quality_pivot_with_date.rename(columns={avg_accuracy_quality_pivot_with_date.columns[0]: 'Model'}, inplace=True)\n",
    "# avg_accuracy_quality_pivot_with_date.rename(columns={avg_accuracy_quality_pivot_with_date.columns[1]: 'Task'}, inplace=True)\n",
    "# Drop bottom row\n",
    "#avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_with_date.drop([avg_accuracy_quality_pivot_with_date.index[-1]])\n",
    "# Move bottom row to top\n",
    "#avg_accuracy_quality_pivot_with_date = pd.concat([avg_accuracy_quality_pivot_with_date.iloc[[-1]], avg_accuracy_quality_pivot_with_date.iloc[:-1]]).reset_index().drop(columns=['index'])\n",
    "# Set column names\n",
    "#new_part = ['Model', 'Task', 'Direct Prompting']\n",
    "#new_names = new_part.extend(avg_accuracy_quality_pivot_with_date.columns[3:])\n",
    "#avg_accuracy_quality_pivot_with_date.columns = new_names\n",
    "# avg_accuracy_quality_pivot_with_date.columns = ['Model', 'Task', 'Zero-Shot Chain-of-Thought', 'Automatic Prompt Engineer', 'Tree-of-Thought',                'Self-Refine',\n",
    "#           'Least-to-Most Prompting',          'Few-Shot Learning',\n",
    "#        'Chain-of-Thought Prompting']\n",
    "print(avg_accuracy_quality_pivot_with_date.columns)\n",
    "\n",
    "# Output to LaTeX\n",
    "print(avg_accuracy_quality_pivot_with_date)\n",
    "avg_accuracy_quality_pivot_with_date.to_latex('../Output/avg_accuracy_quality_pivot_with_date.tex', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
