{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interannotator Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import simpledorff\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Combined_Data.xlsx\n",
    "combined_data = pd.read_excel('Combined_Data.xlsx')\n",
    "\n",
    "# GSM8k data - limit to task = \"gsm8k\"\n",
    "gsm8k_data = combined_data[combined_data['task'] == 'gsm8k']\n",
    "\n",
    "# Creative writing data - limit to task = \"cw\"\n",
    "cw_data = combined_data[combined_data['task'] == 'cw']\n",
    "\n",
    "# Load direct_prompting_comparison.xlsx\n",
    "direct_prompting_comparison = pd.read_excel('direct_prompting_comparison.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A closer look at creative writing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Aggregated_Prediction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ijyli\\repo\\anlp23-project\\Data\\03d Interannotator Agreement.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/03d%20Interannotator%20Agreement.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Summary statistics for variables: coherence_1_incoherent_10_very_coherent, Prediction_Based_On_First_10, Prediction_Based_On_Last_10, Aggregated_Prediction\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/03d%20Interannotator%20Agreement.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(cw_data[[\u001b[39m'\u001b[39m\u001b[39mcoherence_1_incoherent_10_very_coherent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrediction_Based_On_First_10\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrediction_Based_On_Last_10\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAggregated_Prediction\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mdescribe())\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Aggregated_Prediction'] not in index\""
     ]
    }
   ],
   "source": [
    "# Summary statistics for variables: coherence_1_incoherent_10_very_coherent, Prediction_Based_On_First_10, Prediction_Based_On_Last_10, Aggregated_Prediction\n",
    "print(cw_data[['coherence_1_incoherent_10_very_coherent', 'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10', 'Aggregated_Prediction']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences between coherence_1_incoherent_10_very_coherent and Aggregated_Prediction\n",
    "print(stats.describe(cw_data['coherence_1_incoherent_10_very_coherent'] - cw_data['Aggregated_Prediction']))\n",
    "\n",
    "# Histogram\n",
    "plt.hist(cw_data['coherence_1_incoherent_10_very_coherent'] - cw_data['Aggregated_Prediction'], bins = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cw_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krippendorff's alpha\n",
    "# I am using the simpledorff package\n",
    "# experiment_col should be the conversation (row of the dataframe) - create model_task_method_conversation_id\n",
    "# annotator_col should be 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'\n",
    "# class col should be the score from coherence_1_incoherent_10_very_coherent, Prediction_Based_On_First_10, Prediction_Based_On_Last_10\n",
    "\n",
    "# Manipulate and reshape dataframe\n",
    "cw_data['model_task_method_conversation_id'] = cw_data['model'] + '_' + cw_data['task'] + '_' + cw_data['method'] + '_' + cw_data['conversation_number'].astype(str)\n",
    "cw_data['Human'] = cw_data['coherence_1_incoherent_10_very_coherent']\n",
    "cw_data['GPT-3.5 - First 10'] = cw_data['Prediction_Based_On_First_10']\n",
    "cw_data['GPT-3.5 - Last 10'] = cw_data['Prediction_Based_On_Last_10']\n",
    "ka_data = cw_data[['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_melted = ka_data.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_melted = ka_data_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print('overall KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n",
    "\n",
    "# Version excluding first 10\n",
    "ka_data_no_first_10 = cw_data[cw_data['conversation_number'] > 10][['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_no_first_10_melted = ka_data_no_first_10.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_no_first_10_melted = ka_data_no_first_10_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('no first 10 KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_no_first_10_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n",
    "\n",
    "# Version excluding last 10\n",
    "ka_data_no_last_10 = cw_data[cw_data['conversation_number'] <= 90][['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_no_last_10_melted = ka_data_no_last_10.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_no_last_10_melted = ka_data_no_last_10_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('no last 10 KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_no_last_10_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n",
    "\n",
    "# Version excluding first and last 10\n",
    "ka_data_no_first_last_10 = cw_data[(cw_data['conversation_number'] > 10) & (cw_data['conversation_number'] <= 90)][['model_task_method_conversation_id', 'Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10']]\n",
    "ka_data_no_first_last_10_melted = ka_data_no_first_last_10.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'GPT-3.5 - First 10', 'GPT-3.5 - Last 10'])\n",
    "ka_data_no_first_last_10_melted = ka_data_no_first_last_10_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('no first and last 10 KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_no_first_last_10_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try aggregated predictions\n",
    "ka_data_agg = cw_data[['model_task_method_conversation_id', 'Human', 'Aggregated_Prediction']]\n",
    "ka_data_agg_melted = ka_data_agg.melt(id_vars=['model_task_method_conversation_id'], value_vars=['Human', 'Aggregated_Prediction'])\n",
    "ka_data_agg_melted = ka_data_agg_melted.rename(columns={'variable': 'grader', 'value': 'coherence_score'})\n",
    "print('aggregated predictions KA')\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_agg_melted,\n",
    "                                                 experiment_col='model_task_method_conversation_id',\n",
    "                                                 annotator_col='grader',\n",
    "                                                 class_col='coherence_score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to demand less of the data - in ka_data_melted, bin 1-10 into 1-5\n",
    "# Divide by 2 and take the ceiling\n",
    "ka_data_melted['coherence_1_to_5'] = ka_data_melted.dropna()['coherence_score'].apply(lambda x: math.ceil(x/2))\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                       experiment_col='model_task_method_conversation_id',\n",
    "                                                       annotator_col='grader',\n",
    "                                                       class_col='coherence_1_to_5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try coherence on a scale of 1 to 3\n",
    "ka_data_melted['coherence_1_to_3'] = ka_data_melted.dropna()['coherence_score'].apply(lambda x: math.ceil(x/3.33))\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                       experiment_col='model_task_method_conversation_id',\n",
    "                                                       annotator_col='grader',\n",
    "                                                       class_col='coherence_1_to_3'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try coherence vs incoherence binary\n",
    "ka_data_melted['coherence_binary'] = ka_data_melted.dropna()['coherence_score'].apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "print(simpledorff.calculate_krippendorffs_alpha_for_df(ka_data_melted,\n",
    "                                                       experiment_col='model_task_method_conversation_id',\n",
    "                                                       annotator_col='grader',\n",
    "                                                       class_col='coherence_binary'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
