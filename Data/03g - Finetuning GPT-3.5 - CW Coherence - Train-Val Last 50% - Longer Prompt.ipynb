{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning GPT-3.5 - CW Coherence.ipynb\n",
        "\n",
        "Sources: https://blog.futuresmart.ai/fine-tuning-gpt-35-a-step-by-step-guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Whether this notebook is first 50% or last 50%\n",
        "this_nb = 'last_50_LP'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_task_method</th>\n",
              "      <th>conversation_number</th>\n",
              "      <th>response</th>\n",
              "      <th>coherence_1_incoherent_10_very_coherent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>1</td>\n",
              "      <td>Learning to do a handstand is a fun activity f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>2</td>\n",
              "      <td>The hawk was used to hunting what he needed fo...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>3</td>\n",
              "      <td>I love the smell of roasting almonds in the ki...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>4</td>\n",
              "      <td>Ralph's bedroom was routinely filled up with s...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>5</td>\n",
              "      <td>Joe had a unique way of dealing with the hospi...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   model_task_method  conversation_number  \\\n",
              "0  td3_cw_direct_prompting_responses                    1   \n",
              "1  td3_cw_direct_prompting_responses                    2   \n",
              "2  td3_cw_direct_prompting_responses                    3   \n",
              "3  td3_cw_direct_prompting_responses                    4   \n",
              "4  td3_cw_direct_prompting_responses                    5   \n",
              "\n",
              "                                            response  \\\n",
              "0  Learning to do a handstand is a fun activity f...   \n",
              "1  The hawk was used to hunting what he needed fo...   \n",
              "2  I love the smell of roasting almonds in the ki...   \n",
              "3  Ralph's bedroom was routinely filled up with s...   \n",
              "4  Joe had a unique way of dealing with the hospi...   \n",
              "\n",
              "   coherence_1_incoherent_10_very_coherent  \n",
              "0                                        1  \n",
              "1                                        7  \n",
              "2                                        1  \n",
              "3                                       10  \n",
              "4                                        4  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "full_human_data = pd.read_csv(\"full_human_data.csv\")\n",
        "full_human_data.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This notebook: train and validate on first 50% of observations for each method\n",
        "# Get predictions on second 50% of observations for each method\n",
        "# Keep first 50% of observations for each model_task_method in dataset\n",
        "# Split on conversation_number LTE 50 and not\n",
        "if this_nb == 'first_50_LP':\n",
        "    this_notebook_train_validate = full_human_data[full_human_data['conversation_number'] <= 50]\n",
        "    this_notebook_predictions = full_human_data[full_human_data['conversation_number'] > 50]\n",
        "else:\n",
        "    this_notebook_train_validate = full_human_data[full_human_data['conversation_number'] > 50]\n",
        "    this_notebook_predictions = full_human_data[full_human_data['conversation_number'] <= 50]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save this notebook's predictions\n",
        "this_notebook_predictions.to_csv('items_to_predict_using_' + this_nb + '.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "He had never been to space before, but the smell of seared steak hit his nose like a wave of familiarity. It caught him off guard that space smelled of seared steak. Little did he know there was a small cafe on board the spaceship that served steak sandwiches.\n",
            "He scrambled, his eyes drawn to the largest creature he had ever seen on board the spaceship. It was terrifyingly long yet gentle. The Great Dane looked more like a horse than a dog. It walked slowly but with an authoritative air. Its snorting echoed in the cabin.\n",
            "\n",
            "John had been procrastinating his research paper for weeks. He knew it had to be turned in soon since it was due on Friday. He feared the consequences of submitting the paper late, and so he dedicated every waking moment to putting the finishing touches on the assignment. He worked tirelessly every day in order to meet the looming deadline. He turned in the research paper on Friday; otherwise, he would have not passed the class.\n",
            "When John and his friends wanted to have some harmless fun, they often found themselves looking for creative ways to play without a large budget. One of their favorite activities was an epic water balloon fight, but what do you do when you don't have any balloons? You pull out your tomatoes instead! Tomatoes make great weapons when water balloons aren't available.\n",
            "\n",
            "Billy had never thought much about his nighttime movements before. He'd wake up the next day with no recollection of the previous night's events. Going through his morning routine, he'd eventually find himself in a different place than normal, with no explanation for how he got there. He had unknowingly taken up sleepwalking as a nighttime hobby.\n",
            "Billy's sleepwalking escapades had recently taken a new turn. Instead of winding up in strange places, he found himself dreaming about having the freedom to leave behind his chaotic life as a lawyer and opening a portable dog wash. He dreamed of leaving his law firm to open a portable dog wash.\n",
            "\n",
            "Ever since I got my pet snake, I've been worried about what he is thinking. He doesn't seem to have any interest in the food I give him and I'm not even sure if he can understand me when I talk to him. He's in a boy band which doesn't make much sense for a snake.\n",
            "Recently, I've started to wonder if my pet turtle can read my mind. He always seems to know when I'm feeling sad or upset and he always comforts me. I was starting to worry that my pet turtle could tell what I was thinking.\n",
            "\n",
            "A glittering gem is not enough for one to make a lasting impression. Although glitz and glamour may attract people's attention, genuine relationships come from being able to relate to someone on a deeper level. A meaningful exchange of conversation and connection between two people is more valuable than a jewel any day.\n",
            "The green tea and avocado smoothie turned out exactly as would be expected. Although it may have looked strange to some, the combination of flavors was refreshing and unique. It was a pleasure to enjoy and experience something so different, and it quickly became a favorite.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print responses for 5 observations\n",
        "for i in range(5):\n",
        "    print(this_notebook_train_validate.iloc[i, 2])\n",
        "    print('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She6a_yOnVsI"
      },
      "source": [
        "### Format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9ZLRixKjVMZ",
        "outputId": "5e60c152-4196-4f76-8268-2f81d13d4eed"
      },
      "outputs": [],
      "source": [
        "def convert_to_gpt35_format(dataset):\n",
        "    fine_tuning_data = []\n",
        "    for _, row in dataset.iterrows():\n",
        "        json_response = '{\"Score\": \"' + str(row['coherence_1_incoherent_10_very_coherent']) + '\"}'\n",
        "        fine_tuning_data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": row['response'] + \"\\nYour Task: Rate the coherence of the passage above on a scale of 1 to 10, 1 being incoherent and 10 being very coherent. If the passage is two unconnected pieces give it a score of 1. If it has sentences that seem to be randomly inserted, has abrupt change in characters, or has abrupt change in setting, give it a low score. If it has a continuous setting or characters and seems plausible, give it a high score. If it is as coherent as you believe is possible, give it a score of 10.\"},\n",
        "                {\"role\": \"assistant\", \"content\": json_response}\n",
        "            ]\n",
        "        })\n",
        "    return fine_tuning_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': 'He had never been to space before, but the smell of seared steak hit his nose like a wave of familiarity. It caught him off guard that space smelled of seared steak. Little did he know there was a small cafe on board the spaceship that served steak sandwiches.\\nHe scrambled, his eyes drawn to the largest creature he had ever seen on board the spaceship. It was terrifyingly long yet gentle. The Great Dane looked more like a horse than a dog. It walked slowly but with an authoritative air. Its snorting echoed in the cabin.\\nYour Task: Rate the coherence of the passage above on a scale of 1 to 10, 1 being incoherent and 10 being very coherent. If the passage is two unconnected pieces give it a score of 1. If it has sentences that seem to be randomly inserted, has abrupt change in characters, or has abrupt change in setting, give it a low score. If it has a continuous setting or characters and seems plausible, give it a high score. If it is as coherent as you believe is possible, give it a score of 10.'},\n",
              " {'role': 'assistant', 'content': '{\"Score\": \"3\"}'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert entire dataset\n",
        "dataset = this_notebook_train_validate\n",
        "converted_data = convert_to_gpt35_format(dataset)\n",
        "converted_data[0]['messages']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzOSh9ZOjh6P",
        "outputId": "0f954c17-e689-442e-9bae-7d77661f7de5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Score': '3'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "json.loads(converted_data[0]['messages'][-1]['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fM5yTsndjp"
      },
      "source": [
        "Create Train and Val Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['td3_cw_direct_prompting_responses',\n",
              "       'td3_cw_zero_shot_cot_responses',\n",
              "       'td3_cw_ape_zero_shot_cot_responses',\n",
              "       'td3_cw_least_to_most_responses',\n",
              "       'td3_cw_manual_few_shot_responses', 'td3_cw_manual_cot_responses',\n",
              "       'td3_cw_tree_of_thought_responses', 'td3_cw_self_refine_responses',\n",
              "       'gpt4_cw_direct_prompting_responses',\n",
              "       'gpt4_cw_zero_shot_cot_responses',\n",
              "       'gpt4_cw_ape_zero_shot_cot_responses',\n",
              "       'gpt4_cw_tree_of_thought_responses',\n",
              "       'gpt4_cw_self_refine_responses', 'gpt4_cw_least_to_most_responses',\n",
              "       'gpt4_cw_manual_few_shot_responses',\n",
              "       'gpt4_cw_manual_cot_responses'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print unique values of model_task_method\n",
        "this_notebook_train_validate['model_task_method'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jslTVNldj5Ml"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified splitting on model_task_method.\n",
        "train_data, val_data = train_test_split(\n",
        "    converted_data,\n",
        "    test_size=0.2,\n",
        "    stratify=this_notebook_train_validate['model_task_method'],\n",
        "    random_state=42  # for reproducibility\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_sf-jBwc5Y",
        "outputId": "45578907-f3b7-438b-aad3-322afb9004e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "640\n",
            "160\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPNfP_GnrDq"
      },
      "source": [
        "Create JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "31vTBdJiitzX"
      },
      "outputs": [],
      "source": [
        "def write_to_jsonl(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for entry in data:\n",
        "            json.dump(entry, file)\n",
        "            file.write('\\n')\n",
        "\n",
        "\n",
        "training_file_name = \"train_\" + this_nb + \".jsonl\"\n",
        "validation_file_name = \"val_\" + this_nb + \".jsonl\"\n",
        "\n",
        "write_to_jsonl(train_data, training_file_name)\n",
        "write_to_jsonl(val_data, validation_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Get and set API key\n",
        "# with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "#     api_key = file.read()\n",
        "# openai.api_key = api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Get and set API key\n",
        "with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "    my_api_key = file.read()\n",
        "\n",
        "#from openai import OpenAI\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=my_api_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHIVr7BAnyjC"
      },
      "source": [
        "Upload Training and Validation File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpCsg8I2ZxLK",
        "outputId": "9ce65740-674b-446b-9829-b9c04c6097c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-fWLxjrz9faLwSPsW1svlZYDX\n",
            "Validation file id: file-ps3hGUfuNT7ZiUTKIT7sZ2lH\n"
          ]
        }
      ],
      "source": [
        "training_file = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(\"Training file id:\", training_file.id)\n",
        "print(\"Validation file id:\", validation_file.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCwIEinan2il"
      },
      "source": [
        "Create Finetuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17X6KNaaIRJ",
        "outputId": "a66d283d-03f7-4ae3-f322-bd449042dfbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-0EJTWZb3IEMVa4CRtwa8E19B', created_at=1701281389, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-MdSScMkbTK60fqqIP4cio0Kx', result_files=[], status='validating_files', trained_tokens=None, training_file='file-fWLxjrz9faLwSPsW1svlZYDX', validation_file='file-ps3hGUfuNT7ZiUTKIT7sZ2lH')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "suffix_name = this_nb\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    validation_file=validation_file.id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "response\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
