{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Regressions.ipynb\n",
    "\n",
    "Logistic regressions of GSM8K accuracy on length and complexity variables, quadratic terms, clustering by identity of the question and method (task, conversation_id, method).\n",
    "\n",
    "Regression of CW scores similarly.\n",
    "\n",
    "Add complexity of provided answers as an interaction term in GSM8K regressions.\n",
    "\n",
    "Add model as an interaction term.\n",
    "\n",
    "Model and question (conversation_number by task) controls can soak up additional variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_task_method', 'conversation_number',\n",
      "       'coherence_1_incoherent_10_very_coherent', 'compliance_OLD',\n",
      "       'ease_of_review_1_easy_10_hard', 'correct',\n",
      "       'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10',\n",
      "       'Aggregated_Prediction', 'Prediction_Based_On_First_10_LP',\n",
      "       'response_Based_On_First_10_LP', 'Prediction_Based_On_Last_10_LP',\n",
      "       'response_Based_On_Last_10_LP', 'response_LP',\n",
      "       'Aggregated_Prediction_LP', 'Prediction_Based_On_First_50_LP',\n",
      "       'response_Based_On_First_50_LP', 'Prediction_Based_On_Last_50_LP',\n",
      "       'response_Based_On_Last_50_LP', 'Aggregated_Prediction_50_LP',\n",
      "       'Prediction_Based_On_random_50_LP_1',\n",
      "       'response_Based_On_random_50_LP_1',\n",
      "       'Prediction_Based_On_random_50_LP_2',\n",
      "       'response_Based_On_random_50_LP_2',\n",
      "       'Aggregated_Prediction_random_50_LP', 'Unnamed: 0_x', 'response_x',\n",
      "       'replace_slash_n_slash_n_with_newline_x',\n",
      "       'replace_slash_n_slash_n_with_newline_values_x',\n",
      "       'replace_slash_n_with_newline_x',\n",
      "       'replace_slash_n_with_newline_values_x', 'avg_cosine_sim',\n",
      "       'num_sentences_x', 'Unnamed: 0_y', 'response_y',\n",
      "       'replace_slash_n_slash_n_with_newline_y',\n",
      "       'replace_slash_n_slash_n_with_newline_values_y',\n",
      "       'replace_slash_n_with_newline_y',\n",
      "       'replace_slash_n_with_newline_values_y',\n",
      "       'avg_inter_paragraph_cosine_sim', 'num_paragraphs', 'num_sentences_y',\n",
      "       'cosine_sims', 'conversation_length', 'input_length', 'output_length',\n",
      "       'conversation_cost', 'gsm8k_question_index', 'gsm8k_answer',\n",
      "       'gsm8k_length_vs_provided', 'length_vs_direct_prompting',\n",
      "       'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc',\n",
      "       'sentence_length', 'fres', 'num_linebreaks_prompts',\n",
      "       'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts',\n",
      "       'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided',\n",
      "       'num_sentences_provided', 'num_step_i_provided',\n",
      "       'num_1_dot_etc_provided', 'length_provided', 'compliance',\n",
      "       'coherence_1_incoherent_10_very_coherent_compliance_adjusted',\n",
      "       'Aggregated_Prediction_random_50_LP_compliance_adjusted',\n",
      "       'avg_cosine_sim_compliance_adjusted',\n",
      "       'avg_inter_paragraph_cosine_sim_compliance_adjusted', 'model', 'task',\n",
      "       'method', 'Model', 'Method', 'Task', 'accuracy_quality',\n",
      "       'accuracy_quality_compliance_adjusted',\n",
      "       'accuracy_quality_avg_inter_paragraph_cosine_sim',\n",
      "       'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_prompts',\n",
      "       'consolidated_num_steps_ideas_provided', 'technique_name',\n",
      "       'ss_publication_date', 'ss_publication_date_datetime',\n",
      "       'Method + Publication Date', 'Publication Date',\n",
      "       'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff',\n",
      "       'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff',\n",
      "       'sentence_length_prompts_diff', 'fres_prompts_diff',\n",
      "       'num_linebreaks_provided_diff', 'num_sentences_provided_diff',\n",
      "       'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_task_method</th>\n",
       "      <th>conversation_number</th>\n",
       "      <th>coherence_1_incoherent_10_very_coherent</th>\n",
       "      <th>compliance_OLD</th>\n",
       "      <th>ease_of_review_1_easy_10_hard</th>\n",
       "      <th>correct</th>\n",
       "      <th>Prediction_Based_On_First_10</th>\n",
       "      <th>Prediction_Based_On_Last_10</th>\n",
       "      <th>Aggregated_Prediction</th>\n",
       "      <th>Prediction_Based_On_First_10_LP</th>\n",
       "      <th>...</th>\n",
       "      <th>num_linebreaks_prompts_diff</th>\n",
       "      <th>num_sentences_prompts_diff</th>\n",
       "      <th>num_step_i_prompts_diff</th>\n",
       "      <th>num_1_dot_etc_prompts_diff</th>\n",
       "      <th>sentence_length_prompts_diff</th>\n",
       "      <th>fres_prompts_diff</th>\n",
       "      <th>num_linebreaks_provided_diff</th>\n",
       "      <th>num_sentences_provided_diff</th>\n",
       "      <th>num_step_i_provided_diff</th>\n",
       "      <th>num_1_dot_etc_provided_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>5.971429</td>\n",
       "      <td>-12.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>9.350000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>6.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>9.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>7.828571</td>\n",
       "      <td>-13.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-16</td>\n",
       "      <td>-39</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-16</td>\n",
       "      <td>-43</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-16</td>\n",
       "      <td>-44</td>\n",
       "      <td>0</td>\n",
       "      <td>-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-15</td>\n",
       "      <td>-44</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-16</td>\n",
       "      <td>-44</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_task_method  conversation_number  \\\n",
       "0     td3_cw_direct_prompting_responses                    1   \n",
       "1     td3_cw_direct_prompting_responses                    2   \n",
       "2     td3_cw_direct_prompting_responses                    3   \n",
       "3     td3_cw_direct_prompting_responses                    4   \n",
       "4     td3_cw_direct_prompting_responses                    5   \n",
       "...                                 ...                  ...   \n",
       "3195    gpt4_gsm8k_manual_cot_responses                   96   \n",
       "3196    gpt4_gsm8k_manual_cot_responses                   97   \n",
       "3197    gpt4_gsm8k_manual_cot_responses                   98   \n",
       "3198    gpt4_gsm8k_manual_cot_responses                   99   \n",
       "3199    gpt4_gsm8k_manual_cot_responses                  100   \n",
       "\n",
       "      coherence_1_incoherent_10_very_coherent  compliance_OLD  \\\n",
       "0                                         1.0             1.0   \n",
       "1                                         7.0             0.0   \n",
       "2                                         1.0             1.0   \n",
       "3                                        10.0             1.0   \n",
       "4                                         4.0             1.0   \n",
       "...                                       ...             ...   \n",
       "3195                                      NaN             NaN   \n",
       "3196                                      NaN             NaN   \n",
       "3197                                      NaN             NaN   \n",
       "3198                                      NaN             NaN   \n",
       "3199                                      NaN             NaN   \n",
       "\n",
       "      ease_of_review_1_easy_10_hard  correct  Prediction_Based_On_First_10  \\\n",
       "0                               1.0      NaN                           NaN   \n",
       "1                               1.0      NaN                           NaN   \n",
       "2                               1.0      NaN                           NaN   \n",
       "3                               1.0      NaN                           NaN   \n",
       "4                               1.0      NaN                           NaN   \n",
       "...                             ...      ...                           ...   \n",
       "3195                            NaN      1.0                           NaN   \n",
       "3196                            NaN      1.0                           NaN   \n",
       "3197                            NaN      1.0                           NaN   \n",
       "3198                            NaN      1.0                           NaN   \n",
       "3199                            NaN      1.0                           NaN   \n",
       "\n",
       "      Prediction_Based_On_Last_10  Aggregated_Prediction  \\\n",
       "0                             1.0                    1.0   \n",
       "1                             7.0                    7.0   \n",
       "2                             1.0                    1.0   \n",
       "3                             7.0                    7.0   \n",
       "4                             1.0                    1.0   \n",
       "...                           ...                    ...   \n",
       "3195                          NaN                    NaN   \n",
       "3196                          NaN                    NaN   \n",
       "3197                          NaN                    NaN   \n",
       "3198                          NaN                    NaN   \n",
       "3199                          NaN                    NaN   \n",
       "\n",
       "      Prediction_Based_On_First_10_LP  ... num_linebreaks_prompts_diff  \\\n",
       "0                                 NaN  ...                           1   \n",
       "1                                 NaN  ...                           1   \n",
       "2                                 NaN  ...                           1   \n",
       "3                                 NaN  ...                           1   \n",
       "4                                 NaN  ...                           1   \n",
       "...                               ...  ...                         ...   \n",
       "3195                              NaN  ...                         -16   \n",
       "3196                              NaN  ...                         -16   \n",
       "3197                              NaN  ...                         -16   \n",
       "3198                              NaN  ...                         -15   \n",
       "3199                              NaN  ...                         -16   \n",
       "\n",
       "      num_sentences_prompts_diff num_step_i_prompts_diff  \\\n",
       "0                              2                       0   \n",
       "1                              3                       0   \n",
       "2                              4                       0   \n",
       "3                              1                       0   \n",
       "4                              2                       0   \n",
       "...                          ...                     ...   \n",
       "3195                         -39                       0   \n",
       "3196                         -43                       0   \n",
       "3197                         -44                       0   \n",
       "3198                         -44                       0   \n",
       "3199                         -44                       0   \n",
       "\n",
       "     num_1_dot_etc_prompts_diff  sentence_length_prompts_diff  \\\n",
       "0                            -2                      5.971429   \n",
       "1                            -2                      9.350000   \n",
       "2                            -2                      4.533333   \n",
       "3                            -2                      9.533333   \n",
       "4                            -2                      7.828571   \n",
       "...                         ...                           ...   \n",
       "3195                        -17                           NaN   \n",
       "3196                        -19                           NaN   \n",
       "3197                        -20                           NaN   \n",
       "3198                        -19                           NaN   \n",
       "3199                        -19                           NaN   \n",
       "\n",
       "      fres_prompts_diff num_linebreaks_provided_diff  \\\n",
       "0                -12.31                          NaN   \n",
       "1                  1.05                          NaN   \n",
       "2                  6.64                          NaN   \n",
       "3                  9.31                          NaN   \n",
       "4                -13.64                          NaN   \n",
       "...                 ...                          ...   \n",
       "3195                NaN                         -4.0   \n",
       "3196                NaN                         -2.0   \n",
       "3197                NaN                         -3.0   \n",
       "3198                NaN                         -1.0   \n",
       "3199                NaN                         -4.0   \n",
       "\n",
       "      num_sentences_provided_diff num_step_i_provided_diff  \\\n",
       "0                             NaN                      NaN   \n",
       "1                             NaN                      NaN   \n",
       "2                             NaN                      NaN   \n",
       "3                             NaN                      NaN   \n",
       "4                             NaN                      NaN   \n",
       "...                           ...                      ...   \n",
       "3195                          1.0                      0.0   \n",
       "3196                          0.0                      0.0   \n",
       "3197                         -1.0                      0.0   \n",
       "3198                          0.0                      0.0   \n",
       "3199                          1.0                      0.0   \n",
       "\n",
       "      num_1_dot_etc_provided_diff  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "3195                          2.0  \n",
       "3196                          1.0  \n",
       "3197                          0.0  \n",
       "3198                          1.0  \n",
       "3199                          1.0  \n",
       "\n",
       "[3200 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Combined_Data.xlsx\n",
    "df = pd.read_excel('Combined_Data.xlsx')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation - divide conversation length by 1000 to get effect per 1000K tokens\n",
    "df['conversation_length_thousands'] = df['conversation_length']/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quadratics\n",
    "df['conversation_length_thousands_2'] = df['conversation_length_thousands']**2\n",
    "df['consolidated_num_steps_ideas_2'] = df['consolidated_num_steps_ideas']**2\n",
    "df['fres_2'] = df['fres']**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clustering variable\n",
    "# Concatenate task, conversation_number, method\n",
    "df['task_conversation_method'] = df['task'].astype(str) + \"_\" + df['conversation_number'].astype(str) + \"_\" + df['method'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task by conversation variable as a control\n",
    "df['task_conversation'] = df['task'].astype(str) + \"_\" + df['conversation_number'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "gsm8k_data = df[df['task'] == 'gsm8k']\n",
    "cw_data = df[df['task'] == 'cw']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Get values of correct in gsm8k_data\n",
    "gsm8k_correct = gsm8k_data['correct'].values\n",
    "print(set(gsm8k_correct))\n",
    "\n",
    "# Print cases where correct is not 0 or 1\n",
    "#print(gsm8k_data[gsm8k_data['correct'] != 0 & gsm8k_data['correct'] != 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for table creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logit df\n",
    "def create_logit_results_df(model, marginal_effects, title):\n",
    "    #coef_names = model.params.index\n",
    "    #print(coef_names)\n",
    "    coef_names_with_mes = list(model.params.index)[1:]\n",
    "    #print(coef_names_with_mes)\n",
    "    me_values = marginal_effects.margeff\n",
    "    #print(me_values)\n",
    "    me_ses = marginal_effects.margeff_se\n",
    "    # print(me_ses)\n",
    "    p_values = marginal_effects.pvalues\n",
    "    # print(p_values)\n",
    "    # Loop over items in coef_names_with_mes, enumerated\n",
    "    string_entries = []\n",
    "    for i, coef_name in enumerate(coef_names_with_mes):\n",
    "        # Print coef_name, me_values[i], me_ses[i], p_values[i]\n",
    "        #print(coef_name, me_values[i], me_ses[i], p_values[i])\n",
    "        # Consolidate me_values[i], me_ses[i], p_values[i] into a string\n",
    "        # me_value* (me_se), where the star is if p_value < 0.05\n",
    "        if p_values[i] < 0.05:\n",
    "            string_entries.append(str(round(me_values[i], 3)) + \"* (\" + str(round(me_ses[i], 3)) + \")\")\n",
    "        else:\n",
    "            string_entries.append(str(round(me_values[i], 3)) + \" (\" + str(round(me_ses[i], 3)) + \")\")\n",
    "\n",
    "    # Make a dataframe with one row with columns of coef_names_with_mes and values of string_entries\n",
    "    # Print the dataframe\n",
    "    model_df = pd.DataFrame([string_entries], columns=coef_names_with_mes)\n",
    "    # Add column Title\n",
    "    model_df['Title'] = title\n",
    "    return model_df\n",
    "\n",
    "# Create linear regression df\n",
    "def create_linear_results_df(model, title):\n",
    "    coef_names = model.params.index\n",
    "    # print(coef_names)\n",
    "    coef_values = model.params.values\n",
    "    # print(coef_values)\n",
    "    sds = model.bse.values\n",
    "    # print(sds)\n",
    "    p_values = model.pvalues.values\n",
    "    # print(p_values)\n",
    "\n",
    "    # Loop over items in coef_names, enumerated\n",
    "    string_entries = []\n",
    "    for i, coef_name in enumerate(coef_names):\n",
    "        # Print coef_name, coef_values[i], sds[i], p_values[i]\n",
    "        #print(coef_name, coef_values[i], sds[i], p_values[i])\n",
    "        # Consolidate coef_values[i], sds[i], p_values[i] into a string\n",
    "        # coef_value* (sd), where the star is if p_value < 0.05\n",
    "        if p_values[i] < 0.05:\n",
    "            string_entries.append(str(round(coef_values[i], 3)) + \"* (\" + str(round(sds[i], 3)) + \")\")\n",
    "        else:\n",
    "            string_entries.append(str(round(coef_values[i], 3)) + \" (\" + str(round(sds[i], 3)) + \")\")\n",
    "\n",
    "    # Make a dataframe with one row with columns of coef_names and values of string_entries\n",
    "    # Print the dataframe\n",
    "    model_df = pd.DataFrame([string_entries], columns=coef_names)\n",
    "    # Add column Title\n",
    "    model_df['Title'] = title\n",
    "    #print(lpm_with_clustering_gsm8k_df)\n",
    "    return model_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (no clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.576353\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1594\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 11 Dec 2023   Pseudo R-squ.:                  0.1496\n",
      "Time:                        15:44:17   Log-Likelihood:                -922.17\n",
      "converged:                       True   LL-Null:                       -1084.4\n",
      "Covariance Type:                  HC3   LLR p-value:                 5.423e-68\n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           1.2184      0.179      6.792      0.000       0.867       1.570\n",
      "model[T.td3]                       -1.9626      0.122    -16.098      0.000      -2.202      -1.724\n",
      "conversation_length_thousands       1.4136      0.733      1.930      0.054      -0.022       2.849\n",
      "consolidated_num_steps_ideas        0.1470      0.034      4.345      0.000       0.081       0.213\n",
      "conversation_length_thousands_2    -2.5436      0.659     -3.858      0.000      -3.836      -1.251\n",
      "consolidated_num_steps_ideas_2     -0.0090      0.002     -3.872      0.000      -0.014      -0.004\n",
      "===================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                correct\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                       -0.3844      0.016    -23.924      0.000      -0.416      -0.353\n",
      "conversation_length_thousands       0.2769      0.143      1.938      0.053      -0.003       0.557\n",
      "consolidated_num_steps_ideas        0.0288      0.007      4.410      0.000       0.016       0.042\n",
      "conversation_length_thousands_2    -0.4982      0.127     -3.910      0.000      -0.748      -0.249\n",
      "consolidated_num_steps_ideas_2     -0.0018      0.000     -3.908      0.000      -0.003      -0.001\n",
      "===================================================================================================\n",
      "      model[T.td3] conversation_length_thousands consolidated_num_steps_ideas  \\\n",
      "0  -0.384* (0.016)                 0.277 (0.143)               0.029* (0.007)   \n",
      "\n",
      "  conversation_length_thousands_2 consolidated_num_steps_ideas_2  \\\n",
      "0                 -0.498* (0.127)                  -0.002* (0.0)   \n",
      "\n",
      "                  Title  \n",
      "0  GSM8K Correct, Logit  \n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model[T.td3][T.td3][T.td3]\n",
    "logit_no_clustering_gsm8k = smf.logit('correct ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + model', data=gsm8k_data).fit(cov_type='HC3')\n",
    "\n",
    "# Display the summary\n",
    "print(logit_no_clustering_gsm8k.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_gsm8k_marginal_effects = logit_no_clustering_gsm8k.get_margeff(at='overall')\n",
    "print(logit_no_clustering_gsm8k_marginal_effects.summary())\n",
    "\n",
    "# # Results for table\n",
    "# # Get conversation_length_thousands marginal effect, star for significant, sd\n",
    "# #clt2 = logit_no_clustering_gsm8k_marginal_effects\n",
    "# #print(clt2)\n",
    "# # Also get consolidated_num_steps_ideas marginal effect, star for significant, sd\n",
    "# # Also get conversation_length_thousands_2 marginal effect, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas_2 marginal effect, star for significant, sd\n",
    "# # Title: \"GSM8K Correct, Logit\"\n",
    "# coef_names = logit_no_clustering_gsm8k.params.index\n",
    "# #print(coef_names)\n",
    "# coef_names_with_mes = list(logit_no_clustering_gsm8k.params.index)[1:]\n",
    "# #print(coef_names_with_mes)\n",
    "# me_values = logit_no_clustering_gsm8k_marginal_effects.margeff\n",
    "# #print(me_values)\n",
    "# me_ses = logit_no_clustering_gsm8k_marginal_effects.margeff_se\n",
    "# # print(me_ses)\n",
    "# p_values = logit_no_clustering_gsm8k_marginal_effects.pvalues\n",
    "# # print(p_values)\n",
    "# # Loop over items in coef_names_with_mes, enumerated\n",
    "# string_entries = []\n",
    "# for i, coef_name in enumerate(coef_names_with_mes):\n",
    "#     # Print coef_name, me_values[i], me_ses[i], p_values[i]\n",
    "#     #print(coef_name, me_values[i], me_ses[i], p_values[i])\n",
    "#     # Consolidate me_values[i], me_ses[i], p_values[i] into a string\n",
    "#     # me_value* (me_se), where the star is if p_value < 0.05\n",
    "#     if p_values[i] < 0.05:\n",
    "#         string_entries.append(str(round(me_values[i], 3)) + \"* (\" + str(round(me_ses[i], 3)) + \")\")\n",
    "#     else:\n",
    "#         string_entries.append(str(round(me_values[i], 3)) + \" (\" + str(round(me_ses[i], 3)) + \")\")\n",
    "\n",
    "# # Make a dataframe with one row with columns of coef_names_with_mes and values of string_entries\n",
    "# # Print the dataframe\n",
    "# logit_no_clustering_gsm8k_marginal_effects_df = pd.DataFrame([string_entries], columns=coef_names_with_mes)\n",
    "# # Add column Title\n",
    "# logit_no_clustering_gsm8k_marginal_effects_df['Title'] = \"GSM8K Correct, Logit\"\n",
    "# print(logit_no_clustering_gsm8k_marginal_effects_df)\n",
    "\n",
    "# Use function to create results df\n",
    "logit_no_clustering_gsm8k_df = create_logit_results_df(logit_no_clustering_gsm8k, logit_no_clustering_gsm8k_marginal_effects, \"GSM8K Correct, Logit\")\n",
    "print(logit_no_clustering_gsm8k_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Probability Model with Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   R-squared:                       0.348\n",
      "Model:                            OLS   Adj. R-squared:                  0.303\n",
      "Method:                 Least Squares   F-statistic:                     32.04\n",
      "Date:                Mon, 11 Dec 2023   Prob (F-statistic):          1.17e-222\n",
      "Time:                        15:44:17   Log-Likelihood:                -793.62\n",
      "No. Observations:                1600   AIC:                             1797.\n",
      "Df Residuals:                    1495   BIC:                             2362.\n",
      "Df Model:                         104                                         \n",
      "Covariance Type:              cluster                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           0.9503      0.084     11.316      0.000       0.786       1.115\n",
      "task_conversation[T.gsm8k_10]      -0.3931      0.115     -3.431      0.001      -0.618      -0.169\n",
      "task_conversation[T.gsm8k_100]     -0.2483      0.166     -1.494      0.135      -0.574       0.078\n",
      "task_conversation[T.gsm8k_11]      -0.1317      0.146     -0.902      0.367      -0.418       0.155\n",
      "task_conversation[T.gsm8k_12]      -0.1629      0.141     -1.155      0.248      -0.439       0.114\n",
      "task_conversation[T.gsm8k_13]      -0.8963      0.085    -10.518      0.000      -1.063      -0.729\n",
      "task_conversation[T.gsm8k_14]      -0.6808      0.107     -6.365      0.000      -0.890      -0.471\n",
      "task_conversation[T.gsm8k_15]      -0.0526      0.146     -0.361      0.718      -0.338       0.233\n",
      "task_conversation[T.gsm8k_16]      -0.1455      0.120     -1.210      0.226      -0.381       0.090\n",
      "task_conversation[T.gsm8k_17]       0.1388      0.105      1.316      0.188      -0.068       0.346\n",
      "task_conversation[T.gsm8k_18]      -0.2559      0.155     -1.652      0.099      -0.560       0.048\n",
      "task_conversation[T.gsm8k_19]      -0.1344      0.154     -0.875      0.382      -0.435       0.167\n",
      "task_conversation[T.gsm8k_2]        0.1362      0.106      1.282      0.200      -0.072       0.344\n",
      "task_conversation[T.gsm8k_20]      -0.3829      0.097     -3.950      0.000      -0.573      -0.193\n",
      "task_conversation[T.gsm8k_21]      -0.4821      0.131     -3.683      0.000      -0.739      -0.226\n",
      "task_conversation[T.gsm8k_22]      -0.3100      0.126     -2.461      0.014      -0.557      -0.063\n",
      "task_conversation[T.gsm8k_23]      -0.1177      0.113     -1.041      0.298      -0.339       0.104\n",
      "task_conversation[T.gsm8k_24]       0.0126      0.118      0.107      0.915      -0.218       0.243\n",
      "task_conversation[T.gsm8k_25]      -0.1544      0.140     -1.099      0.272      -0.430       0.121\n",
      "task_conversation[T.gsm8k_26]      -0.3042      0.143     -2.132      0.033      -0.584      -0.025\n",
      "task_conversation[T.gsm8k_27]      -0.2419      0.149     -1.620      0.105      -0.535       0.051\n",
      "task_conversation[T.gsm8k_28]      -0.0641      0.105     -0.609      0.543      -0.271       0.142\n",
      "task_conversation[T.gsm8k_29]      -0.0091      0.129     -0.070      0.944      -0.262       0.244\n",
      "task_conversation[T.gsm8k_3]       -0.6070      0.118     -5.133      0.000      -0.839      -0.375\n",
      "task_conversation[T.gsm8k_30]      -0.2841      0.130     -2.178      0.029      -0.540      -0.028\n",
      "task_conversation[T.gsm8k_31]      -0.3986      0.125     -3.181      0.001      -0.644      -0.153\n",
      "task_conversation[T.gsm8k_32]      -0.2982      0.095     -3.125      0.002      -0.485      -0.111\n",
      "task_conversation[T.gsm8k_33]      -0.0660      0.133     -0.496      0.620      -0.327       0.195\n",
      "task_conversation[T.gsm8k_34]      -0.3270      0.082     -4.008      0.000      -0.487      -0.167\n",
      "task_conversation[T.gsm8k_35]      -0.1911      0.164     -1.164      0.244      -0.513       0.131\n",
      "task_conversation[T.gsm8k_36]      -0.3088      0.145     -2.124      0.034      -0.594      -0.024\n",
      "task_conversation[T.gsm8k_37]      -0.2025      0.143     -1.419      0.156      -0.482       0.077\n",
      "task_conversation[T.gsm8k_38]      -0.7165      0.095     -7.557      0.000      -0.902      -0.531\n",
      "task_conversation[T.gsm8k_39]      -0.3763      0.082     -4.566      0.000      -0.538      -0.215\n",
      "task_conversation[T.gsm8k_4]        0.0654      0.117      0.560      0.576      -0.164       0.294\n",
      "task_conversation[T.gsm8k_40]      -0.3718      0.122     -3.057      0.002      -0.610      -0.133\n",
      "task_conversation[T.gsm8k_41]       0.0185      0.121      0.153      0.879      -0.219       0.256\n",
      "task_conversation[T.gsm8k_42]      -0.3574      0.129     -2.766      0.006      -0.611      -0.104\n",
      "task_conversation[T.gsm8k_43]      -0.0506      0.120     -0.423      0.672      -0.285       0.184\n",
      "task_conversation[T.gsm8k_44]      -0.5159      0.110     -4.683      0.000      -0.732      -0.300\n",
      "task_conversation[T.gsm8k_45]      -0.1662      0.155     -1.073      0.283      -0.470       0.137\n",
      "task_conversation[T.gsm8k_46]      -0.3260      0.129     -2.529      0.011      -0.579      -0.073\n",
      "task_conversation[T.gsm8k_47]      -0.3823      0.110     -3.485      0.000      -0.597      -0.167\n",
      "task_conversation[T.gsm8k_48]      -0.2761      0.144     -1.924      0.054      -0.557       0.005\n",
      "task_conversation[T.gsm8k_49]       0.1871      0.083      2.266      0.023       0.025       0.349\n",
      "task_conversation[T.gsm8k_5]       -0.2479      0.133     -1.865      0.062      -0.508       0.013\n",
      "task_conversation[T.gsm8k_50]      -0.0121      0.119     -0.101      0.919      -0.245       0.221\n",
      "task_conversation[T.gsm8k_51]      -0.2701      0.158     -1.710      0.087      -0.580       0.040\n",
      "task_conversation[T.gsm8k_52]      -0.1800      0.137     -1.310      0.190      -0.449       0.089\n",
      "task_conversation[T.gsm8k_53]      -0.2244      0.121     -1.850      0.064      -0.462       0.013\n",
      "task_conversation[T.gsm8k_54]      -0.1854      0.158     -1.175      0.240      -0.495       0.124\n",
      "task_conversation[T.gsm8k_55]      -0.2547      0.166     -1.538      0.124      -0.579       0.070\n",
      "task_conversation[T.gsm8k_56]      -0.0043      0.115     -0.037      0.970      -0.229       0.220\n",
      "task_conversation[T.gsm8k_57]      -0.0806      0.116     -0.694      0.487      -0.308       0.147\n",
      "task_conversation[T.gsm8k_58]      -0.1367      0.123     -1.109      0.267      -0.378       0.105\n",
      "task_conversation[T.gsm8k_59]      -0.1886      0.153     -1.234      0.217      -0.488       0.111\n",
      "task_conversation[T.gsm8k_6]       -0.4356      0.132     -3.307      0.001      -0.694      -0.177\n",
      "task_conversation[T.gsm8k_60]      -0.0595      0.119     -0.501      0.616      -0.292       0.173\n",
      "task_conversation[T.gsm8k_61]      -0.3193      0.173     -1.842      0.066      -0.659       0.020\n",
      "task_conversation[T.gsm8k_62]      -0.1044      0.120     -0.872      0.383      -0.339       0.130\n",
      "task_conversation[T.gsm8k_63]      -0.5864      0.134     -4.383      0.000      -0.849      -0.324\n",
      "task_conversation[T.gsm8k_64]      -0.3513      0.138     -2.542      0.011      -0.622      -0.080\n",
      "task_conversation[T.gsm8k_65]      -0.1214      0.125     -0.970      0.332      -0.367       0.124\n",
      "task_conversation[T.gsm8k_66]      -0.3146      0.157     -2.000      0.046      -0.623      -0.006\n",
      "task_conversation[T.gsm8k_67]      -0.3184      0.148     -2.150      0.032      -0.609      -0.028\n",
      "task_conversation[T.gsm8k_68]      -0.2507      0.166     -1.509      0.131      -0.576       0.075\n",
      "task_conversation[T.gsm8k_69]      -0.2584      0.151     -1.709      0.087      -0.555       0.038\n",
      "task_conversation[T.gsm8k_7]       -0.1960      0.147     -1.334      0.182      -0.484       0.092\n",
      "task_conversation[T.gsm8k_70]      -0.0984      0.118     -0.836      0.403      -0.329       0.132\n",
      "task_conversation[T.gsm8k_71]      -0.3963      0.127     -3.111      0.002      -0.646      -0.147\n",
      "task_conversation[T.gsm8k_72]    8.395e-05      0.118      0.001      0.999      -0.232       0.232\n",
      "task_conversation[T.gsm8k_73]      -0.2817      0.160     -1.765      0.078      -0.594       0.031\n",
      "task_conversation[T.gsm8k_74]      -0.3571      0.173     -2.067      0.039      -0.696      -0.018\n",
      "task_conversation[T.gsm8k_75]      -0.2477      0.160     -1.551      0.121      -0.561       0.065\n",
      "task_conversation[T.gsm8k_76]      -0.5281      0.115     -4.584      0.000      -0.754      -0.302\n",
      "task_conversation[T.gsm8k_77]      -0.2920      0.141     -2.068      0.039      -0.569      -0.015\n",
      "task_conversation[T.gsm8k_78]      -0.1877      0.184     -1.021      0.307      -0.548       0.173\n",
      "task_conversation[T.gsm8k_79]      -0.2641      0.154     -1.712      0.087      -0.567       0.038\n",
      "task_conversation[T.gsm8k_8]       -0.5327      0.115     -4.651      0.000      -0.757      -0.308\n",
      "task_conversation[T.gsm8k_80]       0.1520      0.083      1.823      0.068      -0.011       0.315\n",
      "task_conversation[T.gsm8k_81]      -0.4964      0.119     -4.182      0.000      -0.729      -0.264\n",
      "task_conversation[T.gsm8k_82]      -0.1189      0.147     -0.807      0.420      -0.408       0.170\n",
      "task_conversation[T.gsm8k_83]      -0.2401      0.158     -1.523      0.128      -0.549       0.069\n",
      "task_conversation[T.gsm8k_84]       0.1950      0.082      2.380      0.017       0.034       0.356\n",
      "task_conversation[T.gsm8k_85]      -0.4634      0.147     -3.145      0.002      -0.752      -0.175\n",
      "task_conversation[T.gsm8k_86]      -0.1355      0.146     -0.927      0.354      -0.422       0.151\n",
      "task_conversation[T.gsm8k_87]      -0.1307      0.147     -0.891      0.373      -0.418       0.157\n",
      "task_conversation[T.gsm8k_88]      -0.6675      0.116     -5.763      0.000      -0.894      -0.440\n",
      "task_conversation[T.gsm8k_89]      -0.2076      0.111     -1.862      0.063      -0.426       0.011\n",
      "task_conversation[T.gsm8k_9]       -0.5766      0.123     -4.707      0.000      -0.817      -0.337\n",
      "task_conversation[T.gsm8k_90]       0.0435      0.117      0.370      0.711      -0.187       0.274\n",
      "task_conversation[T.gsm8k_91]      -0.1782      0.149     -1.197      0.231      -0.470       0.114\n",
      "task_conversation[T.gsm8k_92]      -0.2371      0.161     -1.476      0.140      -0.552       0.078\n",
      "task_conversation[T.gsm8k_93]      -0.3691      0.155     -2.388      0.017      -0.672      -0.066\n",
      "task_conversation[T.gsm8k_94]      -0.4135      0.135     -3.070      0.002      -0.678      -0.149\n",
      "task_conversation[T.gsm8k_95]      -0.3246      0.123     -2.641      0.008      -0.566      -0.084\n",
      "task_conversation[T.gsm8k_96]      -0.0942      0.159     -0.594      0.553      -0.405       0.217\n",
      "task_conversation[T.gsm8k_97]      -0.1469      0.143     -1.028      0.304      -0.427       0.133\n",
      "task_conversation[T.gsm8k_98]      -0.2545      0.125     -2.030      0.042      -0.500      -0.009\n",
      "task_conversation[T.gsm8k_99]      -0.3050      0.159     -1.922      0.055      -0.616       0.006\n",
      "model[T.td3]                       -0.4140      0.020    -20.482      0.000      -0.454      -0.374\n",
      "conversation_length_thousands       0.2821      0.114      2.473      0.013       0.058       0.506\n",
      "consolidated_num_steps_ideas        0.0432      0.006      7.168      0.000       0.031       0.055\n",
      "conversation_length_thousands_2    -0.4181      0.091     -4.603      0.000      -0.596      -0.240\n",
      "consolidated_num_steps_ideas_2     -0.0023      0.000     -5.783      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                      106.014   Durbin-Watson:                   1.581\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.547\n",
      "Skew:                          -0.164   Prob(JB):                     3.50e-10\n",
      "Kurtosis:                       2.261   Cond. No.                     5.68e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 5.68e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "       Intercept task_conversation[T.gsm8k_10] task_conversation[T.gsm8k_100]  \\\n",
      "0  0.95* (0.084)               -0.393* (0.115)                 -0.248 (0.166)   \n",
      "\n",
      "  task_conversation[T.gsm8k_11] task_conversation[T.gsm8k_12]  \\\n",
      "0                -0.132 (0.146)                -0.163 (0.141)   \n",
      "\n",
      "  task_conversation[T.gsm8k_13] task_conversation[T.gsm8k_14]  \\\n",
      "0               -0.896* (0.085)               -0.681* (0.107)   \n",
      "\n",
      "  task_conversation[T.gsm8k_15] task_conversation[T.gsm8k_16]  \\\n",
      "0                -0.053 (0.146)                 -0.145 (0.12)   \n",
      "\n",
      "  task_conversation[T.gsm8k_17]  ... task_conversation[T.gsm8k_96]  \\\n",
      "0                 0.139 (0.105)  ...                -0.094 (0.159)   \n",
      "\n",
      "  task_conversation[T.gsm8k_97] task_conversation[T.gsm8k_98]  \\\n",
      "0                -0.147 (0.143)               -0.255* (0.125)   \n",
      "\n",
      "  task_conversation[T.gsm8k_99]    model[T.td3] conversation_length_thousands  \\\n",
      "0                -0.305 (0.159)  -0.414* (0.02)                0.282* (0.114)   \n",
      "\n",
      "  consolidated_num_steps_ideas conversation_length_thousands_2  \\\n",
      "0               0.043* (0.006)                 -0.418* (0.091)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2                  Title  \n",
      "0                  -0.002* (0.0)  GSM8K Correct, Linear  \n",
      "\n",
      "[1 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_gsm8k = smf.ols('correct ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + task_conversation + model', data=gsm8k_data).fit(cov_type='cluster', cov_kwds={'groups': gsm8k_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(lpm_with_clustering_gsm8k.summary())\n",
    "\n",
    "# # Results for table\n",
    "# # Get conversation_length_thousands coefficient, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas coefficient, star for significant, sd\n",
    "# # Also get conversation_length_thousands_2 coefficient, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas_2 coefficient, star for significant, sd\n",
    "# # Title: \"GSM8K Correct, Linear\"\n",
    "# coef_names = lpm_with_clustering_gsm8k.params.index\n",
    "# # print(coef_names)\n",
    "# coef_values = lpm_with_clustering_gsm8k.params.values\n",
    "# # print(coef_values)\n",
    "# sds = lpm_with_clustering_gsm8k.bse.values\n",
    "# # print(sds)\n",
    "# p_values = lpm_with_clustering_gsm8k.pvalues.values\n",
    "# # print(p_values)\n",
    "\n",
    "# # Loop over items in coef_names, enumerated\n",
    "# string_entries = []\n",
    "# for i, coef_name in enumerate(coef_names):\n",
    "#     # Print coef_name, coef_values[i], sds[i], p_values[i]\n",
    "#     #print(coef_name, coef_values[i], sds[i], p_values[i])\n",
    "#     # Consolidate coef_values[i], sds[i], p_values[i] into a string\n",
    "#     # coef_value* (sd), where the star is if p_value < 0.05\n",
    "#     if p_values[i] < 0.05:\n",
    "#         string_entries.append(str(round(coef_values[i], 3)) + \"* (\" + str(round(sds[i], 3)) + \")\")\n",
    "#     else:\n",
    "#         string_entries.append(str(round(coef_values[i], 3)) + \" (\" + str(round(sds[i], 3)) + \")\")\n",
    "\n",
    "# # Make a dataframe with one row with columns of coef_names and values of string_entries\n",
    "# # Print the dataframe\n",
    "# lpm_with_clustering_gsm8k_df = pd.DataFrame([string_entries], columns=coef_names)\n",
    "# # Add column Title\n",
    "# lpm_with_clustering_gsm8k_df['Title'] = \"GSM8K Correct, Linear\"\n",
    "# print(lpm_with_clustering_gsm8k_df)\n",
    "\n",
    "# Use function to create results df\n",
    "lpm_with_clustering_gsm8k_df = create_linear_results_df(lpm_with_clustering_gsm8k, \"GSM8K Correct, Linear\")\n",
    "print(lpm_with_clustering_gsm8k_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "# Is avg_inter_paragraph_cosine_sim always present\n",
    "#print(cw_data[cw_data['avg_inter_paragraph_cosine_sim'].isnull()])\n",
    "\n",
    "# Check length\n",
    "#print(len(cw_data['avg_inter_paragraph_cosine_sim']))\n",
    "#print(len(cw_data['fres'].dropna()))\n",
    "\n",
    "# Limit cw_data to rows where avg_inter_paragraph_cosine_sim is not null\n",
    "cw_data = cw_data[cw_data['avg_inter_paragraph_cosine_sim'].notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preferred cosine similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     avg_inter_paragraph_cosine_sim   R-squared:                       0.427\n",
      "Model:                                        OLS   Adj. R-squared:                  0.381\n",
      "Method:                             Least Squares   F-statistic:                     20.48\n",
      "Date:                            Mon, 11 Dec 2023   Prob (F-statistic):          2.79e-163\n",
      "Time:                                    15:44:18   Log-Likelihood:                 927.69\n",
      "No. Observations:                            1434   AIC:                            -1641.\n",
      "Df Residuals:                                1327   BIC:                            -1078.\n",
      "Df Model:                                     106                                         \n",
      "Covariance Type:                          cluster                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           0.5852      0.150      3.891      0.000       0.290       0.880\n",
      "task_conversation[T.cw_10]          0.0801      0.053      1.498      0.134      -0.025       0.185\n",
      "task_conversation[T.cw_100]         0.0840      0.052      1.615      0.106      -0.018       0.186\n",
      "task_conversation[T.cw_11]          0.2857      0.038      7.447      0.000       0.211       0.361\n",
      "task_conversation[T.cw_12]          0.1660      0.055      3.026      0.002       0.058       0.274\n",
      "task_conversation[T.cw_13]          0.1189      0.047      2.504      0.012       0.026       0.212\n",
      "task_conversation[T.cw_14]          0.1461      0.047      3.108      0.002       0.054       0.238\n",
      "task_conversation[T.cw_15]          0.0856      0.048      1.790      0.073      -0.008       0.179\n",
      "task_conversation[T.cw_16]          0.1078      0.038      2.835      0.005       0.033       0.182\n",
      "task_conversation[T.cw_17]          0.0813      0.050      1.635      0.102      -0.016       0.179\n",
      "task_conversation[T.cw_18]          0.0917      0.069      1.325      0.185      -0.044       0.227\n",
      "task_conversation[T.cw_19]          0.1420      0.047      3.035      0.002       0.050       0.234\n",
      "task_conversation[T.cw_2]           0.1454      0.060      2.441      0.015       0.029       0.262\n",
      "task_conversation[T.cw_20]          0.0578      0.044      1.303      0.192      -0.029       0.145\n",
      "task_conversation[T.cw_21]          0.2812      0.037      7.674      0.000       0.209       0.353\n",
      "task_conversation[T.cw_22]          0.2287      0.058      3.956      0.000       0.115       0.342\n",
      "task_conversation[T.cw_23]          0.2711      0.038      7.063      0.000       0.196       0.346\n",
      "task_conversation[T.cw_24]          0.2146      0.050      4.290      0.000       0.117       0.313\n",
      "task_conversation[T.cw_25]         -0.0219      0.046     -0.478      0.633      -0.112       0.068\n",
      "task_conversation[T.cw_26]          0.2632      0.043      6.058      0.000       0.178       0.348\n",
      "task_conversation[T.cw_27]          0.0534      0.042      1.280      0.200      -0.028       0.135\n",
      "task_conversation[T.cw_28]          0.1908      0.043      4.425      0.000       0.106       0.275\n",
      "task_conversation[T.cw_29]          0.2718      0.043      6.391      0.000       0.188       0.355\n",
      "task_conversation[T.cw_3]           0.1344      0.038      3.500      0.000       0.059       0.210\n",
      "task_conversation[T.cw_30]          0.1028      0.058      1.758      0.079      -0.012       0.217\n",
      "task_conversation[T.cw_31]          0.0543      0.041      1.329      0.184      -0.026       0.134\n",
      "task_conversation[T.cw_32]          0.0801      0.053      1.502      0.133      -0.024       0.185\n",
      "task_conversation[T.cw_33]          0.2079      0.044      4.753      0.000       0.122       0.294\n",
      "task_conversation[T.cw_34]          0.2697      0.047      5.757      0.000       0.178       0.361\n",
      "task_conversation[T.cw_35]          0.1003      0.054      1.871      0.061      -0.005       0.205\n",
      "task_conversation[T.cw_36]         -0.0277      0.052     -0.531      0.596      -0.130       0.075\n",
      "task_conversation[T.cw_37]          0.0360      0.060      0.598      0.550      -0.082       0.154\n",
      "task_conversation[T.cw_38]          0.1024      0.051      2.024      0.043       0.003       0.202\n",
      "task_conversation[T.cw_39]         -0.0396      0.036     -1.087      0.277      -0.111       0.032\n",
      "task_conversation[T.cw_4]           0.2671      0.040      6.750      0.000       0.190       0.345\n",
      "task_conversation[T.cw_40]          0.1080      0.066      1.635      0.102      -0.021       0.237\n",
      "task_conversation[T.cw_41]          0.0879      0.055      1.595      0.111      -0.020       0.196\n",
      "task_conversation[T.cw_42]          0.0249      0.040      0.627      0.531      -0.053       0.103\n",
      "task_conversation[T.cw_43]          0.1352      0.042      3.253      0.001       0.054       0.217\n",
      "task_conversation[T.cw_44]          0.2295      0.040      5.675      0.000       0.150       0.309\n",
      "task_conversation[T.cw_45]          0.3278      0.051      6.370      0.000       0.227       0.429\n",
      "task_conversation[T.cw_46]         -0.0864      0.042     -2.079      0.038      -0.168      -0.005\n",
      "task_conversation[T.cw_47]          0.0742      0.046      1.611      0.107      -0.016       0.164\n",
      "task_conversation[T.cw_48]          0.0213      0.040      0.534      0.593      -0.057       0.100\n",
      "task_conversation[T.cw_49]         -0.0343      0.046     -0.741      0.459      -0.125       0.056\n",
      "task_conversation[T.cw_5]           0.0751      0.042      1.806      0.071      -0.006       0.157\n",
      "task_conversation[T.cw_50]          0.1552      0.051      3.057      0.002       0.056       0.255\n",
      "task_conversation[T.cw_51]          0.2208      0.039      5.664      0.000       0.144       0.297\n",
      "task_conversation[T.cw_52]         -0.0016      0.048     -0.033      0.973      -0.096       0.093\n",
      "task_conversation[T.cw_53]          0.2898      0.038      7.589      0.000       0.215       0.365\n",
      "task_conversation[T.cw_54]          0.1816      0.048      3.800      0.000       0.088       0.275\n",
      "task_conversation[T.cw_55]          0.0907      0.052      1.739      0.082      -0.012       0.193\n",
      "task_conversation[T.cw_56]          0.0020      0.040      0.049      0.961      -0.077       0.081\n",
      "task_conversation[T.cw_57]          0.2737      0.039      7.068      0.000       0.198       0.350\n",
      "task_conversation[T.cw_58]          0.2521      0.040      6.313      0.000       0.174       0.330\n",
      "task_conversation[T.cw_59]          0.0935      0.051      1.839      0.066      -0.006       0.193\n",
      "task_conversation[T.cw_6]           0.1060      0.054      1.949      0.051      -0.001       0.213\n",
      "task_conversation[T.cw_60]         -0.0631      0.044     -1.444      0.149      -0.149       0.023\n",
      "task_conversation[T.cw_61]          0.0461      0.041      1.132      0.258      -0.034       0.126\n",
      "task_conversation[T.cw_62]          0.1414      0.056      2.504      0.012       0.031       0.252\n",
      "task_conversation[T.cw_63]          0.2477      0.056      4.462      0.000       0.139       0.357\n",
      "task_conversation[T.cw_64]          0.2044      0.044      4.631      0.000       0.118       0.291\n",
      "task_conversation[T.cw_65]          0.3109      0.039      7.915      0.000       0.234       0.388\n",
      "task_conversation[T.cw_66]          0.1877      0.043      4.327      0.000       0.103       0.273\n",
      "task_conversation[T.cw_67]          0.1839      0.047      3.889      0.000       0.091       0.277\n",
      "task_conversation[T.cw_68]          0.0139      0.055      0.254      0.799      -0.093       0.121\n",
      "task_conversation[T.cw_69]          0.2452      0.041      6.018      0.000       0.165       0.325\n",
      "task_conversation[T.cw_7]           0.0882      0.039      2.245      0.025       0.011       0.165\n",
      "task_conversation[T.cw_70]         -0.0475      0.045     -1.053      0.292      -0.136       0.041\n",
      "task_conversation[T.cw_71]          0.1263      0.080      1.587      0.113      -0.030       0.282\n",
      "task_conversation[T.cw_72]         -0.0342      0.044     -0.780      0.436      -0.120       0.052\n",
      "task_conversation[T.cw_73]          0.1291      0.047      2.760      0.006       0.037       0.221\n",
      "task_conversation[T.cw_74]          0.0503      0.043      1.173      0.241      -0.034       0.134\n",
      "task_conversation[T.cw_75]          0.2025      0.046      4.394      0.000       0.112       0.293\n",
      "task_conversation[T.cw_76]          0.1981      0.045      4.389      0.000       0.110       0.287\n",
      "task_conversation[T.cw_77]          0.2287      0.053      4.304      0.000       0.125       0.333\n",
      "task_conversation[T.cw_78]          0.2576      0.044      5.814      0.000       0.171       0.344\n",
      "task_conversation[T.cw_79]          0.2296      0.045      5.115      0.000       0.142       0.318\n",
      "task_conversation[T.cw_8]           0.1727      0.043      4.040      0.000       0.089       0.257\n",
      "task_conversation[T.cw_80]          0.2926      0.043      6.758      0.000       0.208       0.377\n",
      "task_conversation[T.cw_81]          0.3683      0.040      9.278      0.000       0.291       0.446\n",
      "task_conversation[T.cw_82]          0.0059      0.054      0.110      0.912      -0.100       0.112\n",
      "task_conversation[T.cw_83]          0.1329      0.046      2.888      0.004       0.043       0.223\n",
      "task_conversation[T.cw_84]          0.2010      0.036      5.577      0.000       0.130       0.272\n",
      "task_conversation[T.cw_85]          0.2235      0.042      5.369      0.000       0.142       0.305\n",
      "task_conversation[T.cw_86]         -0.0217      0.043     -0.503      0.615      -0.106       0.063\n",
      "task_conversation[T.cw_87]          0.0769      0.051      1.512      0.131      -0.023       0.177\n",
      "task_conversation[T.cw_88]          0.0963      0.053      1.823      0.068      -0.007       0.200\n",
      "task_conversation[T.cw_89]          0.0394      0.050      0.794      0.427      -0.058       0.137\n",
      "task_conversation[T.cw_9]           0.2611      0.039      6.637      0.000       0.184       0.338\n",
      "task_conversation[T.cw_90]          0.0312      0.054      0.581      0.561      -0.074       0.136\n",
      "task_conversation[T.cw_91]         -0.0761      0.060     -1.264      0.206      -0.194       0.042\n",
      "task_conversation[T.cw_92]          0.0123      0.052      0.238      0.812      -0.089       0.114\n",
      "task_conversation[T.cw_93]          0.0285      0.059      0.485      0.628      -0.087       0.144\n",
      "task_conversation[T.cw_94]          0.1397      0.058      2.395      0.017       0.025       0.254\n",
      "task_conversation[T.cw_95]         -0.0628      0.047     -1.330      0.183      -0.155       0.030\n",
      "task_conversation[T.cw_96]          0.1976      0.046      4.341      0.000       0.108       0.287\n",
      "task_conversation[T.cw_97]          0.0317      0.042      0.757      0.449      -0.050       0.114\n",
      "task_conversation[T.cw_98]          0.1974      0.044      4.500      0.000       0.111       0.283\n",
      "task_conversation[T.cw_99]          0.0923      0.044      2.083      0.037       0.005       0.179\n",
      "model[T.td3]                        0.0136      0.010      1.330      0.183      -0.006       0.034\n",
      "conversation_length_thousands       0.2121      0.045      4.693      0.000       0.124       0.301\n",
      "consolidated_num_steps_ideas        0.0096      0.004      2.193      0.028       0.001       0.018\n",
      "conversation_length_thousands_2    -0.1194      0.030     -3.979      0.000      -0.178      -0.061\n",
      "consolidated_num_steps_ideas_2  -2.548e-05      0.001     -0.037      0.971      -0.001       0.001\n",
      "fres                               -0.0112      0.004     -2.597      0.009      -0.020      -0.003\n",
      "fres_2                           8.196e-05   3.21e-05      2.554      0.011    1.91e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        9.659   Durbin-Watson:                   1.959\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):               13.160\n",
      "Skew:                           0.039   Prob(JB):                      0.00139\n",
      "Kurtosis:                       3.463   Cond. No.                     4.89e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 4.89e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "       Intercept task_conversation[T.cw_10] task_conversation[T.cw_100]  \\\n",
      "0  0.585* (0.15)               0.08 (0.053)               0.084 (0.052)   \n",
      "\n",
      "  task_conversation[T.cw_11] task_conversation[T.cw_12]  \\\n",
      "0             0.286* (0.038)             0.166* (0.055)   \n",
      "\n",
      "  task_conversation[T.cw_13] task_conversation[T.cw_14]  \\\n",
      "0             0.119* (0.047)             0.146* (0.047)   \n",
      "\n",
      "  task_conversation[T.cw_15] task_conversation[T.cw_16]  \\\n",
      "0              0.086 (0.048)             0.108* (0.038)   \n",
      "\n",
      "  task_conversation[T.cw_17]  ... task_conversation[T.cw_98]  \\\n",
      "0               0.081 (0.05)  ...             0.197* (0.044)   \n",
      "\n",
      "  task_conversation[T.cw_99]  model[T.td3] conversation_length_thousands  \\\n",
      "0             0.092* (0.044)  0.014 (0.01)                0.212* (0.045)   \n",
      "\n",
      "  consolidated_num_steps_ideas conversation_length_thousands_2  \\\n",
      "0                0.01* (0.004)                  -0.119* (0.03)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2             fres      fres_2  \\\n",
      "0                   -0.0 (0.001)  -0.011* (0.004)  0.0* (0.0)   \n",
      "\n",
      "                                Title  \n",
      "0  Creative Writing Cosine Similarity  \n",
      "\n",
      "[1 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "reg_with_clustering_cw = smf.ols(\"avg_inter_paragraph_cosine_sim ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + fres + fres_2 + task_conversation + model\",\n",
    "                                 data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(reg_with_clustering_cw.summary())\n",
    "\n",
    "# # Results for table\n",
    "# # Get conversation_length_thousands coefficient, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas coefficient, star for significant, sd\n",
    "# # Also get conversation_length_thousands_2 coefficient, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas_2 coefficient, star for significant, sd\n",
    "# # Also get fres coefficient, star for significant, sd\n",
    "# # Also get fres_2 coefficient, star for significant, sd\n",
    "# # Title \"Creative Writing Cosine Similarity\"\n",
    "# coef_names = reg_with_clustering_cw.params.index\n",
    "# #print(coef_names)\n",
    "# coef_values = reg_with_clustering_cw.params.values\n",
    "# #print(coef_values)\n",
    "# sds = reg_with_clustering_cw.bse.values\n",
    "# #print(sds)\n",
    "# p_values = reg_with_clustering_cw.pvalues.values\n",
    "# #print(p_values)\n",
    "\n",
    "# # Loop over items in coef_names, enumerated\n",
    "# string_entries = []\n",
    "# for i, coef_name in enumerate(coef_names):\n",
    "#     # Print coef_name, coef_values[i], sds[i], p_values[i]\n",
    "#     #print(coef_name, coef_values[i], sds[i], p_values[i])\n",
    "#     # Consolidate coef_values[i], sds[i], p_values[i] into a string\n",
    "#     # coef_value* (sd), where the star is if p_value < 0.05\n",
    "#     if p_values[i] < 0.05:\n",
    "#         string_entries.append(str(round(coef_values[i], 3)) + \"* (\" + str(round(sds[i], 3)) + \")\")\n",
    "#     else:\n",
    "#         string_entries.append(str(round(coef_values[i], 3)) + \" (\" + str(round(sds[i], 3)) + \")\")\n",
    "\n",
    "# # Make a dataframe with one row with columns of coef_names and values of string_entries\n",
    "# # Print the dataframe\n",
    "# reg_with_clustering_cw_df = pd.DataFrame([string_entries], columns=coef_names)\n",
    "# # Add column Title\n",
    "# reg_with_clustering_cw_df['Title'] = \"GSM8K Correct, Linear\"\n",
    "# print(reg_with_clustering_cw)\n",
    "\n",
    "# Use function to create results df\n",
    "reg_with_clustering_cw_df = create_linear_results_df(reg_with_clustering_cw, \"Creative Writing Cosine Similarity\")\n",
    "print(reg_with_clustering_cw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check task compliance as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_task_method', 'conversation_number', 'coherence_1_incoherent_10_very_coherent', 'compliance_OLD', 'ease_of_review_1_easy_10_hard', 'correct', 'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10', 'Aggregated_Prediction', 'Prediction_Based_On_First_10_LP', 'response_Based_On_First_10_LP', 'Prediction_Based_On_Last_10_LP', 'response_Based_On_Last_10_LP', 'response_LP', 'Aggregated_Prediction_LP', 'Prediction_Based_On_First_50_LP', 'response_Based_On_First_50_LP', 'Prediction_Based_On_Last_50_LP', 'response_Based_On_Last_50_LP', 'Aggregated_Prediction_50_LP', 'Prediction_Based_On_random_50_LP_1', 'response_Based_On_random_50_LP_1', 'Prediction_Based_On_random_50_LP_2', 'response_Based_On_random_50_LP_2', 'Aggregated_Prediction_random_50_LP', 'Unnamed: 0_x', 'response_x', 'replace_slash_n_slash_n_with_newline_x', 'replace_slash_n_slash_n_with_newline_values_x', 'replace_slash_n_with_newline_x', 'replace_slash_n_with_newline_values_x', 'avg_cosine_sim', 'num_sentences_x', 'Unnamed: 0_y', 'response_y', 'replace_slash_n_slash_n_with_newline_y', 'replace_slash_n_slash_n_with_newline_values_y', 'replace_slash_n_with_newline_y', 'replace_slash_n_with_newline_values_y', 'avg_inter_paragraph_cosine_sim', 'num_paragraphs', 'num_sentences_y', 'cosine_sims', 'conversation_length', 'input_length', 'output_length', 'conversation_cost', 'gsm8k_question_index', 'gsm8k_answer', 'gsm8k_length_vs_provided', 'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres', 'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided', 'num_sentences_provided', 'num_step_i_provided', 'num_1_dot_etc_provided', 'length_provided', 'compliance', 'coherence_1_incoherent_10_very_coherent_compliance_adjusted', 'Aggregated_Prediction_random_50_LP_compliance_adjusted', 'avg_cosine_sim_compliance_adjusted', 'avg_inter_paragraph_cosine_sim_compliance_adjusted', 'model', 'task', 'method', 'Model', 'Method', 'Task', 'accuracy_quality', 'accuracy_quality_compliance_adjusted', 'accuracy_quality_avg_inter_paragraph_cosine_sim', 'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_prompts', 'consolidated_num_steps_ideas_provided', 'technique_name', 'ss_publication_date', 'ss_publication_date_datetime', 'Method + Publication Date', 'Publication Date', 'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'sentence_length_prompts_diff', 'fres_prompts_diff', 'num_linebreaks_provided_diff', 'num_sentences_provided_diff', 'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff', 'conversation_length_thousands', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas_2', 'fres_2', 'task_conversation_method', 'task_conversation']\n"
     ]
    }
   ],
   "source": [
    "print(list(cw_data.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654309\n",
      "         Iterations 5\n",
      "logit no clustering cw compliance\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   No. Observations:                 1434\n",
      "Model:                          Logit   Df Residuals:                     1426\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Mon, 11 Dec 2023   Pseudo R-squ.:                 0.05297\n",
      "Time:                        15:44:18   Log-Likelihood:                -938.28\n",
      "converged:                       True   LL-Null:                       -990.76\n",
      "Covariance Type:                  HC3   LLR p-value:                 1.019e-19\n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          -5.6147      2.459     -2.283      0.022     -10.434      -0.795\n",
      "model[T.td3]                       -1.1195      0.145     -7.713      0.000      -1.404      -0.835\n",
      "conversation_length_thousands      -2.4087      0.707     -3.407      0.001      -3.795      -1.023\n",
      "consolidated_num_steps_ideas       -0.1075      0.077     -1.395      0.163      -0.258       0.044\n",
      "conversation_length_thousands_2     0.9949      0.478      2.082      0.037       0.058       1.931\n",
      "consolidated_num_steps_ideas_2      0.0208      0.014      1.529      0.126      -0.006       0.047\n",
      "fres                                0.1761      0.073      2.415      0.016       0.033       0.319\n",
      "fres_2                             -0.0010      0.001     -1.966      0.049      -0.002   -3.11e-06\n",
      "===================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:             compliance\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                       -0.2588      0.031     -8.385      0.000      -0.319      -0.198\n",
      "conversation_length_thousands      -0.5569      0.161     -3.456      0.001      -0.873      -0.241\n",
      "consolidated_num_steps_ideas       -0.0248      0.018     -1.398      0.162      -0.060       0.010\n",
      "conversation_length_thousands_2     0.2300      0.110      2.093      0.036       0.015       0.445\n",
      "consolidated_num_steps_ideas_2      0.0048      0.003      1.534      0.125      -0.001       0.011\n",
      "fres                                0.0407      0.017      2.435      0.015       0.008       0.073\n",
      "fres_2                             -0.0002      0.000     -1.977      0.048      -0.000   -2.04e-06\n",
      "===================================================================================================\n",
      "      model[T.td3] conversation_length_thousands consolidated_num_steps_ideas  \\\n",
      "0  -0.259* (0.031)               -0.557* (0.161)               -0.025 (0.018)   \n",
      "\n",
      "  conversation_length_thousands_2 consolidated_num_steps_ideas_2  \\\n",
      "0                    0.23* (0.11)                  0.005 (0.003)   \n",
      "\n",
      "             fres       fres_2                               Title  \n",
      "0  0.041* (0.017)  -0.0* (0.0)  Creative Writing Compliance, Logit  \n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_cw_compliance = smf.logit('compliance ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + fres + fres_2 + model', data=cw_data).fit(cov_type='HC3')\n",
    "\n",
    "print('logit no clustering cw compliance')\n",
    "# Display the summary\n",
    "print(logit_no_clustering_cw_compliance.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_cw_compliance_marginal_effects = logit_no_clustering_cw_compliance.get_margeff(at='overall')\n",
    "print(logit_no_clustering_cw_compliance_marginal_effects.summary())\n",
    "\n",
    "# # Results for table\n",
    "# # Get conversation_length_thousands marginal effect, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas marginal effect, star for significant, sd\n",
    "# # Also get conversation_length_thousands_2 marginal effect, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas_2 marginal effect, star for significant, sd\n",
    "# # Also get fres marginal effect, star for significant, sd\n",
    "# # Also get fres_2 marginal effect, star for significant, sd\n",
    "# # Title: \"Creative Writing Compliance, Logit\"\n",
    "# coef_names = logit_no_clustering_cw_compliance.params.index\n",
    "# #print(coef_names)\n",
    "# coef_names_with_mes = list(logit_no_clustering_cw_compliance.params.index)[1:]\n",
    "# #print(coef_names_with_mes)\n",
    "# me_values = logit_no_clustering_cw_compliance_marginal_effects.margeff\n",
    "# #print(me_values)\n",
    "# me_ses = logit_no_clustering_cw_compliance_marginal_effects.margeff_se\n",
    "# #print(me_ses)\n",
    "# p_values = logit_no_clustering_cw_compliance_marginal_effects.pvalues\n",
    "# #print(p_values)\n",
    "# # Loop over items in coef_names_with_mes, enumerated\n",
    "# string_entries = []\n",
    "\n",
    "# for i, coef_name in enumerate(coef_names_with_mes):\n",
    "#     # Print coef_name, me_values[i], me_ses[i], p_values[i]\n",
    "#     #print(coef_name, me_values[i], me_ses[i], p_values[i])\n",
    "#     # Consolidate me_values[i], me_ses[i], p_values[i] into a string\n",
    "#     # me_value* (me_se), where the star is if p_value < 0.05\n",
    "#     if p_values[i] < 0.05:\n",
    "#         string_entries.append(str(round(me_values[i], 3)) + \"* (\" + str(round(me_ses[i], 3)) + \")\")\n",
    "#     else:\n",
    "#         string_entries.append(str(round(me_values[i], 3)) + \" (\" + str(round(me_ses[i], 3)) + \")\")\n",
    "\n",
    "# # Make a dataframe with one row with columns of coef_names_with_mes and values of string_entries\n",
    "# # Print the dataframe\n",
    "# logit_no_clustering_cw_compliance_marginal_effects_df = pd.DataFrame([string_entries], columns=coef_names_with_mes)\n",
    "# # Add column Title\n",
    "# logit_no_clustering_cw_compliance_marginal_effects_df['Title'] = \"Creative Writing Compliance, Logit\"\n",
    "# print(logit_no_clustering_cw_compliance_marginal_effects_df)\n",
    "\n",
    "# Use function to create results df\n",
    "logit_no_clustering_cw_compliance_df = create_logit_results_df(logit_no_clustering_cw_compliance, logit_no_clustering_cw_compliance_marginal_effects, \"Creative Writing Compliance, Logit\")\n",
    "print(logit_no_clustering_cw_compliance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpm with clustering cw compliance\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   R-squared:                       0.203\n",
      "Model:                            OLS   Adj. R-squared:                  0.140\n",
      "Method:                 Least Squares   F-statistic:                     12.22\n",
      "Date:                Mon, 11 Dec 2023   Prob (F-statistic):          5.08e-108\n",
      "Time:                        15:44:18   Log-Likelihood:                -874.55\n",
      "No. Observations:                1434   AIC:                             1963.\n",
      "Df Residuals:                    1327   BIC:                             2527.\n",
      "Df Model:                         106                                         \n",
      "Covariance Type:              cluster                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          -0.9952      0.556     -1.789      0.074      -2.085       0.095\n",
      "task_conversation[T.cw_10]         -0.0568      0.162     -0.350      0.727      -0.375       0.261\n",
      "task_conversation[T.cw_100]         0.0324      0.165      0.196      0.844      -0.291       0.356\n",
      "task_conversation[T.cw_11]         -0.0459      0.205     -0.223      0.823      -0.448       0.356\n",
      "task_conversation[T.cw_12]         -0.2910      0.162     -1.794      0.073      -0.609       0.027\n",
      "task_conversation[T.cw_13]          0.1099      0.219      0.501      0.616      -0.320       0.540\n",
      "task_conversation[T.cw_14]          0.2267      0.165      1.375      0.169      -0.096       0.550\n",
      "task_conversation[T.cw_15]         -0.0279      0.182     -0.153      0.878      -0.385       0.329\n",
      "task_conversation[T.cw_16]         -0.1075      0.166     -0.649      0.516      -0.432       0.217\n",
      "task_conversation[T.cw_17]          0.1649      0.163      1.013      0.311      -0.154       0.484\n",
      "task_conversation[T.cw_18]          0.1384      0.198      0.698      0.485      -0.250       0.527\n",
      "task_conversation[T.cw_19]          0.2465      0.222      1.112      0.266      -0.188       0.681\n",
      "task_conversation[T.cw_2]          -0.0670      0.194     -0.345      0.730      -0.448       0.314\n",
      "task_conversation[T.cw_20]          0.1666      0.201      0.827      0.408      -0.228       0.561\n",
      "task_conversation[T.cw_21]          0.2140      0.178      1.205      0.228      -0.134       0.562\n",
      "task_conversation[T.cw_22]          0.2397      0.162      1.478      0.139      -0.078       0.557\n",
      "task_conversation[T.cw_23]          0.1263      0.191      0.662      0.508      -0.248       0.500\n",
      "task_conversation[T.cw_24]          0.0425      0.169      0.252      0.801      -0.288       0.373\n",
      "task_conversation[T.cw_25]          0.2698      0.185      1.456      0.145      -0.093       0.633\n",
      "task_conversation[T.cw_26]          0.2256      0.156      1.447      0.148      -0.080       0.531\n",
      "task_conversation[T.cw_27]          0.0769      0.194      0.397      0.691      -0.302       0.456\n",
      "task_conversation[T.cw_28]         -0.0402      0.166     -0.242      0.809      -0.366       0.285\n",
      "task_conversation[T.cw_29]         -0.4053      0.146     -2.768      0.006      -0.692      -0.118\n",
      "task_conversation[T.cw_3]           0.2243      0.190      1.180      0.238      -0.148       0.597\n",
      "task_conversation[T.cw_30]          0.1584      0.165      0.957      0.338      -0.166       0.483\n",
      "task_conversation[T.cw_31]          0.0013      0.200      0.007      0.995      -0.391       0.394\n",
      "task_conversation[T.cw_32]          0.3167      0.184      1.717      0.086      -0.045       0.678\n",
      "task_conversation[T.cw_33]         -0.0305      0.175     -0.174      0.862      -0.374       0.313\n",
      "task_conversation[T.cw_34]          0.1047      0.175      0.597      0.550      -0.239       0.448\n",
      "task_conversation[T.cw_35]          0.2865      0.174      1.643      0.100      -0.055       0.628\n",
      "task_conversation[T.cw_36]          0.0744      0.210      0.354      0.723      -0.337       0.486\n",
      "task_conversation[T.cw_37]          0.1771      0.161      1.098      0.272      -0.139       0.493\n",
      "task_conversation[T.cw_38]          0.0658      0.191      0.344      0.731      -0.309       0.441\n",
      "task_conversation[T.cw_39]          0.1291      0.201      0.642      0.521      -0.265       0.523\n",
      "task_conversation[T.cw_4]           0.2670      0.193      1.381      0.167      -0.112       0.646\n",
      "task_conversation[T.cw_40]         -0.0990      0.190     -0.522      0.602      -0.471       0.273\n",
      "task_conversation[T.cw_41]          0.0791      0.180      0.440      0.660      -0.273       0.431\n",
      "task_conversation[T.cw_42]          0.1973      0.166      1.191      0.234      -0.127       0.522\n",
      "task_conversation[T.cw_43]          0.1955      0.177      1.102      0.271      -0.152       0.543\n",
      "task_conversation[T.cw_44]         -0.0992      0.165     -0.600      0.548      -0.423       0.225\n",
      "task_conversation[T.cw_45]         -0.1138      0.180     -0.631      0.528      -0.467       0.240\n",
      "task_conversation[T.cw_46]          0.1827      0.192      0.951      0.342      -0.194       0.559\n",
      "task_conversation[T.cw_47]         -0.1904      0.174     -1.097      0.273      -0.531       0.150\n",
      "task_conversation[T.cw_48]          0.1270      0.183      0.693      0.488      -0.232       0.486\n",
      "task_conversation[T.cw_49]          0.0328      0.172      0.190      0.849      -0.305       0.370\n",
      "task_conversation[T.cw_5]           0.2649      0.173      1.528      0.126      -0.075       0.605\n",
      "task_conversation[T.cw_50]         -0.2891      0.148     -1.949      0.051      -0.580       0.002\n",
      "task_conversation[T.cw_51]          0.2428      0.186      1.304      0.192      -0.122       0.608\n",
      "task_conversation[T.cw_52]          0.0077      0.195      0.040      0.968      -0.374       0.390\n",
      "task_conversation[T.cw_53]          0.2346      0.214      1.096      0.273      -0.185       0.654\n",
      "task_conversation[T.cw_54]          0.1014      0.220      0.460      0.645      -0.330       0.533\n",
      "task_conversation[T.cw_55]          0.0691      0.166      0.417      0.677      -0.256       0.394\n",
      "task_conversation[T.cw_56]          0.3642      0.179      2.035      0.042       0.013       0.715\n",
      "task_conversation[T.cw_57]         -0.3006      0.161     -1.862      0.063      -0.617       0.016\n",
      "task_conversation[T.cw_58]          0.1861      0.185      1.008      0.314      -0.176       0.548\n",
      "task_conversation[T.cw_59]          0.1831      0.184      0.993      0.321      -0.178       0.544\n",
      "task_conversation[T.cw_6]          -0.2957      0.147     -2.007      0.045      -0.585      -0.007\n",
      "task_conversation[T.cw_60]         -0.3021      0.147     -2.056      0.040      -0.590      -0.014\n",
      "task_conversation[T.cw_61]          0.0094      0.187      0.051      0.960      -0.356       0.375\n",
      "task_conversation[T.cw_62]          0.0892      0.200      0.446      0.656      -0.303       0.481\n",
      "task_conversation[T.cw_63]         -0.0658      0.200     -0.329      0.743      -0.458       0.327\n",
      "task_conversation[T.cw_64]          0.2780      0.203      1.367      0.172      -0.121       0.677\n",
      "task_conversation[T.cw_65]          0.2532      0.187      1.351      0.177      -0.114       0.621\n",
      "task_conversation[T.cw_66]         -0.1336      0.182     -0.733      0.463      -0.491       0.223\n",
      "task_conversation[T.cw_67]          0.3931      0.202      1.951      0.051      -0.002       0.788\n",
      "task_conversation[T.cw_68]          0.1711      0.199      0.860      0.390      -0.219       0.561\n",
      "task_conversation[T.cw_69]         -0.1615      0.175     -0.924      0.355      -0.504       0.181\n",
      "task_conversation[T.cw_7]          -0.1069      0.166     -0.643      0.520      -0.433       0.219\n",
      "task_conversation[T.cw_70]          0.2585      0.186      1.388      0.165      -0.106       0.623\n",
      "task_conversation[T.cw_71]          0.1100      0.206      0.535      0.593      -0.293       0.513\n",
      "task_conversation[T.cw_72]          0.2540      0.158      1.608      0.108      -0.056       0.564\n",
      "task_conversation[T.cw_73]         -0.2219      0.171     -1.298      0.194      -0.557       0.113\n",
      "task_conversation[T.cw_74]          0.1924      0.208      0.923      0.356      -0.216       0.601\n",
      "task_conversation[T.cw_75]          0.0462      0.176      0.263      0.793      -0.299       0.391\n",
      "task_conversation[T.cw_76]         -0.3110      0.166     -1.876      0.061      -0.636       0.014\n",
      "task_conversation[T.cw_77]          0.2586      0.158      1.632      0.103      -0.052       0.569\n",
      "task_conversation[T.cw_78]          0.0830      0.212      0.391      0.696      -0.333       0.499\n",
      "task_conversation[T.cw_79]          0.1581      0.212      0.745      0.456      -0.258       0.574\n",
      "task_conversation[T.cw_8]           0.3445      0.184      1.873      0.061      -0.016       0.705\n",
      "task_conversation[T.cw_80]          0.1244      0.178      0.700      0.484      -0.224       0.473\n",
      "task_conversation[T.cw_81]          0.6115      0.160      3.826      0.000       0.298       0.925\n",
      "task_conversation[T.cw_82]         -0.0136      0.209     -0.065      0.948      -0.423       0.395\n",
      "task_conversation[T.cw_83]          0.0738      0.207      0.357      0.721      -0.331       0.479\n",
      "task_conversation[T.cw_84]         -0.1217      0.158     -0.769      0.442      -0.432       0.188\n",
      "task_conversation[T.cw_85]         -0.0921      0.174     -0.529      0.597      -0.433       0.249\n",
      "task_conversation[T.cw_86]          0.2399      0.189      1.267      0.205      -0.131       0.611\n",
      "task_conversation[T.cw_87]          0.2114      0.192      1.104      0.270      -0.164       0.587\n",
      "task_conversation[T.cw_88]         -0.1538      0.173     -0.888      0.375      -0.493       0.186\n",
      "task_conversation[T.cw_89]          0.1239      0.214      0.578      0.563      -0.296       0.544\n",
      "task_conversation[T.cw_9]           0.1706      0.182      0.940      0.347      -0.185       0.526\n",
      "task_conversation[T.cw_90]          0.0704      0.204      0.345      0.730      -0.329       0.470\n",
      "task_conversation[T.cw_91]          0.2299      0.215      1.071      0.284      -0.191       0.651\n",
      "task_conversation[T.cw_92]          0.2170      0.178      1.216      0.224      -0.133       0.567\n",
      "task_conversation[T.cw_93]          0.1720      0.211      0.815      0.415      -0.242       0.586\n",
      "task_conversation[T.cw_94]         -0.0360      0.182     -0.198      0.843      -0.393       0.321\n",
      "task_conversation[T.cw_95]          0.2911      0.174      1.671      0.095      -0.050       0.633\n",
      "task_conversation[T.cw_96]          0.3790      0.175      2.160      0.031       0.035       0.723\n",
      "task_conversation[T.cw_97]          0.1041      0.191      0.545      0.585      -0.270       0.478\n",
      "task_conversation[T.cw_98]          0.2322      0.192      1.210      0.226      -0.144       0.608\n",
      "task_conversation[T.cw_99]         -0.0916      0.174     -0.527      0.598      -0.432       0.249\n",
      "model[T.td3]                       -0.2439      0.035     -6.989      0.000      -0.312      -0.176\n",
      "conversation_length_thousands      -0.5305      0.158     -3.366      0.001      -0.839      -0.222\n",
      "consolidated_num_steps_ideas       -0.0334      0.016     -2.134      0.033      -0.064      -0.003\n",
      "conversation_length_thousands_2     0.2256      0.107      2.099      0.036       0.015       0.436\n",
      "consolidated_num_steps_ideas_2      0.0061      0.003      2.359      0.018       0.001       0.011\n",
      "fres                                0.0450      0.016      2.871      0.004       0.014       0.076\n",
      "fres_2                             -0.0003      0.000     -2.449      0.014      -0.001   -5.65e-05\n",
      "==============================================================================\n",
      "Omnibus:                     4778.065   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.476\n",
      "Skew:                           0.033   Prob(JB):                     3.39e-23\n",
      "Kurtosis:                       1.686   Cond. No.                     4.89e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 4.89e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "        Intercept task_conversation[T.cw_10] task_conversation[T.cw_100]  \\\n",
      "0  -0.995 (0.556)             -0.057 (0.162)               0.032 (0.165)   \n",
      "\n",
      "  task_conversation[T.cw_11] task_conversation[T.cw_12]  \\\n",
      "0             -0.046 (0.205)             -0.291 (0.162)   \n",
      "\n",
      "  task_conversation[T.cw_13] task_conversation[T.cw_14]  \\\n",
      "0               0.11 (0.219)              0.227 (0.165)   \n",
      "\n",
      "  task_conversation[T.cw_15] task_conversation[T.cw_16]  \\\n",
      "0             -0.028 (0.182)             -0.108 (0.166)   \n",
      "\n",
      "  task_conversation[T.cw_17]  ... task_conversation[T.cw_98]  \\\n",
      "0              0.165 (0.163)  ...              0.232 (0.192)   \n",
      "\n",
      "  task_conversation[T.cw_99]     model[T.td3] conversation_length_thousands  \\\n",
      "0             -0.092 (0.174)  -0.244* (0.035)               -0.531* (0.158)   \n",
      "\n",
      "  consolidated_num_steps_ideas conversation_length_thousands_2  \\\n",
      "0              -0.033* (0.016)                  0.226* (0.107)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2            fres       fres_2  \\\n",
      "0                 0.006* (0.003)  0.045* (0.016)  -0.0* (0.0)   \n",
      "\n",
      "                                 Title  \n",
      "0  Creative Writing Compliance, Linear  \n",
      "\n",
      "[1 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_cw_compliance = smf.ols('compliance ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + fres + fres_2 + task_conversation + model', data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print('lpm with clustering cw compliance')\n",
    "print(lpm_with_clustering_cw_compliance.summary())\n",
    "\n",
    "# # Results for table\n",
    "# # Get conversation_length_thousands coefficient, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas coefficient, star for significant, sd\n",
    "# # Also get conversation_length_thousands_2 coefficient, star for significant, sd\n",
    "# # Also get consolidated_num_steps_ideas_2 coefficient, star for significant, sd\n",
    "# # Also get fres coefficient, star for significant, sd\n",
    "# # Also get fres_2 coefficient, star for significant, sd\n",
    "# # Title: \"Creative Writing Compliance, Linear\"\n",
    "# coef_names = lpm_with_clustering_cw_compliance.params.index\n",
    "# #print(coef_names)\n",
    "# coef_values = lpm_with_clustering_cw_compliance.params.values\n",
    "# #print(coef_values)\n",
    "# sds = lpm_with_clustering_cw_compliance.bse.values\n",
    "# #print(sds)\n",
    "# p_values = lpm_with_clustering_cw_compliance.pvalues.values\n",
    "# #print(p_values)\n",
    "\n",
    "# # Loop over items in coef_names, enumerated\n",
    "# string_entries = []\n",
    "# for i, coef_name in enumerate(coef_names):\n",
    "#     # Print coef_name, coef_values[i], sds[i], p_values[i]\n",
    "#     #print(coef_name, coef_values[i], sds[i], p_values[i])\n",
    "#     # Consolidate coef_values[i], sds[i], p_values[i] into a string\n",
    "#     # coef_value* (sd), where the star is if p_value < 0.05\n",
    "#     if p_values[i] < 0.05:\n",
    "#         string_entries.append(str(round(coef_values[i], 3)) + \"* (\" + str(round(sds[i], 3)) + \")\")\n",
    "#     else:\n",
    "#         string_entries.append(str(round(coef_values[i], 3)) + \" (\" + str(round(sds[i], 3)) + \")\")\n",
    "\n",
    "# # Make a dataframe with one row with columns of coef_names and values of string_entries\n",
    "# # Print the dataframe\n",
    "# lpm_with_clustering_cw_compliance_df = pd.DataFrame([string_entries], columns=coef_names)\n",
    "# # Add column Title\n",
    "# lpm_with_clustering_cw_compliance_df['Title'] = \"GSM8K Correct, Linear\"\n",
    "# print(lpm_with_clustering_cw_compliance_df)\n",
    "\n",
    "# Use function to create results df\n",
    "lpm_with_clustering_cw_compliance_df = create_linear_results_df(lpm_with_clustering_cw_compliance, \"Creative Writing Compliance, Linear\")\n",
    "print(lpm_with_clustering_cw_compliance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}}\n",
      "\\toprule\n",
      "\\hline\n",
      "Model & Conversation Length (Thousands of Tokens) & Conversation Length (Thousands of Tokens) Squared & Number of Steps/Ideas & Number of Steps/Ideas Squared & Flesch Reading Ease & Flesch Reading Ease Squared \\\\\n",
      "\\hline\n",
      "\\midrule\n",
      "GSM8K Correct, Logit & 0.277 (0.143) & -0.498* (0.127) & 0.029* (0.007) & -0.002* (0.0) &  &  \\\\\n",
      "\\hline\n",
      "GSM8K Correct, Linear & 0.282* (0.114) & -0.418* (0.091) & 0.043* (0.006) & -0.002* (0.0) &  &  \\\\\n",
      "\\hline\n",
      "Creative Writing Cosine Similarity & 0.212* (0.045) & -0.119* (0.03) & 0.01* (0.004) & -0.0 (0.001) & -0.011* (0.004) & 0.0* (0.0) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Logit & -0.557* (0.161) & 0.23* (0.11) & -0.025 (0.018) & 0.005 (0.003) & 0.041* (0.017) & -0.0* (0.0) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Linear & -0.531* (0.158) & 0.226* (0.107) & -0.033* (0.016) & 0.006* (0.003) & 0.045* (0.016) & -0.0* (0.0) \\\\\n",
      "\\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "                                 Model  \\\n",
      "0                 GSM8K Correct, Logit   \n",
      "1                GSM8K Correct, Linear   \n",
      "2   Creative Writing Cosine Similarity   \n",
      "3   Creative Writing Compliance, Logit   \n",
      "4  Creative Writing Compliance, Linear   \n",
      "\n",
      "  Conversation Length (Thousands of Tokens)  \\\n",
      "0                             0.277 (0.143)   \n",
      "1                            0.282* (0.114)   \n",
      "2                            0.212* (0.045)   \n",
      "3                           -0.557* (0.161)   \n",
      "4                           -0.531* (0.158)   \n",
      "\n",
      "  Conversation Length (Thousands of Tokens) Squared Number of Steps/Ideas  \\\n",
      "0                                   -0.498* (0.127)        0.029* (0.007)   \n",
      "1                                   -0.418* (0.091)        0.043* (0.006)   \n",
      "2                                    -0.119* (0.03)         0.01* (0.004)   \n",
      "3                                      0.23* (0.11)        -0.025 (0.018)   \n",
      "4                                    0.226* (0.107)       -0.033* (0.016)   \n",
      "\n",
      "  Number of Steps/Ideas Squared Flesch Reading Ease  \\\n",
      "0                 -0.002* (0.0)                       \n",
      "1                 -0.002* (0.0)                       \n",
      "2                  -0.0 (0.001)     -0.011* (0.004)   \n",
      "3                 0.005 (0.003)      0.041* (0.017)   \n",
      "4                0.006* (0.003)      0.045* (0.016)   \n",
      "\n",
      "  Flesch Reading Ease Squared  \n",
      "0                              \n",
      "1                              \n",
      "2                  0.0* (0.0)  \n",
      "3                 -0.0* (0.0)  \n",
      "4                 -0.0* (0.0)  \n",
      "\\begin{tabular}{x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}}\n",
      "\\toprule\n",
      "\\hline\n",
      "Model & Conversation Length (Thousands of Tokens) & Conversation Length (Thousands of Tokens) Squared & Number of Steps/Ideas & Number of Steps/Ideas Squared & Flesch Reading Ease & Flesch Reading Ease Squared \\\\\n",
      "\\hline\n",
      "\\midrule\n",
      "GSM8K Correct, Logit & 0.277 (0.143) & -0.498* (0.127) & 0.029* (0.007) & -0.002* (0.0) &  &  \\\\\n",
      "\\hline\n",
      "GSM8K Correct, Linear & 0.282* (0.114) & -0.418* (0.091) & 0.043* (0.006) & -0.002* (0.0) &  &  \\\\\n",
      "\\hline\n",
      "Creative Writing Cosine Similarity & 0.212* (0.045) & -0.119* (0.03) & 0.01* (0.004) & -0.0 (0.001) & -0.011* (0.004) & 0.0* (0.0) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Logit & -0.557* (0.161) & 0.23* (0.11) & -0.025 (0.018) & 0.005 (0.003) & 0.041* (0.017) & -0.0* (0.0) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Linear & -0.531* (0.158) & 0.226* (0.107) & -0.033* (0.016) & 0.006* (0.003) & 0.045* (0.016) & -0.0* (0.0) \\\\\n",
      "\\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack results dataframes together for output\n",
    "results_df = pd.concat([logit_no_clustering_gsm8k_df, lpm_with_clustering_gsm8k_df, reg_with_clustering_cw_df, logit_no_clustering_cw_compliance_df, lpm_with_clustering_cw_compliance_df], ignore_index=True)\n",
    "\n",
    "# Limit columns to Title, conversation_length_thousands, consolidated_num_steps_ideas, conversation_length_thousands_2, consolidated_num_steps_ideas_2, fres, fres_2\n",
    "results_df = results_df[['Title', 'conversation_length_thousands', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_2', 'fres', 'fres_2']]\n",
    "\n",
    "# Replace NaN with blanks\n",
    "results_df = results_df.fillna('')\n",
    "\n",
    "# Rename Title to Model, rename conversation_length_thousands to Conversation Length, rename consolidated_num_steps_ideas to Number of Steps/Ideas, rename conversation_length_thousands_2 to Conversation Length Squared, rename consolidated_num_steps_ideas_2 to Number of Steps/Ideas Squared, rename fres to FRES, rename fres_2 to FRES Squared\n",
    "results_df = results_df.rename(columns={'Title': 'Model', 'conversation_length_thousands': 'Conversation Length (Thousands of Tokens)', 'consolidated_num_steps_ideas': 'Number of Steps/Ideas', 'conversation_length_thousands_2': 'Conversation Length (Thousands of Tokens) Squared', 'consolidated_num_steps_ideas_2': 'Number of Steps/Ideas Squared', 'fres': 'Flesch Reading Ease', 'fres_2': 'Flesch Reading Ease Squared'})\n",
    "\n",
    "# Output to latex. center columns, wrap text, and remove index\n",
    "latex_string = results_df.to_latex(index=False, \n",
    "                      column_format='x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}', \n",
    "                      #booktabs = True\n",
    "                      #longtable = True\n",
    "                      )\n",
    "\n",
    "# Add lines between rows\n",
    "lines = latex_string.split('\\n')\n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(line)\n",
    "    if '\\\\' in line and '&' in line:  # Identifies a row of the table\n",
    "        new_lines.append('\\\\hline')\n",
    "# Insert \\\\hline after \\toprule\n",
    "new_lines.insert(2, '\\\\hline')\n",
    "\n",
    "# Rejoin the modified lines\n",
    "modified_latex_table = '\\n'.join(new_lines)\n",
    "\n",
    "print(modified_latex_table)\n",
    "\n",
    "# Save string to file\n",
    "with open('../Output/regressions.tex', 'w') as f:\n",
    "    f.write(modified_latex_table)\n",
    "\n",
    "# Print results_df\n",
    "print(results_df)\n",
    "\n",
    "# Print modifed latex table\n",
    "print(modified_latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K Regression with Provided Answer Complexity Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_task_method', 'conversation_number', 'coherence_1_incoherent_10_very_coherent', 'compliance_OLD', 'ease_of_review_1_easy_10_hard', 'correct', 'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10', 'Aggregated_Prediction', 'Prediction_Based_On_First_10_LP', 'response_Based_On_First_10_LP', 'Prediction_Based_On_Last_10_LP', 'response_Based_On_Last_10_LP', 'response_LP', 'Aggregated_Prediction_LP', 'Prediction_Based_On_First_50_LP', 'response_Based_On_First_50_LP', 'Prediction_Based_On_Last_50_LP', 'response_Based_On_Last_50_LP', 'Aggregated_Prediction_50_LP', 'Prediction_Based_On_random_50_LP_1', 'response_Based_On_random_50_LP_1', 'Prediction_Based_On_random_50_LP_2', 'response_Based_On_random_50_LP_2', 'Aggregated_Prediction_random_50_LP', 'Unnamed: 0_x', 'response_x', 'replace_slash_n_slash_n_with_newline_x', 'replace_slash_n_slash_n_with_newline_values_x', 'replace_slash_n_with_newline_x', 'replace_slash_n_with_newline_values_x', 'avg_cosine_sim', 'num_sentences_x', 'Unnamed: 0_y', 'response_y', 'replace_slash_n_slash_n_with_newline_y', 'replace_slash_n_slash_n_with_newline_values_y', 'replace_slash_n_with_newline_y', 'replace_slash_n_with_newline_values_y', 'avg_inter_paragraph_cosine_sim', 'num_paragraphs', 'num_sentences_y', 'cosine_sims', 'conversation_length', 'input_length', 'output_length', 'conversation_cost', 'gsm8k_question_index', 'gsm8k_answer', 'gsm8k_length_vs_provided', 'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres', 'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided', 'num_sentences_provided', 'num_step_i_provided', 'num_1_dot_etc_provided', 'length_provided', 'compliance', 'coherence_1_incoherent_10_very_coherent_compliance_adjusted', 'Aggregated_Prediction_random_50_LP_compliance_adjusted', 'avg_cosine_sim_compliance_adjusted', 'avg_inter_paragraph_cosine_sim_compliance_adjusted', 'model', 'task', 'method', 'Model', 'Method', 'Task', 'accuracy_quality', 'accuracy_quality_compliance_adjusted', 'accuracy_quality_avg_inter_paragraph_cosine_sim', 'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_prompts', 'consolidated_num_steps_ideas_provided', 'technique_name', 'ss_publication_date', 'ss_publication_date_datetime', 'Method + Publication Date', 'Publication Date', 'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'sentence_length_prompts_diff', 'fres_prompts_diff', 'num_linebreaks_provided_diff', 'num_sentences_provided_diff', 'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff', 'conversation_length_thousands', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas_2', 'fres_2', 'task_conversation_method', 'task_conversation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_30272\\2596320842.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gsm8k_data['length_provided_thousands'] = gsm8k_data['length_provided']/1000\n",
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_30272\\2596320842.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gsm8k_data['length_provided_thousands_2'] = gsm8k_data['length_provided_thousands']**2\n"
     ]
    }
   ],
   "source": [
    "print(list(gsm8k_data.columns))\n",
    "\n",
    "# Length_provided in thousands\n",
    "gsm8k_data['length_provided_thousands'] = gsm8k_data['length_provided']/1000\n",
    "\n",
    "# Squared length_provided in thousands\n",
    "gsm8k_data['length_provided_thousands_2'] = gsm8k_data['length_provided_thousands']**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549825\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1588\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 11 Dec 2023   Pseudo R-squ.:                  0.1888\n",
      "Time:                        15:44:18   Log-Likelihood:                -879.72\n",
      "converged:                       True   LL-Null:                       -1084.4\n",
      "Covariance Type:                  HC3   LLR p-value:                 6.248e-81\n",
      "=============================================================================================================================\n",
      "                                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                     1.8132      0.500      3.627      0.000       0.833       2.793\n",
      "model[T.td3]                                                 -1.7038      0.330     -5.166      0.000      -2.350      -1.057\n",
      "conversation_length_thousands                                 3.9992      2.241      1.784      0.074      -0.394       8.392\n",
      "length_provided_thousands                                    -6.5764      5.309     -1.239      0.215     -16.982       3.829\n",
      "model[T.td3]:length_provided_thousands                       -4.2025      3.358     -1.252      0.211     -10.784       2.379\n",
      "conversation_length_thousands:length_provided_thousands     -27.5385     19.346     -1.423      0.155     -65.457      10.380\n",
      "consolidated_num_steps_ideas                                  0.1480      0.101      1.461      0.144      -0.050       0.346\n",
      "consolidated_num_steps_ideas:length_provided_thousands        0.4681      0.910      0.515      0.607      -1.315       2.251\n",
      "conversation_length_thousands_2                              -3.7799      2.346     -1.611      0.107      -8.378       0.819\n",
      "conversation_length_thousands_2:length_provided_thousands    15.7313     17.671      0.890      0.373     -18.903      50.366\n",
      "consolidated_num_steps_ideas_2                               -0.0126      0.007     -1.688      0.091      -0.027       0.002\n",
      "consolidated_num_steps_ideas_2:length_provided_thousands      0.0147      0.061      0.241      0.809      -0.105       0.134\n",
      "=============================================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                correct\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "=============================================================================================================================\n",
      "                                                               dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                                                 -0.3150      0.061     -5.191      0.000      -0.434      -0.196\n",
      "conversation_length_thousands                                 0.7394      0.413      1.791      0.073      -0.070       1.549\n",
      "length_provided_thousands                                    -1.2158      0.982     -1.239      0.215      -3.140       0.708\n",
      "model[T.td3]:length_provided_thousands                       -0.7769      0.616     -1.261      0.207      -1.985       0.431\n",
      "conversation_length_thousands:length_provided_thousands      -5.0913      3.570     -1.426      0.154     -12.088       1.905\n",
      "consolidated_num_steps_ideas                                  0.0274      0.019      1.463      0.144      -0.009       0.064\n",
      "consolidated_num_steps_ideas:length_provided_thousands        0.0865      0.168      0.515      0.607      -0.243       0.416\n",
      "conversation_length_thousands_2                              -0.6988      0.433     -1.614      0.107      -1.548       0.150\n",
      "conversation_length_thousands_2:length_provided_thousands     2.9084      3.266      0.890      0.373      -3.493       9.310\n",
      "consolidated_num_steps_ideas_2                               -0.0023      0.001     -1.691      0.091      -0.005       0.000\n",
      "consolidated_num_steps_ideas_2:length_provided_thousands      0.0027      0.011      0.241      0.809      -0.019       0.025\n",
      "=============================================================================================================================\n",
      "      model[T.td3] conversation_length_thousands length_provided_thousands  \\\n",
      "0  -0.315* (0.061)                 0.739 (0.413)            -1.216 (0.982)   \n",
      "\n",
      "  model[T.td3]:length_provided_thousands  \\\n",
      "0                         -0.777 (0.616)   \n",
      "\n",
      "  conversation_length_thousands:length_provided_thousands  \\\n",
      "0                                      -5.091 (3.57)        \n",
      "\n",
      "  consolidated_num_steps_ideas  \\\n",
      "0                0.027 (0.019)   \n",
      "\n",
      "  consolidated_num_steps_ideas:length_provided_thousands  \\\n",
      "0                                      0.087 (0.168)       \n",
      "\n",
      "  conversation_length_thousands_2  \\\n",
      "0                  -0.699 (0.433)   \n",
      "\n",
      "  conversation_length_thousands_2:length_provided_thousands  \\\n",
      "0                                      2.908 (3.266)          \n",
      "\n",
      "  consolidated_num_steps_ideas_2  \\\n",
      "0                 -0.002 (0.001)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:length_provided_thousands  \\\n",
      "0                                      0.003 (0.011)         \n",
      "\n",
      "                  Title  \n",
      "0  GSM8K Correct, Logit  \n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_gsm8k_provided_interaction = smf.logit('correct ~ conversation_length_thousands * length_provided_thousands + consolidated_num_steps_ideas * length_provided_thousands + conversation_length_thousands_2 * length_provided_thousands + consolidated_num_steps_ideas_2 * length_provided_thousands + model * length_provided_thousands', data=gsm8k_data).fit(cov_type='HC3')\n",
    "\n",
    "# Display the summary\n",
    "print(logit_no_clustering_gsm8k_provided_interaction.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_gsm8k_provided_interaction_marginal_effects = logit_no_clustering_gsm8k_provided_interaction.get_margeff(at='overall')\n",
    "print(logit_no_clustering_gsm8k_provided_interaction_marginal_effects.summary())\n",
    "\n",
    "# Create results df\n",
    "logit_no_clustering_gsm8k_provided_interaction_df = create_logit_results_df(logit_no_clustering_gsm8k_provided_interaction, logit_no_clustering_gsm8k_provided_interaction_marginal_effects, \"GSM8K Correct, Logit\")\n",
    "\n",
    "# Print results df\n",
    "print(logit_no_clustering_gsm8k_provided_interaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\statsmodels\\base\\model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 209, but rank is 206\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.319\n",
      "Method:                 Least Squares   F-statistic:                     71.79\n",
      "Date:                Mon, 11 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        15:44:18   Log-Likelihood:                -718.03\n",
      "No. Observations:                1600   AIC:                             1852.\n",
      "Df Residuals:                    1392   BIC:                             2971.\n",
      "Df Model:                         207                                         \n",
      "Covariance Type:              cluster                                         \n",
      "=============================================================================================================================\n",
      "                                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                     1.2490      6.827      0.183      0.855     -12.133      14.631\n",
      "task_conversation[T.gsm8k_10]                                26.0031     24.006      1.083      0.279     -21.047      73.054\n",
      "task_conversation[T.gsm8k_100]                                9.2377      7.536      1.226      0.220      -5.532      24.007\n",
      "task_conversation[T.gsm8k_11]                                 3.9171      7.366      0.532      0.595     -10.520      18.354\n",
      "task_conversation[T.gsm8k_12]                               -14.8570     12.416     -1.197      0.231     -39.191       9.478\n",
      "task_conversation[T.gsm8k_13]                                 4.7980      6.007      0.799      0.424      -6.975      16.571\n",
      "task_conversation[T.gsm8k_14]                                 1.2633      6.208      0.204      0.839     -10.903      13.430\n",
      "task_conversation[T.gsm8k_15]                                 4.9883      6.638      0.751      0.452      -8.023      17.999\n",
      "task_conversation[T.gsm8k_16]                                12.8574     10.757      1.195      0.232      -8.226      33.941\n",
      "task_conversation[T.gsm8k_17]                                17.8344      5.647      3.158      0.002       6.767      28.902\n",
      "task_conversation[T.gsm8k_18]                                14.3991     15.415      0.934      0.350     -15.814      44.612\n",
      "task_conversation[T.gsm8k_19]                                 0.3196      6.203      0.052      0.959     -11.838      12.477\n",
      "task_conversation[T.gsm8k_2]                                  3.5940      5.717      0.629      0.530      -7.612      14.800\n",
      "task_conversation[T.gsm8k_20]                                 1.9700      7.979      0.247      0.805     -13.669      17.609\n",
      "task_conversation[T.gsm8k_21]                                 2.1259     11.996      0.177      0.859     -21.386      25.638\n",
      "task_conversation[T.gsm8k_22]                                -6.7799      5.952     -1.139      0.255     -18.446       4.886\n",
      "task_conversation[T.gsm8k_23]                                -0.1331      6.381     -0.021      0.983     -12.640      12.374\n",
      "task_conversation[T.gsm8k_24]                                -0.4829      6.012     -0.080      0.936     -12.266      11.300\n",
      "task_conversation[T.gsm8k_25]                                 1.1746     12.237      0.096      0.924     -22.809      25.158\n",
      "task_conversation[T.gsm8k_26]                               -11.4911     14.537     -0.790      0.429     -39.983      17.000\n",
      "task_conversation[T.gsm8k_27]                                -4.5030     10.931     -0.412      0.680     -25.928      16.922\n",
      "task_conversation[T.gsm8k_28]                                 0.3515      6.128      0.057      0.954     -11.658      12.361\n",
      "task_conversation[T.gsm8k_29]                                -0.6905      6.256     -0.110      0.912     -12.952      11.571\n",
      "task_conversation[T.gsm8k_3]                                 -1.0830      6.440     -0.168      0.866     -13.706      11.540\n",
      "task_conversation[T.gsm8k_30]                                 0.3292      6.806      0.048      0.961     -13.010      13.668\n",
      "task_conversation[T.gsm8k_31]                                -3.0010      6.160     -0.487      0.626     -15.073       9.071\n",
      "task_conversation[T.gsm8k_32]                                -3.7492      6.206     -0.604      0.546     -15.913       8.415\n",
      "task_conversation[T.gsm8k_33]                                 1.3849      6.482      0.214      0.831     -11.320      14.090\n",
      "task_conversation[T.gsm8k_34]                                33.5623     15.396      2.180      0.029       3.387      63.737\n",
      "task_conversation[T.gsm8k_35]                                 1.9018      5.925      0.321      0.748      -9.712      13.516\n",
      "task_conversation[T.gsm8k_36]                                -1.3654      6.072     -0.225      0.822     -13.267      10.536\n",
      "task_conversation[T.gsm8k_37]                                 2.3487      6.323      0.371      0.710     -10.045      14.742\n",
      "task_conversation[T.gsm8k_38]                                 0.2816      6.163      0.046      0.964     -11.797      12.360\n",
      "task_conversation[T.gsm8k_39]                               -50.3755      7.277     -6.923      0.000     -64.638     -36.113\n",
      "task_conversation[T.gsm8k_4]                                  1.1048      5.914      0.187      0.852     -10.486      12.696\n",
      "task_conversation[T.gsm8k_40]                                 1.9501     26.091      0.075      0.940     -49.187      53.087\n",
      "task_conversation[T.gsm8k_41]                                -0.5753      9.143     -0.063      0.950     -18.496      17.345\n",
      "task_conversation[T.gsm8k_42]                                -0.4075      6.356     -0.064      0.949     -12.866      12.051\n",
      "task_conversation[T.gsm8k_43]                                -1.9043      6.209     -0.307      0.759     -14.073      10.265\n",
      "task_conversation[T.gsm8k_44]                                -1.5186      6.523     -0.233      0.816     -14.303      11.266\n",
      "task_conversation[T.gsm8k_45]                                 3.2793      7.070      0.464      0.643     -10.578      17.137\n",
      "task_conversation[T.gsm8k_46]                                -4.6330      7.255     -0.639      0.523     -18.853       9.587\n",
      "task_conversation[T.gsm8k_47]                                 2.5263     11.527      0.219      0.827     -20.066      25.119\n",
      "task_conversation[T.gsm8k_48]                                 2.2824      6.687      0.341      0.733     -10.824      15.389\n",
      "task_conversation[T.gsm8k_49]                                 5.4120      5.620      0.963      0.336      -5.603      16.427\n",
      "task_conversation[T.gsm8k_5]                                 -4.2778      6.252     -0.684      0.494     -16.531       7.975\n",
      "task_conversation[T.gsm8k_50]                                 0.7569      6.429      0.118      0.906     -11.843      13.357\n",
      "task_conversation[T.gsm8k_51]                                 2.7380      7.920      0.346      0.730     -12.784      18.260\n",
      "task_conversation[T.gsm8k_52]                                -2.1978      6.136     -0.358      0.720     -14.223       9.828\n",
      "task_conversation[T.gsm8k_53]                                 0.8824      6.413      0.138      0.891     -11.686      13.451\n",
      "task_conversation[T.gsm8k_54]                                 8.2096      8.376      0.980      0.327      -8.207      24.627\n",
      "task_conversation[T.gsm8k_55]                                 0.2778      6.121      0.045      0.964     -11.719      12.275\n",
      "task_conversation[T.gsm8k_56]                                -0.3635      6.095     -0.060      0.952     -12.309      11.582\n",
      "task_conversation[T.gsm8k_57]                                -1.8732      6.115     -0.306      0.759     -13.859      10.112\n",
      "task_conversation[T.gsm8k_58]                                -0.6566      6.449     -0.102      0.919     -13.297      11.984\n",
      "task_conversation[T.gsm8k_59]                                 6.9711      8.958      0.778      0.436     -10.586      24.528\n",
      "task_conversation[T.gsm8k_6]                                 -1.7144      6.630     -0.259      0.796     -14.709      11.280\n",
      "task_conversation[T.gsm8k_60]                                -2.0315      6.100     -0.333      0.739     -13.987       9.924\n",
      "task_conversation[T.gsm8k_61]                                 4.5754      6.736      0.679      0.497      -8.627      17.778\n",
      "task_conversation[T.gsm8k_62]                                -1.4846      6.130     -0.242      0.809     -13.499      10.530\n",
      "task_conversation[T.gsm8k_63]                                13.1342      6.293      2.087      0.037       0.800      25.468\n",
      "task_conversation[T.gsm8k_64]                                17.7553     30.996      0.573      0.567     -42.995      78.506\n",
      "task_conversation[T.gsm8k_65]                                -0.5616      6.375     -0.088      0.930     -13.057      11.934\n",
      "task_conversation[T.gsm8k_66]                                -1.2710      6.167     -0.206      0.837     -13.358      10.816\n",
      "task_conversation[T.gsm8k_67]                                -0.1622      7.903     -0.021      0.984     -15.651      15.327\n",
      "task_conversation[T.gsm8k_68]                                 0.4315      6.131      0.070      0.944     -11.585      12.448\n",
      "task_conversation[T.gsm8k_69]                                 0.2107      6.187      0.034      0.973     -11.915      12.336\n",
      "task_conversation[T.gsm8k_7]                                 -1.1360      6.153     -0.185      0.854     -13.197      10.925\n",
      "task_conversation[T.gsm8k_70]                                -2.7015      5.979     -0.452      0.651     -14.419       9.016\n",
      "task_conversation[T.gsm8k_71]                                -2.5537      6.291     -0.406      0.685     -14.884       9.777\n",
      "task_conversation[T.gsm8k_72]                                -0.6047      6.023     -0.100      0.920     -12.410      11.201\n",
      "task_conversation[T.gsm8k_73]                                26.7816     18.271      1.466      0.143      -9.029      62.592\n",
      "task_conversation[T.gsm8k_74]                               -25.4810     21.694     -1.175      0.240     -68.001      17.039\n",
      "task_conversation[T.gsm8k_75]                                 5.0198      8.298      0.605      0.545     -11.243      21.283\n",
      "task_conversation[T.gsm8k_76]                                -1.5522      6.422     -0.242      0.809     -14.139      11.035\n",
      "task_conversation[T.gsm8k_77]                                -2.0413      6.504     -0.314      0.754     -14.790      10.707\n",
      "task_conversation[T.gsm8k_78]                                 3.6977      6.089      0.607      0.544      -8.237      15.632\n",
      "task_conversation[T.gsm8k_79]                                18.0193      6.370      2.829      0.005       5.534      30.505\n",
      "task_conversation[T.gsm8k_8]                                 -0.5299      6.570     -0.081      0.936     -13.407      12.348\n",
      "task_conversation[T.gsm8k_80]                                 5.0907      5.497      0.926      0.354      -5.684      15.865\n",
      "task_conversation[T.gsm8k_81]                               -15.2660     19.540     -0.781      0.435     -53.563      23.031\n",
      "task_conversation[T.gsm8k_82]                                 0.1222      6.055      0.020      0.984     -11.746      11.990\n",
      "task_conversation[T.gsm8k_83]                                -0.3376      1.560     -0.216      0.829      -3.394       2.719\n",
      "task_conversation[T.gsm8k_84]                                 5.0414      5.538      0.910      0.363      -5.814      15.897\n",
      "task_conversation[T.gsm8k_85]                                -0.1120      6.155     -0.018      0.985     -12.176      11.952\n",
      "task_conversation[T.gsm8k_86]                                 0.8492      6.241      0.136      0.892     -11.383      13.082\n",
      "task_conversation[T.gsm8k_87]                                12.4482     19.747      0.630      0.528     -26.256      51.152\n",
      "task_conversation[T.gsm8k_88]                               -19.4673     14.419     -1.350      0.177     -47.727       8.793\n",
      "task_conversation[T.gsm8k_89]                                -3.5500      6.215     -0.571      0.568     -15.731       8.631\n",
      "task_conversation[T.gsm8k_9]                                  1.4107      6.696      0.211      0.833     -11.713      14.534\n",
      "task_conversation[T.gsm8k_90]                                 3.0397      6.058      0.502      0.616      -8.835      14.914\n",
      "task_conversation[T.gsm8k_91]                                -1.4631      7.176     -0.204      0.838     -15.527      12.601\n",
      "task_conversation[T.gsm8k_92]                                -0.1881      6.047     -0.031      0.975     -12.040      11.664\n",
      "task_conversation[T.gsm8k_93]                                -0.4689      6.256     -0.075      0.940     -12.730      11.792\n",
      "task_conversation[T.gsm8k_94]                                -7.9010      7.820     -1.010      0.312     -23.228       7.426\n",
      "task_conversation[T.gsm8k_95]                                -1.5510      6.990     -0.222      0.824     -15.251      12.149\n",
      "task_conversation[T.gsm8k_96]                                 3.0273      6.200      0.488      0.625      -9.125      15.180\n",
      "task_conversation[T.gsm8k_97]                                -0.4414      5.952     -0.074      0.941     -12.107      11.224\n",
      "task_conversation[T.gsm8k_98]                                -3.7695      6.151     -0.613      0.540     -15.826       8.287\n",
      "task_conversation[T.gsm8k_99]                                -1.4536      6.165     -0.236      0.814     -13.536      10.629\n",
      "model[T.td3]                                                 -0.2804      0.249     -1.125      0.261      -0.769       0.208\n",
      "conversation_length_thousands                                 0.7098      0.346      2.049      0.040       0.031       1.389\n",
      "length_provided_thousands                                    -6.5415    124.292     -0.053      0.958    -250.150     237.067\n",
      "task_conversation[T.gsm8k_10]:length_provided_thousands    -200.0908    238.219     -0.840      0.401    -666.991     266.809\n",
      "task_conversation[T.gsm8k_100]:length_provided_thousands    -84.1166    117.856     -0.714      0.475    -315.109     146.876\n",
      "task_conversation[T.gsm8k_11]:length_provided_thousands     -23.8710    118.217     -0.202      0.840    -255.572     207.830\n",
      "task_conversation[T.gsm8k_12]:length_provided_thousands     136.5024    165.475      0.825      0.409    -187.823     460.828\n",
      "task_conversation[T.gsm8k_13]:length_provided_thousands     -39.8213    117.892     -0.338      0.736    -270.885     191.243\n",
      "task_conversation[T.gsm8k_14]:length_provided_thousands     -11.3180    117.496     -0.096      0.923    -241.605     218.969\n",
      "task_conversation[T.gsm8k_15]:length_provided_thousands     -35.2780    115.317     -0.306      0.760    -261.296     190.740\n",
      "task_conversation[T.gsm8k_16]:length_provided_thousands     -99.2254    129.003     -0.769      0.442    -352.067     153.616\n",
      "task_conversation[T.gsm8k_17]:length_provided_thousands    -151.8556    108.953     -1.394      0.163    -365.399      61.688\n",
      "task_conversation[T.gsm8k_18]:length_provided_thousands     -88.5393    139.191     -0.636      0.525    -361.349     184.270\n",
      "task_conversation[T.gsm8k_19]:length_provided_thousands      -1.2053    116.617     -0.010      0.992    -229.771     227.361\n",
      "task_conversation[T.gsm8k_2]:length_provided_thousands      -77.5116    104.100     -0.745      0.457    -281.543     126.520\n",
      "task_conversation[T.gsm8k_20]:length_provided_thousands      -7.2154    124.225     -0.058      0.954    -250.693     236.262\n",
      "task_conversation[T.gsm8k_21]:length_provided_thousands     -15.6053    130.094     -0.120      0.905    -270.585     239.375\n",
      "task_conversation[T.gsm8k_22]:length_provided_thousands     123.0608    109.313      1.126      0.260     -91.189     337.310\n",
      "task_conversation[T.gsm8k_23]:length_provided_thousands       2.1303    116.259      0.018      0.985    -225.732     229.993\n",
      "task_conversation[T.gsm8k_24]:length_provided_thousands       9.2436    109.603      0.084      0.933    -205.573     224.061\n",
      "task_conversation[T.gsm8k_25]:length_provided_thousands     -20.7655    212.813     -0.098      0.922    -437.871     396.340\n",
      "task_conversation[T.gsm8k_26]:length_provided_thousands      91.4278    172.934      0.529      0.597    -247.516     430.372\n",
      "task_conversation[T.gsm8k_27]:length_provided_thousands      91.2604    238.206      0.383      0.702    -375.614     558.135\n",
      "task_conversation[T.gsm8k_28]:length_provided_thousands      -3.0882    114.192     -0.027      0.978    -226.900     220.723\n",
      "task_conversation[T.gsm8k_29]:length_provided_thousands      12.6996    113.855      0.112      0.911    -210.452     235.851\n",
      "task_conversation[T.gsm8k_3]:length_provided_thousands        9.0280    117.335      0.077      0.939    -220.944     239.000\n",
      "task_conversation[T.gsm8k_30]:length_provided_thousands      -6.9711    118.730     -0.059      0.953    -239.677     225.735\n",
      "task_conversation[T.gsm8k_31]:length_provided_thousands      31.9002    114.814      0.278      0.781    -193.131     256.932\n",
      "task_conversation[T.gsm8k_32]:length_provided_thousands      39.0679    117.897      0.331      0.740    -192.006     270.142\n",
      "task_conversation[T.gsm8k_33]:length_provided_thousands     -37.6314    127.247     -0.296      0.767    -287.031     211.768\n",
      "task_conversation[T.gsm8k_34]:length_provided_thousands    -507.8411    251.989     -2.015      0.044   -1001.731     -13.952\n",
      "task_conversation[T.gsm8k_35]:length_provided_thousands     -25.5623    109.938     -0.233      0.816    -241.037     189.912\n",
      "task_conversation[T.gsm8k_36]:length_provided_thousands      16.7374    113.160      0.148      0.882    -205.052     238.526\n",
      "task_conversation[T.gsm8k_37]:length_provided_thousands     -16.7084    117.169     -0.143      0.887    -246.355     212.938\n",
      "task_conversation[T.gsm8k_38]:length_provided_thousands      -7.7853    116.650     -0.067      0.947    -236.415     220.845\n",
      "task_conversation[T.gsm8k_39]:length_provided_thousands     416.6138     78.643      5.298      0.000     262.476     570.752\n",
      "task_conversation[T.gsm8k_4]:length_provided_thousands      -31.5388    109.811     -0.287      0.774    -246.765     183.687\n",
      "task_conversation[T.gsm8k_40]:length_provided_thousands      -3.2429    165.792     -0.020      0.984    -328.189     321.704\n",
      "task_conversation[T.gsm8k_41]:length_provided_thousands      11.6178    180.778      0.064      0.949    -342.701     365.937\n",
      "task_conversation[T.gsm8k_42]:length_provided_thousands       3.3504    117.388      0.029      0.977    -226.726     233.426\n",
      "task_conversation[T.gsm8k_43]:length_provided_thousands      29.7281    111.486      0.267      0.790    -188.780     248.236\n",
      "task_conversation[T.gsm8k_44]:length_provided_thousands      12.5557    121.874      0.103      0.918    -226.314     251.425\n",
      "task_conversation[T.gsm8k_45]:length_provided_thousands     -14.7120    121.293     -0.121      0.903    -252.441     223.017\n",
      "task_conversation[T.gsm8k_46]:length_provided_thousands      35.4861    118.206      0.300      0.764    -196.194     267.166\n",
      "task_conversation[T.gsm8k_47]:length_provided_thousands     -22.2870    158.930     -0.140      0.888    -333.784     289.210\n",
      "task_conversation[T.gsm8k_48]:length_provided_thousands     -15.0652    117.037     -0.129      0.898    -244.453     214.323\n",
      "task_conversation[T.gsm8k_49]:length_provided_thousands     -66.0907    108.428     -0.610      0.542    -278.606     146.424\n",
      "task_conversation[T.gsm8k_5]:length_provided_thousands       48.6313    112.861      0.431      0.667    -172.572     269.835\n",
      "task_conversation[T.gsm8k_50]:length_provided_thousands      -3.9459    113.785     -0.035      0.972    -226.961     219.070\n",
      "task_conversation[T.gsm8k_51]:length_provided_thousands     -36.9334    121.587     -0.304      0.761    -275.239     201.372\n",
      "task_conversation[T.gsm8k_52]:length_provided_thousands      33.3148    111.140      0.300      0.764    -184.516     251.146\n",
      "task_conversation[T.gsm8k_53]:length_provided_thousands      -9.8046    116.883     -0.084      0.933    -238.892     219.283\n",
      "task_conversation[T.gsm8k_54]:length_provided_thousands     -88.5685    117.190     -0.756      0.450    -318.257     141.120\n",
      "task_conversation[T.gsm8k_55]:length_provided_thousands      -3.0244    111.909     -0.027      0.978    -222.361     216.312\n",
      "task_conversation[T.gsm8k_56]:length_provided_thousands       6.2768    110.668      0.057      0.955    -210.628     223.182\n",
      "task_conversation[T.gsm8k_57]:length_provided_thousands      34.5961    111.337      0.311      0.756    -183.620     252.812\n",
      "task_conversation[T.gsm8k_58]:length_provided_thousands       9.4458    116.137      0.081      0.935    -218.178     237.070\n",
      "task_conversation[T.gsm8k_59]:length_provided_thousands     -49.7324    119.271     -0.417      0.677    -283.499     184.035\n",
      "task_conversation[T.gsm8k_6]:length_provided_thousands       14.4847    119.763      0.121      0.904    -220.246     249.215\n",
      "task_conversation[T.gsm8k_60]:length_provided_thousands      32.6548    110.333      0.296      0.767    -183.594     248.903\n",
      "task_conversation[T.gsm8k_61]:length_provided_thousands     -57.0204    112.522     -0.507      0.612    -277.560     163.519\n",
      "task_conversation[T.gsm8k_62]:length_provided_thousands      22.8519    112.927      0.202      0.840    -198.482     244.186\n",
      "task_conversation[T.gsm8k_63]:length_provided_thousands    -130.8954    115.540     -1.133      0.257    -357.349      95.558\n",
      "task_conversation[T.gsm8k_64]:length_provided_thousands     -92.6495    194.559     -0.476      0.634    -473.978     288.679\n",
      "task_conversation[T.gsm8k_65]:length_provided_thousands       8.1715    115.774      0.071      0.944    -218.742     235.084\n",
      "task_conversation[T.gsm8k_66]:length_provided_thousands      14.2525    113.790      0.125      0.900    -208.772     237.277\n",
      "task_conversation[T.gsm8k_67]:length_provided_thousands       4.2960    118.278      0.036      0.971    -227.524     236.116\n",
      "task_conversation[T.gsm8k_68]:length_provided_thousands      -5.5740    110.131     -0.051      0.960    -221.428     210.279\n",
      "task_conversation[T.gsm8k_69]:length_provided_thousands      -2.3508    115.233     -0.020      0.984    -228.203     223.502\n",
      "task_conversation[T.gsm8k_7]:length_provided_thousands       14.4788    114.914      0.126      0.900    -210.748     239.706\n",
      "task_conversation[T.gsm8k_70]:length_provided_thousands      54.5827    110.448      0.494      0.621    -161.890     271.056\n",
      "task_conversation[T.gsm8k_71]:length_provided_thousands      22.2676    118.825      0.187      0.851    -210.626     255.161\n",
      "task_conversation[T.gsm8k_72]:length_provided_thousands      11.5922    111.247      0.104      0.917    -206.448     229.632\n",
      "task_conversation[T.gsm8k_73]:length_provided_thousands    -351.0653    239.777     -1.464      0.143    -821.020     118.889\n",
      "task_conversation[T.gsm8k_74]:length_provided_thousands     244.8507    252.801      0.969      0.333    -250.630     740.332\n",
      "task_conversation[T.gsm8k_75]:length_provided_thousands     -21.4754    123.876     -0.173      0.862    -264.269     221.318\n",
      "task_conversation[T.gsm8k_76]:length_provided_thousands      13.3218    121.019      0.110      0.912    -223.872     250.516\n",
      "task_conversation[T.gsm8k_77]:length_provided_thousands      18.1963    120.177      0.151      0.880    -217.347     253.740\n",
      "task_conversation[T.gsm8k_78]:length_provided_thousands     -37.2179    111.921     -0.333      0.739    -256.579     182.143\n",
      "task_conversation[T.gsm8k_79]:length_provided_thousands    -135.4185    116.122     -1.166      0.244    -363.013      92.176\n",
      "task_conversation[T.gsm8k_8]:length_provided_thousands        5.9655    120.842      0.049      0.961    -230.881     242.812\n",
      "task_conversation[T.gsm8k_80]:length_provided_thousands    -128.2085     95.959     -1.336      0.182    -316.286      59.869\n",
      "task_conversation[T.gsm8k_81]:length_provided_thousands     141.9250    187.462      0.757      0.449    -225.493     509.343\n",
      "task_conversation[T.gsm8k_82]:length_provided_thousands      -1.9177    111.756     -0.017      0.986    -220.956     217.121\n",
      "task_conversation[T.gsm8k_83]:length_provided_thousands      -0.0142      0.066     -0.216      0.829      -0.143       0.114\n",
      "task_conversation[T.gsm8k_84]:length_provided_thousands     -72.3354    104.720     -0.691      0.490    -277.582     132.911\n",
      "task_conversation[T.gsm8k_85]:length_provided_thousands       0.5655    114.120      0.005      0.996    -223.106     224.237\n",
      "task_conversation[T.gsm8k_86]:length_provided_thousands      -6.9448    114.162     -0.061      0.951    -230.698     216.809\n",
      "task_conversation[T.gsm8k_87]:length_provided_thousands    -110.2039    185.155     -0.595      0.552    -473.100     252.692\n",
      "task_conversation[T.gsm8k_88]:length_provided_thousands     148.4063    166.699      0.890      0.373    -178.318     475.131\n",
      "task_conversation[T.gsm8k_89]:length_provided_thousands      39.8903    114.939      0.347      0.729    -185.386     265.167\n",
      "task_conversation[T.gsm8k_9]:length_provided_thousands       -6.6722    119.777     -0.056      0.956    -241.431     228.087\n",
      "task_conversation[T.gsm8k_90]:length_provided_thousands     -71.0435    110.174     -0.645      0.519    -286.981     144.894\n",
      "task_conversation[T.gsm8k_91]:length_provided_thousands      16.5676    115.700      0.143      0.886    -210.200     243.335\n",
      "task_conversation[T.gsm8k_92]:length_provided_thousands       0.6718    111.620      0.006      0.995    -218.100     219.444\n",
      "task_conversation[T.gsm8k_93]:length_provided_thousands       4.1661    117.108      0.036      0.972    -225.361     233.694\n",
      "task_conversation[T.gsm8k_94]:length_provided_thousands      74.8277    116.164      0.644      0.519    -152.849     302.505\n",
      "task_conversation[T.gsm8k_95]:length_provided_thousands      15.7596    119.230      0.132      0.895    -217.927     249.446\n",
      "task_conversation[T.gsm8k_96]:length_provided_thousands     -27.2344    115.132     -0.237      0.813    -252.888     198.420\n",
      "task_conversation[T.gsm8k_97]:length_provided_thousands       5.0838    109.885      0.046      0.963    -210.287     220.454\n",
      "task_conversation[T.gsm8k_98]:length_provided_thousands      43.8464    113.476      0.386      0.699    -178.563     266.256\n",
      "task_conversation[T.gsm8k_99]:length_provided_thousands      16.3582    114.635      0.143      0.887    -208.322     241.038\n",
      "model[T.td3]:length_provided_thousands                       -2.2256      1.718     -1.295      0.195      -5.594       1.143\n",
      "conversation_length_thousands:length_provided_thousands      -5.3034      2.850     -1.861      0.063     -10.888       0.282\n",
      "consolidated_num_steps_ideas                                  0.0406      0.020      2.076      0.038       0.002       0.079\n",
      "consolidated_num_steps_ideas:length_provided_thousands        0.0053      0.176      0.030      0.976      -0.339       0.350\n",
      "conversation_length_thousands_2                              -0.5127      0.327     -1.567      0.117      -1.154       0.129\n",
      "conversation_length_thousands_2:length_provided_thousands     1.7863      2.190      0.816      0.415      -2.506       6.079\n",
      "consolidated_num_steps_ideas_2                               -0.0018      0.002     -1.188      0.235      -0.005       0.001\n",
      "consolidated_num_steps_ideas_2:length_provided_thousands     -0.0013      0.012     -0.107      0.915      -0.024       0.022\n",
      "==============================================================================\n",
      "Omnibus:                       31.544   Durbin-Watson:                   1.563\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               25.231\n",
      "Skew:                          -0.227   Prob(JB):                     3.32e-06\n",
      "Kurtosis:                       2.585   Cond. No.                     2.70e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The smallest eigenvalue is 7.1e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "       Intercept task_conversation[T.gsm8k_10] task_conversation[T.gsm8k_100]  \\\n",
      "0  1.249 (6.827)               26.003 (24.006)                  9.238 (7.536)   \n",
      "\n",
      "  task_conversation[T.gsm8k_11] task_conversation[T.gsm8k_12]  \\\n",
      "0                 3.917 (7.366)              -14.857 (12.416)   \n",
      "\n",
      "  task_conversation[T.gsm8k_13] task_conversation[T.gsm8k_14]  \\\n",
      "0                 4.798 (6.007)                 1.263 (6.208)   \n",
      "\n",
      "  task_conversation[T.gsm8k_15] task_conversation[T.gsm8k_16]  \\\n",
      "0                 4.988 (6.638)               12.857 (10.757)   \n",
      "\n",
      "  task_conversation[T.gsm8k_17]  ...  \\\n",
      "0               17.834* (5.647)  ...   \n",
      "\n",
      "  task_conversation[T.gsm8k_99]:length_provided_thousands  \\\n",
      "0                                   16.358 (114.635)        \n",
      "\n",
      "  model[T.td3]:length_provided_thousands  \\\n",
      "0                         -2.226 (1.718)   \n",
      "\n",
      "  conversation_length_thousands:length_provided_thousands  \\\n",
      "0                                      -5.303 (2.85)        \n",
      "\n",
      "  consolidated_num_steps_ideas  \\\n",
      "0                0.041* (0.02)   \n",
      "\n",
      "  consolidated_num_steps_ideas:length_provided_thousands  \\\n",
      "0                                      0.005 (0.176)       \n",
      "\n",
      "  conversation_length_thousands_2  \\\n",
      "0                  -0.513 (0.327)   \n",
      "\n",
      "  conversation_length_thousands_2:length_provided_thousands  \\\n",
      "0                                       1.786 (2.19)          \n",
      "\n",
      "  consolidated_num_steps_ideas_2  \\\n",
      "0                 -0.002 (0.002)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:length_provided_thousands  \\\n",
      "0                                     -0.001 (0.012)         \n",
      "\n",
      "                   Title  \n",
      "0  GSM8K Correct, Linear  \n",
      "\n",
      "[1 rows x 211 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_gsm8k_provided_interaction = smf.ols('correct ~ conversation_length_thousands * length_provided_thousands + consolidated_num_steps_ideas * length_provided_thousands + conversation_length_thousands_2 * length_provided_thousands + consolidated_num_steps_ideas_2 * length_provided_thousands +  task_conversation * length_provided_thousands + model * length_provided_thousands', data=gsm8k_data).fit(cov_type='cluster', cov_kwds={'groups': gsm8k_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(lpm_with_clustering_gsm8k_provided_interaction.summary())\n",
    "\n",
    "# Create results df\n",
    "lpm_with_clustering_gsm8k_provided_interaction_df = create_linear_results_df(lpm_with_clustering_gsm8k_provided_interaction, \"GSM8K Correct, Linear\")\n",
    "\n",
    "# Print results df\n",
    "print(lpm_with_clustering_gsm8k_provided_interaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}}\n",
      "\\toprule\n",
      "\\hline\n",
      "Model & Length * Provided Length & Number of Steps/Ideas * Provided Length & Length Squared * Provided Length & Number of Steps/Ideas Squared * Provided Length & Conversation Length & Number of Steps/Ideas & Conversation Length Squared & Number of Steps/Ideas Squared & Provided Length \\\\\n",
      "\\hline\n",
      "\\midrule\n",
      "GSM8K Correct, Logit & -5.091 (3.57) & 0.087 (0.168) & 2.908 (3.266) & 0.003 (0.011) & 0.739 (0.413) & 0.027 (0.019) & -0.699 (0.433) & -0.002 (0.001) & -1.216 (0.982) \\\\\n",
      "\\hline\n",
      "GSM8K Correct, Linear & -5.303 (2.85) & 0.005 (0.176) & 1.786 (2.19) & -0.001 (0.012) & 0.71* (0.346) & 0.041* (0.02) & -0.513 (0.327) & -0.002 (0.002) & -6.541 (124.292) \\\\\n",
      "\\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "                   Model Length * Provided Length  \\\n",
      "0   GSM8K Correct, Logit            -5.091 (3.57)   \n",
      "1  GSM8K Correct, Linear            -5.303 (2.85)   \n",
      "\n",
      "  Number of Steps/Ideas * Provided Length Length Squared * Provided Length  \\\n",
      "0                           0.087 (0.168)                    2.908 (3.266)   \n",
      "1                           0.005 (0.176)                     1.786 (2.19)   \n",
      "\n",
      "  Number of Steps/Ideas Squared * Provided Length Conversation Length  \\\n",
      "0                                   0.003 (0.011)       0.739 (0.413)   \n",
      "1                                  -0.001 (0.012)       0.71* (0.346)   \n",
      "\n",
      "  Number of Steps/Ideas Conversation Length Squared  \\\n",
      "0         0.027 (0.019)              -0.699 (0.433)   \n",
      "1         0.041* (0.02)              -0.513 (0.327)   \n",
      "\n",
      "  Number of Steps/Ideas Squared   Provided Length  \n",
      "0                -0.002 (0.001)    -1.216 (0.982)  \n",
      "1                -0.002 (0.002)  -6.541 (124.292)  \n",
      "\\begin{tabular}{x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}}\n",
      "\\toprule\n",
      "\\hline\n",
      "Model & Length * Provided Length & Number of Steps/Ideas * Provided Length & Length Squared * Provided Length & Number of Steps/Ideas Squared * Provided Length & Conversation Length & Number of Steps/Ideas & Conversation Length Squared & Number of Steps/Ideas Squared & Provided Length \\\\\n",
      "\\hline\n",
      "\\midrule\n",
      "GSM8K Correct, Logit & -5.091 (3.57) & 0.087 (0.168) & 2.908 (3.266) & 0.003 (0.011) & 0.739 (0.413) & 0.027 (0.019) & -0.699 (0.433) & -0.002 (0.001) & -1.216 (0.982) \\\\\n",
      "\\hline\n",
      "GSM8K Correct, Linear & -5.303 (2.85) & 0.005 (0.176) & 1.786 (2.19) & -0.001 (0.012) & 0.71* (0.346) & 0.041* (0.02) & -0.513 (0.327) & -0.002 (0.002) & -6.541 (124.292) \\\\\n",
      "\\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack results dataframes together for output\n",
    "results_df = pd.concat([logit_no_clustering_gsm8k_provided_interaction_df, lpm_with_clustering_gsm8k_provided_interaction_df], ignore_index=True)\n",
    "\n",
    "# Limit columns to Title, conversation_length_thousands:length_provided_thousands, consolidated_num_steps_ideas:length_provided_thousands, conversation_length_thousands_2:length_provided_thousands, consolidated_num_steps_ideas_2:length_provided_thousands, length_provided_thousands, length_provided_thousands_2, conversation_length_thousands, consolidated_num_steps_ideas, conversation_length_thousands_2, consolidated_num_steps_ideas_2\n",
    "results_df = results_df[['Title', 'conversation_length_thousands:length_provided_thousands', 'consolidated_num_steps_ideas:length_provided_thousands', 'conversation_length_thousands_2:length_provided_thousands', 'consolidated_num_steps_ideas_2:length_provided_thousands', 'conversation_length_thousands', 'consolidated_num_steps_ideas', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas_2', 'length_provided_thousands']]\n",
    "\n",
    "# Replace NaN with blanks\n",
    "results_df = results_df.fillna('')\n",
    "\n",
    "# Rename Title to Model, conversation_length_thousands:length_provided_thousands to Length * Provided Length, consolidated_num_steps_ideas:length_provided_thousands to Number of Steps/Ideas * Provided Length, conversation_length_thousands_2:length_provided_thousands to Length Squared * Provided Length, consolidated_num_steps_ideas_2:length_provided_thousands to Number of Steps/Ideas Squared * Provided Length, conversation_length_thousands to Conversation Length, consolidated_num_steps_ideas to Number of Steps/Ideas, conversation_length_thousands_2 to Conversation Length Squared, consolidated_num_steps_ideas_2 to Number of Steps/Ideas Squared, length_provided_thousands to Provided Length, length_provided_thousands_2 to Provided Length Squared\n",
    "results_df = results_df.rename(columns={'Title': 'Model', 'conversation_length_thousands:length_provided_thousands': 'Length * Provided Length', 'consolidated_num_steps_ideas:length_provided_thousands': 'Number of Steps/Ideas * Provided Length', 'conversation_length_thousands_2:length_provided_thousands': 'Length Squared * Provided Length', 'consolidated_num_steps_ideas_2:length_provided_thousands': 'Number of Steps/Ideas Squared * Provided Length', 'conversation_length_thousands': 'Conversation Length', 'consolidated_num_steps_ideas': 'Number of Steps/Ideas', 'conversation_length_thousands_2': 'Conversation Length Squared', 'consolidated_num_steps_ideas_2': 'Number of Steps/Ideas Squared', 'length_provided_thousands': 'Provided Length', 'length_provided_thousands_2': 'Provided Length Squared'})\n",
    "\n",
    "# Output to latex. center columns, wrap text, and remove index\n",
    "# Output to latex. center columns, wrap text, and remove index\n",
    "latex_string = results_df.to_latex(index=False, \n",
    "                      column_format='x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}', \n",
    "                      #booktabs = True\n",
    "                      #longtable = True\n",
    "                      )\n",
    "\n",
    "# Add lines between rows\n",
    "lines = latex_string.split('\\n')\n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(line)\n",
    "    if '\\\\' in line and '&' in line:  # Identifies a row of the table\n",
    "        new_lines.append('\\\\hline')\n",
    "# Insert \\\\hline after \\toprule\n",
    "new_lines.insert(2, '\\\\hline')\n",
    "\n",
    "# Rejoin the modified lines\n",
    "modified_latex_table = '\\n'.join(new_lines)\n",
    "\n",
    "print(modified_latex_table)\n",
    "\n",
    "# Save string to file\n",
    "with open('../Output/regressions_provided_interaction.tex', 'w') as f:\n",
    "    f.write(modified_latex_table)\n",
    "\n",
    "# Print results_df\n",
    "print(results_df)\n",
    "\n",
    "# Print modifed latex table\n",
    "print(modified_latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add model interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566818\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1590\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 11 Dec 2023   Pseudo R-squ.:                  0.1637\n",
      "Time:                        15:44:19   Log-Likelihood:                -906.91\n",
      "converged:                       True   LL-Null:                       -1084.4\n",
      "Covariance Type:                  HC3   LLR p-value:                 5.343e-71\n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        1.9500      0.341      5.724      0.000       1.282       2.618\n",
      "model[T.td3]                                    -2.3559      0.412     -5.719      0.000      -3.163      -1.548\n",
      "conversation_length_thousands                   -1.0197      1.230     -0.829      0.407      -3.431       1.391\n",
      "conversation_length_thousands:model[T.td3]      -2.0950      2.085     -1.005      0.315      -6.182       1.992\n",
      "consolidated_num_steps_ideas                     0.1627      0.053      3.072      0.002       0.059       0.267\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0170      0.073      0.232      0.816      -0.126       0.160\n",
      "conversation_length_thousands_2                 -1.1919      0.941     -1.266      0.205      -3.037       0.653\n",
      "conversation_length_thousands_2:model[T.td3]     5.6188      2.295      2.448      0.014       1.121      10.117\n",
      "consolidated_num_steps_ideas_2                  -0.0097      0.003     -3.015      0.003      -0.016      -0.003\n",
      "consolidated_num_steps_ideas_2:model[T.td3]   5.437e-05      0.005      0.010      0.992      -0.010       0.010\n",
      "================================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                correct\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "================================================================================================================\n",
      "                                                  dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                                    -0.4533      0.076     -5.944      0.000      -0.603      -0.304\n",
      "conversation_length_thousands                   -0.1962      0.236     -0.830      0.407      -0.659       0.267\n",
      "conversation_length_thousands:model[T.td3]      -0.4031      0.401     -1.006      0.315      -1.189       0.383\n",
      "consolidated_num_steps_ideas                     0.0313      0.010      3.081      0.002       0.011       0.051\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0033      0.014      0.232      0.816      -0.024       0.031\n",
      "conversation_length_thousands_2                 -0.2293      0.181     -1.266      0.205      -0.584       0.126\n",
      "conversation_length_thousands_2:model[T.td3]     1.0810      0.439      2.463      0.014       0.221       1.941\n",
      "consolidated_num_steps_ideas_2                  -0.0019      0.001     -3.023      0.003      -0.003      -0.001\n",
      "consolidated_num_steps_ideas_2:model[T.td3]   1.046e-05      0.001      0.010      0.992      -0.002       0.002\n",
      "================================================================================================================\n",
      "      model[T.td3] conversation_length_thousands  \\\n",
      "0  -0.453* (0.076)                -0.196 (0.236)   \n",
      "\n",
      "  conversation_length_thousands:model[T.td3] consolidated_num_steps_ideas  \\\n",
      "0                             -0.403 (0.401)                0.031* (0.01)   \n",
      "\n",
      "  consolidated_num_steps_ideas:model[T.td3] conversation_length_thousands_2  \\\n",
      "0                             0.003 (0.014)                  -0.229 (0.181)   \n",
      "\n",
      "  conversation_length_thousands_2:model[T.td3] consolidated_num_steps_ideas_2  \\\n",
      "0                               1.081* (0.439)                -0.002* (0.001)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:model[T.td3]                 Title  \n",
      "0                                 0.0 (0.001)  GSM8K Correct, Logit  \n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_gsm8k_model_interaction = smf.logit('correct ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model', data=gsm8k_data).fit(cov_type='HC3')\n",
    "\n",
    "# Display the summary\n",
    "print(logit_no_clustering_gsm8k_model_interaction.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_gsm8k_marginal_effects_model_interaction = logit_no_clustering_gsm8k_model_interaction.get_margeff(at='overall')\n",
    "print(logit_no_clustering_gsm8k_marginal_effects_model_interaction.summary())\n",
    "\n",
    "# Create results df\n",
    "logit_no_clustering_gsm8k_model_interaction_df = create_logit_results_df(logit_no_clustering_gsm8k_model_interaction, logit_no_clustering_gsm8k_marginal_effects_model_interaction, \"GSM8K Correct, Logit\")\n",
    "\n",
    "# Print results df\n",
    "print(logit_no_clustering_gsm8k_model_interaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   R-squared:                       0.361\n",
      "Model:                            OLS   Adj. R-squared:                  0.314\n",
      "Method:                 Least Squares   F-statistic:                     28.54\n",
      "Date:                Mon, 11 Dec 2023   Prob (F-statistic):          1.64e-210\n",
      "Time:                        15:44:19   Log-Likelihood:                -778.49\n",
      "No. Observations:                1600   AIC:                             1775.\n",
      "Df Residuals:                    1491   BIC:                             2361.\n",
      "Df Model:                         108                                         \n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        1.0557      0.087     12.136      0.000       0.885       1.226\n",
      "model[T.td3]                                    -0.4686      0.059     -7.894      0.000      -0.585      -0.352\n",
      "task_conversation[T.gsm8k_10]                   -0.3934      0.112     -3.526      0.000      -0.612      -0.175\n",
      "task_conversation[T.gsm8k_100]                  -0.2421      0.164     -1.472      0.141      -0.564       0.080\n",
      "task_conversation[T.gsm8k_11]                   -0.1281      0.140     -0.912      0.362      -0.403       0.147\n",
      "task_conversation[T.gsm8k_12]                   -0.1671      0.137     -1.224      0.221      -0.435       0.100\n",
      "task_conversation[T.gsm8k_13]                   -0.9012      0.087    -10.363      0.000      -1.072      -0.731\n",
      "task_conversation[T.gsm8k_14]                   -0.6837      0.111     -6.183      0.000      -0.900      -0.467\n",
      "task_conversation[T.gsm8k_15]                   -0.0450      0.139     -0.323      0.747      -0.318       0.228\n",
      "task_conversation[T.gsm8k_16]                   -0.1433      0.116     -1.235      0.217      -0.371       0.084\n",
      "task_conversation[T.gsm8k_17]                    0.1388      0.102      1.360      0.174      -0.061       0.339\n",
      "task_conversation[T.gsm8k_18]                   -0.2498      0.153     -1.631      0.103      -0.550       0.050\n",
      "task_conversation[T.gsm8k_19]                   -0.1340      0.151     -0.890      0.374      -0.429       0.161\n",
      "task_conversation[T.gsm8k_2]                     0.1287      0.103      1.250      0.211      -0.073       0.331\n",
      "task_conversation[T.gsm8k_20]                   -0.3782      0.093     -4.051      0.000      -0.561      -0.195\n",
      "task_conversation[T.gsm8k_21]                   -0.4838      0.128     -3.766      0.000      -0.736      -0.232\n",
      "task_conversation[T.gsm8k_22]                   -0.3156      0.122     -2.583      0.010      -0.555      -0.076\n",
      "task_conversation[T.gsm8k_23]                   -0.1211      0.111     -1.095      0.274      -0.338       0.096\n",
      "task_conversation[T.gsm8k_24]                    0.0118      0.117      0.101      0.920      -0.217       0.241\n",
      "task_conversation[T.gsm8k_25]                   -0.1728      0.145     -1.193      0.233      -0.457       0.111\n",
      "task_conversation[T.gsm8k_26]                   -0.3046      0.135     -2.253      0.024      -0.570      -0.040\n",
      "task_conversation[T.gsm8k_27]                   -0.2557      0.145     -1.762      0.078      -0.540       0.029\n",
      "task_conversation[T.gsm8k_28]                   -0.0679      0.104     -0.654      0.513      -0.271       0.135\n",
      "task_conversation[T.gsm8k_29]                   -0.0134      0.126     -0.106      0.915      -0.261       0.234\n",
      "task_conversation[T.gsm8k_3]                    -0.6020      0.122     -4.946      0.000      -0.841      -0.363\n",
      "task_conversation[T.gsm8k_30]                   -0.2849      0.127     -2.245      0.025      -0.534      -0.036\n",
      "task_conversation[T.gsm8k_31]                   -0.4019      0.120     -3.337      0.001      -0.638      -0.166\n",
      "task_conversation[T.gsm8k_32]                   -0.2978      0.097     -3.054      0.002      -0.489      -0.107\n",
      "task_conversation[T.gsm8k_33]                   -0.0672      0.132     -0.509      0.611      -0.326       0.192\n",
      "task_conversation[T.gsm8k_34]                   -0.3256      0.081     -3.997      0.000      -0.485      -0.166\n",
      "task_conversation[T.gsm8k_35]                   -0.2005      0.162     -1.234      0.217      -0.519       0.118\n",
      "task_conversation[T.gsm8k_36]                   -0.3157      0.144     -2.185      0.029      -0.599      -0.033\n",
      "task_conversation[T.gsm8k_37]                   -0.2036      0.139     -1.469      0.142      -0.475       0.068\n",
      "task_conversation[T.gsm8k_38]                   -0.7202      0.096     -7.470      0.000      -0.909      -0.531\n",
      "task_conversation[T.gsm8k_39]                   -0.3729      0.083     -4.472      0.000      -0.536      -0.209\n",
      "task_conversation[T.gsm8k_4]                     0.0601      0.112      0.538      0.590      -0.159       0.279\n",
      "task_conversation[T.gsm8k_40]                   -0.3682      0.120     -3.079      0.002      -0.603      -0.134\n",
      "task_conversation[T.gsm8k_41]                    0.0117      0.119      0.098      0.922      -0.222       0.246\n",
      "task_conversation[T.gsm8k_42]                   -0.3476      0.128     -2.721      0.007      -0.598      -0.097\n",
      "task_conversation[T.gsm8k_43]                   -0.0500      0.116     -0.430      0.667      -0.278       0.178\n",
      "task_conversation[T.gsm8k_44]                   -0.5125      0.110     -4.657      0.000      -0.728      -0.297\n",
      "task_conversation[T.gsm8k_45]                   -0.1747      0.152     -1.146      0.252      -0.473       0.124\n",
      "task_conversation[T.gsm8k_46]                   -0.3185      0.128     -2.484      0.013      -0.570      -0.067\n",
      "task_conversation[T.gsm8k_47]                   -0.3715      0.106     -3.489      0.000      -0.580      -0.163\n",
      "task_conversation[T.gsm8k_48]                   -0.2721      0.142     -1.918      0.055      -0.550       0.006\n",
      "task_conversation[T.gsm8k_49]                    0.1804      0.082      2.188      0.029       0.019       0.342\n",
      "task_conversation[T.gsm8k_5]                    -0.2396      0.133     -1.801      0.072      -0.500       0.021\n",
      "task_conversation[T.gsm8k_50]                   -0.0067      0.117     -0.057      0.954      -0.236       0.223\n",
      "task_conversation[T.gsm8k_51]                   -0.2734      0.155     -1.759      0.079      -0.578       0.031\n",
      "task_conversation[T.gsm8k_52]                   -0.1755      0.138     -1.270      0.204      -0.446       0.095\n",
      "task_conversation[T.gsm8k_53]                   -0.2262      0.120     -1.883      0.060      -0.462       0.009\n",
      "task_conversation[T.gsm8k_54]                   -0.1744      0.153     -1.143      0.253      -0.474       0.125\n",
      "task_conversation[T.gsm8k_55]                   -0.2504      0.159     -1.572      0.116      -0.563       0.062\n",
      "task_conversation[T.gsm8k_56]                   -0.0051      0.112     -0.046      0.963      -0.224       0.214\n",
      "task_conversation[T.gsm8k_57]                   -0.0851      0.114     -0.744      0.457      -0.309       0.139\n",
      "task_conversation[T.gsm8k_58]                   -0.1291      0.118     -1.091      0.275      -0.361       0.103\n",
      "task_conversation[T.gsm8k_59]                   -0.2034      0.150     -1.354      0.176      -0.498       0.091\n",
      "task_conversation[T.gsm8k_6]                    -0.4355      0.127     -3.416      0.001      -0.685      -0.186\n",
      "task_conversation[T.gsm8k_60]                   -0.0669      0.116     -0.576      0.565      -0.294       0.161\n",
      "task_conversation[T.gsm8k_61]                   -0.3203      0.171     -1.873      0.061      -0.656       0.015\n",
      "task_conversation[T.gsm8k_62]                   -0.1072      0.115     -0.929      0.353      -0.333       0.119\n",
      "task_conversation[T.gsm8k_63]                   -0.5807      0.132     -4.410      0.000      -0.839      -0.323\n",
      "task_conversation[T.gsm8k_64]                   -0.3458      0.136     -2.539      0.011      -0.613      -0.079\n",
      "task_conversation[T.gsm8k_65]                   -0.1202      0.122     -0.987      0.324      -0.359       0.119\n",
      "task_conversation[T.gsm8k_66]                   -0.3084      0.151     -2.048      0.041      -0.603      -0.013\n",
      "task_conversation[T.gsm8k_67]                   -0.3115      0.141     -2.203      0.028      -0.589      -0.034\n",
      "task_conversation[T.gsm8k_68]                   -0.2486      0.161     -1.548      0.122      -0.563       0.066\n",
      "task_conversation[T.gsm8k_69]                   -0.2551      0.153     -1.669      0.095      -0.555       0.044\n",
      "task_conversation[T.gsm8k_7]                    -0.1987      0.142     -1.401      0.161      -0.477       0.079\n",
      "task_conversation[T.gsm8k_70]                   -0.1086      0.115     -0.946      0.344      -0.334       0.116\n",
      "task_conversation[T.gsm8k_71]                   -0.3968      0.125     -3.182      0.001      -0.641      -0.152\n",
      "task_conversation[T.gsm8k_72]                   -0.0062      0.118     -0.053      0.958      -0.237       0.225\n",
      "task_conversation[T.gsm8k_73]                   -0.2811      0.159     -1.766      0.077      -0.593       0.031\n",
      "task_conversation[T.gsm8k_74]                   -0.3552      0.169     -2.103      0.036      -0.686      -0.024\n",
      "task_conversation[T.gsm8k_75]                   -0.2408      0.158     -1.524      0.127      -0.550       0.069\n",
      "task_conversation[T.gsm8k_76]                   -0.5289      0.113     -4.665      0.000      -0.751      -0.307\n",
      "task_conversation[T.gsm8k_77]                   -0.3095      0.136     -2.270      0.023      -0.577      -0.042\n",
      "task_conversation[T.gsm8k_78]                   -0.1870      0.179     -1.046      0.296      -0.538       0.164\n",
      "task_conversation[T.gsm8k_79]                   -0.2669      0.149     -1.790      0.074      -0.559       0.025\n",
      "task_conversation[T.gsm8k_8]                    -0.5220      0.119     -4.399      0.000      -0.755      -0.289\n",
      "task_conversation[T.gsm8k_80]                    0.1426      0.084      1.705      0.088      -0.021       0.307\n",
      "task_conversation[T.gsm8k_81]                   -0.4966      0.116     -4.267      0.000      -0.725      -0.268\n",
      "task_conversation[T.gsm8k_82]                   -0.1127      0.149     -0.759      0.448      -0.404       0.178\n",
      "task_conversation[T.gsm8k_83]                   -0.2496      0.156     -1.598      0.110      -0.556       0.057\n",
      "task_conversation[T.gsm8k_84]                    0.1853      0.082      2.267      0.023       0.025       0.346\n",
      "task_conversation[T.gsm8k_85]                   -0.4691      0.153     -3.073      0.002      -0.768      -0.170\n",
      "task_conversation[T.gsm8k_86]                   -0.1338      0.143     -0.933      0.351      -0.415       0.147\n",
      "task_conversation[T.gsm8k_87]                   -0.1268      0.143     -0.888      0.375      -0.407       0.153\n",
      "task_conversation[T.gsm8k_88]                   -0.6643      0.111     -5.963      0.000      -0.883      -0.446\n",
      "task_conversation[T.gsm8k_89]                   -0.2025      0.111     -1.819      0.069      -0.421       0.016\n",
      "task_conversation[T.gsm8k_9]                    -0.5718      0.120     -4.748      0.000      -0.808      -0.336\n",
      "task_conversation[T.gsm8k_90]                    0.0404      0.113      0.358      0.720      -0.181       0.261\n",
      "task_conversation[T.gsm8k_91]                   -0.1645      0.145     -1.134      0.257      -0.449       0.120\n",
      "task_conversation[T.gsm8k_92]                   -0.2393      0.156     -1.537      0.124      -0.545       0.066\n",
      "task_conversation[T.gsm8k_93]                   -0.3720      0.153     -2.429      0.015      -0.672      -0.072\n",
      "task_conversation[T.gsm8k_94]                   -0.4143      0.129     -3.202      0.001      -0.668      -0.161\n",
      "task_conversation[T.gsm8k_95]                   -0.3249      0.116     -2.801      0.005      -0.552      -0.098\n",
      "task_conversation[T.gsm8k_96]                   -0.0906      0.158     -0.573      0.567      -0.401       0.219\n",
      "task_conversation[T.gsm8k_97]                   -0.1551      0.143     -1.087      0.277      -0.435       0.124\n",
      "task_conversation[T.gsm8k_98]                   -0.2546      0.131     -1.936      0.053      -0.512       0.003\n",
      "task_conversation[T.gsm8k_99]                   -0.2995      0.152     -1.968      0.049      -0.598      -0.001\n",
      "conversation_length_thousands                   -0.0765      0.146     -0.525      0.599      -0.362       0.209\n",
      "conversation_length_thousands:model[T.td3]      -0.4493      0.365     -1.232      0.218      -1.164       0.265\n",
      "consolidated_num_steps_ideas                     0.0426      0.007      5.925      0.000       0.028       0.057\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0094      0.012      0.793      0.428      -0.014       0.033\n",
      "conversation_length_thousands_2                 -0.2277      0.104     -2.185      0.029      -0.432      -0.023\n",
      "conversation_length_thousands_2:model[T.td3]     1.0920      0.439      2.488      0.013       0.232       1.952\n",
      "consolidated_num_steps_ideas_2                  -0.0022      0.000     -5.018      0.000      -0.003      -0.001\n",
      "consolidated_num_steps_ideas_2:model[T.td3]     -0.0004      0.001     -0.436      0.663      -0.002       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      104.284   Durbin-Watson:                   1.624\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.429\n",
      "Skew:                          -0.118   Prob(JB):                     1.66e-09\n",
      "Kurtosis:                       2.258   Cond. No.                     5.86e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 5.86e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "        Intercept     model[T.td3] task_conversation[T.gsm8k_10]  \\\n",
      "0  1.056* (0.087)  -0.469* (0.059)               -0.393* (0.112)   \n",
      "\n",
      "  task_conversation[T.gsm8k_100] task_conversation[T.gsm8k_11]  \\\n",
      "0                 -0.242 (0.164)                 -0.128 (0.14)   \n",
      "\n",
      "  task_conversation[T.gsm8k_12] task_conversation[T.gsm8k_13]  \\\n",
      "0                -0.167 (0.137)               -0.901* (0.087)   \n",
      "\n",
      "  task_conversation[T.gsm8k_14] task_conversation[T.gsm8k_15]  \\\n",
      "0               -0.684* (0.111)                -0.045 (0.139)   \n",
      "\n",
      "  task_conversation[T.gsm8k_16]  ... task_conversation[T.gsm8k_99]  \\\n",
      "0                -0.143 (0.116)  ...                 -0.3* (0.152)   \n",
      "\n",
      "  conversation_length_thousands conversation_length_thousands:model[T.td3]  \\\n",
      "0                -0.076 (0.146)                             -0.449 (0.365)   \n",
      "\n",
      "  consolidated_num_steps_ideas consolidated_num_steps_ideas:model[T.td3]  \\\n",
      "0               0.043* (0.007)                             0.009 (0.012)   \n",
      "\n",
      "  conversation_length_thousands_2  \\\n",
      "0                 -0.228* (0.104)   \n",
      "\n",
      "  conversation_length_thousands_2:model[T.td3] consolidated_num_steps_ideas_2  \\\n",
      "0                               1.092* (0.439)                  -0.002* (0.0)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:model[T.td3]                  Title  \n",
      "0                                -0.0 (0.001)  GSM8K Correct, Linear  \n",
      "\n",
      "[1 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_gsm8k_model_interaction = smf.ols('correct ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + task_conversation', data=gsm8k_data).fit(cov_type='cluster', cov_kwds={'groups': gsm8k_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(lpm_with_clustering_gsm8k_model_interaction.summary())\n",
    "\n",
    "# Create results df\n",
    "lpm_with_clustering_gsm8k_model_interaction_df = create_linear_results_df(lpm_with_clustering_gsm8k_model_interaction, \"GSM8K Correct, Linear\")\n",
    "\n",
    "# Print results df\n",
    "print(lpm_with_clustering_gsm8k_model_interaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     avg_inter_paragraph_cosine_sim   R-squared:                       0.438\n",
      "Model:                                        OLS   Adj. R-squared:                  0.391\n",
      "Method:                             Least Squares   F-statistic:                     20.59\n",
      "Date:                            Mon, 11 Dec 2023   Prob (F-statistic):          4.44e-168\n",
      "Time:                                    15:44:19   Log-Likelihood:                 941.60\n",
      "No. Observations:                            1434   AIC:                            -1657.\n",
      "Df Residuals:                                1321   BIC:                            -1062.\n",
      "Df Model:                                     112                                         \n",
      "Covariance Type:                          cluster                                         \n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        0.6990      0.198      3.524      0.000       0.310       1.088\n",
      "model[T.td3]                                     0.0251      0.438      0.057      0.954      -0.834       0.884\n",
      "task_conversation[T.cw_10]                       0.0887      0.055      1.607      0.108      -0.020       0.197\n",
      "task_conversation[T.cw_100]                      0.0868      0.052      1.667      0.095      -0.015       0.189\n",
      "task_conversation[T.cw_11]                       0.2906      0.040      7.327      0.000       0.213       0.368\n",
      "task_conversation[T.cw_12]                       0.1688      0.056      3.015      0.003       0.059       0.279\n",
      "task_conversation[T.cw_13]                       0.1233      0.048      2.577      0.010       0.030       0.217\n",
      "task_conversation[T.cw_14]                       0.1522      0.047      3.236      0.001       0.060       0.244\n",
      "task_conversation[T.cw_15]                       0.0881      0.048      1.848      0.065      -0.005       0.182\n",
      "task_conversation[T.cw_16]                       0.1064      0.038      2.774      0.006       0.031       0.182\n",
      "task_conversation[T.cw_17]                       0.0819      0.048      1.696      0.090      -0.013       0.176\n",
      "task_conversation[T.cw_18]                       0.0948      0.068      1.402      0.161      -0.038       0.227\n",
      "task_conversation[T.cw_19]                       0.1489      0.047      3.136      0.002       0.056       0.242\n",
      "task_conversation[T.cw_2]                        0.1505      0.059      2.567      0.010       0.036       0.265\n",
      "task_conversation[T.cw_20]                       0.0618      0.045      1.383      0.167      -0.026       0.149\n",
      "task_conversation[T.cw_21]                       0.2833      0.036      7.790      0.000       0.212       0.355\n",
      "task_conversation[T.cw_22]                       0.2300      0.059      3.889      0.000       0.114       0.346\n",
      "task_conversation[T.cw_23]                       0.2761      0.039      7.168      0.000       0.201       0.352\n",
      "task_conversation[T.cw_24]                       0.2129      0.050      4.263      0.000       0.115       0.311\n",
      "task_conversation[T.cw_25]                      -0.0236      0.048     -0.496      0.620      -0.117       0.070\n",
      "task_conversation[T.cw_26]                       0.2654      0.044      6.083      0.000       0.180       0.351\n",
      "task_conversation[T.cw_27]                       0.0542      0.041      1.320      0.187      -0.026       0.135\n",
      "task_conversation[T.cw_28]                       0.1951      0.043      4.519      0.000       0.110       0.280\n",
      "task_conversation[T.cw_29]                       0.2745      0.043      6.351      0.000       0.190       0.359\n",
      "task_conversation[T.cw_3]                        0.1374      0.039      3.526      0.000       0.061       0.214\n",
      "task_conversation[T.cw_30]                       0.1051      0.059      1.768      0.077      -0.011       0.222\n",
      "task_conversation[T.cw_31]                       0.0609      0.042      1.456      0.145      -0.021       0.143\n",
      "task_conversation[T.cw_32]                       0.0814      0.053      1.539      0.124      -0.022       0.185\n",
      "task_conversation[T.cw_33]                       0.2108      0.044      4.846      0.000       0.126       0.296\n",
      "task_conversation[T.cw_34]                       0.2704      0.047      5.798      0.000       0.179       0.362\n",
      "task_conversation[T.cw_35]                       0.1038      0.054      1.930      0.054      -0.002       0.209\n",
      "task_conversation[T.cw_36]                      -0.0224      0.051     -0.435      0.664      -0.123       0.078\n",
      "task_conversation[T.cw_37]                       0.0373      0.060      0.622      0.534      -0.080       0.155\n",
      "task_conversation[T.cw_38]                       0.1082      0.052      2.075      0.038       0.006       0.210\n",
      "task_conversation[T.cw_39]                      -0.0366      0.036     -1.002      0.316      -0.108       0.035\n",
      "task_conversation[T.cw_4]                        0.2676      0.039      6.844      0.000       0.191       0.344\n",
      "task_conversation[T.cw_40]                       0.1126      0.066      1.696      0.090      -0.017       0.243\n",
      "task_conversation[T.cw_41]                       0.0922      0.055      1.687      0.092      -0.015       0.199\n",
      "task_conversation[T.cw_42]                       0.0293      0.040      0.736      0.462      -0.049       0.107\n",
      "task_conversation[T.cw_43]                       0.1355      0.041      3.334      0.001       0.056       0.215\n",
      "task_conversation[T.cw_44]                       0.2307      0.040      5.840      0.000       0.153       0.308\n",
      "task_conversation[T.cw_45]                       0.3332      0.052      6.429      0.000       0.232       0.435\n",
      "task_conversation[T.cw_46]                      -0.0925      0.042     -2.213      0.027      -0.174      -0.011\n",
      "task_conversation[T.cw_47]                       0.0770      0.047      1.640      0.101      -0.015       0.169\n",
      "task_conversation[T.cw_48]                       0.0194      0.040      0.479      0.632      -0.060       0.099\n",
      "task_conversation[T.cw_49]                      -0.0299      0.047     -0.632      0.527      -0.123       0.063\n",
      "task_conversation[T.cw_5]                        0.0803      0.041      1.969      0.049       0.000       0.160\n",
      "task_conversation[T.cw_50]                       0.1600      0.052      3.081      0.002       0.058       0.262\n",
      "task_conversation[T.cw_51]                       0.2229      0.040      5.629      0.000       0.145       0.301\n",
      "task_conversation[T.cw_52]                      -0.0025      0.047     -0.053      0.958      -0.095       0.090\n",
      "task_conversation[T.cw_53]                       0.2962      0.039      7.580      0.000       0.220       0.373\n",
      "task_conversation[T.cw_54]                       0.1863      0.047      3.953      0.000       0.094       0.279\n",
      "task_conversation[T.cw_55]                       0.0964      0.053      1.824      0.068      -0.007       0.200\n",
      "task_conversation[T.cw_56]                      -0.0016      0.040     -0.039      0.969      -0.080       0.077\n",
      "task_conversation[T.cw_57]                       0.2732      0.039      7.039      0.000       0.197       0.349\n",
      "task_conversation[T.cw_58]                       0.2599      0.040      6.513      0.000       0.182       0.338\n",
      "task_conversation[T.cw_59]                       0.0982      0.051      1.911      0.056      -0.003       0.199\n",
      "task_conversation[T.cw_6]                        0.1150      0.054      2.118      0.034       0.009       0.221\n",
      "task_conversation[T.cw_60]                      -0.0579      0.043     -1.360      0.174      -0.141       0.026\n",
      "task_conversation[T.cw_61]                       0.0511      0.041      1.261      0.207      -0.028       0.131\n",
      "task_conversation[T.cw_62]                       0.1482      0.056      2.636      0.008       0.038       0.258\n",
      "task_conversation[T.cw_63]                       0.2499      0.053      4.712      0.000       0.146       0.354\n",
      "task_conversation[T.cw_64]                       0.2120      0.043      4.899      0.000       0.127       0.297\n",
      "task_conversation[T.cw_65]                       0.3100      0.039      7.930      0.000       0.233       0.387\n",
      "task_conversation[T.cw_66]                       0.1856      0.044      4.255      0.000       0.100       0.271\n",
      "task_conversation[T.cw_67]                       0.1912      0.048      3.999      0.000       0.097       0.285\n",
      "task_conversation[T.cw_68]                       0.0182      0.055      0.331      0.741      -0.090       0.126\n",
      "task_conversation[T.cw_69]                       0.2459      0.041      6.025      0.000       0.166       0.326\n",
      "task_conversation[T.cw_7]                        0.0877      0.040      2.196      0.028       0.009       0.166\n",
      "task_conversation[T.cw_70]                      -0.0470      0.045     -1.034      0.301      -0.136       0.042\n",
      "task_conversation[T.cw_71]                       0.1280      0.079      1.612      0.107      -0.028       0.284\n",
      "task_conversation[T.cw_72]                      -0.0354      0.045     -0.792      0.429      -0.123       0.052\n",
      "task_conversation[T.cw_73]                       0.1320      0.047      2.829      0.005       0.041       0.223\n",
      "task_conversation[T.cw_74]                       0.0554      0.043      1.285      0.199      -0.029       0.140\n",
      "task_conversation[T.cw_75]                       0.2054      0.046      4.423      0.000       0.114       0.296\n",
      "task_conversation[T.cw_76]                       0.1975      0.045      4.356      0.000       0.109       0.286\n",
      "task_conversation[T.cw_77]                       0.2317      0.052      4.464      0.000       0.130       0.333\n",
      "task_conversation[T.cw_78]                       0.2612      0.043      6.035      0.000       0.176       0.346\n",
      "task_conversation[T.cw_79]                       0.2342      0.046      5.076      0.000       0.144       0.325\n",
      "task_conversation[T.cw_8]                        0.1760      0.042      4.219      0.000       0.094       0.258\n",
      "task_conversation[T.cw_80]                       0.2956      0.043      6.838      0.000       0.211       0.380\n",
      "task_conversation[T.cw_81]                       0.3754      0.039      9.565      0.000       0.298       0.452\n",
      "task_conversation[T.cw_82]                       0.0120      0.054      0.224      0.822      -0.093       0.117\n",
      "task_conversation[T.cw_83]                       0.1375      0.046      2.987      0.003       0.047       0.228\n",
      "task_conversation[T.cw_84]                       0.2054      0.036      5.655      0.000       0.134       0.277\n",
      "task_conversation[T.cw_85]                       0.2218      0.041      5.382      0.000       0.141       0.303\n",
      "task_conversation[T.cw_86]                      -0.0248      0.043     -0.581      0.561      -0.108       0.059\n",
      "task_conversation[T.cw_87]                       0.0868      0.052      1.685      0.092      -0.014       0.188\n",
      "task_conversation[T.cw_88]                       0.0938      0.052      1.789      0.074      -0.009       0.197\n",
      "task_conversation[T.cw_89]                       0.0378      0.051      0.747      0.455      -0.061       0.137\n",
      "task_conversation[T.cw_9]                        0.2633      0.040      6.643      0.000       0.186       0.341\n",
      "task_conversation[T.cw_90]                       0.0298      0.054      0.552      0.581      -0.076       0.136\n",
      "task_conversation[T.cw_91]                      -0.0758      0.062     -1.225      0.221      -0.197       0.046\n",
      "task_conversation[T.cw_92]                       0.0137      0.052      0.265      0.791      -0.088       0.115\n",
      "task_conversation[T.cw_93]                       0.0322      0.060      0.541      0.589      -0.084       0.149\n",
      "task_conversation[T.cw_94]                       0.1438      0.060      2.381      0.017       0.025       0.262\n",
      "task_conversation[T.cw_95]                      -0.0666      0.047     -1.427      0.153      -0.158       0.025\n",
      "task_conversation[T.cw_96]                       0.2003      0.046      4.314      0.000       0.109       0.291\n",
      "task_conversation[T.cw_97]                       0.0325      0.041      0.787      0.431      -0.048       0.114\n",
      "task_conversation[T.cw_98]                       0.2036      0.045      4.562      0.000       0.116       0.291\n",
      "task_conversation[T.cw_99]                       0.0964      0.044      2.171      0.030       0.009       0.183\n",
      "conversation_length_thousands                   -0.0535      0.064     -0.829      0.407      -0.180       0.073\n",
      "conversation_length_thousands:model[T.td3]       0.2775      0.123      2.248      0.025       0.036       0.519\n",
      "consolidated_num_steps_ideas                     0.0141      0.005      3.013      0.003       0.005       0.023\n",
      "consolidated_num_steps_ideas:model[T.td3]       -0.0198      0.012     -1.632      0.103      -0.044       0.004\n",
      "conversation_length_thousands_2                  0.0185      0.039      0.475      0.635      -0.058       0.095\n",
      "conversation_length_thousands_2:model[T.td3]    -0.1077      0.095     -1.137      0.256      -0.293       0.078\n",
      "consolidated_num_steps_ideas_2                  -0.0009      0.001     -1.346      0.178      -0.002       0.000\n",
      "consolidated_num_steps_ideas_2:model[T.td3]      0.0043      0.003      1.520      0.129      -0.001       0.010\n",
      "fres                                            -0.0125      0.006     -2.024      0.043      -0.025      -0.000\n",
      "fres:model[T.td3]                               -0.0026      0.012     -0.214      0.831      -0.027       0.022\n",
      "fres_2                                        9.844e-05   4.88e-05      2.019      0.044    2.86e-06       0.000\n",
      "fres_2:model[T.td3]                           1.053e-05   8.67e-05      0.121      0.903      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       14.289   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.460\n",
      "Skew:                           0.054   Prob(JB):                     2.19e-05\n",
      "Kurtosis:                       3.590   Cond. No.                     8.26e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 8.26e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "        Intercept   model[T.td3] task_conversation[T.cw_10]  \\\n",
      "0  0.699* (0.198)  0.025 (0.438)              0.089 (0.055)   \n",
      "\n",
      "  task_conversation[T.cw_100] task_conversation[T.cw_11]  \\\n",
      "0               0.087 (0.052)              0.291* (0.04)   \n",
      "\n",
      "  task_conversation[T.cw_12] task_conversation[T.cw_13]  \\\n",
      "0             0.169* (0.056)             0.123* (0.048)   \n",
      "\n",
      "  task_conversation[T.cw_14] task_conversation[T.cw_15]  \\\n",
      "0             0.152* (0.047)              0.088 (0.048)   \n",
      "\n",
      "  task_conversation[T.cw_16]  ... consolidated_num_steps_ideas:model[T.td3]  \\\n",
      "0             0.106* (0.038)  ...                             -0.02 (0.012)   \n",
      "\n",
      "  conversation_length_thousands_2  \\\n",
      "0                   0.018 (0.039)   \n",
      "\n",
      "  conversation_length_thousands_2:model[T.td3] consolidated_num_steps_ideas_2  \\\n",
      "0                               -0.108 (0.095)                 -0.001 (0.001)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:model[T.td3]             fres  \\\n",
      "0                               0.004 (0.003)  -0.013* (0.006)   \n",
      "\n",
      "  fres:model[T.td3]      fres_2 fres_2:model[T.td3]  \\\n",
      "0    -0.003 (0.012)  0.0* (0.0)           0.0 (0.0)   \n",
      "\n",
      "                                Title  \n",
      "0  Creative Writing Cosine Similarity  \n",
      "\n",
      "[1 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "reg_with_clustering_cw_model_interaction = smf.ols(\"avg_inter_paragraph_cosine_sim ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + fres * model + fres_2 * model + task_conversation\",\n",
    "                                 data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(reg_with_clustering_cw_model_interaction.summary())\n",
    "\n",
    "# Create results df\n",
    "reg_with_clustering_cw_model_interaction_df = create_linear_results_df(reg_with_clustering_cw_model_interaction, \"Creative Writing Cosine Similarity\")\n",
    "\n",
    "# Print results df\n",
    "print(reg_with_clustering_cw_model_interaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650621\n",
      "         Iterations 5\n",
      "logit no clustering cw compliance\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   No. Observations:                 1434\n",
      "Model:                          Logit   Df Residuals:                     1420\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 11 Dec 2023   Pseudo R-squ.:                 0.05831\n",
      "Time:                        15:44:19   Log-Likelihood:                -932.99\n",
      "converged:                       True   LL-Null:                       -990.76\n",
      "Covariance Type:                  HC3   LLR p-value:                 1.531e-18\n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                       -8.3356      4.010     -2.078      0.038     -16.196      -0.475\n",
      "model[T.td3]                                    -1.0071      7.080     -0.142      0.887     -14.884      12.870\n",
      "conversation_length_thousands                   -0.5153      1.114     -0.462      0.644      -2.699       1.669\n",
      "conversation_length_thousands:model[T.td3]      -0.7232      2.033     -0.356      0.722      -4.709       3.262\n",
      "consolidated_num_steps_ideas                    -0.0387      0.096     -0.401      0.688      -0.228       0.150\n",
      "consolidated_num_steps_ideas:model[T.td3]       -0.0981      0.180     -0.544      0.587      -0.452       0.256\n",
      "conversation_length_thousands_2                  0.0157      0.666      0.024      0.981      -1.290       1.321\n",
      "conversation_length_thousands_2:model[T.td3]    -0.3089      1.587     -0.195      0.846      -3.419       2.802\n",
      "consolidated_num_steps_ideas_2                   0.0135      0.015      0.874      0.382      -0.017       0.044\n",
      "consolidated_num_steps_ideas_2:model[T.td3]      0.0075      0.039      0.195      0.845      -0.068       0.083\n",
      "fres                                             0.2431      0.126      1.932      0.053      -0.004       0.490\n",
      "fres:model[T.td3]                               -0.0012      0.203     -0.006      0.995      -0.400       0.397\n",
      "fres_2                                          -0.0016      0.001     -1.646      0.100      -0.004       0.000\n",
      "fres_2:model[T.td3]                              0.0002      0.001      0.104      0.917      -0.003       0.003\n",
      "================================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:             compliance\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "================================================================================================================\n",
      "                                                  dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                                    -0.2314      1.627     -0.142      0.887      -3.419       2.957\n",
      "conversation_length_thousands                   -0.1184      0.256     -0.463      0.644      -0.620       0.383\n",
      "conversation_length_thousands:model[T.td3]      -0.1661      0.467     -0.356      0.722      -1.082       0.749\n",
      "consolidated_num_steps_ideas                    -0.0089      0.022     -0.401      0.688      -0.052       0.035\n",
      "consolidated_num_steps_ideas:model[T.td3]       -0.0225      0.041     -0.544      0.587      -0.104       0.059\n",
      "conversation_length_thousands_2                  0.0036      0.153      0.024      0.981      -0.296       0.303\n",
      "conversation_length_thousands_2:model[T.td3]    -0.0710      0.365     -0.195      0.846      -0.785       0.644\n",
      "consolidated_num_steps_ideas_2                   0.0031      0.004      0.875      0.381      -0.004       0.010\n",
      "consolidated_num_steps_ideas_2:model[T.td3]      0.0017      0.009      0.195      0.845      -0.016       0.019\n",
      "fres                                             0.0559      0.029      1.941      0.052      -0.001       0.112\n",
      "fres:model[T.td3]                               -0.0003      0.047     -0.006      0.995      -0.092       0.091\n",
      "fres_2                                          -0.0004      0.000     -1.652      0.099      -0.001    6.94e-05\n",
      "fres_2:model[T.td3]                           3.507e-05      0.000      0.104      0.917      -0.001       0.001\n",
      "================================================================================================================\n",
      "     model[T.td3] conversation_length_thousands  \\\n",
      "0  -0.231 (1.627)                -0.118 (0.256)   \n",
      "\n",
      "  conversation_length_thousands:model[T.td3] consolidated_num_steps_ideas  \\\n",
      "0                             -0.166 (0.467)               -0.009 (0.022)   \n",
      "\n",
      "  consolidated_num_steps_ideas:model[T.td3] conversation_length_thousands_2  \\\n",
      "0                            -0.023 (0.041)                   0.004 (0.153)   \n",
      "\n",
      "  conversation_length_thousands_2:model[T.td3] consolidated_num_steps_ideas_2  \\\n",
      "0                               -0.071 (0.365)                  0.003 (0.004)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:model[T.td3]           fres  \\\n",
      "0                               0.002 (0.009)  0.056 (0.029)   \n",
      "\n",
      "  fres:model[T.td3]      fres_2 fres_2:model[T.td3]  \\\n",
      "0      -0.0 (0.047)  -0.0 (0.0)           0.0 (0.0)   \n",
      "\n",
      "                                Title  \n",
      "0  Creative Writing Compliance, Logit  \n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_cw_compliance_model_interaction = smf.logit('compliance ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + fres * model + fres_2 * model', data=cw_data).fit(cov_type='HC3')\n",
    "\n",
    "print('logit no clustering cw compliance')\n",
    "# Display the summary\n",
    "print(logit_no_clustering_cw_compliance_model_interaction.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_cw_compliance_marginal_effects_model_interaction = logit_no_clustering_cw_compliance_model_interaction.get_margeff(at='overall')\n",
    "print(logit_no_clustering_cw_compliance_marginal_effects_model_interaction.summary())\n",
    "\n",
    "# Create results df\n",
    "logit_no_clustering_cw_compliance_model_interaction_df = create_logit_results_df(logit_no_clustering_cw_compliance_model_interaction, logit_no_clustering_cw_compliance_marginal_effects_model_interaction, \"Creative Writing Compliance, Logit\")\n",
    "\n",
    "# Print results df\n",
    "print(logit_no_clustering_cw_compliance_model_interaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpm with clustering cw compliance\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   R-squared:                       0.321\n",
      "Model:                            OLS   Adj. R-squared:                  0.204\n",
      "Method:                 Least Squares   F-statistic:                     67.99\n",
      "Date:                Mon, 11 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        15:44:19   Log-Likelihood:                -759.90\n",
      "No. Observations:                1434   AIC:                             1944.\n",
      "Df Residuals:                    1222   BIC:                             3061.\n",
      "Df Model:                         211                                         \n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                       -1.6098      0.874     -1.842      0.066      -3.323       0.103\n",
      "model[T.td3]                                     0.3499      1.628      0.215      0.830      -2.841       3.541\n",
      "task_conversation[T.cw_10]                      -0.1557      0.240     -0.648      0.517      -0.627       0.315\n",
      "task_conversation[T.cw_100]                      0.4184      0.266      1.575      0.115      -0.102       0.939\n",
      "task_conversation[T.cw_11]                       0.1550      0.285      0.544      0.586      -0.403       0.713\n",
      "task_conversation[T.cw_12]                      -0.1466      0.249     -0.588      0.557      -0.635       0.342\n",
      "task_conversation[T.cw_13]                       0.3582      0.271      1.320      0.187      -0.174       0.890\n",
      "task_conversation[T.cw_14]                       0.5081      0.258      1.970      0.049       0.003       1.014\n",
      "task_conversation[T.cw_15]                       0.2963      0.281      1.056      0.291      -0.254       0.846\n",
      "task_conversation[T.cw_16]                       0.2396      0.270      0.889      0.374      -0.289       0.768\n",
      "task_conversation[T.cw_17]                       0.6541      0.200      3.277      0.001       0.263       1.045\n",
      "task_conversation[T.cw_18]                       0.2032      0.264      0.771      0.441      -0.314       0.720\n",
      "task_conversation[T.cw_19]                       0.3205      0.271      1.182      0.237      -0.211       0.852\n",
      "task_conversation[T.cw_2]                        0.3253      0.273      1.193      0.233      -0.209       0.860\n",
      "task_conversation[T.cw_20]                       0.4145      0.287      1.443      0.149      -0.149       0.978\n",
      "task_conversation[T.cw_21]                       0.5857      0.232      2.523      0.012       0.131       1.041\n",
      "task_conversation[T.cw_22]                       0.7159      0.198      3.614      0.000       0.328       1.104\n",
      "task_conversation[T.cw_23]                       0.4459      0.278      1.602      0.109      -0.100       0.991\n",
      "task_conversation[T.cw_24]                       0.2786      0.282      0.987      0.324      -0.275       0.832\n",
      "task_conversation[T.cw_25]                       0.5738      0.244      2.348      0.019       0.095       1.053\n",
      "task_conversation[T.cw_26]                       0.7443      0.200      3.724      0.000       0.353       1.136\n",
      "task_conversation[T.cw_27]                       0.2562      0.278      0.920      0.357      -0.289       0.802\n",
      "task_conversation[T.cw_28]                       0.2203      0.276      0.799      0.425      -0.320       0.761\n",
      "task_conversation[T.cw_29]                      -0.2931      0.197     -1.484      0.138      -0.680       0.094\n",
      "task_conversation[T.cw_3]                        0.5111      0.248      2.060      0.039       0.025       0.997\n",
      "task_conversation[T.cw_30]                       0.5903      0.220      2.684      0.007       0.159       1.021\n",
      "task_conversation[T.cw_31]                       0.2004      0.284      0.705      0.481      -0.357       0.758\n",
      "task_conversation[T.cw_32]                       0.7036      0.198      3.553      0.000       0.315       1.092\n",
      "task_conversation[T.cw_33]                      -0.0791      0.258     -0.307      0.759      -0.584       0.426\n",
      "task_conversation[T.cw_34]                       0.6186      0.248      2.497      0.013       0.133       1.104\n",
      "task_conversation[T.cw_35]                       0.3169      0.292      1.087      0.277      -0.254       0.888\n",
      "task_conversation[T.cw_36]                       0.3683      0.271      1.361      0.173      -0.162       0.898\n",
      "task_conversation[T.cw_37]                       0.4152      0.270      1.540      0.124      -0.113       0.944\n",
      "task_conversation[T.cw_38]                       0.4799      0.266      1.803      0.071      -0.042       1.002\n",
      "task_conversation[T.cw_39]                       0.5101      0.263      1.937      0.053      -0.006       1.026\n",
      "task_conversation[T.cw_4]                        0.4846      0.254      1.908      0.056      -0.013       0.982\n",
      "task_conversation[T.cw_40]                       0.1007      0.268      0.375      0.708      -0.426       0.627\n",
      "task_conversation[T.cw_41]                       0.1231      0.270      0.457      0.648      -0.405       0.651\n",
      "task_conversation[T.cw_42]                       0.1832      0.288      0.636      0.525      -0.381       0.747\n",
      "task_conversation[T.cw_43]                       0.4217      0.260      1.625      0.104      -0.087       0.930\n",
      "task_conversation[T.cw_44]                      -0.1899      0.240     -0.792      0.428      -0.660       0.280\n",
      "task_conversation[T.cw_45]                      -0.0257      0.257     -0.100      0.920      -0.529       0.478\n",
      "task_conversation[T.cw_46]                       0.0977      0.268      0.365      0.715      -0.428       0.623\n",
      "task_conversation[T.cw_47]                      -0.2290      0.203     -1.129      0.259      -0.627       0.169\n",
      "task_conversation[T.cw_48]                       0.2321      0.287      0.808      0.419      -0.331       0.795\n",
      "task_conversation[T.cw_49]                       0.2097      0.289      0.725      0.469      -0.358       0.777\n",
      "task_conversation[T.cw_5]                        0.5393      0.256      2.111      0.035       0.038       1.040\n",
      "task_conversation[T.cw_50]                      -0.1206      0.209     -0.577      0.564      -0.530       0.289\n",
      "task_conversation[T.cw_51]                       0.5681      0.232      2.446      0.014       0.113       1.023\n",
      "task_conversation[T.cw_52]                      -0.0026      0.257     -0.010      0.992      -0.506       0.501\n",
      "task_conversation[T.cw_53]                       0.5204      0.267      1.950      0.051      -0.003       1.043\n",
      "task_conversation[T.cw_54]                       0.1304      0.273      0.478      0.633      -0.405       0.665\n",
      "task_conversation[T.cw_55]                       0.3144      0.268      1.173      0.241      -0.211       0.840\n",
      "task_conversation[T.cw_56]                       0.5908      0.228      2.594      0.009       0.144       1.037\n",
      "task_conversation[T.cw_57]                      -0.1418      0.239     -0.594      0.553      -0.610       0.326\n",
      "task_conversation[T.cw_58]                       0.4097      0.266      1.538      0.124      -0.112       0.932\n",
      "task_conversation[T.cw_59]                       0.6126      0.239      2.558      0.011       0.143       1.082\n",
      "task_conversation[T.cw_6]                       -0.1844      0.204     -0.902      0.367      -0.585       0.216\n",
      "task_conversation[T.cw_60]                      -0.1537      0.208     -0.739      0.460      -0.562       0.254\n",
      "task_conversation[T.cw_61]                       0.2760      0.280      0.987      0.324      -0.272       0.824\n",
      "task_conversation[T.cw_62]                       0.1182      0.268      0.441      0.659      -0.407       0.643\n",
      "task_conversation[T.cw_63]                       0.1402      0.264      0.530      0.596      -0.378       0.658\n",
      "task_conversation[T.cw_64]                       0.3097      0.283      1.096      0.273      -0.244       0.864\n",
      "task_conversation[T.cw_65]                       0.5588      0.238      2.347      0.019       0.092       1.025\n",
      "task_conversation[T.cw_66]                      -0.1587      0.231     -0.686      0.493      -0.612       0.295\n",
      "task_conversation[T.cw_67]                       0.6009      0.245      2.451      0.014       0.120       1.082\n",
      "task_conversation[T.cw_68]                       0.2843      0.280      1.014      0.310      -0.265       0.834\n",
      "task_conversation[T.cw_69]                       0.0055      0.268      0.021      0.984      -0.519       0.530\n",
      "task_conversation[T.cw_7]                       -0.0499      0.233     -0.215      0.830      -0.506       0.406\n",
      "task_conversation[T.cw_70]                       0.6157      0.237      2.595      0.009       0.151       1.081\n",
      "task_conversation[T.cw_71]                       0.2586      0.270      0.958      0.338      -0.270       0.788\n",
      "task_conversation[T.cw_72]                       0.5919      0.246      2.407      0.016       0.110       1.074\n",
      "task_conversation[T.cw_73]                      -0.0422      0.258     -0.164      0.870      -0.548       0.464\n",
      "task_conversation[T.cw_74]                       0.4842      0.275      1.759      0.079      -0.055       1.024\n",
      "task_conversation[T.cw_75]                       0.1451      0.281      0.517      0.605      -0.405       0.695\n",
      "task_conversation[T.cw_76]                      -0.2458      0.200     -1.226      0.220      -0.639       0.147\n",
      "task_conversation[T.cw_77]                       0.7561      0.202      3.742      0.000       0.360       1.152\n",
      "task_conversation[T.cw_78]                       0.4161      0.263      1.584      0.113      -0.099       0.931\n",
      "task_conversation[T.cw_79]                       0.1437      0.270      0.531      0.595      -0.386       0.674\n",
      "task_conversation[T.cw_8]                        0.6429      0.236      2.722      0.006       0.180       1.106\n",
      "task_conversation[T.cw_80]                       0.0125      0.276      0.045      0.964      -0.529       0.554\n",
      "task_conversation[T.cw_81]                       0.8552      0.210      4.063      0.000       0.443       1.268\n",
      "task_conversation[T.cw_82]                      -0.1147      0.247     -0.463      0.643      -0.600       0.370\n",
      "task_conversation[T.cw_83]                       0.2532      0.279      0.908      0.364      -0.293       0.799\n",
      "task_conversation[T.cw_84]                      -0.1462      0.242     -0.604      0.546      -0.621       0.328\n",
      "task_conversation[T.cw_85]                       0.3297      0.269      1.224      0.221      -0.198       0.858\n",
      "task_conversation[T.cw_86]                       0.4767      0.244      1.954      0.051      -0.002       0.955\n",
      "task_conversation[T.cw_87]                       0.5994      0.238      2.518      0.012       0.133       1.066\n",
      "task_conversation[T.cw_88]                      -0.1409      0.240     -0.588      0.557      -0.611       0.329\n",
      "task_conversation[T.cw_89]                       0.2632      0.284      0.927      0.354      -0.293       0.819\n",
      "task_conversation[T.cw_9]                        0.4962      0.244      2.035      0.042       0.018       0.974\n",
      "task_conversation[T.cw_90]                       0.1985      0.285      0.697      0.486      -0.360       0.757\n",
      "task_conversation[T.cw_91]                       0.3266      0.283      1.154      0.248      -0.228       0.881\n",
      "task_conversation[T.cw_92]                       0.4127      0.256      1.610      0.107      -0.090       0.915\n",
      "task_conversation[T.cw_93]                       0.2996      0.292      1.028      0.304      -0.272       0.871\n",
      "task_conversation[T.cw_94]                       0.1362      0.276      0.494      0.621      -0.404       0.677\n",
      "task_conversation[T.cw_95]                       0.7192      0.199      3.623      0.000       0.330       1.108\n",
      "task_conversation[T.cw_96]                       0.3478      0.279      1.246      0.213      -0.199       0.895\n",
      "task_conversation[T.cw_97]                       0.5500      0.251      2.196      0.028       0.059       1.041\n",
      "task_conversation[T.cw_98]                       0.3845      0.262      1.466      0.143      -0.130       0.899\n",
      "task_conversation[T.cw_99]                      -0.1146      0.236     -0.485      0.628      -0.578       0.349\n",
      "task_conversation[T.cw_10]:model[T.td3]          0.2161      0.347      0.623      0.533      -0.463       0.896\n",
      "task_conversation[T.cw_100]:model[T.td3]        -0.7591      0.306     -2.485      0.013      -1.358      -0.160\n",
      "task_conversation[T.cw_11]:model[T.td3]         -0.3908      0.292     -1.340      0.180      -0.962       0.181\n",
      "task_conversation[T.cw_12]:model[T.td3]         -0.2726      0.236     -1.156      0.248      -0.735       0.189\n",
      "task_conversation[T.cw_13]:model[T.td3]         -0.5249      0.225     -2.329      0.020      -0.967      -0.083\n",
      "task_conversation[T.cw_14]:model[T.td3]         -0.5501      0.380     -1.446      0.148      -1.296       0.195\n",
      "task_conversation[T.cw_15]:model[T.td3]         -0.6386      0.282     -2.266      0.023      -1.191      -0.086\n",
      "task_conversation[T.cw_16]:model[T.td3]         -0.7438      0.288     -2.581      0.010      -1.309      -0.179\n",
      "task_conversation[T.cw_17]:model[T.td3]         -1.0122      0.233     -4.338      0.000      -1.470      -0.555\n",
      "task_conversation[T.cw_18]:model[T.td3]         -0.0964      0.332     -0.291      0.771      -0.746       0.554\n",
      "task_conversation[T.cw_19]:model[T.td3]         -0.1312      0.224     -0.585      0.558      -0.570       0.308\n",
      "task_conversation[T.cw_2]:model[T.td3]          -0.8798      0.233     -3.768      0.000      -1.337      -0.422\n",
      "task_conversation[T.cw_20]:model[T.td3]         -0.5021      0.308     -1.629      0.103      -1.106       0.102\n",
      "task_conversation[T.cw_21]:model[T.td3]         -0.7764      0.254     -3.061      0.002      -1.274      -0.279\n",
      "task_conversation[T.cw_22]:model[T.td3]         -0.9380      0.249     -3.769      0.000      -1.426      -0.450\n",
      "task_conversation[T.cw_23]:model[T.td3]         -0.6454      0.295     -2.190      0.029      -1.223      -0.068\n",
      "task_conversation[T.cw_24]:model[T.td3]         -0.4433      0.338     -1.311      0.190      -1.106       0.219\n",
      "task_conversation[T.cw_25]:model[T.td3]         -0.5617      0.244     -2.299      0.022      -1.041      -0.083\n",
      "task_conversation[T.cw_26]:model[T.td3]         -1.2285      0.183     -6.721      0.000      -1.587      -0.870\n",
      "task_conversation[T.cw_27]:model[T.td3]         -0.3573      0.334     -1.070      0.285      -1.012       0.297\n",
      "task_conversation[T.cw_28]:model[T.td3]         -0.5334      0.358     -1.491      0.136      -1.235       0.168\n",
      "task_conversation[T.cw_29]:model[T.td3]         -0.2201      0.178     -1.238      0.216      -0.569       0.128\n",
      "task_conversation[T.cw_3]:model[T.td3]          -0.5830      0.267     -2.185      0.029      -1.106      -0.060\n",
      "task_conversation[T.cw_30]:model[T.td3]         -0.9428      0.260     -3.622      0.000      -1.453      -0.433\n",
      "task_conversation[T.cw_31]:model[T.td3]         -0.3907      0.319     -1.225      0.220      -1.016       0.234\n",
      "task_conversation[T.cw_32]:model[T.td3]         -0.8545      0.312     -2.742      0.006      -1.465      -0.244\n",
      "task_conversation[T.cw_33]:model[T.td3]          0.1262      0.311      0.406      0.685      -0.483       0.735\n",
      "task_conversation[T.cw_34]:model[T.td3]         -0.9737      0.279     -3.486      0.000      -1.521      -0.426\n",
      "task_conversation[T.cw_35]:model[T.td3]         -0.0728      0.324     -0.225      0.822      -0.708       0.562\n",
      "task_conversation[T.cw_36]:model[T.td3]         -0.6014      0.253     -2.379      0.017      -1.097      -0.106\n",
      "task_conversation[T.cw_37]:model[T.td3]         -0.4620      0.382     -1.208      0.227      -1.211       0.287\n",
      "task_conversation[T.cw_38]:model[T.td3]         -0.8170      0.289     -2.824      0.005      -1.384      -0.250\n",
      "task_conversation[T.cw_39]:model[T.td3]         -0.7536      0.235     -3.213      0.001      -1.213      -0.294\n",
      "task_conversation[T.cw_4]:model[T.td3]          -0.4212      0.280     -1.505      0.132      -0.970       0.127\n",
      "task_conversation[T.cw_40]:model[T.td3]         -0.4040      0.282     -1.433      0.152      -0.956       0.148\n",
      "task_conversation[T.cw_41]:model[T.td3]         -0.0898      0.325     -0.277      0.782      -0.726       0.547\n",
      "task_conversation[T.cw_42]:model[T.td3]          0.0312      0.409      0.076      0.939      -0.770       0.832\n",
      "task_conversation[T.cw_43]:model[T.td3]         -0.4244      0.281     -1.508      0.132      -0.976       0.127\n",
      "task_conversation[T.cw_44]:model[T.td3]          0.1936      0.292      0.663      0.507      -0.379       0.766\n",
      "task_conversation[T.cw_45]:model[T.td3]         -0.1562      0.307     -0.510      0.610      -0.757       0.445\n",
      "task_conversation[T.cw_46]:model[T.td3]          0.2429      0.250      0.972      0.331      -0.247       0.733\n",
      "task_conversation[T.cw_47]:model[T.td3]          0.0804      0.254      0.317      0.751      -0.417       0.578\n",
      "task_conversation[T.cw_48]:model[T.td3]         -0.1962      0.329     -0.597      0.551      -0.840       0.448\n",
      "task_conversation[T.cw_49]:model[T.td3]         -0.3378      0.384     -0.879      0.379      -1.091       0.415\n",
      "task_conversation[T.cw_5]:model[T.td3]          -0.5582      0.327     -1.708      0.088      -1.199       0.082\n",
      "task_conversation[T.cw_50]:model[T.td3]         -0.3153      0.189     -1.670      0.095      -0.685       0.055\n",
      "task_conversation[T.cw_51]:model[T.td3]         -0.6756      0.268     -2.517      0.012      -1.202      -0.150\n",
      "task_conversation[T.cw_52]:model[T.td3]          0.0732      0.332      0.220      0.826      -0.578       0.724\n",
      "task_conversation[T.cw_53]:model[T.td3]         -0.5786      0.253     -2.291      0.022      -1.074      -0.084\n",
      "task_conversation[T.cw_54]:model[T.td3]         -0.0756      0.237     -0.320      0.749      -0.539       0.388\n",
      "task_conversation[T.cw_55]:model[T.td3]         -0.4905      0.372     -1.317      0.188      -1.220       0.239\n",
      "task_conversation[T.cw_56]:model[T.td3]         -0.4491      0.221     -2.028      0.043      -0.883      -0.015\n",
      "task_conversation[T.cw_57]:model[T.td3]         -0.3066      0.220     -1.391      0.164      -0.739       0.125\n",
      "task_conversation[T.cw_58]:model[T.td3]         -0.4665      0.339     -1.374      0.169      -1.132       0.199\n",
      "task_conversation[T.cw_59]:model[T.td3]         -0.8521      0.252     -3.378      0.001      -1.346      -0.358\n",
      "task_conversation[T.cw_6]:model[T.td3]          -0.2152      0.186     -1.157      0.247      -0.580       0.149\n",
      "task_conversation[T.cw_60]:model[T.td3]         -0.2864      0.189     -1.515      0.130      -0.657       0.084\n",
      "task_conversation[T.cw_61]:model[T.td3]         -0.5313      0.317     -1.675      0.094      -1.153       0.090\n",
      "task_conversation[T.cw_62]:model[T.td3]         -0.0565      0.258     -0.219      0.826      -0.561       0.448\n",
      "task_conversation[T.cw_63]:model[T.td3]         -0.4190      0.267     -1.572      0.116      -0.942       0.104\n",
      "task_conversation[T.cw_64]:model[T.td3]         -0.0389      0.254     -0.153      0.878      -0.537       0.459\n",
      "task_conversation[T.cw_65]:model[T.td3]         -0.6240      0.235     -2.659      0.008      -1.084      -0.164\n",
      "task_conversation[T.cw_66]:model[T.td3]          0.1326      0.308      0.430      0.667      -0.471       0.736\n",
      "task_conversation[T.cw_67]:model[T.td3]         -0.4492      0.227     -1.981      0.048      -0.894      -0.005\n",
      "task_conversation[T.cw_68]:model[T.td3]         -0.2133      0.323     -0.661      0.509      -0.846       0.420\n",
      "task_conversation[T.cw_69]:model[T.td3]         -0.3238      0.327     -0.990      0.322      -0.965       0.318\n",
      "task_conversation[T.cw_7]:model[T.td3]          -0.0467      0.318     -0.147      0.883      -0.670       0.577\n",
      "task_conversation[T.cw_70]:model[T.td3]         -0.7573      0.312     -2.429      0.015      -1.368      -0.146\n",
      "task_conversation[T.cw_71]:model[T.td3]         -0.2789      0.278     -1.003      0.316      -0.824       0.266\n",
      "task_conversation[T.cw_72]:model[T.td3]         -0.6431      0.331     -1.945      0.052      -1.291       0.005\n",
      "task_conversation[T.cw_73]:model[T.td3]         -0.3507      0.295     -1.189      0.234      -0.929       0.227\n",
      "task_conversation[T.cw_74]:model[T.td3]         -0.5844      0.284     -2.061      0.039      -1.140      -0.029\n",
      "task_conversation[T.cw_75]:model[T.td3]         -0.1765      0.397     -0.445      0.657      -0.955       0.601\n",
      "task_conversation[T.cw_76]:model[T.td3]         -0.0288      0.292     -0.098      0.922      -0.602       0.544\n",
      "task_conversation[T.cw_77]:model[T.td3]         -1.0793      0.231     -4.678      0.000      -1.531      -0.627\n",
      "task_conversation[T.cw_78]:model[T.td3]         -0.6679      0.249     -2.685      0.007      -1.156      -0.180\n",
      "task_conversation[T.cw_79]:model[T.td3]          0.0582      0.248      0.234      0.815      -0.428       0.545\n",
      "task_conversation[T.cw_8]:model[T.td3]          -0.5890      0.253     -2.331      0.020      -1.084      -0.094\n",
      "task_conversation[T.cw_80]:model[T.td3]          0.2817      0.290      0.972      0.331      -0.287       0.850\n",
      "task_conversation[T.cw_81]:model[T.td3]         -0.4956      0.216     -2.294      0.022      -0.919      -0.072\n",
      "task_conversation[T.cw_82]:model[T.td3]          0.2148      0.240      0.896      0.370      -0.255       0.685\n",
      "task_conversation[T.cw_83]:model[T.td3]         -0.3673      0.284     -1.292      0.196      -0.924       0.190\n",
      "task_conversation[T.cw_84]:model[T.td3]          0.0515      0.311      0.165      0.869      -0.559       0.661\n",
      "task_conversation[T.cw_85]:model[T.td3]         -0.8549      0.237     -3.614      0.000      -1.319      -0.391\n",
      "task_conversation[T.cw_86]:model[T.td3]         -0.4562      0.377     -1.209      0.227      -1.196       0.283\n",
      "task_conversation[T.cw_87]:model[T.td3]         -0.7951      0.250     -3.176      0.001      -1.286      -0.304\n",
      "task_conversation[T.cw_88]:model[T.td3]          0.0646      0.299      0.216      0.829      -0.521       0.650\n",
      "task_conversation[T.cw_89]:model[T.td3]         -0.2602      0.281     -0.927      0.354      -0.810       0.290\n",
      "task_conversation[T.cw_9]:model[T.td3]          -0.6862      0.318     -2.156      0.031      -1.310      -0.062\n",
      "task_conversation[T.cw_90]:model[T.td3]         -0.2268      0.320     -0.710      0.478      -0.853       0.400\n",
      "task_conversation[T.cw_91]:model[T.td3]         -0.1718      0.230     -0.746      0.456      -0.623       0.280\n",
      "task_conversation[T.cw_92]:model[T.td3]         -0.3780      0.313     -1.207      0.227      -0.992       0.236\n",
      "task_conversation[T.cw_93]:model[T.td3]         -0.2309      0.322     -0.717      0.473      -0.862       0.400\n",
      "task_conversation[T.cw_94]:model[T.td3]         -0.3221      0.383     -0.842      0.400      -1.072       0.428\n",
      "task_conversation[T.cw_95]:model[T.td3]         -0.8653      0.264     -3.272      0.001      -1.384      -0.347\n",
      "task_conversation[T.cw_96]:model[T.td3]          0.1274      0.271      0.471      0.638      -0.403       0.658\n",
      "task_conversation[T.cw_97]:model[T.td3]         -0.8772      0.229     -3.823      0.000      -1.327      -0.427\n",
      "task_conversation[T.cw_98]:model[T.td3]         -0.2992      0.278     -1.076      0.282      -0.844       0.246\n",
      "task_conversation[T.cw_99]:model[T.td3]          0.0785      0.253      0.310      0.757      -0.418       0.575\n",
      "conversation_length_thousands                   -0.0579      0.248     -0.233      0.815      -0.544       0.428\n",
      "conversation_length_thousands:model[T.td3]      -0.2764      0.424     -0.651      0.515      -1.108       0.555\n",
      "consolidated_num_steps_ideas                    -0.0234      0.020     -1.190      0.234      -0.062       0.015\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0029      0.042      0.069      0.945      -0.079       0.085\n",
      "conversation_length_thousands_2                 -0.0119      0.149     -0.080      0.936      -0.304       0.280\n",
      "conversation_length_thousands_2:model[T.td3]     0.0104      0.321      0.033      0.974      -0.619       0.640\n",
      "consolidated_num_steps_ideas_2                   0.0059      0.003      2.096      0.036       0.000       0.011\n",
      "consolidated_num_steps_ideas_2:model[T.td3]     -0.0051      0.009     -0.546      0.585      -0.024       0.013\n",
      "fres                                             0.0527      0.026      2.031      0.042       0.002       0.104\n",
      "fres:model[T.td3]                               -0.0035      0.046     -0.076      0.940      -0.094       0.087\n",
      "fres_2                                          -0.0004      0.000     -1.733      0.083      -0.001    4.59e-05\n",
      "fres_2:model[T.td3]                           4.859e-05      0.000      0.148      0.883      -0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      180.161   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               48.067\n",
      "Skew:                           0.062   Prob(JB):                     3.65e-11\n",
      "Kurtosis:                       2.112   Cond. No.                     1.38e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 1.38e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "       Intercept  model[T.td3] task_conversation[T.cw_10]  \\\n",
      "0  -1.61 (0.874)  0.35 (1.628)              -0.156 (0.24)   \n",
      "\n",
      "  task_conversation[T.cw_100] task_conversation[T.cw_11]  \\\n",
      "0               0.418 (0.266)              0.155 (0.285)   \n",
      "\n",
      "  task_conversation[T.cw_12] task_conversation[T.cw_13]  \\\n",
      "0             -0.147 (0.249)              0.358 (0.271)   \n",
      "\n",
      "  task_conversation[T.cw_14] task_conversation[T.cw_15]  \\\n",
      "0             0.508* (0.258)              0.296 (0.281)   \n",
      "\n",
      "  task_conversation[T.cw_16]  ... consolidated_num_steps_ideas:model[T.td3]  \\\n",
      "0                0.24 (0.27)  ...                             0.003 (0.042)   \n",
      "\n",
      "  conversation_length_thousands_2  \\\n",
      "0                  -0.012 (0.149)   \n",
      "\n",
      "  conversation_length_thousands_2:model[T.td3] consolidated_num_steps_ideas_2  \\\n",
      "0                                 0.01 (0.321)                 0.006* (0.003)   \n",
      "\n",
      "  consolidated_num_steps_ideas_2:model[T.td3]            fres  \\\n",
      "0                              -0.005 (0.009)  0.053* (0.026)   \n",
      "\n",
      "  fres:model[T.td3]      fres_2 fres_2:model[T.td3]  \\\n",
      "0    -0.003 (0.046)  -0.0 (0.0)           0.0 (0.0)   \n",
      "\n",
      "                                 Title  \n",
      "0  Creative Writing Compliance, Linear  \n",
      "\n",
      "[1 rows x 213 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_cw_compliance_model_interaction = smf.ols('compliance ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + fres * model + fres_2 * model + task_conversation * model', data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print('lpm with clustering cw compliance')\n",
    "print(lpm_with_clustering_cw_compliance_model_interaction.summary())\n",
    "\n",
    "# Create results df\n",
    "lpm_with_clustering_cw_compliance_model_interaction_df = create_linear_results_df(lpm_with_clustering_cw_compliance_model_interaction, \"Creative Writing Compliance, Linear\")\n",
    "\n",
    "# Print results df\n",
    "print(lpm_with_clustering_cw_compliance_model_interaction_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}}\n",
      "\\toprule\n",
      "\\hline\n",
      "Model & Conversation Length * Model = TD3 & Number of Steps/Ideas * Model = TD3 & Conversation Length Squared * Model = TD3 & Number of Steps/Ideas Squared * Model = TD3 & Flesch Reading Ease * Model = TD3 & Flesch Reading Ease Squared * Model = TD3 & Conversation Length & Number of Steps/Ideas & Conversation Length Squared & Number of Steps/Ideas Squared & Flesch Reading Ease & Flesch Reading Ease Squared & Model = TD3 \\\\\n",
      "\\hline\n",
      "\\midrule\n",
      "GSM8K Correct, Logit & -0.403 (0.401) & 0.003 (0.014) & 1.081* (0.439) & 0.0 (0.001) &  &  & -0.196 (0.236) & 0.031* (0.01) & -0.229 (0.181) & -0.002* (0.001) &  &  & -0.453* (0.076) \\\\\n",
      "\\hline\n",
      "GSM8K Correct, Linear & -0.449 (0.365) & 0.009 (0.012) & 1.092* (0.439) & -0.0 (0.001) &  &  & -0.076 (0.146) & 0.043* (0.007) & -0.228* (0.104) & -0.002* (0.0) &  &  & -0.469* (0.059) \\\\\n",
      "\\hline\n",
      "Creative Writing Cosine Similarity & 0.277* (0.123) & -0.02 (0.012) & -0.108 (0.095) & 0.004 (0.003) & -0.003 (0.012) & 0.0 (0.0) & -0.053 (0.064) & 0.014* (0.005) & 0.018 (0.039) & -0.001 (0.001) & -0.013* (0.006) & 0.0* (0.0) & 0.025 (0.438) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Logit & -0.166 (0.467) & -0.023 (0.041) & -0.071 (0.365) & 0.002 (0.009) & -0.0 (0.047) & 0.0 (0.0) & -0.118 (0.256) & -0.009 (0.022) & 0.004 (0.153) & 0.003 (0.004) & 0.056 (0.029) & -0.0 (0.0) & -0.231 (1.627) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Linear & -0.276 (0.424) & 0.003 (0.042) & 0.01 (0.321) & -0.005 (0.009) & -0.003 (0.046) & 0.0 (0.0) & -0.058 (0.248) & -0.023 (0.02) & -0.012 (0.149) & 0.006* (0.003) & 0.053* (0.026) & -0.0 (0.0) & 0.35 (1.628) \\\\\n",
      "\\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "                                 Model Conversation Length * Model = TD3  \\\n",
      "0                 GSM8K Correct, Logit                    -0.403 (0.401)   \n",
      "1                GSM8K Correct, Linear                    -0.449 (0.365)   \n",
      "2   Creative Writing Cosine Similarity                    0.277* (0.123)   \n",
      "3   Creative Writing Compliance, Logit                    -0.166 (0.467)   \n",
      "4  Creative Writing Compliance, Linear                    -0.276 (0.424)   \n",
      "\n",
      "  Number of Steps/Ideas * Model = TD3  \\\n",
      "0                       0.003 (0.014)   \n",
      "1                       0.009 (0.012)   \n",
      "2                       -0.02 (0.012)   \n",
      "3                      -0.023 (0.041)   \n",
      "4                       0.003 (0.042)   \n",
      "\n",
      "  Conversation Length Squared * Model = TD3  \\\n",
      "0                            1.081* (0.439)   \n",
      "1                            1.092* (0.439)   \n",
      "2                            -0.108 (0.095)   \n",
      "3                            -0.071 (0.365)   \n",
      "4                              0.01 (0.321)   \n",
      "\n",
      "  Number of Steps/Ideas Squared * Model = TD3  \\\n",
      "0                                 0.0 (0.001)   \n",
      "1                                -0.0 (0.001)   \n",
      "2                               0.004 (0.003)   \n",
      "3                               0.002 (0.009)   \n",
      "4                              -0.005 (0.009)   \n",
      "\n",
      "  Flesch Reading Ease * Model = TD3 Flesch Reading Ease Squared * Model = TD3  \\\n",
      "0                                                                               \n",
      "1                                                                               \n",
      "2                    -0.003 (0.012)                                 0.0 (0.0)   \n",
      "3                      -0.0 (0.047)                                 0.0 (0.0)   \n",
      "4                    -0.003 (0.046)                                 0.0 (0.0)   \n",
      "\n",
      "  Conversation Length Number of Steps/Ideas Conversation Length Squared  \\\n",
      "0      -0.196 (0.236)         0.031* (0.01)              -0.229 (0.181)   \n",
      "1      -0.076 (0.146)        0.043* (0.007)             -0.228* (0.104)   \n",
      "2      -0.053 (0.064)        0.014* (0.005)               0.018 (0.039)   \n",
      "3      -0.118 (0.256)        -0.009 (0.022)               0.004 (0.153)   \n",
      "4      -0.058 (0.248)         -0.023 (0.02)              -0.012 (0.149)   \n",
      "\n",
      "  Number of Steps/Ideas Squared Flesch Reading Ease  \\\n",
      "0               -0.002* (0.001)                       \n",
      "1                 -0.002* (0.0)                       \n",
      "2                -0.001 (0.001)     -0.013* (0.006)   \n",
      "3                 0.003 (0.004)       0.056 (0.029)   \n",
      "4                0.006* (0.003)      0.053* (0.026)   \n",
      "\n",
      "  Flesch Reading Ease Squared      Model = TD3  \n",
      "0                              -0.453* (0.076)  \n",
      "1                              -0.469* (0.059)  \n",
      "2                  0.0* (0.0)    0.025 (0.438)  \n",
      "3                  -0.0 (0.0)   -0.231 (1.627)  \n",
      "4                  -0.0 (0.0)     0.35 (1.628)  \n",
      "\\begin{tabular}{x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}}\n",
      "\\toprule\n",
      "\\hline\n",
      "Model & Conversation Length * Model = TD3 & Number of Steps/Ideas * Model = TD3 & Conversation Length Squared * Model = TD3 & Number of Steps/Ideas Squared * Model = TD3 & Flesch Reading Ease * Model = TD3 & Flesch Reading Ease Squared * Model = TD3 & Conversation Length & Number of Steps/Ideas & Conversation Length Squared & Number of Steps/Ideas Squared & Flesch Reading Ease & Flesch Reading Ease Squared & Model = TD3 \\\\\n",
      "\\hline\n",
      "\\midrule\n",
      "GSM8K Correct, Logit & -0.403 (0.401) & 0.003 (0.014) & 1.081* (0.439) & 0.0 (0.001) &  &  & -0.196 (0.236) & 0.031* (0.01) & -0.229 (0.181) & -0.002* (0.001) &  &  & -0.453* (0.076) \\\\\n",
      "\\hline\n",
      "GSM8K Correct, Linear & -0.449 (0.365) & 0.009 (0.012) & 1.092* (0.439) & -0.0 (0.001) &  &  & -0.076 (0.146) & 0.043* (0.007) & -0.228* (0.104) & -0.002* (0.0) &  &  & -0.469* (0.059) \\\\\n",
      "\\hline\n",
      "Creative Writing Cosine Similarity & 0.277* (0.123) & -0.02 (0.012) & -0.108 (0.095) & 0.004 (0.003) & -0.003 (0.012) & 0.0 (0.0) & -0.053 (0.064) & 0.014* (0.005) & 0.018 (0.039) & -0.001 (0.001) & -0.013* (0.006) & 0.0* (0.0) & 0.025 (0.438) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Logit & -0.166 (0.467) & -0.023 (0.041) & -0.071 (0.365) & 0.002 (0.009) & -0.0 (0.047) & 0.0 (0.0) & -0.118 (0.256) & -0.009 (0.022) & 0.004 (0.153) & 0.003 (0.004) & 0.056 (0.029) & -0.0 (0.0) & -0.231 (1.627) \\\\\n",
      "\\hline\n",
      "Creative Writing Compliance, Linear & -0.276 (0.424) & 0.003 (0.042) & 0.01 (0.321) & -0.005 (0.009) & -0.003 (0.046) & 0.0 (0.0) & -0.058 (0.248) & -0.023 (0.02) & -0.012 (0.149) & 0.006* (0.003) & 0.053* (0.026) & -0.0 (0.0) & 0.35 (1.628) \\\\\n",
      "\\hline\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack results dataframes together for output\n",
    "results_df = pd.concat([logit_no_clustering_gsm8k_model_interaction_df, lpm_with_clustering_gsm8k_model_interaction_df, reg_with_clustering_cw_model_interaction_df, logit_no_clustering_cw_compliance_model_interaction_df, lpm_with_clustering_cw_compliance_model_interaction_df], ignore_index=True)\n",
    "\n",
    "# Limit columns to Title, conversation_length_thousands:model[T.td3], consolidated_num_steps_ideas:model[T.td3], conversation_length_thousands_2:model[T.td3], consolidated_num_steps_ideas_2:model[T.td3], fres:model[T.td3], fres_2:model[T.td3], task_conversation:model[T.td3], conversation_length_thousands, consolidated_num_steps_ideas, conversation_length_thousands_2, consolidated_num_steps_ideas_2, fres, fres_2, model[T.td3]\n",
    "results_df = results_df[['Title', 'conversation_length_thousands:model[T.td3]', 'consolidated_num_steps_ideas:model[T.td3]', 'conversation_length_thousands_2:model[T.td3]', 'consolidated_num_steps_ideas_2:model[T.td3]', 'fres:model[T.td3]', 'fres_2:model[T.td3]', 'conversation_length_thousands', 'consolidated_num_steps_ideas', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas_2', 'fres', 'fres_2', 'model[T.td3]']]\n",
    "\n",
    "# Replace NaN with blanks\n",
    "results_df = results_df.fillna('')\n",
    "\n",
    "# Rename Title to Model, conversation_length_thousands:model to Conversation Length * Model, consolidated_num_steps_ideas:model to Number of Steps/Ideas * Model, conversation_length_thousands_2:model to Conversation Length Squared * Model, consolidated_num_steps_ideas_2:model to Number of Steps/Ideas Squared * Model, fres:model to FRES * Model, fres_2:model to FRES Squared * Model, task_conversation:model to Task Conversation * Model, conversation_length_thousands to Conversation Length, consolidated_num_steps_ideas to Number of Steps/Ideas, conversation_length_thousands_2 to Conversation Length Squared, consolidated_num_steps_ideas_2 to Number of Steps/Ideas Squared, fres to FRES, fres_2 to FRES Squared, model to Model\n",
    "results_df = results_df.rename(columns={'Title': 'Model', 'conversation_length_thousands:model[T.td3]': 'Conversation Length * Model = TD3', 'consolidated_num_steps_ideas:model[T.td3]': 'Number of Steps/Ideas * Model = TD3', 'conversation_length_thousands_2:model[T.td3]': 'Conversation Length Squared * Model = TD3', 'consolidated_num_steps_ideas_2:model[T.td3]': 'Number of Steps/Ideas Squared * Model = TD3', 'fres:model[T.td3]': 'Flesch Reading Ease * Model = TD3', 'fres_2:model[T.td3]': 'Flesch Reading Ease Squared * Model = TD3', 'conversation_length_thousands': 'Conversation Length', 'consolidated_num_steps_ideas': 'Number of Steps/Ideas', 'conversation_length_thousands_2': 'Conversation Length Squared', 'consolidated_num_steps_ideas_2': 'Number of Steps/Ideas Squared', 'fres': 'Flesch Reading Ease', 'fres_2': 'Flesch Reading Ease Squared', 'model[T.td3]': 'Model = TD3'})\n",
    "\n",
    "# Output to latex. center columns, wrap text, and remove index\n",
    "latex_string = results_df.to_latex(index=False, \n",
    "                      column_format='x{1.5cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}|x{0.75cm}', \n",
    "                      #booktabs = True\n",
    "                      #longtable = True\n",
    "                      )\n",
    "\n",
    "# Add lines between rows\n",
    "lines = latex_string.split('\\n')\n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(line)\n",
    "    if '\\\\' in line and '&' in line:  # Identifies a row of the table\n",
    "        new_lines.append('\\\\hline')\n",
    "# Insert \\\\hline after \\toprule\n",
    "new_lines.insert(2, '\\\\hline')\n",
    "\n",
    "# Rejoin the modified lines\n",
    "modified_latex_table = '\\n'.join(new_lines)\n",
    "\n",
    "print(modified_latex_table)\n",
    "\n",
    "# Save string to file\n",
    "with open('../Output/regressions_model_interaction.tex', 'w') as f:\n",
    "    f.write(modified_latex_table)\n",
    "\n",
    "# Print results_df\n",
    "print(results_df)\n",
    "\n",
    "# Print modifed latex table\n",
    "print(modified_latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
