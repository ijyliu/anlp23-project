{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Regressions.ipynb\n",
    "\n",
    "Logistic regressions of GSM8K accuracy on length and complexity variables, quadratic terms, clustering by identity of the question and method (task, conversation_id, method).\n",
    "\n",
    "Regression of CW scores similarly.\n",
    "\n",
    "Add complexity of provided answers as an interaction term in GSM8K regressions.\n",
    "\n",
    "Add model as an interaction term.\n",
    "\n",
    "Model and question (conversation_number by task) controls can soak up additional variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_task_method', 'conversation_number',\n",
      "       'coherence_1_incoherent_10_very_coherent', 'compliance_OLD',\n",
      "       'ease_of_review_1_easy_10_hard', 'correct',\n",
      "       'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10',\n",
      "       'Aggregated_Prediction', 'Prediction_Based_On_First_10_LP',\n",
      "       'response_Based_On_First_10_LP', 'Prediction_Based_On_Last_10_LP',\n",
      "       'response_Based_On_Last_10_LP', 'response_LP',\n",
      "       'Aggregated_Prediction_LP', 'Prediction_Based_On_First_50_LP',\n",
      "       'response_Based_On_First_50_LP', 'Prediction_Based_On_Last_50_LP',\n",
      "       'response_Based_On_Last_50_LP', 'Aggregated_Prediction_50_LP',\n",
      "       'Prediction_Based_On_random_50_LP_1',\n",
      "       'response_Based_On_random_50_LP_1',\n",
      "       'Prediction_Based_On_random_50_LP_2',\n",
      "       'response_Based_On_random_50_LP_2',\n",
      "       'Aggregated_Prediction_random_50_LP', 'Unnamed: 0_x', 'response_x',\n",
      "       'replace_slash_n_slash_n_with_newline_x',\n",
      "       'replace_slash_n_slash_n_with_newline_values_x',\n",
      "       'replace_slash_n_with_newline_x',\n",
      "       'replace_slash_n_with_newline_values_x', 'avg_cosine_sim',\n",
      "       'num_sentences_x', 'Unnamed: 0_y', 'response_y',\n",
      "       'replace_slash_n_slash_n_with_newline_y',\n",
      "       'replace_slash_n_slash_n_with_newline_values_y',\n",
      "       'replace_slash_n_with_newline_y',\n",
      "       'replace_slash_n_with_newline_values_y',\n",
      "       'avg_inter_paragraph_cosine_sim', 'num_paragraphs', 'num_sentences_y',\n",
      "       'cosine_sims', 'conversation_length', 'input_length', 'output_length',\n",
      "       'conversation_cost', 'gsm8k_question_index', 'gsm8k_answer',\n",
      "       'gsm8k_length_vs_provided', 'length_vs_direct_prompting',\n",
      "       'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc',\n",
      "       'sentence_length', 'fres', 'num_linebreaks_prompts',\n",
      "       'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts',\n",
      "       'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided',\n",
      "       'num_sentences_provided', 'num_step_i_provided',\n",
      "       'num_1_dot_etc_provided', 'length_provided', 'compliance',\n",
      "       'coherence_1_incoherent_10_very_coherent_compliance_adjusted',\n",
      "       'Aggregated_Prediction_random_50_LP_compliance_adjusted',\n",
      "       'avg_cosine_sim_compliance_adjusted',\n",
      "       'avg_inter_paragraph_cosine_sim_compliance_adjusted', 'model', 'task',\n",
      "       'method', 'Model', 'Method', 'Task', 'accuracy_quality',\n",
      "       'accuracy_quality_compliance_adjusted',\n",
      "       'accuracy_quality_avg_inter_paragraph_cosine_sim',\n",
      "       'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_prompts',\n",
      "       'consolidated_num_steps_ideas_provided', 'technique_name',\n",
      "       'ss_publication_date', 'ss_publication_date_datetime',\n",
      "       'Method + Publication Date', 'Publication Date',\n",
      "       'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff',\n",
      "       'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff',\n",
      "       'sentence_length_prompts_diff', 'fres_prompts_diff',\n",
      "       'num_linebreaks_provided_diff', 'num_sentences_provided_diff',\n",
      "       'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_task_method</th>\n",
       "      <th>conversation_number</th>\n",
       "      <th>coherence_1_incoherent_10_very_coherent</th>\n",
       "      <th>compliance_OLD</th>\n",
       "      <th>ease_of_review_1_easy_10_hard</th>\n",
       "      <th>correct</th>\n",
       "      <th>Prediction_Based_On_First_10</th>\n",
       "      <th>Prediction_Based_On_Last_10</th>\n",
       "      <th>Aggregated_Prediction</th>\n",
       "      <th>Prediction_Based_On_First_10_LP</th>\n",
       "      <th>...</th>\n",
       "      <th>num_linebreaks_prompts_diff</th>\n",
       "      <th>num_sentences_prompts_diff</th>\n",
       "      <th>num_step_i_prompts_diff</th>\n",
       "      <th>num_1_dot_etc_prompts_diff</th>\n",
       "      <th>sentence_length_prompts_diff</th>\n",
       "      <th>fres_prompts_diff</th>\n",
       "      <th>num_linebreaks_provided_diff</th>\n",
       "      <th>num_sentences_provided_diff</th>\n",
       "      <th>num_step_i_provided_diff</th>\n",
       "      <th>num_1_dot_etc_provided_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.571429</td>\n",
       "      <td>12.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.350000</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.911111</td>\n",
       "      <td>-6.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-10.500000</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>td3_cw_direct_prompting_responses</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.428571</td>\n",
       "      <td>13.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_task_method  conversation_number  \\\n",
       "0     td3_cw_direct_prompting_responses                    1   \n",
       "1     td3_cw_direct_prompting_responses                    2   \n",
       "2     td3_cw_direct_prompting_responses                    3   \n",
       "3     td3_cw_direct_prompting_responses                    4   \n",
       "4     td3_cw_direct_prompting_responses                    5   \n",
       "...                                 ...                  ...   \n",
       "3195    gpt4_gsm8k_manual_cot_responses                   96   \n",
       "3196    gpt4_gsm8k_manual_cot_responses                   97   \n",
       "3197    gpt4_gsm8k_manual_cot_responses                   98   \n",
       "3198    gpt4_gsm8k_manual_cot_responses                   99   \n",
       "3199    gpt4_gsm8k_manual_cot_responses                  100   \n",
       "\n",
       "      coherence_1_incoherent_10_very_coherent  compliance_OLD  \\\n",
       "0                                         1.0             1.0   \n",
       "1                                         7.0             0.0   \n",
       "2                                         1.0             1.0   \n",
       "3                                        10.0             1.0   \n",
       "4                                         4.0             1.0   \n",
       "...                                       ...             ...   \n",
       "3195                                      NaN             NaN   \n",
       "3196                                      NaN             NaN   \n",
       "3197                                      NaN             NaN   \n",
       "3198                                      NaN             NaN   \n",
       "3199                                      NaN             NaN   \n",
       "\n",
       "      ease_of_review_1_easy_10_hard  correct  Prediction_Based_On_First_10  \\\n",
       "0                               1.0      NaN                           NaN   \n",
       "1                               1.0      NaN                           NaN   \n",
       "2                               1.0      NaN                           NaN   \n",
       "3                               1.0      NaN                           NaN   \n",
       "4                               1.0      NaN                           NaN   \n",
       "...                             ...      ...                           ...   \n",
       "3195                            NaN      1.0                           NaN   \n",
       "3196                            NaN      1.0                           NaN   \n",
       "3197                            NaN      1.0                           NaN   \n",
       "3198                            NaN      1.0                           NaN   \n",
       "3199                            NaN      1.0                           NaN   \n",
       "\n",
       "      Prediction_Based_On_Last_10  Aggregated_Prediction  \\\n",
       "0                             1.0                    1.0   \n",
       "1                             7.0                    7.0   \n",
       "2                             1.0                    1.0   \n",
       "3                             7.0                    7.0   \n",
       "4                             1.0                    1.0   \n",
       "...                           ...                    ...   \n",
       "3195                          NaN                    NaN   \n",
       "3196                          NaN                    NaN   \n",
       "3197                          NaN                    NaN   \n",
       "3198                          NaN                    NaN   \n",
       "3199                          NaN                    NaN   \n",
       "\n",
       "      Prediction_Based_On_First_10_LP  ... num_linebreaks_prompts_diff  \\\n",
       "0                                 NaN  ...                          -1   \n",
       "1                                 NaN  ...                          -1   \n",
       "2                                 NaN  ...                          -1   \n",
       "3                                 NaN  ...                          -1   \n",
       "4                                 NaN  ...                          -1   \n",
       "...                               ...  ...                         ...   \n",
       "3195                              NaN  ...                          16   \n",
       "3196                              NaN  ...                          16   \n",
       "3197                              NaN  ...                          16   \n",
       "3198                              NaN  ...                          15   \n",
       "3199                              NaN  ...                          16   \n",
       "\n",
       "      num_sentences_prompts_diff num_step_i_prompts_diff  \\\n",
       "0                             -2                       0   \n",
       "1                             -3                       0   \n",
       "2                             -4                       0   \n",
       "3                             -1                       0   \n",
       "4                             -2                       0   \n",
       "...                          ...                     ...   \n",
       "3195                          39                       0   \n",
       "3196                          43                       0   \n",
       "3197                          44                       0   \n",
       "3198                          44                       0   \n",
       "3199                          44                       0   \n",
       "\n",
       "     num_1_dot_etc_prompts_diff  sentence_length_prompts_diff  \\\n",
       "0                             2                     -6.571429   \n",
       "1                             2                     -9.350000   \n",
       "2                             2                     -4.911111   \n",
       "3                             2                    -10.500000   \n",
       "4                             2                     -8.428571   \n",
       "...                         ...                           ...   \n",
       "3195                         17                           NaN   \n",
       "3196                         19                           NaN   \n",
       "3197                         20                           NaN   \n",
       "3198                         19                           NaN   \n",
       "3199                         19                           NaN   \n",
       "\n",
       "      fres_prompts_diff num_linebreaks_provided_diff  \\\n",
       "0                 12.31                          NaN   \n",
       "1                 -1.05                          NaN   \n",
       "2                 -6.64                          NaN   \n",
       "3                 -9.31                          NaN   \n",
       "4                 13.64                          NaN   \n",
       "...                 ...                          ...   \n",
       "3195                NaN                          4.0   \n",
       "3196                NaN                          2.0   \n",
       "3197                NaN                          3.0   \n",
       "3198                NaN                          1.0   \n",
       "3199                NaN                          4.0   \n",
       "\n",
       "      num_sentences_provided_diff num_step_i_provided_diff  \\\n",
       "0                             NaN                      NaN   \n",
       "1                             NaN                      NaN   \n",
       "2                             NaN                      NaN   \n",
       "3                             NaN                      NaN   \n",
       "4                             NaN                      NaN   \n",
       "...                           ...                      ...   \n",
       "3195                         -1.0                      0.0   \n",
       "3196                          0.0                      0.0   \n",
       "3197                          1.0                      0.0   \n",
       "3198                          0.0                      0.0   \n",
       "3199                         -1.0                      0.0   \n",
       "\n",
       "      num_1_dot_etc_provided_diff  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "3195                         -2.0  \n",
       "3196                         -1.0  \n",
       "3197                          0.0  \n",
       "3198                         -1.0  \n",
       "3199                         -1.0  \n",
       "\n",
       "[3200 rows x 100 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Combined_Data.xlsx\n",
    "df = pd.read_excel('Combined_Data.xlsx')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation - divide conversation length by 1000 to get effect per 1000K tokens\n",
    "df['conversation_length_thousands'] = df['conversation_length']/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quadratics\n",
    "df['conversation_length_thousands_2'] = df['conversation_length_thousands']**2\n",
    "df['consolidated_num_steps_ideas_2'] = df['consolidated_num_steps_ideas']**2\n",
    "df['fres_2'] = df['fres']**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clustering variable\n",
    "# Concatenate task, conversation_number, method\n",
    "df['task_conversation_method'] = df['task'].astype(str) + \"_\" + df['conversation_number'].astype(str) + \"_\" + df['method'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task by conversation variable as a control\n",
    "df['task_conversation'] = df['task'].astype(str) + \"_\" + df['conversation_number'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "gsm8k_data = df[df['task'] == 'gsm8k']\n",
    "cw_data = df[df['task'] == 'cw']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Get values of correct in gsm8k_data\n",
    "gsm8k_correct = gsm8k_data['correct'].values\n",
    "print(set(gsm8k_correct))\n",
    "\n",
    "# Print cases where correct is not 0 or 1\n",
    "#print(gsm8k_data[gsm8k_data['correct'] != 0 & gsm8k_data['correct'] != 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (no clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.576353\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1594\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 05 Dec 2023   Pseudo R-squ.:                  0.1496\n",
      "Time:                        00:08:55   Log-Likelihood:                -922.17\n",
      "converged:                       True   LL-Null:                       -1084.4\n",
      "Covariance Type:                  HC3   LLR p-value:                 5.423e-68\n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           1.2184      0.179      6.792      0.000       0.867       1.570\n",
      "model[T.td3]                       -1.9626      0.122    -16.098      0.000      -2.202      -1.724\n",
      "conversation_length_thousands       1.4136      0.733      1.930      0.054      -0.022       2.849\n",
      "consolidated_num_steps_ideas        0.1470      0.034      4.345      0.000       0.081       0.213\n",
      "conversation_length_thousands_2    -2.5436      0.659     -3.858      0.000      -3.836      -1.251\n",
      "consolidated_num_steps_ideas_2     -0.0090      0.002     -3.872      0.000      -0.014      -0.004\n",
      "===================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                correct\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                       -0.3844      0.016    -23.924      0.000      -0.416      -0.353\n",
      "conversation_length_thousands       0.2769      0.143      1.938      0.053      -0.003       0.557\n",
      "consolidated_num_steps_ideas        0.0288      0.007      4.410      0.000       0.016       0.042\n",
      "conversation_length_thousands_2    -0.4982      0.127     -3.910      0.000      -0.748      -0.249\n",
      "consolidated_num_steps_ideas_2     -0.0018      0.000     -3.908      0.000      -0.003      -0.001\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_gsm8k = smf.logit('correct ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + model', data=gsm8k_data).fit(cov_type='HC3')\n",
    "\n",
    "# Display the summary\n",
    "print(logit_no_clustering_gsm8k.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_gsm8k_marginal_effects = logit_no_clustering_gsm8k.get_margeff(at='overall')\n",
    "print(logit_no_clustering_gsm8k_marginal_effects.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Probability Model with Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   R-squared:                       0.348\n",
      "Model:                            OLS   Adj. R-squared:                  0.303\n",
      "Method:                 Least Squares   F-statistic:                     32.04\n",
      "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          1.17e-222\n",
      "Time:                        00:08:55   Log-Likelihood:                -793.62\n",
      "No. Observations:                1600   AIC:                             1797.\n",
      "Df Residuals:                    1495   BIC:                             2362.\n",
      "Df Model:                         104                                         \n",
      "Covariance Type:              cluster                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           0.9503      0.084     11.316      0.000       0.786       1.115\n",
      "task_conversation[T.gsm8k_10]      -0.3931      0.115     -3.431      0.001      -0.618      -0.169\n",
      "task_conversation[T.gsm8k_100]     -0.2483      0.166     -1.494      0.135      -0.574       0.078\n",
      "task_conversation[T.gsm8k_11]      -0.1317      0.146     -0.902      0.367      -0.418       0.155\n",
      "task_conversation[T.gsm8k_12]      -0.1629      0.141     -1.155      0.248      -0.439       0.114\n",
      "task_conversation[T.gsm8k_13]      -0.8963      0.085    -10.518      0.000      -1.063      -0.729\n",
      "task_conversation[T.gsm8k_14]      -0.6808      0.107     -6.365      0.000      -0.890      -0.471\n",
      "task_conversation[T.gsm8k_15]      -0.0526      0.146     -0.361      0.718      -0.338       0.233\n",
      "task_conversation[T.gsm8k_16]      -0.1455      0.120     -1.210      0.226      -0.381       0.090\n",
      "task_conversation[T.gsm8k_17]       0.1388      0.105      1.316      0.188      -0.068       0.346\n",
      "task_conversation[T.gsm8k_18]      -0.2559      0.155     -1.652      0.099      -0.560       0.048\n",
      "task_conversation[T.gsm8k_19]      -0.1344      0.154     -0.875      0.382      -0.435       0.167\n",
      "task_conversation[T.gsm8k_2]        0.1362      0.106      1.282      0.200      -0.072       0.344\n",
      "task_conversation[T.gsm8k_20]      -0.3829      0.097     -3.950      0.000      -0.573      -0.193\n",
      "task_conversation[T.gsm8k_21]      -0.4821      0.131     -3.683      0.000      -0.739      -0.226\n",
      "task_conversation[T.gsm8k_22]      -0.3100      0.126     -2.461      0.014      -0.557      -0.063\n",
      "task_conversation[T.gsm8k_23]      -0.1177      0.113     -1.041      0.298      -0.339       0.104\n",
      "task_conversation[T.gsm8k_24]       0.0126      0.118      0.107      0.915      -0.218       0.243\n",
      "task_conversation[T.gsm8k_25]      -0.1544      0.140     -1.099      0.272      -0.430       0.121\n",
      "task_conversation[T.gsm8k_26]      -0.3042      0.143     -2.132      0.033      -0.584      -0.025\n",
      "task_conversation[T.gsm8k_27]      -0.2419      0.149     -1.620      0.105      -0.535       0.051\n",
      "task_conversation[T.gsm8k_28]      -0.0641      0.105     -0.609      0.543      -0.271       0.142\n",
      "task_conversation[T.gsm8k_29]      -0.0091      0.129     -0.070      0.944      -0.262       0.244\n",
      "task_conversation[T.gsm8k_3]       -0.6070      0.118     -5.133      0.000      -0.839      -0.375\n",
      "task_conversation[T.gsm8k_30]      -0.2841      0.130     -2.178      0.029      -0.540      -0.028\n",
      "task_conversation[T.gsm8k_31]      -0.3986      0.125     -3.181      0.001      -0.644      -0.153\n",
      "task_conversation[T.gsm8k_32]      -0.2982      0.095     -3.125      0.002      -0.485      -0.111\n",
      "task_conversation[T.gsm8k_33]      -0.0660      0.133     -0.496      0.620      -0.327       0.195\n",
      "task_conversation[T.gsm8k_34]      -0.3270      0.082     -4.008      0.000      -0.487      -0.167\n",
      "task_conversation[T.gsm8k_35]      -0.1911      0.164     -1.164      0.244      -0.513       0.131\n",
      "task_conversation[T.gsm8k_36]      -0.3088      0.145     -2.124      0.034      -0.594      -0.024\n",
      "task_conversation[T.gsm8k_37]      -0.2025      0.143     -1.419      0.156      -0.482       0.077\n",
      "task_conversation[T.gsm8k_38]      -0.7165      0.095     -7.557      0.000      -0.902      -0.531\n",
      "task_conversation[T.gsm8k_39]      -0.3763      0.082     -4.566      0.000      -0.538      -0.215\n",
      "task_conversation[T.gsm8k_4]        0.0654      0.117      0.560      0.576      -0.164       0.294\n",
      "task_conversation[T.gsm8k_40]      -0.3718      0.122     -3.057      0.002      -0.610      -0.133\n",
      "task_conversation[T.gsm8k_41]       0.0185      0.121      0.153      0.879      -0.219       0.256\n",
      "task_conversation[T.gsm8k_42]      -0.3574      0.129     -2.766      0.006      -0.611      -0.104\n",
      "task_conversation[T.gsm8k_43]      -0.0506      0.120     -0.423      0.672      -0.285       0.184\n",
      "task_conversation[T.gsm8k_44]      -0.5159      0.110     -4.683      0.000      -0.732      -0.300\n",
      "task_conversation[T.gsm8k_45]      -0.1662      0.155     -1.073      0.283      -0.470       0.137\n",
      "task_conversation[T.gsm8k_46]      -0.3260      0.129     -2.529      0.011      -0.579      -0.073\n",
      "task_conversation[T.gsm8k_47]      -0.3823      0.110     -3.485      0.000      -0.597      -0.167\n",
      "task_conversation[T.gsm8k_48]      -0.2761      0.144     -1.924      0.054      -0.557       0.005\n",
      "task_conversation[T.gsm8k_49]       0.1871      0.083      2.266      0.023       0.025       0.349\n",
      "task_conversation[T.gsm8k_5]       -0.2479      0.133     -1.865      0.062      -0.508       0.013\n",
      "task_conversation[T.gsm8k_50]      -0.0121      0.119     -0.101      0.919      -0.245       0.221\n",
      "task_conversation[T.gsm8k_51]      -0.2701      0.158     -1.710      0.087      -0.580       0.040\n",
      "task_conversation[T.gsm8k_52]      -0.1800      0.137     -1.310      0.190      -0.449       0.089\n",
      "task_conversation[T.gsm8k_53]      -0.2244      0.121     -1.850      0.064      -0.462       0.013\n",
      "task_conversation[T.gsm8k_54]      -0.1854      0.158     -1.175      0.240      -0.495       0.124\n",
      "task_conversation[T.gsm8k_55]      -0.2547      0.166     -1.538      0.124      -0.579       0.070\n",
      "task_conversation[T.gsm8k_56]      -0.0043      0.115     -0.037      0.970      -0.229       0.220\n",
      "task_conversation[T.gsm8k_57]      -0.0806      0.116     -0.694      0.487      -0.308       0.147\n",
      "task_conversation[T.gsm8k_58]      -0.1367      0.123     -1.109      0.267      -0.378       0.105\n",
      "task_conversation[T.gsm8k_59]      -0.1886      0.153     -1.234      0.217      -0.488       0.111\n",
      "task_conversation[T.gsm8k_6]       -0.4356      0.132     -3.307      0.001      -0.694      -0.177\n",
      "task_conversation[T.gsm8k_60]      -0.0595      0.119     -0.501      0.616      -0.292       0.173\n",
      "task_conversation[T.gsm8k_61]      -0.3193      0.173     -1.842      0.066      -0.659       0.020\n",
      "task_conversation[T.gsm8k_62]      -0.1044      0.120     -0.872      0.383      -0.339       0.130\n",
      "task_conversation[T.gsm8k_63]      -0.5864      0.134     -4.383      0.000      -0.849      -0.324\n",
      "task_conversation[T.gsm8k_64]      -0.3513      0.138     -2.542      0.011      -0.622      -0.080\n",
      "task_conversation[T.gsm8k_65]      -0.1214      0.125     -0.970      0.332      -0.367       0.124\n",
      "task_conversation[T.gsm8k_66]      -0.3146      0.157     -2.000      0.046      -0.623      -0.006\n",
      "task_conversation[T.gsm8k_67]      -0.3184      0.148     -2.150      0.032      -0.609      -0.028\n",
      "task_conversation[T.gsm8k_68]      -0.2507      0.166     -1.509      0.131      -0.576       0.075\n",
      "task_conversation[T.gsm8k_69]      -0.2584      0.151     -1.709      0.087      -0.555       0.038\n",
      "task_conversation[T.gsm8k_7]       -0.1960      0.147     -1.334      0.182      -0.484       0.092\n",
      "task_conversation[T.gsm8k_70]      -0.0984      0.118     -0.836      0.403      -0.329       0.132\n",
      "task_conversation[T.gsm8k_71]      -0.3963      0.127     -3.111      0.002      -0.646      -0.147\n",
      "task_conversation[T.gsm8k_72]    8.395e-05      0.118      0.001      0.999      -0.232       0.232\n",
      "task_conversation[T.gsm8k_73]      -0.2817      0.160     -1.765      0.078      -0.594       0.031\n",
      "task_conversation[T.gsm8k_74]      -0.3571      0.173     -2.067      0.039      -0.696      -0.018\n",
      "task_conversation[T.gsm8k_75]      -0.2477      0.160     -1.551      0.121      -0.561       0.065\n",
      "task_conversation[T.gsm8k_76]      -0.5281      0.115     -4.584      0.000      -0.754      -0.302\n",
      "task_conversation[T.gsm8k_77]      -0.2920      0.141     -2.068      0.039      -0.569      -0.015\n",
      "task_conversation[T.gsm8k_78]      -0.1877      0.184     -1.021      0.307      -0.548       0.173\n",
      "task_conversation[T.gsm8k_79]      -0.2641      0.154     -1.712      0.087      -0.567       0.038\n",
      "task_conversation[T.gsm8k_8]       -0.5327      0.115     -4.651      0.000      -0.757      -0.308\n",
      "task_conversation[T.gsm8k_80]       0.1520      0.083      1.823      0.068      -0.011       0.315\n",
      "task_conversation[T.gsm8k_81]      -0.4964      0.119     -4.182      0.000      -0.729      -0.264\n",
      "task_conversation[T.gsm8k_82]      -0.1189      0.147     -0.807      0.420      -0.408       0.170\n",
      "task_conversation[T.gsm8k_83]      -0.2401      0.158     -1.523      0.128      -0.549       0.069\n",
      "task_conversation[T.gsm8k_84]       0.1950      0.082      2.380      0.017       0.034       0.356\n",
      "task_conversation[T.gsm8k_85]      -0.4634      0.147     -3.145      0.002      -0.752      -0.175\n",
      "task_conversation[T.gsm8k_86]      -0.1355      0.146     -0.927      0.354      -0.422       0.151\n",
      "task_conversation[T.gsm8k_87]      -0.1307      0.147     -0.891      0.373      -0.418       0.157\n",
      "task_conversation[T.gsm8k_88]      -0.6675      0.116     -5.763      0.000      -0.894      -0.440\n",
      "task_conversation[T.gsm8k_89]      -0.2076      0.111     -1.862      0.063      -0.426       0.011\n",
      "task_conversation[T.gsm8k_9]       -0.5766      0.123     -4.707      0.000      -0.817      -0.337\n",
      "task_conversation[T.gsm8k_90]       0.0435      0.117      0.370      0.711      -0.187       0.274\n",
      "task_conversation[T.gsm8k_91]      -0.1782      0.149     -1.197      0.231      -0.470       0.114\n",
      "task_conversation[T.gsm8k_92]      -0.2371      0.161     -1.476      0.140      -0.552       0.078\n",
      "task_conversation[T.gsm8k_93]      -0.3691      0.155     -2.388      0.017      -0.672      -0.066\n",
      "task_conversation[T.gsm8k_94]      -0.4135      0.135     -3.070      0.002      -0.678      -0.149\n",
      "task_conversation[T.gsm8k_95]      -0.3246      0.123     -2.641      0.008      -0.566      -0.084\n",
      "task_conversation[T.gsm8k_96]      -0.0942      0.159     -0.594      0.553      -0.405       0.217\n",
      "task_conversation[T.gsm8k_97]      -0.1469      0.143     -1.028      0.304      -0.427       0.133\n",
      "task_conversation[T.gsm8k_98]      -0.2545      0.125     -2.030      0.042      -0.500      -0.009\n",
      "task_conversation[T.gsm8k_99]      -0.3050      0.159     -1.922      0.055      -0.616       0.006\n",
      "model[T.td3]                       -0.4140      0.020    -20.482      0.000      -0.454      -0.374\n",
      "conversation_length_thousands       0.2821      0.114      2.473      0.013       0.058       0.506\n",
      "consolidated_num_steps_ideas        0.0432      0.006      7.168      0.000       0.031       0.055\n",
      "conversation_length_thousands_2    -0.4181      0.091     -4.603      0.000      -0.596      -0.240\n",
      "consolidated_num_steps_ideas_2     -0.0023      0.000     -5.783      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                      106.014   Durbin-Watson:                   1.581\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.547\n",
      "Skew:                          -0.164   Prob(JB):                     3.50e-10\n",
      "Kurtosis:                       2.261   Cond. No.                     5.68e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 5.68e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_gsm8k = smf.ols('correct ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + task_conversation + model', data=gsm8k_data).fit(cov_type='cluster', cov_kwds={'groups': gsm8k_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(lpm_with_clustering_gsm8k.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "# Is avg_inter_paragraph_cosine_sim always present\n",
    "#print(cw_data[cw_data['avg_inter_paragraph_cosine_sim'].isnull()])\n",
    "\n",
    "# Check length\n",
    "#print(len(cw_data['avg_inter_paragraph_cosine_sim']))\n",
    "#print(len(cw_data['fres'].dropna()))\n",
    "\n",
    "# Limit cw_data to rows where avg_inter_paragraph_cosine_sim is not null\n",
    "cw_data = cw_data[cw_data['avg_inter_paragraph_cosine_sim'].notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preferred cosine similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     avg_inter_paragraph_cosine_sim   R-squared:                       0.427\n",
      "Model:                                        OLS   Adj. R-squared:                  0.381\n",
      "Method:                             Least Squares   F-statistic:                     20.48\n",
      "Date:                            Tue, 05 Dec 2023   Prob (F-statistic):          2.79e-163\n",
      "Time:                                    00:08:55   Log-Likelihood:                 927.69\n",
      "No. Observations:                            1434   AIC:                            -1641.\n",
      "Df Residuals:                                1327   BIC:                            -1078.\n",
      "Df Model:                                     106                                         \n",
      "Covariance Type:                          cluster                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           0.5852      0.150      3.891      0.000       0.290       0.880\n",
      "task_conversation[T.cw_10]          0.0801      0.053      1.498      0.134      -0.025       0.185\n",
      "task_conversation[T.cw_100]         0.0840      0.052      1.615      0.106      -0.018       0.186\n",
      "task_conversation[T.cw_11]          0.2857      0.038      7.447      0.000       0.211       0.361\n",
      "task_conversation[T.cw_12]          0.1660      0.055      3.026      0.002       0.058       0.274\n",
      "task_conversation[T.cw_13]          0.1189      0.047      2.504      0.012       0.026       0.212\n",
      "task_conversation[T.cw_14]          0.1461      0.047      3.108      0.002       0.054       0.238\n",
      "task_conversation[T.cw_15]          0.0856      0.048      1.790      0.073      -0.008       0.179\n",
      "task_conversation[T.cw_16]          0.1078      0.038      2.835      0.005       0.033       0.182\n",
      "task_conversation[T.cw_17]          0.0813      0.050      1.635      0.102      -0.016       0.179\n",
      "task_conversation[T.cw_18]          0.0917      0.069      1.325      0.185      -0.044       0.227\n",
      "task_conversation[T.cw_19]          0.1420      0.047      3.035      0.002       0.050       0.234\n",
      "task_conversation[T.cw_2]           0.1454      0.060      2.441      0.015       0.029       0.262\n",
      "task_conversation[T.cw_20]          0.0578      0.044      1.303      0.192      -0.029       0.145\n",
      "task_conversation[T.cw_21]          0.2812      0.037      7.674      0.000       0.209       0.353\n",
      "task_conversation[T.cw_22]          0.2287      0.058      3.956      0.000       0.115       0.342\n",
      "task_conversation[T.cw_23]          0.2711      0.038      7.063      0.000       0.196       0.346\n",
      "task_conversation[T.cw_24]          0.2146      0.050      4.290      0.000       0.117       0.313\n",
      "task_conversation[T.cw_25]         -0.0219      0.046     -0.478      0.633      -0.112       0.068\n",
      "task_conversation[T.cw_26]          0.2632      0.043      6.058      0.000       0.178       0.348\n",
      "task_conversation[T.cw_27]          0.0534      0.042      1.280      0.200      -0.028       0.135\n",
      "task_conversation[T.cw_28]          0.1908      0.043      4.425      0.000       0.106       0.275\n",
      "task_conversation[T.cw_29]          0.2718      0.043      6.391      0.000       0.188       0.355\n",
      "task_conversation[T.cw_3]           0.1344      0.038      3.500      0.000       0.059       0.210\n",
      "task_conversation[T.cw_30]          0.1028      0.058      1.758      0.079      -0.012       0.217\n",
      "task_conversation[T.cw_31]          0.0543      0.041      1.329      0.184      -0.026       0.134\n",
      "task_conversation[T.cw_32]          0.0801      0.053      1.502      0.133      -0.024       0.185\n",
      "task_conversation[T.cw_33]          0.2079      0.044      4.753      0.000       0.122       0.294\n",
      "task_conversation[T.cw_34]          0.2697      0.047      5.757      0.000       0.178       0.361\n",
      "task_conversation[T.cw_35]          0.1003      0.054      1.871      0.061      -0.005       0.205\n",
      "task_conversation[T.cw_36]         -0.0277      0.052     -0.531      0.596      -0.130       0.075\n",
      "task_conversation[T.cw_37]          0.0360      0.060      0.598      0.550      -0.082       0.154\n",
      "task_conversation[T.cw_38]          0.1024      0.051      2.024      0.043       0.003       0.202\n",
      "task_conversation[T.cw_39]         -0.0396      0.036     -1.087      0.277      -0.111       0.032\n",
      "task_conversation[T.cw_4]           0.2671      0.040      6.750      0.000       0.190       0.345\n",
      "task_conversation[T.cw_40]          0.1080      0.066      1.635      0.102      -0.021       0.237\n",
      "task_conversation[T.cw_41]          0.0879      0.055      1.595      0.111      -0.020       0.196\n",
      "task_conversation[T.cw_42]          0.0249      0.040      0.627      0.531      -0.053       0.103\n",
      "task_conversation[T.cw_43]          0.1352      0.042      3.253      0.001       0.054       0.217\n",
      "task_conversation[T.cw_44]          0.2295      0.040      5.675      0.000       0.150       0.309\n",
      "task_conversation[T.cw_45]          0.3278      0.051      6.370      0.000       0.227       0.429\n",
      "task_conversation[T.cw_46]         -0.0864      0.042     -2.079      0.038      -0.168      -0.005\n",
      "task_conversation[T.cw_47]          0.0742      0.046      1.611      0.107      -0.016       0.164\n",
      "task_conversation[T.cw_48]          0.0213      0.040      0.534      0.593      -0.057       0.100\n",
      "task_conversation[T.cw_49]         -0.0343      0.046     -0.741      0.459      -0.125       0.056\n",
      "task_conversation[T.cw_5]           0.0751      0.042      1.806      0.071      -0.006       0.157\n",
      "task_conversation[T.cw_50]          0.1552      0.051      3.057      0.002       0.056       0.255\n",
      "task_conversation[T.cw_51]          0.2208      0.039      5.664      0.000       0.144       0.297\n",
      "task_conversation[T.cw_52]         -0.0016      0.048     -0.033      0.973      -0.096       0.093\n",
      "task_conversation[T.cw_53]          0.2898      0.038      7.589      0.000       0.215       0.365\n",
      "task_conversation[T.cw_54]          0.1816      0.048      3.800      0.000       0.088       0.275\n",
      "task_conversation[T.cw_55]          0.0907      0.052      1.739      0.082      -0.012       0.193\n",
      "task_conversation[T.cw_56]          0.0020      0.040      0.049      0.961      -0.077       0.081\n",
      "task_conversation[T.cw_57]          0.2737      0.039      7.068      0.000       0.198       0.350\n",
      "task_conversation[T.cw_58]          0.2521      0.040      6.313      0.000       0.174       0.330\n",
      "task_conversation[T.cw_59]          0.0935      0.051      1.839      0.066      -0.006       0.193\n",
      "task_conversation[T.cw_6]           0.1060      0.054      1.949      0.051      -0.001       0.213\n",
      "task_conversation[T.cw_60]         -0.0631      0.044     -1.444      0.149      -0.149       0.023\n",
      "task_conversation[T.cw_61]          0.0461      0.041      1.132      0.258      -0.034       0.126\n",
      "task_conversation[T.cw_62]          0.1414      0.056      2.504      0.012       0.031       0.252\n",
      "task_conversation[T.cw_63]          0.2477      0.056      4.462      0.000       0.139       0.357\n",
      "task_conversation[T.cw_64]          0.2044      0.044      4.631      0.000       0.118       0.291\n",
      "task_conversation[T.cw_65]          0.3109      0.039      7.915      0.000       0.234       0.388\n",
      "task_conversation[T.cw_66]          0.1877      0.043      4.327      0.000       0.103       0.273\n",
      "task_conversation[T.cw_67]          0.1839      0.047      3.889      0.000       0.091       0.277\n",
      "task_conversation[T.cw_68]          0.0139      0.055      0.254      0.799      -0.093       0.121\n",
      "task_conversation[T.cw_69]          0.2452      0.041      6.018      0.000       0.165       0.325\n",
      "task_conversation[T.cw_7]           0.0882      0.039      2.245      0.025       0.011       0.165\n",
      "task_conversation[T.cw_70]         -0.0475      0.045     -1.053      0.292      -0.136       0.041\n",
      "task_conversation[T.cw_71]          0.1263      0.080      1.587      0.113      -0.030       0.282\n",
      "task_conversation[T.cw_72]         -0.0342      0.044     -0.780      0.436      -0.120       0.052\n",
      "task_conversation[T.cw_73]          0.1291      0.047      2.760      0.006       0.037       0.221\n",
      "task_conversation[T.cw_74]          0.0503      0.043      1.173      0.241      -0.034       0.134\n",
      "task_conversation[T.cw_75]          0.2025      0.046      4.394      0.000       0.112       0.293\n",
      "task_conversation[T.cw_76]          0.1981      0.045      4.389      0.000       0.110       0.287\n",
      "task_conversation[T.cw_77]          0.2287      0.053      4.304      0.000       0.125       0.333\n",
      "task_conversation[T.cw_78]          0.2576      0.044      5.814      0.000       0.171       0.344\n",
      "task_conversation[T.cw_79]          0.2296      0.045      5.115      0.000       0.142       0.318\n",
      "task_conversation[T.cw_8]           0.1727      0.043      4.040      0.000       0.089       0.257\n",
      "task_conversation[T.cw_80]          0.2926      0.043      6.758      0.000       0.208       0.377\n",
      "task_conversation[T.cw_81]          0.3683      0.040      9.278      0.000       0.291       0.446\n",
      "task_conversation[T.cw_82]          0.0059      0.054      0.110      0.912      -0.100       0.112\n",
      "task_conversation[T.cw_83]          0.1329      0.046      2.888      0.004       0.043       0.223\n",
      "task_conversation[T.cw_84]          0.2010      0.036      5.577      0.000       0.130       0.272\n",
      "task_conversation[T.cw_85]          0.2235      0.042      5.369      0.000       0.142       0.305\n",
      "task_conversation[T.cw_86]         -0.0217      0.043     -0.503      0.615      -0.106       0.063\n",
      "task_conversation[T.cw_87]          0.0769      0.051      1.512      0.131      -0.023       0.177\n",
      "task_conversation[T.cw_88]          0.0963      0.053      1.823      0.068      -0.007       0.200\n",
      "task_conversation[T.cw_89]          0.0394      0.050      0.794      0.427      -0.058       0.137\n",
      "task_conversation[T.cw_9]           0.2611      0.039      6.637      0.000       0.184       0.338\n",
      "task_conversation[T.cw_90]          0.0312      0.054      0.581      0.561      -0.074       0.136\n",
      "task_conversation[T.cw_91]         -0.0761      0.060     -1.264      0.206      -0.194       0.042\n",
      "task_conversation[T.cw_92]          0.0123      0.052      0.238      0.812      -0.089       0.114\n",
      "task_conversation[T.cw_93]          0.0285      0.059      0.485      0.628      -0.087       0.144\n",
      "task_conversation[T.cw_94]          0.1397      0.058      2.395      0.017       0.025       0.254\n",
      "task_conversation[T.cw_95]         -0.0628      0.047     -1.330      0.183      -0.155       0.030\n",
      "task_conversation[T.cw_96]          0.1976      0.046      4.341      0.000       0.108       0.287\n",
      "task_conversation[T.cw_97]          0.0317      0.042      0.757      0.449      -0.050       0.114\n",
      "task_conversation[T.cw_98]          0.1974      0.044      4.500      0.000       0.111       0.283\n",
      "task_conversation[T.cw_99]          0.0923      0.044      2.083      0.037       0.005       0.179\n",
      "model[T.td3]                        0.0136      0.010      1.330      0.183      -0.006       0.034\n",
      "conversation_length_thousands       0.2121      0.045      4.693      0.000       0.124       0.301\n",
      "consolidated_num_steps_ideas        0.0096      0.004      2.193      0.028       0.001       0.018\n",
      "conversation_length_thousands_2    -0.1194      0.030     -3.979      0.000      -0.178      -0.061\n",
      "consolidated_num_steps_ideas_2  -2.548e-05      0.001     -0.037      0.971      -0.001       0.001\n",
      "fres                               -0.0112      0.004     -2.597      0.009      -0.020      -0.003\n",
      "fres_2                           8.196e-05   3.21e-05      2.554      0.011    1.91e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        9.659   Durbin-Watson:                   1.959\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):               13.160\n",
      "Skew:                           0.039   Prob(JB):                      0.00139\n",
      "Kurtosis:                       3.463   Cond. No.                     4.89e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 4.89e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "reg_with_clustering_cw = smf.ols(\"avg_inter_paragraph_cosine_sim ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + fres + fres_2 + task_conversation + model\",\n",
    "                                 data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(reg_with_clustering_cw.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check task compliance as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_task_method', 'conversation_number', 'coherence_1_incoherent_10_very_coherent', 'compliance_OLD', 'ease_of_review_1_easy_10_hard', 'correct', 'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10', 'Aggregated_Prediction', 'Prediction_Based_On_First_10_LP', 'response_Based_On_First_10_LP', 'Prediction_Based_On_Last_10_LP', 'response_Based_On_Last_10_LP', 'response_LP', 'Aggregated_Prediction_LP', 'Prediction_Based_On_First_50_LP', 'response_Based_On_First_50_LP', 'Prediction_Based_On_Last_50_LP', 'response_Based_On_Last_50_LP', 'Aggregated_Prediction_50_LP', 'Prediction_Based_On_random_50_LP_1', 'response_Based_On_random_50_LP_1', 'Prediction_Based_On_random_50_LP_2', 'response_Based_On_random_50_LP_2', 'Aggregated_Prediction_random_50_LP', 'Unnamed: 0_x', 'response_x', 'replace_slash_n_slash_n_with_newline_x', 'replace_slash_n_slash_n_with_newline_values_x', 'replace_slash_n_with_newline_x', 'replace_slash_n_with_newline_values_x', 'avg_cosine_sim', 'num_sentences_x', 'Unnamed: 0_y', 'response_y', 'replace_slash_n_slash_n_with_newline_y', 'replace_slash_n_slash_n_with_newline_values_y', 'replace_slash_n_with_newline_y', 'replace_slash_n_with_newline_values_y', 'avg_inter_paragraph_cosine_sim', 'num_paragraphs', 'num_sentences_y', 'cosine_sims', 'conversation_length', 'input_length', 'output_length', 'conversation_cost', 'gsm8k_question_index', 'gsm8k_answer', 'gsm8k_length_vs_provided', 'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres', 'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided', 'num_sentences_provided', 'num_step_i_provided', 'num_1_dot_etc_provided', 'length_provided', 'compliance', 'coherence_1_incoherent_10_very_coherent_compliance_adjusted', 'Aggregated_Prediction_random_50_LP_compliance_adjusted', 'avg_cosine_sim_compliance_adjusted', 'avg_inter_paragraph_cosine_sim_compliance_adjusted', 'model', 'task', 'method', 'Model', 'Method', 'Task', 'accuracy_quality', 'accuracy_quality_compliance_adjusted', 'accuracy_quality_avg_inter_paragraph_cosine_sim', 'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_prompts', 'consolidated_num_steps_ideas_provided', 'technique_name', 'ss_publication_date', 'ss_publication_date_datetime', 'Method + Publication Date', 'Publication Date', 'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'sentence_length_prompts_diff', 'fres_prompts_diff', 'num_linebreaks_provided_diff', 'num_sentences_provided_diff', 'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff', 'conversation_length_thousands', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas_2', 'fres_2', 'task_conversation_method', 'task_conversation']\n"
     ]
    }
   ],
   "source": [
    "print(list(cw_data.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654309\n",
      "         Iterations 5\n",
      "logit no clustering cw compliance\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   No. Observations:                 1434\n",
      "Model:                          Logit   Df Residuals:                     1426\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Tue, 05 Dec 2023   Pseudo R-squ.:                 0.05297\n",
      "Time:                        00:08:56   Log-Likelihood:                -938.28\n",
      "converged:                       True   LL-Null:                       -990.76\n",
      "Covariance Type:                  HC3   LLR p-value:                 1.019e-19\n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          -5.6147      2.459     -2.283      0.022     -10.434      -0.795\n",
      "model[T.td3]                       -1.1195      0.145     -7.713      0.000      -1.404      -0.835\n",
      "conversation_length_thousands      -2.4087      0.707     -3.407      0.001      -3.795      -1.023\n",
      "consolidated_num_steps_ideas       -0.1075      0.077     -1.395      0.163      -0.258       0.044\n",
      "conversation_length_thousands_2     0.9949      0.478      2.082      0.037       0.058       1.931\n",
      "consolidated_num_steps_ideas_2      0.0208      0.014      1.529      0.126      -0.006       0.047\n",
      "fres                                0.1761      0.073      2.415      0.016       0.033       0.319\n",
      "fres_2                             -0.0010      0.001     -1.966      0.049      -0.002   -3.11e-06\n",
      "===================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:             compliance\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                       -0.2588      0.031     -8.385      0.000      -0.319      -0.198\n",
      "conversation_length_thousands      -0.5569      0.161     -3.456      0.001      -0.873      -0.241\n",
      "consolidated_num_steps_ideas       -0.0248      0.018     -1.398      0.162      -0.060       0.010\n",
      "conversation_length_thousands_2     0.2300      0.110      2.093      0.036       0.015       0.445\n",
      "consolidated_num_steps_ideas_2      0.0048      0.003      1.534      0.125      -0.001       0.011\n",
      "fres                                0.0407      0.017      2.435      0.015       0.008       0.073\n",
      "fres_2                             -0.0002      0.000     -1.977      0.048      -0.000   -2.04e-06\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_cw_compliance = smf.logit('compliance ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + fres + fres_2 + model', data=cw_data).fit(cov_type='HC3')\n",
    "\n",
    "print('logit no clustering cw compliance')\n",
    "# Display the summary\n",
    "print(logit_no_clustering_cw_compliance.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_cw_compliance_marginal_effects = logit_no_clustering_cw_compliance.get_margeff(at='overall')\n",
    "print(logit_no_clustering_cw_compliance_marginal_effects.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpm with clustering cw compliance\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   R-squared:                       0.203\n",
      "Model:                            OLS   Adj. R-squared:                  0.140\n",
      "Method:                 Least Squares   F-statistic:                     12.22\n",
      "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          5.08e-108\n",
      "Time:                        00:08:56   Log-Likelihood:                -874.55\n",
      "No. Observations:                1434   AIC:                             1963.\n",
      "Df Residuals:                    1327   BIC:                             2527.\n",
      "Df Model:                         106                                         \n",
      "Covariance Type:              cluster                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          -0.9952      0.556     -1.789      0.074      -2.085       0.095\n",
      "task_conversation[T.cw_10]         -0.0568      0.162     -0.350      0.727      -0.375       0.261\n",
      "task_conversation[T.cw_100]         0.0324      0.165      0.196      0.844      -0.291       0.356\n",
      "task_conversation[T.cw_11]         -0.0459      0.205     -0.223      0.823      -0.448       0.356\n",
      "task_conversation[T.cw_12]         -0.2910      0.162     -1.794      0.073      -0.609       0.027\n",
      "task_conversation[T.cw_13]          0.1099      0.219      0.501      0.616      -0.320       0.540\n",
      "task_conversation[T.cw_14]          0.2267      0.165      1.375      0.169      -0.096       0.550\n",
      "task_conversation[T.cw_15]         -0.0279      0.182     -0.153      0.878      -0.385       0.329\n",
      "task_conversation[T.cw_16]         -0.1075      0.166     -0.649      0.516      -0.432       0.217\n",
      "task_conversation[T.cw_17]          0.1649      0.163      1.013      0.311      -0.154       0.484\n",
      "task_conversation[T.cw_18]          0.1384      0.198      0.698      0.485      -0.250       0.527\n",
      "task_conversation[T.cw_19]          0.2465      0.222      1.112      0.266      -0.188       0.681\n",
      "task_conversation[T.cw_2]          -0.0670      0.194     -0.345      0.730      -0.448       0.314\n",
      "task_conversation[T.cw_20]          0.1666      0.201      0.827      0.408      -0.228       0.561\n",
      "task_conversation[T.cw_21]          0.2140      0.178      1.205      0.228      -0.134       0.562\n",
      "task_conversation[T.cw_22]          0.2397      0.162      1.478      0.139      -0.078       0.557\n",
      "task_conversation[T.cw_23]          0.1263      0.191      0.662      0.508      -0.248       0.500\n",
      "task_conversation[T.cw_24]          0.0425      0.169      0.252      0.801      -0.288       0.373\n",
      "task_conversation[T.cw_25]          0.2698      0.185      1.456      0.145      -0.093       0.633\n",
      "task_conversation[T.cw_26]          0.2256      0.156      1.447      0.148      -0.080       0.531\n",
      "task_conversation[T.cw_27]          0.0769      0.194      0.397      0.691      -0.302       0.456\n",
      "task_conversation[T.cw_28]         -0.0402      0.166     -0.242      0.809      -0.366       0.285\n",
      "task_conversation[T.cw_29]         -0.4053      0.146     -2.768      0.006      -0.692      -0.118\n",
      "task_conversation[T.cw_3]           0.2243      0.190      1.180      0.238      -0.148       0.597\n",
      "task_conversation[T.cw_30]          0.1584      0.165      0.957      0.338      -0.166       0.483\n",
      "task_conversation[T.cw_31]          0.0013      0.200      0.007      0.995      -0.391       0.394\n",
      "task_conversation[T.cw_32]          0.3167      0.184      1.717      0.086      -0.045       0.678\n",
      "task_conversation[T.cw_33]         -0.0305      0.175     -0.174      0.862      -0.374       0.313\n",
      "task_conversation[T.cw_34]          0.1047      0.175      0.597      0.550      -0.239       0.448\n",
      "task_conversation[T.cw_35]          0.2865      0.174      1.643      0.100      -0.055       0.628\n",
      "task_conversation[T.cw_36]          0.0744      0.210      0.354      0.723      -0.337       0.486\n",
      "task_conversation[T.cw_37]          0.1771      0.161      1.098      0.272      -0.139       0.493\n",
      "task_conversation[T.cw_38]          0.0658      0.191      0.344      0.731      -0.309       0.441\n",
      "task_conversation[T.cw_39]          0.1291      0.201      0.642      0.521      -0.265       0.523\n",
      "task_conversation[T.cw_4]           0.2670      0.193      1.381      0.167      -0.112       0.646\n",
      "task_conversation[T.cw_40]         -0.0990      0.190     -0.522      0.602      -0.471       0.273\n",
      "task_conversation[T.cw_41]          0.0791      0.180      0.440      0.660      -0.273       0.431\n",
      "task_conversation[T.cw_42]          0.1973      0.166      1.191      0.234      -0.127       0.522\n",
      "task_conversation[T.cw_43]          0.1955      0.177      1.102      0.271      -0.152       0.543\n",
      "task_conversation[T.cw_44]         -0.0992      0.165     -0.600      0.548      -0.423       0.225\n",
      "task_conversation[T.cw_45]         -0.1138      0.180     -0.631      0.528      -0.467       0.240\n",
      "task_conversation[T.cw_46]          0.1827      0.192      0.951      0.342      -0.194       0.559\n",
      "task_conversation[T.cw_47]         -0.1904      0.174     -1.097      0.273      -0.531       0.150\n",
      "task_conversation[T.cw_48]          0.1270      0.183      0.693      0.488      -0.232       0.486\n",
      "task_conversation[T.cw_49]          0.0328      0.172      0.190      0.849      -0.305       0.370\n",
      "task_conversation[T.cw_5]           0.2649      0.173      1.528      0.126      -0.075       0.605\n",
      "task_conversation[T.cw_50]         -0.2891      0.148     -1.949      0.051      -0.580       0.002\n",
      "task_conversation[T.cw_51]          0.2428      0.186      1.304      0.192      -0.122       0.608\n",
      "task_conversation[T.cw_52]          0.0077      0.195      0.040      0.968      -0.374       0.390\n",
      "task_conversation[T.cw_53]          0.2346      0.214      1.096      0.273      -0.185       0.654\n",
      "task_conversation[T.cw_54]          0.1014      0.220      0.460      0.645      -0.330       0.533\n",
      "task_conversation[T.cw_55]          0.0691      0.166      0.417      0.677      -0.256       0.394\n",
      "task_conversation[T.cw_56]          0.3642      0.179      2.035      0.042       0.013       0.715\n",
      "task_conversation[T.cw_57]         -0.3006      0.161     -1.862      0.063      -0.617       0.016\n",
      "task_conversation[T.cw_58]          0.1861      0.185      1.008      0.314      -0.176       0.548\n",
      "task_conversation[T.cw_59]          0.1831      0.184      0.993      0.321      -0.178       0.544\n",
      "task_conversation[T.cw_6]          -0.2957      0.147     -2.007      0.045      -0.585      -0.007\n",
      "task_conversation[T.cw_60]         -0.3021      0.147     -2.056      0.040      -0.590      -0.014\n",
      "task_conversation[T.cw_61]          0.0094      0.187      0.051      0.960      -0.356       0.375\n",
      "task_conversation[T.cw_62]          0.0892      0.200      0.446      0.656      -0.303       0.481\n",
      "task_conversation[T.cw_63]         -0.0658      0.200     -0.329      0.743      -0.458       0.327\n",
      "task_conversation[T.cw_64]          0.2780      0.203      1.367      0.172      -0.121       0.677\n",
      "task_conversation[T.cw_65]          0.2532      0.187      1.351      0.177      -0.114       0.621\n",
      "task_conversation[T.cw_66]         -0.1336      0.182     -0.733      0.463      -0.491       0.223\n",
      "task_conversation[T.cw_67]          0.3931      0.202      1.951      0.051      -0.002       0.788\n",
      "task_conversation[T.cw_68]          0.1711      0.199      0.860      0.390      -0.219       0.561\n",
      "task_conversation[T.cw_69]         -0.1615      0.175     -0.924      0.355      -0.504       0.181\n",
      "task_conversation[T.cw_7]          -0.1069      0.166     -0.643      0.520      -0.433       0.219\n",
      "task_conversation[T.cw_70]          0.2585      0.186      1.388      0.165      -0.106       0.623\n",
      "task_conversation[T.cw_71]          0.1100      0.206      0.535      0.593      -0.293       0.513\n",
      "task_conversation[T.cw_72]          0.2540      0.158      1.608      0.108      -0.056       0.564\n",
      "task_conversation[T.cw_73]         -0.2219      0.171     -1.298      0.194      -0.557       0.113\n",
      "task_conversation[T.cw_74]          0.1924      0.208      0.923      0.356      -0.216       0.601\n",
      "task_conversation[T.cw_75]          0.0462      0.176      0.263      0.793      -0.299       0.391\n",
      "task_conversation[T.cw_76]         -0.3110      0.166     -1.876      0.061      -0.636       0.014\n",
      "task_conversation[T.cw_77]          0.2586      0.158      1.632      0.103      -0.052       0.569\n",
      "task_conversation[T.cw_78]          0.0830      0.212      0.391      0.696      -0.333       0.499\n",
      "task_conversation[T.cw_79]          0.1581      0.212      0.745      0.456      -0.258       0.574\n",
      "task_conversation[T.cw_8]           0.3445      0.184      1.873      0.061      -0.016       0.705\n",
      "task_conversation[T.cw_80]          0.1244      0.178      0.700      0.484      -0.224       0.473\n",
      "task_conversation[T.cw_81]          0.6115      0.160      3.826      0.000       0.298       0.925\n",
      "task_conversation[T.cw_82]         -0.0136      0.209     -0.065      0.948      -0.423       0.395\n",
      "task_conversation[T.cw_83]          0.0738      0.207      0.357      0.721      -0.331       0.479\n",
      "task_conversation[T.cw_84]         -0.1217      0.158     -0.769      0.442      -0.432       0.188\n",
      "task_conversation[T.cw_85]         -0.0921      0.174     -0.529      0.597      -0.433       0.249\n",
      "task_conversation[T.cw_86]          0.2399      0.189      1.267      0.205      -0.131       0.611\n",
      "task_conversation[T.cw_87]          0.2114      0.192      1.104      0.270      -0.164       0.587\n",
      "task_conversation[T.cw_88]         -0.1538      0.173     -0.888      0.375      -0.493       0.186\n",
      "task_conversation[T.cw_89]          0.1239      0.214      0.578      0.563      -0.296       0.544\n",
      "task_conversation[T.cw_9]           0.1706      0.182      0.940      0.347      -0.185       0.526\n",
      "task_conversation[T.cw_90]          0.0704      0.204      0.345      0.730      -0.329       0.470\n",
      "task_conversation[T.cw_91]          0.2299      0.215      1.071      0.284      -0.191       0.651\n",
      "task_conversation[T.cw_92]          0.2170      0.178      1.216      0.224      -0.133       0.567\n",
      "task_conversation[T.cw_93]          0.1720      0.211      0.815      0.415      -0.242       0.586\n",
      "task_conversation[T.cw_94]         -0.0360      0.182     -0.198      0.843      -0.393       0.321\n",
      "task_conversation[T.cw_95]          0.2911      0.174      1.671      0.095      -0.050       0.633\n",
      "task_conversation[T.cw_96]          0.3790      0.175      2.160      0.031       0.035       0.723\n",
      "task_conversation[T.cw_97]          0.1041      0.191      0.545      0.585      -0.270       0.478\n",
      "task_conversation[T.cw_98]          0.2322      0.192      1.210      0.226      -0.144       0.608\n",
      "task_conversation[T.cw_99]         -0.0916      0.174     -0.527      0.598      -0.432       0.249\n",
      "model[T.td3]                       -0.2439      0.035     -6.989      0.000      -0.312      -0.176\n",
      "conversation_length_thousands      -0.5305      0.158     -3.366      0.001      -0.839      -0.222\n",
      "consolidated_num_steps_ideas       -0.0334      0.016     -2.134      0.033      -0.064      -0.003\n",
      "conversation_length_thousands_2     0.2256      0.107      2.099      0.036       0.015       0.436\n",
      "consolidated_num_steps_ideas_2      0.0061      0.003      2.359      0.018       0.001       0.011\n",
      "fres                                0.0450      0.016      2.871      0.004       0.014       0.076\n",
      "fres_2                             -0.0003      0.000     -2.449      0.014      -0.001   -5.65e-05\n",
      "==============================================================================\n",
      "Omnibus:                     4778.065   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.476\n",
      "Skew:                           0.033   Prob(JB):                     3.39e-23\n",
      "Kurtosis:                       1.686   Cond. No.                     4.89e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 4.89e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_cw_compliance = smf.ols('compliance ~ conversation_length_thousands + consolidated_num_steps_ideas + conversation_length_thousands_2 + consolidated_num_steps_ideas_2 + fres + fres_2 + task_conversation + model', data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print('lpm with clustering cw compliance')\n",
    "print(lpm_with_clustering_cw_compliance.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K Regression with Provided Answer Complexity Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_task_method', 'conversation_number', 'coherence_1_incoherent_10_very_coherent', 'compliance_OLD', 'ease_of_review_1_easy_10_hard', 'correct', 'Prediction_Based_On_First_10', 'Prediction_Based_On_Last_10', 'Aggregated_Prediction', 'Prediction_Based_On_First_10_LP', 'response_Based_On_First_10_LP', 'Prediction_Based_On_Last_10_LP', 'response_Based_On_Last_10_LP', 'response_LP', 'Aggregated_Prediction_LP', 'Prediction_Based_On_First_50_LP', 'response_Based_On_First_50_LP', 'Prediction_Based_On_Last_50_LP', 'response_Based_On_Last_50_LP', 'Aggregated_Prediction_50_LP', 'Prediction_Based_On_random_50_LP_1', 'response_Based_On_random_50_LP_1', 'Prediction_Based_On_random_50_LP_2', 'response_Based_On_random_50_LP_2', 'Aggregated_Prediction_random_50_LP', 'Unnamed: 0_x', 'response_x', 'replace_slash_n_slash_n_with_newline_x', 'replace_slash_n_slash_n_with_newline_values_x', 'replace_slash_n_with_newline_x', 'replace_slash_n_with_newline_values_x', 'avg_cosine_sim', 'num_sentences_x', 'Unnamed: 0_y', 'response_y', 'replace_slash_n_slash_n_with_newline_y', 'replace_slash_n_slash_n_with_newline_values_y', 'replace_slash_n_with_newline_y', 'replace_slash_n_with_newline_values_y', 'avg_inter_paragraph_cosine_sim', 'num_paragraphs', 'num_sentences_y', 'cosine_sims', 'conversation_length', 'input_length', 'output_length', 'conversation_cost', 'gsm8k_question_index', 'gsm8k_answer', 'gsm8k_length_vs_provided', 'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres', 'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided', 'num_sentences_provided', 'num_step_i_provided', 'num_1_dot_etc_provided', 'length_provided', 'compliance', 'coherence_1_incoherent_10_very_coherent_compliance_adjusted', 'Aggregated_Prediction_random_50_LP_compliance_adjusted', 'avg_cosine_sim_compliance_adjusted', 'avg_inter_paragraph_cosine_sim_compliance_adjusted', 'model', 'task', 'method', 'Model', 'Method', 'Task', 'accuracy_quality', 'accuracy_quality_compliance_adjusted', 'accuracy_quality_avg_inter_paragraph_cosine_sim', 'consolidated_num_steps_ideas', 'consolidated_num_steps_ideas_prompts', 'consolidated_num_steps_ideas_provided', 'technique_name', 'ss_publication_date', 'ss_publication_date_datetime', 'Method + Publication Date', 'Publication Date', 'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'sentence_length_prompts_diff', 'fres_prompts_diff', 'num_linebreaks_provided_diff', 'num_sentences_provided_diff', 'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff', 'conversation_length_thousands', 'conversation_length_thousands_2', 'consolidated_num_steps_ideas_2', 'fres_2', 'task_conversation_method', 'task_conversation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_11424\\2596320842.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gsm8k_data['length_provided_thousands'] = gsm8k_data['length_provided']/1000\n",
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_11424\\2596320842.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gsm8k_data['length_provided_thousands_2'] = gsm8k_data['length_provided_thousands']**2\n"
     ]
    }
   ],
   "source": [
    "print(list(gsm8k_data.columns))\n",
    "\n",
    "# Length_provided in thousands\n",
    "gsm8k_data['length_provided_thousands'] = gsm8k_data['length_provided']/1000\n",
    "\n",
    "# Squared length_provided in thousands\n",
    "gsm8k_data['length_provided_thousands_2'] = gsm8k_data['length_provided_thousands']**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541507\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1587\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Tue, 05 Dec 2023   Pseudo R-squ.:                  0.2010\n",
      "Time:                        00:08:56   Log-Likelihood:                -866.41\n",
      "converged:                       True   LL-Null:                       -1084.4\n",
      "Covariance Type:                  HC3   LLR p-value:                 8.873e-86\n",
      "=============================================================================================================================\n",
      "                                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                     3.4927      0.565      6.185      0.000       2.386       4.599\n",
      "model[T.td3]                                                 -2.1234      0.356     -5.959      0.000      -2.822      -1.425\n",
      "length_provided_thousands                                   -42.3230      8.024     -5.275      0.000     -58.049     -26.597\n",
      "length_provided_thousands:model[T.td3]                       -0.4262      3.419     -0.125      0.901      -7.127       6.275\n",
      "conversation_length_thousands                                 4.3564      2.000      2.178      0.029       0.437       8.276\n",
      "length_provided_thousands:conversation_length_thousands     -33.5674     16.599     -2.022      0.043     -66.101      -1.033\n",
      "consolidated_num_steps_ideas                                  0.2396      0.103      2.322      0.020       0.037       0.442\n",
      "length_provided_thousands:consolidated_num_steps_ideas       -0.3433      0.894     -0.384      0.701      -2.095       1.408\n",
      "conversation_length_thousands_2                              -3.4751      1.989     -1.747      0.081      -7.374       0.424\n",
      "length_provided_thousands:conversation_length_thousands_2    15.7148     13.754      1.143      0.253     -11.242      42.672\n",
      "consolidated_num_steps_ideas_2                               -0.0169      0.007     -2.459      0.014      -0.030      -0.003\n",
      "length_provided_thousands:consolidated_num_steps_ideas_2      0.0514      0.053      0.968      0.333      -0.053       0.156\n",
      "length_provided_thousands_2                                 172.5851     32.531      5.305      0.000     108.826     236.344\n",
      "=============================================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                correct\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "=============================================================================================================================\n",
      "                                                               dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                                                 -0.3855      0.063     -6.093      0.000      -0.509      -0.261\n",
      "length_provided_thousands                                    -7.6835      1.431     -5.369      0.000     -10.489      -4.878\n",
      "length_provided_thousands:model[T.td3]                       -0.0774      0.620     -0.125      0.901      -1.293       1.139\n",
      "conversation_length_thousands                                 0.7909      0.360      2.196      0.028       0.085       1.497\n",
      "length_provided_thousands:conversation_length_thousands      -6.0940      2.990     -2.038      0.042     -11.954      -0.234\n",
      "consolidated_num_steps_ideas                                  0.0435      0.019      2.340      0.019       0.007       0.080\n",
      "length_provided_thousands:consolidated_num_steps_ideas       -0.0623      0.162     -0.384      0.701      -0.380       0.255\n",
      "conversation_length_thousands_2                              -0.6309      0.360     -1.754      0.079      -1.336       0.074\n",
      "length_provided_thousands:conversation_length_thousands_2     2.8529      2.490      1.146      0.252      -2.028       7.733\n",
      "consolidated_num_steps_ideas_2                               -0.0031      0.001     -2.479      0.013      -0.006      -0.001\n",
      "length_provided_thousands:consolidated_num_steps_ideas_2      0.0093      0.010      0.970      0.332      -0.010       0.028\n",
      "length_provided_thousands_2                                  31.3320      5.748      5.451      0.000      20.066      42.598\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_gsm8k_provided_interaction = smf.logit('correct ~ length_provided_thousands * conversation_length_thousands + length_provided_thousands * consolidated_num_steps_ideas + length_provided_thousands * conversation_length_thousands_2 + length_provided_thousands * consolidated_num_steps_ideas_2 + length_provided_thousands * model + length_provided_thousands_2', data=gsm8k_data).fit(cov_type='HC3')\n",
    "\n",
    "# Display the summary\n",
    "print(logit_no_clustering_gsm8k_provided_interaction.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_gsm8k_provided_interaction_marginal_effects = logit_no_clustering_gsm8k_provided_interaction.get_margeff(at='overall')\n",
    "print(logit_no_clustering_gsm8k_provided_interaction_marginal_effects.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\statsmodels\\base\\model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 210, but rank is 206\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.319\n",
      "Method:                 Least Squares   F-statistic:                     71.75\n",
      "Date:                Tue, 05 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        00:08:56   Log-Likelihood:                -718.03\n",
      "No. Observations:                1600   AIC:                             1852.\n",
      "Df Residuals:                    1392   BIC:                             2971.\n",
      "Df Model:                         207                                         \n",
      "Covariance Type:              cluster                                         \n",
      "=============================================================================================================================\n",
      "                                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                     1.1920      7.917      0.151      0.880     -14.326      16.710\n",
      "task_conversation[T.gsm8k_10]                                25.2719     18.055      1.400      0.162     -10.115      60.659\n",
      "task_conversation[T.gsm8k_100]                                9.0901      6.212      1.463      0.143      -3.085      21.265\n",
      "task_conversation[T.gsm8k_11]                                 3.6278      5.282      0.687      0.492      -6.724      13.979\n",
      "task_conversation[T.gsm8k_12]                               -15.1840      8.521     -1.782      0.075     -31.885       1.517\n",
      "task_conversation[T.gsm8k_13]                                 4.5170      0.943      4.788      0.000       2.668       6.366\n",
      "task_conversation[T.gsm8k_14]                                 1.0243      2.555      0.401      0.689      -3.984       6.033\n",
      "task_conversation[T.gsm8k_15]                                 4.7577      4.341      1.096      0.273      -3.750      13.266\n",
      "task_conversation[T.gsm8k_16]                                12.6763      9.998      1.268      0.205      -6.919      32.271\n",
      "task_conversation[T.gsm8k_17]                                17.6657      3.541      4.989      0.000      10.725      24.606\n",
      "task_conversation[T.gsm8k_18]                                14.2125     15.061      0.944      0.345     -15.307      43.732\n",
      "task_conversation[T.gsm8k_19]                                 0.1957      4.015      0.049      0.961      -7.674       8.065\n",
      "task_conversation[T.gsm8k_2]                                  3.6039      5.882      0.613      0.540      -7.925      15.133\n",
      "task_conversation[T.gsm8k_20]                                 1.3977      6.810      0.205      0.837     -11.949      14.744\n",
      "task_conversation[T.gsm8k_21]                                 2.0059     11.709      0.171      0.864     -20.943      24.955\n",
      "task_conversation[T.gsm8k_22]                                -6.7812      5.934     -1.143      0.253     -18.412       4.850\n",
      "task_conversation[T.gsm8k_23]                                -0.1766      5.653     -0.031      0.975     -11.256      10.903\n",
      "task_conversation[T.gsm8k_24]                                -0.4726      6.190     -0.076      0.939     -12.606      11.660\n",
      "task_conversation[T.gsm8k_25]                                 1.1232     11.441      0.098      0.922     -21.300      23.547\n",
      "task_conversation[T.gsm8k_26]                               -12.0359      9.524     -1.264      0.206     -30.702       6.630\n",
      "task_conversation[T.gsm8k_27]                                -4.4892     10.966     -0.409      0.682     -25.982      17.004\n",
      "task_conversation[T.gsm8k_28]                                 0.2881      5.001      0.058      0.954      -9.514      10.090\n",
      "task_conversation[T.gsm8k_29]                                -0.6935      6.215     -0.112      0.911     -12.875      11.488\n",
      "task_conversation[T.gsm8k_3]                                 -1.3394      3.344     -0.401      0.689      -7.893       5.214\n",
      "task_conversation[T.gsm8k_30]                                 0.2914      6.305      0.046      0.963     -12.066      12.649\n",
      "task_conversation[T.gsm8k_31]                                -3.1198      4.229     -0.738      0.461     -11.408       5.168\n",
      "task_conversation[T.gsm8k_32]                                -3.9028      3.381     -1.154      0.248     -10.530       2.724\n",
      "task_conversation[T.gsm8k_33]                                 1.4007      6.722      0.208      0.835     -11.774      14.575\n",
      "task_conversation[T.gsm8k_34]                                33.4565     13.616      2.457      0.014       6.769      60.144\n",
      "task_conversation[T.gsm8k_35]                                 1.8463      5.019      0.368      0.713      -7.992      11.684\n",
      "task_conversation[T.gsm8k_36]                                -1.4229      5.066     -0.281      0.779     -11.351       8.506\n",
      "task_conversation[T.gsm8k_37]                                 2.1212      3.088      0.687      0.492      -3.932       8.174\n",
      "task_conversation[T.gsm8k_38]                                 0.1694      4.113      0.041      0.967      -7.892       8.231\n",
      "task_conversation[T.gsm8k_39]                               -50.3135      7.102     -7.085      0.000     -64.233     -36.394\n",
      "task_conversation[T.gsm8k_4]                                  1.1262      6.276      0.179      0.858     -11.174      13.426\n",
      "task_conversation[T.gsm8k_40]                                 1.5812     25.171      0.063      0.950     -47.752      50.915\n",
      "task_conversation[T.gsm8k_41]                                -0.5665      9.304     -0.061      0.951     -18.803      17.670\n",
      "task_conversation[T.gsm8k_42]                                -0.4824      5.040     -0.096      0.924     -10.361       9.397\n",
      "task_conversation[T.gsm8k_43]                                -1.9352      5.750     -0.337      0.736     -13.205       9.335\n",
      "task_conversation[T.gsm8k_44]                                -1.9445      2.237     -0.869      0.385      -6.328       2.439\n",
      "task_conversation[T.gsm8k_45]                                 2.7797      5.135      0.541      0.588      -7.285      12.844\n",
      "task_conversation[T.gsm8k_46]                                -4.9611      5.151     -0.963      0.335     -15.057       5.134\n",
      "task_conversation[T.gsm8k_47]                                 2.2462      8.128      0.276      0.782     -13.685      18.178\n",
      "task_conversation[T.gsm8k_48]                                 2.0326      4.051      0.502      0.616      -5.907       9.973\n",
      "task_conversation[T.gsm8k_49]                                 5.3494      4.468      1.197      0.231      -3.407      14.106\n",
      "task_conversation[T.gsm8k_5]                                 -4.3774      4.829     -0.907      0.365     -13.842       5.087\n",
      "task_conversation[T.gsm8k_50]                                 0.6343      4.806      0.132      0.895      -8.785      10.054\n",
      "task_conversation[T.gsm8k_51]                                 2.7064      7.719      0.351      0.726     -12.423      17.836\n",
      "task_conversation[T.gsm8k_52]                                -2.2221      5.766     -0.385      0.700     -13.523       9.079\n",
      "task_conversation[T.gsm8k_53]                                 0.7871      4.853      0.162      0.871      -8.726      10.300\n",
      "task_conversation[T.gsm8k_54]                                 8.1536      8.104      1.006      0.314      -7.729      24.037\n",
      "task_conversation[T.gsm8k_55]                                 0.1937      4.855      0.040      0.968      -9.323       9.710\n",
      "task_conversation[T.gsm8k_56]                                -0.3561      6.228     -0.057      0.954     -12.563      11.850\n",
      "task_conversation[T.gsm8k_57]                                -1.8746      6.091     -0.308      0.758     -13.813      10.064\n",
      "task_conversation[T.gsm8k_58]                                -0.6867      5.984     -0.115      0.909     -12.415      11.041\n",
      "task_conversation[T.gsm8k_59]                                 6.7698      8.024      0.844      0.399      -8.956      22.496\n",
      "task_conversation[T.gsm8k_6]                                 -2.1023      3.417     -0.615      0.538      -8.799       4.594\n",
      "task_conversation[T.gsm8k_60]                                -2.0558      5.728     -0.359      0.720     -13.282       9.170\n",
      "task_conversation[T.gsm8k_61]                                 4.5157      6.110      0.739      0.460      -7.459      16.491\n",
      "task_conversation[T.gsm8k_62]                                -1.5176      5.547     -0.274      0.784     -12.390       9.355\n",
      "task_conversation[T.gsm8k_63]                                12.9817      3.984      3.258      0.001       5.173      20.791\n",
      "task_conversation[T.gsm8k_64]                                17.9639     31.527      0.570      0.569     -43.828      79.756\n",
      "task_conversation[T.gsm8k_65]                                -0.5802      6.079     -0.095      0.924     -12.495      11.334\n",
      "task_conversation[T.gsm8k_66]                                -1.3773      4.510     -0.305      0.760     -10.218       7.463\n",
      "task_conversation[T.gsm8k_67]                                -0.4087      6.336     -0.064      0.949     -12.828      12.011\n",
      "task_conversation[T.gsm8k_68]                                 0.3661      5.219      0.070      0.944      -9.863      10.595\n",
      "task_conversation[T.gsm8k_69]                                 0.1187      4.606      0.026      0.979      -8.909       9.146\n",
      "task_conversation[T.gsm8k_7]                                 -1.2246      4.616     -0.265      0.791     -10.272       7.822\n",
      "task_conversation[T.gsm8k_70]                                -2.6931      6.111     -0.441      0.659     -14.671       9.285\n",
      "task_conversation[T.gsm8k_71]                                -2.8347      2.072     -1.368      0.171      -6.895       1.226\n",
      "task_conversation[T.gsm8k_72]                                -0.5979      6.130     -0.098      0.922     -12.613      11.417\n",
      "task_conversation[T.gsm8k_73]                                26.7970     18.265      1.467      0.142      -9.003      62.597\n",
      "task_conversation[T.gsm8k_74]                               -25.9158     16.709     -1.551      0.121     -58.665       6.834\n",
      "task_conversation[T.gsm8k_75]                                 4.3840      8.185      0.536      0.592     -11.659      20.427\n",
      "task_conversation[T.gsm8k_76]                                -1.8427      1.356     -1.359      0.174      -4.501       0.816\n",
      "task_conversation[T.gsm8k_77]                                -2.3998      2.463     -0.974      0.330      -7.227       2.427\n",
      "task_conversation[T.gsm8k_78]                                 3.5818      4.417      0.811      0.417      -5.076      12.240\n",
      "task_conversation[T.gsm8k_79]                                17.7509      3.474      5.109      0.000      10.941      24.560\n",
      "task_conversation[T.gsm8k_8]                                 -0.9674      3.276     -0.295      0.768      -7.388       5.453\n",
      "task_conversation[T.gsm8k_80]                                 5.1094      5.832      0.876      0.381      -6.320      16.539\n",
      "task_conversation[T.gsm8k_81]                               -15.2241     19.494     -0.781      0.435     -53.432      22.984\n",
      "task_conversation[T.gsm8k_82]                                 0.0841      5.398      0.016      0.988     -10.496      10.664\n",
      "task_conversation[T.gsm8k_83]                                -0.3369      1.574     -0.214      0.831      -3.422       2.748\n",
      "task_conversation[T.gsm8k_84]                                 5.0089      4.947      1.012      0.311      -4.687      14.705\n",
      "task_conversation[T.gsm8k_85]                                -0.2500      4.081     -0.061      0.951      -8.248       7.749\n",
      "task_conversation[T.gsm8k_86]                                 0.7361      4.523      0.163      0.871      -8.129       9.602\n",
      "task_conversation[T.gsm8k_87]                                12.4926     19.699      0.634      0.526     -26.117      51.103\n",
      "task_conversation[T.gsm8k_88]                               -19.9562     10.728     -1.860      0.063     -40.982       1.070\n",
      "task_conversation[T.gsm8k_89]                                -3.6688      4.304     -0.852      0.394     -12.105       4.768\n",
      "task_conversation[T.gsm8k_9]                                  0.9865      4.020      0.245      0.806      -6.892       8.865\n",
      "task_conversation[T.gsm8k_90]                                 3.0524      6.288      0.485      0.627      -9.272      15.377\n",
      "task_conversation[T.gsm8k_91]                                -1.6107      5.773     -0.279      0.780     -12.926       9.705\n",
      "task_conversation[T.gsm8k_92]                                -0.2187      5.515     -0.040      0.968     -11.028      10.590\n",
      "task_conversation[T.gsm8k_93]                                -0.5520      4.731     -0.117      0.907      -9.824       8.720\n",
      "task_conversation[T.gsm8k_94]                                -8.0262      6.939     -1.157      0.247     -21.626       5.573\n",
      "task_conversation[T.gsm8k_95]                                -1.7400      4.688     -0.371      0.711     -10.929       7.449\n",
      "task_conversation[T.gsm8k_96]                                 2.8826      3.935      0.733      0.464      -4.830      10.595\n",
      "task_conversation[T.gsm8k_97]                                -0.4345      6.060     -0.072      0.943     -12.312      11.443\n",
      "task_conversation[T.gsm8k_98]                                -3.8660      4.629     -0.835      0.404     -12.939       5.207\n",
      "task_conversation[T.gsm8k_99]                                -1.5654      4.340     -0.361      0.718     -10.072       6.941\n",
      "model[T.td3]                                                 -0.2789      0.268     -1.040      0.298      -0.805       0.247\n",
      "length_provided_thousands                                    -4.2231    168.599     -0.025      0.980    -334.671     326.225\n",
      "length_provided_thousands:task_conversation[T.gsm8k_10]    -193.2671    151.068     -1.279      0.201    -489.355     102.821\n",
      "length_provided_thousands:task_conversation[T.gsm8k_100]    -82.0170     84.576     -0.970      0.332    -247.782      83.748\n",
      "length_provided_thousands:task_conversation[T.gsm8k_11]     -20.4527     59.994     -0.341      0.733    -138.040      97.134\n",
      "length_provided_thousands:task_conversation[T.gsm8k_12]     140.2395    105.327      1.331      0.183     -66.197     346.676\n",
      "length_provided_thousands:task_conversation[T.gsm8k_13]     -36.5023     54.904     -0.665      0.506    -144.112      71.108\n",
      "length_provided_thousands:task_conversation[T.gsm8k_14]      -8.3589     62.594     -0.134      0.894    -131.040     114.322\n",
      "length_provided_thousands:task_conversation[T.gsm8k_15]     -32.3716     64.345     -0.503      0.615    -158.485      93.742\n",
      "length_provided_thousands:task_conversation[T.gsm8k_16]     -96.7173     95.844     -1.009      0.313    -284.568      91.133\n",
      "length_provided_thousands:task_conversation[T.gsm8k_17]    -149.5305     67.294     -2.222      0.026    -281.425     -17.637\n",
      "length_provided_thousands:task_conversation[T.gsm8k_18]     -85.6597    105.981     -0.808      0.419    -293.378     122.059\n",
      "length_provided_thousands:task_conversation[T.gsm8k_19]       0.6025     82.918      0.007      0.994    -161.913     163.118\n",
      "length_provided_thousands:task_conversation[T.gsm8k_2]      -77.7328    107.541     -0.723      0.470    -288.509     133.043\n",
      "length_provided_thousands:task_conversation[T.gsm8k_20]      -1.8456     34.008     -0.054      0.957     -68.500      64.809\n",
      "length_provided_thousands:task_conversation[T.gsm8k_21]     -13.5811    106.727     -0.127      0.899    -222.761     195.599\n",
      "length_provided_thousands:task_conversation[T.gsm8k_22]     123.0815    109.047      1.129      0.259     -90.647     336.810\n",
      "length_provided_thousands:task_conversation[T.gsm8k_23]       2.8865    102.935      0.028      0.978    -198.862     204.635\n",
      "length_provided_thousands:task_conversation[T.gsm8k_24]       9.0141    113.390      0.079      0.937    -213.225     231.254\n",
      "length_provided_thousands:task_conversation[T.gsm8k_25]     -19.8777    198.808     -0.100      0.920    -409.534     369.779\n",
      "length_provided_thousands:task_conversation[T.gsm8k_26]      96.7820     91.466      1.058      0.290     -82.488     276.052\n",
      "length_provided_thousands:task_conversation[T.gsm8k_27]      90.9547    238.386      0.382      0.703    -376.274     558.183\n",
      "length_provided_thousands:task_conversation[T.gsm8k_28]      -2.0412     94.881     -0.022      0.983    -188.005     183.923\n",
      "length_provided_thousands:task_conversation[T.gsm8k_29]      12.7548    113.114      0.113      0.910    -208.944     234.454\n",
      "length_provided_thousands:task_conversation[T.gsm8k_3]       12.1466     60.968      0.199      0.842    -107.349     131.642\n",
      "length_provided_thousands:task_conversation[T.gsm8k_30]      -6.2990    108.476     -0.058      0.954    -218.909     206.311\n",
      "length_provided_thousands:task_conversation[T.gsm8k_31]      33.6512     82.974      0.406      0.685    -128.974     196.277\n",
      "length_provided_thousands:task_conversation[T.gsm8k_32]      41.2024     77.579      0.531      0.595    -110.849     193.254\n",
      "length_provided_thousands:task_conversation[T.gsm8k_33]     -37.9908    131.832     -0.288      0.773    -296.377     220.396\n",
      "length_provided_thousands:task_conversation[T.gsm8k_34]    -506.1536    223.029     -2.269      0.023    -943.281     -69.026\n",
      "length_provided_thousands:task_conversation[T.gsm8k_35]     -24.6247     93.348     -0.264      0.792    -207.583     158.334\n",
      "length_provided_thousands:task_conversation[T.gsm8k_36]      17.7008     95.581      0.185      0.853    -169.634     205.035\n",
      "length_provided_thousands:task_conversation[T.gsm8k_37]     -13.8514     64.734     -0.214      0.831    -140.728     113.025\n",
      "length_provided_thousands:task_conversation[T.gsm8k_38]      -6.1127     85.255     -0.072      0.943    -173.210     160.985\n",
      "length_provided_thousands:task_conversation[T.gsm8k_39]     417.0985     72.564      5.748      0.000     274.875     559.322\n",
      "length_provided_thousands:task_conversation[T.gsm8k_4]      -32.0364    117.057     -0.274      0.784    -261.463     197.390\n",
      "length_provided_thousands:task_conversation[T.gsm8k_40]       1.5469    114.526      0.014      0.989    -222.920     226.014\n",
      "length_provided_thousands:task_conversation[T.gsm8k_41]      11.4224    184.247      0.062      0.951    -349.695     372.540\n",
      "length_provided_thousands:task_conversation[T.gsm8k_42]       4.5562     95.267      0.048      0.962    -182.163     191.276\n",
      "length_provided_thousands:task_conversation[T.gsm8k_43]      30.2875    102.380      0.296      0.767    -170.374     230.949\n",
      "length_provided_thousands:task_conversation[T.gsm8k_44]      16.9809     38.783      0.438      0.661     -59.032      92.993\n",
      "length_provided_thousands:task_conversation[T.gsm8k_45]      -9.7935     33.658     -0.291      0.771     -75.761      56.174\n",
      "length_provided_thousands:task_conversation[T.gsm8k_46]      39.2195     53.967      0.727      0.467     -66.554     144.993\n",
      "length_provided_thousands:task_conversation[T.gsm8k_47]     -18.9546    104.870     -0.181      0.857    -224.496     186.587\n",
      "length_provided_thousands:task_conversation[T.gsm8k_48]     -11.9983     62.680     -0.191      0.848    -134.849     110.852\n",
      "length_provided_thousands:task_conversation[T.gsm8k_49]     -65.0529     88.979     -0.731      0.465    -239.448     109.343\n",
      "length_provided_thousands:task_conversation[T.gsm8k_5]       50.1596     86.263      0.581      0.561    -118.912     219.231\n",
      "length_provided_thousands:task_conversation[T.gsm8k_50]      -2.1420     82.514     -0.026      0.979    -163.866     159.582\n",
      "length_provided_thousands:task_conversation[T.gsm8k_51]     -36.3062    114.762     -0.316      0.752    -261.236     188.624\n",
      "length_provided_thousands:task_conversation[T.gsm8k_52]      33.7616    103.877      0.325      0.745    -169.833     237.356\n",
      "length_provided_thousands:task_conversation[T.gsm8k_53]      -8.3367     90.415     -0.092      0.927    -185.546     168.873\n",
      "length_provided_thousands:task_conversation[T.gsm8k_54]     -87.5136    104.741     -0.836      0.403    -292.802     117.774\n",
      "length_provided_thousands:task_conversation[T.gsm8k_55]      -1.6930     88.599     -0.019      0.985    -175.345     171.959\n",
      "length_provided_thousands:task_conversation[T.gsm8k_56]       6.1119    113.549      0.054      0.957    -216.441     228.665\n",
      "length_provided_thousands:task_conversation[T.gsm8k_57]      34.6192    110.965      0.312      0.755    -182.867     252.106\n",
      "length_provided_thousands:task_conversation[T.gsm8k_58]       9.9897    107.165      0.093      0.926    -200.050     220.030\n",
      "length_provided_thousands:task_conversation[T.gsm8k_59]     -47.0171     79.214     -0.594      0.553    -202.273     108.239\n",
      "length_provided_thousands:task_conversation[T.gsm8k_6]       18.6365     44.017      0.423      0.672     -67.634     104.907\n",
      "length_provided_thousands:task_conversation[T.gsm8k_60]      33.1016    103.011      0.321      0.748    -168.796     234.999\n",
      "length_provided_thousands:task_conversation[T.gsm8k_61]     -55.9980     97.351     -0.575      0.565    -246.803     134.807\n",
      "length_provided_thousands:task_conversation[T.gsm8k_62]      23.4423    102.217      0.229      0.819    -176.900     223.784\n",
      "length_provided_thousands:task_conversation[T.gsm8k_63]    -128.7715     76.981     -1.673      0.094    -279.651      22.108\n",
      "length_provided_thousands:task_conversation[T.gsm8k_64]     -91.5304    184.767     -0.495      0.620    -453.668     270.607\n",
      "length_provided_thousands:task_conversation[T.gsm8k_65]       8.5184    110.067      0.077      0.938    -207.209     224.246\n",
      "length_provided_thousands:task_conversation[T.gsm8k_66]      15.8584     85.058      0.186      0.852    -150.853     182.569\n",
      "length_provided_thousands:task_conversation[T.gsm8k_67]       7.3724     68.479      0.108      0.914    -126.845     141.590\n",
      "length_provided_thousands:task_conversation[T.gsm8k_68]      -4.4887     91.936     -0.049      0.961    -184.679     175.702\n",
      "length_provided_thousands:task_conversation[T.gsm8k_69]      -0.9250     89.081     -0.010      0.992    -175.520     173.670\n",
      "length_provided_thousands:task_conversation[T.gsm8k_7]       15.8624     89.467      0.177      0.859    -159.489     191.214\n",
      "length_provided_thousands:task_conversation[T.gsm8k_70]      54.3960    113.198      0.481      0.631    -167.469     276.261\n",
      "length_provided_thousands:task_conversation[T.gsm8k_71]      25.5867     56.797      0.450      0.652     -85.734     136.907\n",
      "length_provided_thousands:task_conversation[T.gsm8k_72]      11.4401    113.482      0.101      0.920    -210.981     233.861\n",
      "length_provided_thousands:task_conversation[T.gsm8k_73]    -351.0486    239.832     -1.464      0.143    -821.110     119.013\n",
      "length_provided_thousands:task_conversation[T.gsm8k_74]     249.6861    183.823      1.358      0.174    -110.600     609.972\n",
      "length_provided_thousands:task_conversation[T.gsm8k_75]     -15.7140     30.627     -0.513      0.608     -75.741      44.313\n",
      "length_provided_thousands:task_conversation[T.gsm8k_76]      16.7285     56.664      0.295      0.768     -94.331     127.788\n",
      "length_provided_thousands:task_conversation[T.gsm8k_77]      22.1272     47.171      0.469      0.639     -70.327     114.581\n",
      "length_provided_thousands:task_conversation[T.gsm8k_78]     -35.4928     81.378     -0.436      0.663    -194.990     124.005\n",
      "length_provided_thousands:task_conversation[T.gsm8k_79]    -132.1892     57.930     -2.282      0.022    -245.729     -18.649\n",
      "length_provided_thousands:task_conversation[T.gsm8k_8]       10.4633     37.814      0.277      0.782     -63.651      84.577\n",
      "length_provided_thousands:task_conversation[T.gsm8k_80]    -128.6370    103.083     -1.248      0.212    -330.677      73.403\n",
      "length_provided_thousands:task_conversation[T.gsm8k_81]     142.2641    186.069      0.765      0.445    -222.425     506.953\n",
      "length_provided_thousands:task_conversation[T.gsm8k_82]      -1.2453     99.701     -0.012      0.990    -196.655     194.164\n",
      "length_provided_thousands:task_conversation[T.gsm8k_83]      -0.0141      0.066     -0.214      0.831      -0.144       0.115\n",
      "length_provided_thousands:task_conversation[T.gsm8k_84]     -71.7522     93.935     -0.764      0.445    -255.862     112.357\n",
      "length_provided_thousands:task_conversation[T.gsm8k_85]       2.5367     78.660      0.032      0.974    -151.634     156.707\n",
      "length_provided_thousands:task_conversation[T.gsm8k_86]      -5.2577     84.064     -0.063      0.950    -170.020     159.505\n",
      "length_provided_thousands:task_conversation[T.gsm8k_87]    -109.8440    183.611     -0.598      0.550    -469.716     250.028\n",
      "length_provided_thousands:task_conversation[T.gsm8k_88]     153.3173     96.179      1.594      0.111     -35.189     341.824\n",
      "length_provided_thousands:task_conversation[T.gsm8k_89]      41.6412     83.109      0.501      0.616    -121.250     204.533\n",
      "length_provided_thousands:task_conversation[T.gsm8k_9]       -2.2578     40.005     -0.056      0.955     -80.667      76.151\n",
      "length_provided_thousands:task_conversation[T.gsm8k_90]     -71.3265    115.109     -0.620      0.535    -296.936     154.283\n",
      "length_provided_thousands:task_conversation[T.gsm8k_91]      18.6672     81.578      0.229      0.819    -141.223     178.558\n",
      "length_provided_thousands:task_conversation[T.gsm8k_92]       1.2226    101.769      0.012      0.990    -198.240     200.685\n",
      "length_provided_thousands:task_conversation[T.gsm8k_93]       5.4808     92.467      0.059      0.953    -175.751     186.713\n",
      "length_provided_thousands:task_conversation[T.gsm8k_94]      76.7138     88.254      0.869      0.385     -96.261     249.689\n",
      "length_provided_thousands:task_conversation[T.gsm8k_95]      18.2565     75.752      0.241      0.810    -130.215     166.728\n",
      "length_provided_thousands:task_conversation[T.gsm8k_96]     -25.1933     77.940     -0.323      0.747    -177.953     127.567\n",
      "length_provided_thousands:task_conversation[T.gsm8k_97]       4.9317    112.150      0.044      0.965    -214.878     224.741\n",
      "length_provided_thousands:task_conversation[T.gsm8k_98]      45.3306     86.926      0.521      0.602    -125.042     215.703\n",
      "length_provided_thousands:task_conversation[T.gsm8k_99]      18.0263     84.307      0.214      0.831    -147.213     183.265\n",
      "length_provided_thousands:model[T.td3]                       -2.2618      2.095     -1.080      0.280      -6.367       1.843\n",
      "conversation_length_thousands                                 0.7098      0.346      2.049      0.040       0.031       1.389\n",
      "length_provided_thousands:conversation_length_thousands      -5.3034      2.851     -1.860      0.063     -10.890       0.284\n",
      "consolidated_num_steps_ideas                                  0.0406      0.020      2.076      0.038       0.002       0.079\n",
      "length_provided_thousands:consolidated_num_steps_ideas        0.0053      0.176      0.030      0.976      -0.339       0.350\n",
      "conversation_length_thousands_2                              -0.5127      0.327     -1.566      0.117      -1.154       0.129\n",
      "length_provided_thousands:conversation_length_thousands_2     1.7863      2.191      0.815      0.415      -2.508       6.080\n",
      "consolidated_num_steps_ideas_2                               -0.0018      0.002     -1.188      0.235      -0.005       0.001\n",
      "length_provided_thousands:consolidated_num_steps_ideas_2     -0.0013      0.012     -0.107      0.915      -0.024       0.022\n",
      "length_provided_thousands_2                                 -23.3104    446.285     -0.052      0.958    -898.012     851.391\n",
      "==============================================================================\n",
      "Omnibus:                       31.544   Durbin-Watson:                   1.563\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               25.231\n",
      "Skew:                          -0.227   Prob(JB):                     3.32e-06\n",
      "Kurtosis:                       2.585   Cond. No.                     2.98e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The smallest eigenvalue is 5.82e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_gsm8k_provided_interaction = smf.ols('correct ~ length_provided_thousands * conversation_length_thousands + length_provided_thousands * consolidated_num_steps_ideas + length_provided_thousands * conversation_length_thousands_2 + length_provided_thousands * consolidated_num_steps_ideas_2 + length_provided_thousands * task_conversation + length_provided_thousands * model + length_provided_thousands_2', data=gsm8k_data).fit(cov_type='cluster', cov_kwds={'groups': gsm8k_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(lpm_with_clustering_gsm8k_provided_interaction.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add model interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566818\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   No. Observations:                 1600\n",
      "Model:                          Logit   Df Residuals:                     1590\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 05 Dec 2023   Pseudo R-squ.:                  0.1637\n",
      "Time:                        00:08:56   Log-Likelihood:                -906.91\n",
      "converged:                       True   LL-Null:                       -1084.4\n",
      "Covariance Type:                  HC3   LLR p-value:                 5.343e-71\n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        1.9500      0.341      5.724      0.000       1.282       2.618\n",
      "model[T.td3]                                    -2.3559      0.412     -5.719      0.000      -3.163      -1.548\n",
      "conversation_length_thousands                   -1.0197      1.230     -0.829      0.407      -3.431       1.391\n",
      "conversation_length_thousands:model[T.td3]      -2.0950      2.085     -1.005      0.315      -6.182       1.992\n",
      "consolidated_num_steps_ideas                     0.1627      0.053      3.072      0.002       0.059       0.267\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0170      0.073      0.232      0.816      -0.126       0.160\n",
      "conversation_length_thousands_2                 -1.1919      0.941     -1.266      0.205      -3.037       0.653\n",
      "conversation_length_thousands_2:model[T.td3]     5.6188      2.295      2.448      0.014       1.121      10.117\n",
      "consolidated_num_steps_ideas_2                  -0.0097      0.003     -3.015      0.003      -0.016      -0.003\n",
      "consolidated_num_steps_ideas_2:model[T.td3]   5.437e-05      0.005      0.010      0.992      -0.010       0.010\n",
      "================================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                correct\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "================================================================================================================\n",
      "                                                  dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                                    -0.4533      0.076     -5.944      0.000      -0.603      -0.304\n",
      "conversation_length_thousands                   -0.1962      0.236     -0.830      0.407      -0.659       0.267\n",
      "conversation_length_thousands:model[T.td3]      -0.4031      0.401     -1.006      0.315      -1.189       0.383\n",
      "consolidated_num_steps_ideas                     0.0313      0.010      3.081      0.002       0.011       0.051\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0033      0.014      0.232      0.816      -0.024       0.031\n",
      "conversation_length_thousands_2                 -0.2293      0.181     -1.266      0.205      -0.584       0.126\n",
      "conversation_length_thousands_2:model[T.td3]     1.0810      0.439      2.463      0.014       0.221       1.941\n",
      "consolidated_num_steps_ideas_2                  -0.0019      0.001     -3.023      0.003      -0.003      -0.001\n",
      "consolidated_num_steps_ideas_2:model[T.td3]   1.046e-05      0.001      0.010      0.992      -0.002       0.002\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_gsm8k_model_interaction = smf.logit('correct ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model', data=gsm8k_data).fit(cov_type='HC3')\n",
    "\n",
    "# Display the summary\n",
    "print(logit_no_clustering_gsm8k_model_interaction.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_gsm8k_marginal_effects_model_interaction = logit_no_clustering_gsm8k_model_interaction.get_margeff(at='overall')\n",
    "print(logit_no_clustering_gsm8k_marginal_effects_model_interaction.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                correct   R-squared:                       0.361\n",
      "Model:                            OLS   Adj. R-squared:                  0.314\n",
      "Method:                 Least Squares   F-statistic:                     28.54\n",
      "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          1.64e-210\n",
      "Time:                        00:08:56   Log-Likelihood:                -778.49\n",
      "No. Observations:                1600   AIC:                             1775.\n",
      "Df Residuals:                    1491   BIC:                             2361.\n",
      "Df Model:                         108                                         \n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        1.0557      0.087     12.136      0.000       0.885       1.226\n",
      "model[T.td3]                                    -0.4686      0.059     -7.894      0.000      -0.585      -0.352\n",
      "task_conversation[T.gsm8k_10]                   -0.3934      0.112     -3.526      0.000      -0.612      -0.175\n",
      "task_conversation[T.gsm8k_100]                  -0.2421      0.164     -1.472      0.141      -0.564       0.080\n",
      "task_conversation[T.gsm8k_11]                   -0.1281      0.140     -0.912      0.362      -0.403       0.147\n",
      "task_conversation[T.gsm8k_12]                   -0.1671      0.137     -1.224      0.221      -0.435       0.100\n",
      "task_conversation[T.gsm8k_13]                   -0.9012      0.087    -10.363      0.000      -1.072      -0.731\n",
      "task_conversation[T.gsm8k_14]                   -0.6837      0.111     -6.183      0.000      -0.900      -0.467\n",
      "task_conversation[T.gsm8k_15]                   -0.0450      0.139     -0.323      0.747      -0.318       0.228\n",
      "task_conversation[T.gsm8k_16]                   -0.1433      0.116     -1.235      0.217      -0.371       0.084\n",
      "task_conversation[T.gsm8k_17]                    0.1388      0.102      1.360      0.174      -0.061       0.339\n",
      "task_conversation[T.gsm8k_18]                   -0.2498      0.153     -1.631      0.103      -0.550       0.050\n",
      "task_conversation[T.gsm8k_19]                   -0.1340      0.151     -0.890      0.374      -0.429       0.161\n",
      "task_conversation[T.gsm8k_2]                     0.1287      0.103      1.250      0.211      -0.073       0.331\n",
      "task_conversation[T.gsm8k_20]                   -0.3782      0.093     -4.051      0.000      -0.561      -0.195\n",
      "task_conversation[T.gsm8k_21]                   -0.4838      0.128     -3.766      0.000      -0.736      -0.232\n",
      "task_conversation[T.gsm8k_22]                   -0.3156      0.122     -2.583      0.010      -0.555      -0.076\n",
      "task_conversation[T.gsm8k_23]                   -0.1211      0.111     -1.095      0.274      -0.338       0.096\n",
      "task_conversation[T.gsm8k_24]                    0.0118      0.117      0.101      0.920      -0.217       0.241\n",
      "task_conversation[T.gsm8k_25]                   -0.1728      0.145     -1.193      0.233      -0.457       0.111\n",
      "task_conversation[T.gsm8k_26]                   -0.3046      0.135     -2.253      0.024      -0.570      -0.040\n",
      "task_conversation[T.gsm8k_27]                   -0.2557      0.145     -1.762      0.078      -0.540       0.029\n",
      "task_conversation[T.gsm8k_28]                   -0.0679      0.104     -0.654      0.513      -0.271       0.135\n",
      "task_conversation[T.gsm8k_29]                   -0.0134      0.126     -0.106      0.915      -0.261       0.234\n",
      "task_conversation[T.gsm8k_3]                    -0.6020      0.122     -4.946      0.000      -0.841      -0.363\n",
      "task_conversation[T.gsm8k_30]                   -0.2849      0.127     -2.245      0.025      -0.534      -0.036\n",
      "task_conversation[T.gsm8k_31]                   -0.4019      0.120     -3.337      0.001      -0.638      -0.166\n",
      "task_conversation[T.gsm8k_32]                   -0.2978      0.097     -3.054      0.002      -0.489      -0.107\n",
      "task_conversation[T.gsm8k_33]                   -0.0672      0.132     -0.509      0.611      -0.326       0.192\n",
      "task_conversation[T.gsm8k_34]                   -0.3256      0.081     -3.997      0.000      -0.485      -0.166\n",
      "task_conversation[T.gsm8k_35]                   -0.2005      0.162     -1.234      0.217      -0.519       0.118\n",
      "task_conversation[T.gsm8k_36]                   -0.3157      0.144     -2.185      0.029      -0.599      -0.033\n",
      "task_conversation[T.gsm8k_37]                   -0.2036      0.139     -1.469      0.142      -0.475       0.068\n",
      "task_conversation[T.gsm8k_38]                   -0.7202      0.096     -7.470      0.000      -0.909      -0.531\n",
      "task_conversation[T.gsm8k_39]                   -0.3729      0.083     -4.472      0.000      -0.536      -0.209\n",
      "task_conversation[T.gsm8k_4]                     0.0601      0.112      0.538      0.590      -0.159       0.279\n",
      "task_conversation[T.gsm8k_40]                   -0.3682      0.120     -3.079      0.002      -0.603      -0.134\n",
      "task_conversation[T.gsm8k_41]                    0.0117      0.119      0.098      0.922      -0.222       0.246\n",
      "task_conversation[T.gsm8k_42]                   -0.3476      0.128     -2.721      0.007      -0.598      -0.097\n",
      "task_conversation[T.gsm8k_43]                   -0.0500      0.116     -0.430      0.667      -0.278       0.178\n",
      "task_conversation[T.gsm8k_44]                   -0.5125      0.110     -4.657      0.000      -0.728      -0.297\n",
      "task_conversation[T.gsm8k_45]                   -0.1747      0.152     -1.146      0.252      -0.473       0.124\n",
      "task_conversation[T.gsm8k_46]                   -0.3185      0.128     -2.484      0.013      -0.570      -0.067\n",
      "task_conversation[T.gsm8k_47]                   -0.3715      0.106     -3.489      0.000      -0.580      -0.163\n",
      "task_conversation[T.gsm8k_48]                   -0.2721      0.142     -1.918      0.055      -0.550       0.006\n",
      "task_conversation[T.gsm8k_49]                    0.1804      0.082      2.188      0.029       0.019       0.342\n",
      "task_conversation[T.gsm8k_5]                    -0.2396      0.133     -1.801      0.072      -0.500       0.021\n",
      "task_conversation[T.gsm8k_50]                   -0.0067      0.117     -0.057      0.954      -0.236       0.223\n",
      "task_conversation[T.gsm8k_51]                   -0.2734      0.155     -1.759      0.079      -0.578       0.031\n",
      "task_conversation[T.gsm8k_52]                   -0.1755      0.138     -1.270      0.204      -0.446       0.095\n",
      "task_conversation[T.gsm8k_53]                   -0.2262      0.120     -1.883      0.060      -0.462       0.009\n",
      "task_conversation[T.gsm8k_54]                   -0.1744      0.153     -1.143      0.253      -0.474       0.125\n",
      "task_conversation[T.gsm8k_55]                   -0.2504      0.159     -1.572      0.116      -0.563       0.062\n",
      "task_conversation[T.gsm8k_56]                   -0.0051      0.112     -0.046      0.963      -0.224       0.214\n",
      "task_conversation[T.gsm8k_57]                   -0.0851      0.114     -0.744      0.457      -0.309       0.139\n",
      "task_conversation[T.gsm8k_58]                   -0.1291      0.118     -1.091      0.275      -0.361       0.103\n",
      "task_conversation[T.gsm8k_59]                   -0.2034      0.150     -1.354      0.176      -0.498       0.091\n",
      "task_conversation[T.gsm8k_6]                    -0.4355      0.127     -3.416      0.001      -0.685      -0.186\n",
      "task_conversation[T.gsm8k_60]                   -0.0669      0.116     -0.576      0.565      -0.294       0.161\n",
      "task_conversation[T.gsm8k_61]                   -0.3203      0.171     -1.873      0.061      -0.656       0.015\n",
      "task_conversation[T.gsm8k_62]                   -0.1072      0.115     -0.929      0.353      -0.333       0.119\n",
      "task_conversation[T.gsm8k_63]                   -0.5807      0.132     -4.410      0.000      -0.839      -0.323\n",
      "task_conversation[T.gsm8k_64]                   -0.3458      0.136     -2.539      0.011      -0.613      -0.079\n",
      "task_conversation[T.gsm8k_65]                   -0.1202      0.122     -0.987      0.324      -0.359       0.119\n",
      "task_conversation[T.gsm8k_66]                   -0.3084      0.151     -2.048      0.041      -0.603      -0.013\n",
      "task_conversation[T.gsm8k_67]                   -0.3115      0.141     -2.203      0.028      -0.589      -0.034\n",
      "task_conversation[T.gsm8k_68]                   -0.2486      0.161     -1.548      0.122      -0.563       0.066\n",
      "task_conversation[T.gsm8k_69]                   -0.2551      0.153     -1.669      0.095      -0.555       0.044\n",
      "task_conversation[T.gsm8k_7]                    -0.1987      0.142     -1.401      0.161      -0.477       0.079\n",
      "task_conversation[T.gsm8k_70]                   -0.1086      0.115     -0.946      0.344      -0.334       0.116\n",
      "task_conversation[T.gsm8k_71]                   -0.3968      0.125     -3.182      0.001      -0.641      -0.152\n",
      "task_conversation[T.gsm8k_72]                   -0.0062      0.118     -0.053      0.958      -0.237       0.225\n",
      "task_conversation[T.gsm8k_73]                   -0.2811      0.159     -1.766      0.077      -0.593       0.031\n",
      "task_conversation[T.gsm8k_74]                   -0.3552      0.169     -2.103      0.036      -0.686      -0.024\n",
      "task_conversation[T.gsm8k_75]                   -0.2408      0.158     -1.524      0.127      -0.550       0.069\n",
      "task_conversation[T.gsm8k_76]                   -0.5289      0.113     -4.665      0.000      -0.751      -0.307\n",
      "task_conversation[T.gsm8k_77]                   -0.3095      0.136     -2.270      0.023      -0.577      -0.042\n",
      "task_conversation[T.gsm8k_78]                   -0.1870      0.179     -1.046      0.296      -0.538       0.164\n",
      "task_conversation[T.gsm8k_79]                   -0.2669      0.149     -1.790      0.074      -0.559       0.025\n",
      "task_conversation[T.gsm8k_8]                    -0.5220      0.119     -4.399      0.000      -0.755      -0.289\n",
      "task_conversation[T.gsm8k_80]                    0.1426      0.084      1.705      0.088      -0.021       0.307\n",
      "task_conversation[T.gsm8k_81]                   -0.4966      0.116     -4.267      0.000      -0.725      -0.268\n",
      "task_conversation[T.gsm8k_82]                   -0.1127      0.149     -0.759      0.448      -0.404       0.178\n",
      "task_conversation[T.gsm8k_83]                   -0.2496      0.156     -1.598      0.110      -0.556       0.057\n",
      "task_conversation[T.gsm8k_84]                    0.1853      0.082      2.267      0.023       0.025       0.346\n",
      "task_conversation[T.gsm8k_85]                   -0.4691      0.153     -3.073      0.002      -0.768      -0.170\n",
      "task_conversation[T.gsm8k_86]                   -0.1338      0.143     -0.933      0.351      -0.415       0.147\n",
      "task_conversation[T.gsm8k_87]                   -0.1268      0.143     -0.888      0.375      -0.407       0.153\n",
      "task_conversation[T.gsm8k_88]                   -0.6643      0.111     -5.963      0.000      -0.883      -0.446\n",
      "task_conversation[T.gsm8k_89]                   -0.2025      0.111     -1.819      0.069      -0.421       0.016\n",
      "task_conversation[T.gsm8k_9]                    -0.5718      0.120     -4.748      0.000      -0.808      -0.336\n",
      "task_conversation[T.gsm8k_90]                    0.0404      0.113      0.358      0.720      -0.181       0.261\n",
      "task_conversation[T.gsm8k_91]                   -0.1645      0.145     -1.134      0.257      -0.449       0.120\n",
      "task_conversation[T.gsm8k_92]                   -0.2393      0.156     -1.537      0.124      -0.545       0.066\n",
      "task_conversation[T.gsm8k_93]                   -0.3720      0.153     -2.429      0.015      -0.672      -0.072\n",
      "task_conversation[T.gsm8k_94]                   -0.4143      0.129     -3.202      0.001      -0.668      -0.161\n",
      "task_conversation[T.gsm8k_95]                   -0.3249      0.116     -2.801      0.005      -0.552      -0.098\n",
      "task_conversation[T.gsm8k_96]                   -0.0906      0.158     -0.573      0.567      -0.401       0.219\n",
      "task_conversation[T.gsm8k_97]                   -0.1551      0.143     -1.087      0.277      -0.435       0.124\n",
      "task_conversation[T.gsm8k_98]                   -0.2546      0.131     -1.936      0.053      -0.512       0.003\n",
      "task_conversation[T.gsm8k_99]                   -0.2995      0.152     -1.968      0.049      -0.598      -0.001\n",
      "conversation_length_thousands                   -0.0765      0.146     -0.525      0.599      -0.362       0.209\n",
      "conversation_length_thousands:model[T.td3]      -0.4493      0.365     -1.232      0.218      -1.164       0.265\n",
      "consolidated_num_steps_ideas                     0.0426      0.007      5.925      0.000       0.028       0.057\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0094      0.012      0.793      0.428      -0.014       0.033\n",
      "conversation_length_thousands_2                 -0.2277      0.104     -2.185      0.029      -0.432      -0.023\n",
      "conversation_length_thousands_2:model[T.td3]     1.0920      0.439      2.488      0.013       0.232       1.952\n",
      "consolidated_num_steps_ideas_2                  -0.0022      0.000     -5.018      0.000      -0.003      -0.001\n",
      "consolidated_num_steps_ideas_2:model[T.td3]     -0.0004      0.001     -0.436      0.663      -0.002       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      104.284   Durbin-Watson:                   1.624\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.429\n",
      "Skew:                          -0.118   Prob(JB):                     1.66e-09\n",
      "Kurtosis:                       2.258   Cond. No.                     5.86e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 5.86e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_gsm8k_model_interaction = smf.ols('correct ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + task_conversation', data=gsm8k_data).fit(cov_type='cluster', cov_kwds={'groups': gsm8k_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(lpm_with_clustering_gsm8k_model_interaction.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     avg_inter_paragraph_cosine_sim   R-squared:                       0.438\n",
      "Model:                                        OLS   Adj. R-squared:                  0.391\n",
      "Method:                             Least Squares   F-statistic:                     20.59\n",
      "Date:                            Tue, 05 Dec 2023   Prob (F-statistic):          4.44e-168\n",
      "Time:                                    00:08:56   Log-Likelihood:                 941.60\n",
      "No. Observations:                            1434   AIC:                            -1657.\n",
      "Df Residuals:                                1321   BIC:                            -1062.\n",
      "Df Model:                                     112                                         \n",
      "Covariance Type:                          cluster                                         \n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                        0.6990      0.198      3.524      0.000       0.310       1.088\n",
      "model[T.td3]                                     0.0251      0.438      0.057      0.954      -0.834       0.884\n",
      "task_conversation[T.cw_10]                       0.0887      0.055      1.607      0.108      -0.020       0.197\n",
      "task_conversation[T.cw_100]                      0.0868      0.052      1.667      0.095      -0.015       0.189\n",
      "task_conversation[T.cw_11]                       0.2906      0.040      7.327      0.000       0.213       0.368\n",
      "task_conversation[T.cw_12]                       0.1688      0.056      3.015      0.003       0.059       0.279\n",
      "task_conversation[T.cw_13]                       0.1233      0.048      2.577      0.010       0.030       0.217\n",
      "task_conversation[T.cw_14]                       0.1522      0.047      3.236      0.001       0.060       0.244\n",
      "task_conversation[T.cw_15]                       0.0881      0.048      1.848      0.065      -0.005       0.182\n",
      "task_conversation[T.cw_16]                       0.1064      0.038      2.774      0.006       0.031       0.182\n",
      "task_conversation[T.cw_17]                       0.0819      0.048      1.696      0.090      -0.013       0.176\n",
      "task_conversation[T.cw_18]                       0.0948      0.068      1.402      0.161      -0.038       0.227\n",
      "task_conversation[T.cw_19]                       0.1489      0.047      3.136      0.002       0.056       0.242\n",
      "task_conversation[T.cw_2]                        0.1505      0.059      2.567      0.010       0.036       0.265\n",
      "task_conversation[T.cw_20]                       0.0618      0.045      1.383      0.167      -0.026       0.149\n",
      "task_conversation[T.cw_21]                       0.2833      0.036      7.790      0.000       0.212       0.355\n",
      "task_conversation[T.cw_22]                       0.2300      0.059      3.889      0.000       0.114       0.346\n",
      "task_conversation[T.cw_23]                       0.2761      0.039      7.168      0.000       0.201       0.352\n",
      "task_conversation[T.cw_24]                       0.2129      0.050      4.263      0.000       0.115       0.311\n",
      "task_conversation[T.cw_25]                      -0.0236      0.048     -0.496      0.620      -0.117       0.070\n",
      "task_conversation[T.cw_26]                       0.2654      0.044      6.083      0.000       0.180       0.351\n",
      "task_conversation[T.cw_27]                       0.0542      0.041      1.320      0.187      -0.026       0.135\n",
      "task_conversation[T.cw_28]                       0.1951      0.043      4.519      0.000       0.110       0.280\n",
      "task_conversation[T.cw_29]                       0.2745      0.043      6.351      0.000       0.190       0.359\n",
      "task_conversation[T.cw_3]                        0.1374      0.039      3.526      0.000       0.061       0.214\n",
      "task_conversation[T.cw_30]                       0.1051      0.059      1.768      0.077      -0.011       0.222\n",
      "task_conversation[T.cw_31]                       0.0609      0.042      1.456      0.145      -0.021       0.143\n",
      "task_conversation[T.cw_32]                       0.0814      0.053      1.539      0.124      -0.022       0.185\n",
      "task_conversation[T.cw_33]                       0.2108      0.044      4.846      0.000       0.126       0.296\n",
      "task_conversation[T.cw_34]                       0.2704      0.047      5.798      0.000       0.179       0.362\n",
      "task_conversation[T.cw_35]                       0.1038      0.054      1.930      0.054      -0.002       0.209\n",
      "task_conversation[T.cw_36]                      -0.0224      0.051     -0.435      0.664      -0.123       0.078\n",
      "task_conversation[T.cw_37]                       0.0373      0.060      0.622      0.534      -0.080       0.155\n",
      "task_conversation[T.cw_38]                       0.1082      0.052      2.075      0.038       0.006       0.210\n",
      "task_conversation[T.cw_39]                      -0.0366      0.036     -1.002      0.316      -0.108       0.035\n",
      "task_conversation[T.cw_4]                        0.2676      0.039      6.844      0.000       0.191       0.344\n",
      "task_conversation[T.cw_40]                       0.1126      0.066      1.696      0.090      -0.017       0.243\n",
      "task_conversation[T.cw_41]                       0.0922      0.055      1.687      0.092      -0.015       0.199\n",
      "task_conversation[T.cw_42]                       0.0293      0.040      0.736      0.462      -0.049       0.107\n",
      "task_conversation[T.cw_43]                       0.1355      0.041      3.334      0.001       0.056       0.215\n",
      "task_conversation[T.cw_44]                       0.2307      0.040      5.840      0.000       0.153       0.308\n",
      "task_conversation[T.cw_45]                       0.3332      0.052      6.429      0.000       0.232       0.435\n",
      "task_conversation[T.cw_46]                      -0.0925      0.042     -2.213      0.027      -0.174      -0.011\n",
      "task_conversation[T.cw_47]                       0.0770      0.047      1.640      0.101      -0.015       0.169\n",
      "task_conversation[T.cw_48]                       0.0194      0.040      0.479      0.632      -0.060       0.099\n",
      "task_conversation[T.cw_49]                      -0.0299      0.047     -0.632      0.527      -0.123       0.063\n",
      "task_conversation[T.cw_5]                        0.0803      0.041      1.969      0.049       0.000       0.160\n",
      "task_conversation[T.cw_50]                       0.1600      0.052      3.081      0.002       0.058       0.262\n",
      "task_conversation[T.cw_51]                       0.2229      0.040      5.629      0.000       0.145       0.301\n",
      "task_conversation[T.cw_52]                      -0.0025      0.047     -0.053      0.958      -0.095       0.090\n",
      "task_conversation[T.cw_53]                       0.2962      0.039      7.580      0.000       0.220       0.373\n",
      "task_conversation[T.cw_54]                       0.1863      0.047      3.953      0.000       0.094       0.279\n",
      "task_conversation[T.cw_55]                       0.0964      0.053      1.824      0.068      -0.007       0.200\n",
      "task_conversation[T.cw_56]                      -0.0016      0.040     -0.039      0.969      -0.080       0.077\n",
      "task_conversation[T.cw_57]                       0.2732      0.039      7.039      0.000       0.197       0.349\n",
      "task_conversation[T.cw_58]                       0.2599      0.040      6.513      0.000       0.182       0.338\n",
      "task_conversation[T.cw_59]                       0.0982      0.051      1.911      0.056      -0.003       0.199\n",
      "task_conversation[T.cw_6]                        0.1150      0.054      2.118      0.034       0.009       0.221\n",
      "task_conversation[T.cw_60]                      -0.0579      0.043     -1.360      0.174      -0.141       0.026\n",
      "task_conversation[T.cw_61]                       0.0511      0.041      1.261      0.207      -0.028       0.131\n",
      "task_conversation[T.cw_62]                       0.1482      0.056      2.636      0.008       0.038       0.258\n",
      "task_conversation[T.cw_63]                       0.2499      0.053      4.712      0.000       0.146       0.354\n",
      "task_conversation[T.cw_64]                       0.2120      0.043      4.899      0.000       0.127       0.297\n",
      "task_conversation[T.cw_65]                       0.3100      0.039      7.930      0.000       0.233       0.387\n",
      "task_conversation[T.cw_66]                       0.1856      0.044      4.255      0.000       0.100       0.271\n",
      "task_conversation[T.cw_67]                       0.1912      0.048      3.999      0.000       0.097       0.285\n",
      "task_conversation[T.cw_68]                       0.0182      0.055      0.331      0.741      -0.090       0.126\n",
      "task_conversation[T.cw_69]                       0.2459      0.041      6.025      0.000       0.166       0.326\n",
      "task_conversation[T.cw_7]                        0.0877      0.040      2.196      0.028       0.009       0.166\n",
      "task_conversation[T.cw_70]                      -0.0470      0.045     -1.034      0.301      -0.136       0.042\n",
      "task_conversation[T.cw_71]                       0.1280      0.079      1.612      0.107      -0.028       0.284\n",
      "task_conversation[T.cw_72]                      -0.0354      0.045     -0.792      0.429      -0.123       0.052\n",
      "task_conversation[T.cw_73]                       0.1320      0.047      2.829      0.005       0.041       0.223\n",
      "task_conversation[T.cw_74]                       0.0554      0.043      1.285      0.199      -0.029       0.140\n",
      "task_conversation[T.cw_75]                       0.2054      0.046      4.423      0.000       0.114       0.296\n",
      "task_conversation[T.cw_76]                       0.1975      0.045      4.356      0.000       0.109       0.286\n",
      "task_conversation[T.cw_77]                       0.2317      0.052      4.464      0.000       0.130       0.333\n",
      "task_conversation[T.cw_78]                       0.2612      0.043      6.035      0.000       0.176       0.346\n",
      "task_conversation[T.cw_79]                       0.2342      0.046      5.076      0.000       0.144       0.325\n",
      "task_conversation[T.cw_8]                        0.1760      0.042      4.219      0.000       0.094       0.258\n",
      "task_conversation[T.cw_80]                       0.2956      0.043      6.838      0.000       0.211       0.380\n",
      "task_conversation[T.cw_81]                       0.3754      0.039      9.565      0.000       0.298       0.452\n",
      "task_conversation[T.cw_82]                       0.0120      0.054      0.224      0.822      -0.093       0.117\n",
      "task_conversation[T.cw_83]                       0.1375      0.046      2.987      0.003       0.047       0.228\n",
      "task_conversation[T.cw_84]                       0.2054      0.036      5.655      0.000       0.134       0.277\n",
      "task_conversation[T.cw_85]                       0.2218      0.041      5.382      0.000       0.141       0.303\n",
      "task_conversation[T.cw_86]                      -0.0248      0.043     -0.581      0.561      -0.108       0.059\n",
      "task_conversation[T.cw_87]                       0.0868      0.052      1.685      0.092      -0.014       0.188\n",
      "task_conversation[T.cw_88]                       0.0938      0.052      1.789      0.074      -0.009       0.197\n",
      "task_conversation[T.cw_89]                       0.0378      0.051      0.747      0.455      -0.061       0.137\n",
      "task_conversation[T.cw_9]                        0.2633      0.040      6.643      0.000       0.186       0.341\n",
      "task_conversation[T.cw_90]                       0.0298      0.054      0.552      0.581      -0.076       0.136\n",
      "task_conversation[T.cw_91]                      -0.0758      0.062     -1.225      0.221      -0.197       0.046\n",
      "task_conversation[T.cw_92]                       0.0137      0.052      0.265      0.791      -0.088       0.115\n",
      "task_conversation[T.cw_93]                       0.0322      0.060      0.541      0.589      -0.084       0.149\n",
      "task_conversation[T.cw_94]                       0.1438      0.060      2.381      0.017       0.025       0.262\n",
      "task_conversation[T.cw_95]                      -0.0666      0.047     -1.427      0.153      -0.158       0.025\n",
      "task_conversation[T.cw_96]                       0.2003      0.046      4.314      0.000       0.109       0.291\n",
      "task_conversation[T.cw_97]                       0.0325      0.041      0.787      0.431      -0.048       0.114\n",
      "task_conversation[T.cw_98]                       0.2036      0.045      4.562      0.000       0.116       0.291\n",
      "task_conversation[T.cw_99]                       0.0964      0.044      2.171      0.030       0.009       0.183\n",
      "conversation_length_thousands                   -0.0535      0.064     -0.829      0.407      -0.180       0.073\n",
      "conversation_length_thousands:model[T.td3]       0.2775      0.123      2.248      0.025       0.036       0.519\n",
      "consolidated_num_steps_ideas                     0.0141      0.005      3.013      0.003       0.005       0.023\n",
      "consolidated_num_steps_ideas:model[T.td3]       -0.0198      0.012     -1.632      0.103      -0.044       0.004\n",
      "conversation_length_thousands_2                  0.0185      0.039      0.475      0.635      -0.058       0.095\n",
      "conversation_length_thousands_2:model[T.td3]    -0.1077      0.095     -1.137      0.256      -0.293       0.078\n",
      "consolidated_num_steps_ideas_2                  -0.0009      0.001     -1.346      0.178      -0.002       0.000\n",
      "consolidated_num_steps_ideas_2:model[T.td3]      0.0043      0.003      1.520      0.129      -0.001       0.010\n",
      "fres                                            -0.0125      0.006     -2.024      0.043      -0.025      -0.000\n",
      "fres:model[T.td3]                               -0.0026      0.012     -0.214      0.831      -0.027       0.022\n",
      "fres_2                                        9.844e-05   4.88e-05      2.019      0.044    2.86e-06       0.000\n",
      "fres_2:model[T.td3]                           1.053e-05   8.67e-05      0.121      0.903      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       14.289   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.460\n",
      "Skew:                           0.054   Prob(JB):                     2.19e-05\n",
      "Kurtosis:                       3.590   Cond. No.                     8.26e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 8.26e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "reg_with_clustering_cw_model_interaction = smf.ols(\"avg_inter_paragraph_cosine_sim ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + fres * model + fres_2 * model + task_conversation\",\n",
    "                                 data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print(reg_with_clustering_cw_model_interaction.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650621\n",
      "         Iterations 5\n",
      "logit no clustering cw compliance\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   No. Observations:                 1434\n",
      "Model:                          Logit   Df Residuals:                     1420\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Tue, 05 Dec 2023   Pseudo R-squ.:                 0.05831\n",
      "Time:                        00:08:56   Log-Likelihood:                -932.99\n",
      "converged:                       True   LL-Null:                       -990.76\n",
      "Covariance Type:                  HC3   LLR p-value:                 1.531e-18\n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                       -8.3356      4.010     -2.078      0.038     -16.196      -0.475\n",
      "model[T.td3]                                    -1.0071      7.080     -0.142      0.887     -14.884      12.870\n",
      "conversation_length_thousands                   -0.5153      1.114     -0.462      0.644      -2.699       1.669\n",
      "conversation_length_thousands:model[T.td3]      -0.7232      2.033     -0.356      0.722      -4.709       3.262\n",
      "consolidated_num_steps_ideas                    -0.0387      0.096     -0.401      0.688      -0.228       0.150\n",
      "consolidated_num_steps_ideas:model[T.td3]       -0.0981      0.180     -0.544      0.587      -0.452       0.256\n",
      "conversation_length_thousands_2                  0.0157      0.666      0.024      0.981      -1.290       1.321\n",
      "conversation_length_thousands_2:model[T.td3]    -0.3089      1.587     -0.195      0.846      -3.419       2.802\n",
      "consolidated_num_steps_ideas_2                   0.0135      0.015      0.874      0.382      -0.017       0.044\n",
      "consolidated_num_steps_ideas_2:model[T.td3]      0.0075      0.039      0.195      0.845      -0.068       0.083\n",
      "fres                                             0.2431      0.126      1.932      0.053      -0.004       0.490\n",
      "fres:model[T.td3]                               -0.0012      0.203     -0.006      0.995      -0.400       0.397\n",
      "fres_2                                          -0.0016      0.001     -1.646      0.100      -0.004       0.000\n",
      "fres_2:model[T.td3]                              0.0002      0.001      0.104      0.917      -0.003       0.003\n",
      "================================================================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:             compliance\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "================================================================================================================\n",
      "                                                  dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "model[T.td3]                                    -0.2314      1.627     -0.142      0.887      -3.419       2.957\n",
      "conversation_length_thousands                   -0.1184      0.256     -0.463      0.644      -0.620       0.383\n",
      "conversation_length_thousands:model[T.td3]      -0.1661      0.467     -0.356      0.722      -1.082       0.749\n",
      "consolidated_num_steps_ideas                    -0.0089      0.022     -0.401      0.688      -0.052       0.035\n",
      "consolidated_num_steps_ideas:model[T.td3]       -0.0225      0.041     -0.544      0.587      -0.104       0.059\n",
      "conversation_length_thousands_2                  0.0036      0.153      0.024      0.981      -0.296       0.303\n",
      "conversation_length_thousands_2:model[T.td3]    -0.0710      0.365     -0.195      0.846      -0.785       0.644\n",
      "consolidated_num_steps_ideas_2                   0.0031      0.004      0.875      0.381      -0.004       0.010\n",
      "consolidated_num_steps_ideas_2:model[T.td3]      0.0017      0.009      0.195      0.845      -0.016       0.019\n",
      "fres                                             0.0559      0.029      1.941      0.052      -0.001       0.112\n",
      "fres:model[T.td3]                               -0.0003      0.047     -0.006      0.995      -0.092       0.091\n",
      "fres_2                                          -0.0004      0.000     -1.652      0.099      -0.001    6.94e-05\n",
      "fres_2:model[T.td3]                           3.507e-05      0.000      0.104      0.917      -0.001       0.001\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logit_no_clustering_cw_compliance_model_interaction = smf.logit('compliance ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + fres * model + fres_2 * model', data=cw_data).fit(cov_type='HC3')\n",
    "\n",
    "print('logit no clustering cw compliance')\n",
    "# Display the summary\n",
    "print(logit_no_clustering_cw_compliance_model_interaction.summary())\n",
    "\n",
    "# Marginal effects\n",
    "logit_no_clustering_cw_compliance_marginal_effects_model_interaction = logit_no_clustering_cw_compliance_model_interaction.get_margeff(at='overall')\n",
    "print(logit_no_clustering_cw_compliance_marginal_effects_model_interaction.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpm with clustering cw compliance\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             compliance   R-squared:                       0.321\n",
      "Model:                            OLS   Adj. R-squared:                  0.204\n",
      "Method:                 Least Squares   F-statistic:                     67.99\n",
      "Date:                Tue, 05 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        00:08:56   Log-Likelihood:                -759.90\n",
      "No. Observations:                1434   AIC:                             1944.\n",
      "Df Residuals:                    1222   BIC:                             3061.\n",
      "Df Model:                         211                                         \n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================================================\n",
      "                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                       -1.6098      0.874     -1.842      0.066      -3.323       0.103\n",
      "model[T.td3]                                     0.3499      1.628      0.215      0.830      -2.841       3.541\n",
      "task_conversation[T.cw_10]                      -0.1557      0.240     -0.648      0.517      -0.627       0.315\n",
      "task_conversation[T.cw_100]                      0.4184      0.266      1.575      0.115      -0.102       0.939\n",
      "task_conversation[T.cw_11]                       0.1550      0.285      0.544      0.586      -0.403       0.713\n",
      "task_conversation[T.cw_12]                      -0.1466      0.249     -0.588      0.557      -0.635       0.342\n",
      "task_conversation[T.cw_13]                       0.3582      0.271      1.320      0.187      -0.174       0.890\n",
      "task_conversation[T.cw_14]                       0.5081      0.258      1.970      0.049       0.003       1.014\n",
      "task_conversation[T.cw_15]                       0.2963      0.281      1.056      0.291      -0.254       0.846\n",
      "task_conversation[T.cw_16]                       0.2396      0.270      0.889      0.374      -0.289       0.768\n",
      "task_conversation[T.cw_17]                       0.6541      0.200      3.277      0.001       0.263       1.045\n",
      "task_conversation[T.cw_18]                       0.2032      0.264      0.771      0.441      -0.314       0.720\n",
      "task_conversation[T.cw_19]                       0.3205      0.271      1.182      0.237      -0.211       0.852\n",
      "task_conversation[T.cw_2]                        0.3253      0.273      1.193      0.233      -0.209       0.860\n",
      "task_conversation[T.cw_20]                       0.4145      0.287      1.443      0.149      -0.149       0.978\n",
      "task_conversation[T.cw_21]                       0.5857      0.232      2.523      0.012       0.131       1.041\n",
      "task_conversation[T.cw_22]                       0.7159      0.198      3.614      0.000       0.328       1.104\n",
      "task_conversation[T.cw_23]                       0.4459      0.278      1.602      0.109      -0.100       0.991\n",
      "task_conversation[T.cw_24]                       0.2786      0.282      0.987      0.324      -0.275       0.832\n",
      "task_conversation[T.cw_25]                       0.5738      0.244      2.348      0.019       0.095       1.053\n",
      "task_conversation[T.cw_26]                       0.7443      0.200      3.724      0.000       0.353       1.136\n",
      "task_conversation[T.cw_27]                       0.2562      0.278      0.920      0.357      -0.289       0.802\n",
      "task_conversation[T.cw_28]                       0.2203      0.276      0.799      0.425      -0.320       0.761\n",
      "task_conversation[T.cw_29]                      -0.2931      0.197     -1.484      0.138      -0.680       0.094\n",
      "task_conversation[T.cw_3]                        0.5111      0.248      2.060      0.039       0.025       0.997\n",
      "task_conversation[T.cw_30]                       0.5903      0.220      2.684      0.007       0.159       1.021\n",
      "task_conversation[T.cw_31]                       0.2004      0.284      0.705      0.481      -0.357       0.758\n",
      "task_conversation[T.cw_32]                       0.7036      0.198      3.553      0.000       0.315       1.092\n",
      "task_conversation[T.cw_33]                      -0.0791      0.258     -0.307      0.759      -0.584       0.426\n",
      "task_conversation[T.cw_34]                       0.6186      0.248      2.497      0.013       0.133       1.104\n",
      "task_conversation[T.cw_35]                       0.3169      0.292      1.087      0.277      -0.254       0.888\n",
      "task_conversation[T.cw_36]                       0.3683      0.271      1.361      0.173      -0.162       0.898\n",
      "task_conversation[T.cw_37]                       0.4152      0.270      1.540      0.124      -0.113       0.944\n",
      "task_conversation[T.cw_38]                       0.4799      0.266      1.803      0.071      -0.042       1.002\n",
      "task_conversation[T.cw_39]                       0.5101      0.263      1.937      0.053      -0.006       1.026\n",
      "task_conversation[T.cw_4]                        0.4846      0.254      1.908      0.056      -0.013       0.982\n",
      "task_conversation[T.cw_40]                       0.1007      0.268      0.375      0.708      -0.426       0.627\n",
      "task_conversation[T.cw_41]                       0.1231      0.270      0.457      0.648      -0.405       0.651\n",
      "task_conversation[T.cw_42]                       0.1832      0.288      0.636      0.525      -0.381       0.747\n",
      "task_conversation[T.cw_43]                       0.4217      0.260      1.625      0.104      -0.087       0.930\n",
      "task_conversation[T.cw_44]                      -0.1899      0.240     -0.792      0.428      -0.660       0.280\n",
      "task_conversation[T.cw_45]                      -0.0257      0.257     -0.100      0.920      -0.529       0.478\n",
      "task_conversation[T.cw_46]                       0.0977      0.268      0.365      0.715      -0.428       0.623\n",
      "task_conversation[T.cw_47]                      -0.2290      0.203     -1.129      0.259      -0.627       0.169\n",
      "task_conversation[T.cw_48]                       0.2321      0.287      0.808      0.419      -0.331       0.795\n",
      "task_conversation[T.cw_49]                       0.2097      0.289      0.725      0.469      -0.358       0.777\n",
      "task_conversation[T.cw_5]                        0.5393      0.256      2.111      0.035       0.038       1.040\n",
      "task_conversation[T.cw_50]                      -0.1206      0.209     -0.577      0.564      -0.530       0.289\n",
      "task_conversation[T.cw_51]                       0.5681      0.232      2.446      0.014       0.113       1.023\n",
      "task_conversation[T.cw_52]                      -0.0026      0.257     -0.010      0.992      -0.506       0.501\n",
      "task_conversation[T.cw_53]                       0.5204      0.267      1.950      0.051      -0.003       1.043\n",
      "task_conversation[T.cw_54]                       0.1304      0.273      0.478      0.633      -0.405       0.665\n",
      "task_conversation[T.cw_55]                       0.3144      0.268      1.173      0.241      -0.211       0.840\n",
      "task_conversation[T.cw_56]                       0.5908      0.228      2.594      0.009       0.144       1.037\n",
      "task_conversation[T.cw_57]                      -0.1418      0.239     -0.594      0.553      -0.610       0.326\n",
      "task_conversation[T.cw_58]                       0.4097      0.266      1.538      0.124      -0.112       0.932\n",
      "task_conversation[T.cw_59]                       0.6126      0.239      2.558      0.011       0.143       1.082\n",
      "task_conversation[T.cw_6]                       -0.1844      0.204     -0.902      0.367      -0.585       0.216\n",
      "task_conversation[T.cw_60]                      -0.1537      0.208     -0.739      0.460      -0.562       0.254\n",
      "task_conversation[T.cw_61]                       0.2760      0.280      0.987      0.324      -0.272       0.824\n",
      "task_conversation[T.cw_62]                       0.1182      0.268      0.441      0.659      -0.407       0.643\n",
      "task_conversation[T.cw_63]                       0.1402      0.264      0.530      0.596      -0.378       0.658\n",
      "task_conversation[T.cw_64]                       0.3097      0.283      1.096      0.273      -0.244       0.864\n",
      "task_conversation[T.cw_65]                       0.5588      0.238      2.347      0.019       0.092       1.025\n",
      "task_conversation[T.cw_66]                      -0.1587      0.231     -0.686      0.493      -0.612       0.295\n",
      "task_conversation[T.cw_67]                       0.6009      0.245      2.451      0.014       0.120       1.082\n",
      "task_conversation[T.cw_68]                       0.2843      0.280      1.014      0.310      -0.265       0.834\n",
      "task_conversation[T.cw_69]                       0.0055      0.268      0.021      0.984      -0.519       0.530\n",
      "task_conversation[T.cw_7]                       -0.0499      0.233     -0.215      0.830      -0.506       0.406\n",
      "task_conversation[T.cw_70]                       0.6157      0.237      2.595      0.009       0.151       1.081\n",
      "task_conversation[T.cw_71]                       0.2586      0.270      0.958      0.338      -0.270       0.788\n",
      "task_conversation[T.cw_72]                       0.5919      0.246      2.407      0.016       0.110       1.074\n",
      "task_conversation[T.cw_73]                      -0.0422      0.258     -0.164      0.870      -0.548       0.464\n",
      "task_conversation[T.cw_74]                       0.4842      0.275      1.759      0.079      -0.055       1.024\n",
      "task_conversation[T.cw_75]                       0.1451      0.281      0.517      0.605      -0.405       0.695\n",
      "task_conversation[T.cw_76]                      -0.2458      0.200     -1.226      0.220      -0.639       0.147\n",
      "task_conversation[T.cw_77]                       0.7561      0.202      3.742      0.000       0.360       1.152\n",
      "task_conversation[T.cw_78]                       0.4161      0.263      1.584      0.113      -0.099       0.931\n",
      "task_conversation[T.cw_79]                       0.1437      0.270      0.531      0.595      -0.386       0.674\n",
      "task_conversation[T.cw_8]                        0.6429      0.236      2.722      0.006       0.180       1.106\n",
      "task_conversation[T.cw_80]                       0.0125      0.276      0.045      0.964      -0.529       0.554\n",
      "task_conversation[T.cw_81]                       0.8552      0.210      4.063      0.000       0.443       1.268\n",
      "task_conversation[T.cw_82]                      -0.1147      0.247     -0.463      0.643      -0.600       0.370\n",
      "task_conversation[T.cw_83]                       0.2532      0.279      0.908      0.364      -0.293       0.799\n",
      "task_conversation[T.cw_84]                      -0.1462      0.242     -0.604      0.546      -0.621       0.328\n",
      "task_conversation[T.cw_85]                       0.3297      0.269      1.224      0.221      -0.198       0.858\n",
      "task_conversation[T.cw_86]                       0.4767      0.244      1.954      0.051      -0.002       0.955\n",
      "task_conversation[T.cw_87]                       0.5994      0.238      2.518      0.012       0.133       1.066\n",
      "task_conversation[T.cw_88]                      -0.1409      0.240     -0.588      0.557      -0.611       0.329\n",
      "task_conversation[T.cw_89]                       0.2632      0.284      0.927      0.354      -0.293       0.819\n",
      "task_conversation[T.cw_9]                        0.4962      0.244      2.035      0.042       0.018       0.974\n",
      "task_conversation[T.cw_90]                       0.1985      0.285      0.697      0.486      -0.360       0.757\n",
      "task_conversation[T.cw_91]                       0.3266      0.283      1.154      0.248      -0.228       0.881\n",
      "task_conversation[T.cw_92]                       0.4127      0.256      1.610      0.107      -0.090       0.915\n",
      "task_conversation[T.cw_93]                       0.2996      0.292      1.028      0.304      -0.272       0.871\n",
      "task_conversation[T.cw_94]                       0.1362      0.276      0.494      0.621      -0.404       0.677\n",
      "task_conversation[T.cw_95]                       0.7192      0.199      3.623      0.000       0.330       1.108\n",
      "task_conversation[T.cw_96]                       0.3478      0.279      1.246      0.213      -0.199       0.895\n",
      "task_conversation[T.cw_97]                       0.5500      0.251      2.196      0.028       0.059       1.041\n",
      "task_conversation[T.cw_98]                       0.3845      0.262      1.466      0.143      -0.130       0.899\n",
      "task_conversation[T.cw_99]                      -0.1146      0.236     -0.485      0.628      -0.578       0.349\n",
      "task_conversation[T.cw_10]:model[T.td3]          0.2161      0.347      0.623      0.533      -0.463       0.896\n",
      "task_conversation[T.cw_100]:model[T.td3]        -0.7591      0.306     -2.485      0.013      -1.358      -0.160\n",
      "task_conversation[T.cw_11]:model[T.td3]         -0.3908      0.292     -1.340      0.180      -0.962       0.181\n",
      "task_conversation[T.cw_12]:model[T.td3]         -0.2726      0.236     -1.156      0.248      -0.735       0.189\n",
      "task_conversation[T.cw_13]:model[T.td3]         -0.5249      0.225     -2.329      0.020      -0.967      -0.083\n",
      "task_conversation[T.cw_14]:model[T.td3]         -0.5501      0.380     -1.446      0.148      -1.296       0.195\n",
      "task_conversation[T.cw_15]:model[T.td3]         -0.6386      0.282     -2.266      0.023      -1.191      -0.086\n",
      "task_conversation[T.cw_16]:model[T.td3]         -0.7438      0.288     -2.581      0.010      -1.309      -0.179\n",
      "task_conversation[T.cw_17]:model[T.td3]         -1.0122      0.233     -4.338      0.000      -1.470      -0.555\n",
      "task_conversation[T.cw_18]:model[T.td3]         -0.0964      0.332     -0.291      0.771      -0.746       0.554\n",
      "task_conversation[T.cw_19]:model[T.td3]         -0.1312      0.224     -0.585      0.558      -0.570       0.308\n",
      "task_conversation[T.cw_2]:model[T.td3]          -0.8798      0.233     -3.768      0.000      -1.337      -0.422\n",
      "task_conversation[T.cw_20]:model[T.td3]         -0.5021      0.308     -1.629      0.103      -1.106       0.102\n",
      "task_conversation[T.cw_21]:model[T.td3]         -0.7764      0.254     -3.061      0.002      -1.274      -0.279\n",
      "task_conversation[T.cw_22]:model[T.td3]         -0.9380      0.249     -3.769      0.000      -1.426      -0.450\n",
      "task_conversation[T.cw_23]:model[T.td3]         -0.6454      0.295     -2.190      0.029      -1.223      -0.068\n",
      "task_conversation[T.cw_24]:model[T.td3]         -0.4433      0.338     -1.311      0.190      -1.106       0.219\n",
      "task_conversation[T.cw_25]:model[T.td3]         -0.5617      0.244     -2.299      0.022      -1.041      -0.083\n",
      "task_conversation[T.cw_26]:model[T.td3]         -1.2285      0.183     -6.721      0.000      -1.587      -0.870\n",
      "task_conversation[T.cw_27]:model[T.td3]         -0.3573      0.334     -1.070      0.285      -1.012       0.297\n",
      "task_conversation[T.cw_28]:model[T.td3]         -0.5334      0.358     -1.491      0.136      -1.235       0.168\n",
      "task_conversation[T.cw_29]:model[T.td3]         -0.2201      0.178     -1.238      0.216      -0.569       0.128\n",
      "task_conversation[T.cw_3]:model[T.td3]          -0.5830      0.267     -2.185      0.029      -1.106      -0.060\n",
      "task_conversation[T.cw_30]:model[T.td3]         -0.9428      0.260     -3.622      0.000      -1.453      -0.433\n",
      "task_conversation[T.cw_31]:model[T.td3]         -0.3907      0.319     -1.225      0.220      -1.016       0.234\n",
      "task_conversation[T.cw_32]:model[T.td3]         -0.8545      0.312     -2.742      0.006      -1.465      -0.244\n",
      "task_conversation[T.cw_33]:model[T.td3]          0.1262      0.311      0.406      0.685      -0.483       0.735\n",
      "task_conversation[T.cw_34]:model[T.td3]         -0.9737      0.279     -3.486      0.000      -1.521      -0.426\n",
      "task_conversation[T.cw_35]:model[T.td3]         -0.0728      0.324     -0.225      0.822      -0.708       0.562\n",
      "task_conversation[T.cw_36]:model[T.td3]         -0.6014      0.253     -2.379      0.017      -1.097      -0.106\n",
      "task_conversation[T.cw_37]:model[T.td3]         -0.4620      0.382     -1.208      0.227      -1.211       0.287\n",
      "task_conversation[T.cw_38]:model[T.td3]         -0.8170      0.289     -2.824      0.005      -1.384      -0.250\n",
      "task_conversation[T.cw_39]:model[T.td3]         -0.7536      0.235     -3.213      0.001      -1.213      -0.294\n",
      "task_conversation[T.cw_4]:model[T.td3]          -0.4212      0.280     -1.505      0.132      -0.970       0.127\n",
      "task_conversation[T.cw_40]:model[T.td3]         -0.4040      0.282     -1.433      0.152      -0.956       0.148\n",
      "task_conversation[T.cw_41]:model[T.td3]         -0.0898      0.325     -0.277      0.782      -0.726       0.547\n",
      "task_conversation[T.cw_42]:model[T.td3]          0.0312      0.409      0.076      0.939      -0.770       0.832\n",
      "task_conversation[T.cw_43]:model[T.td3]         -0.4244      0.281     -1.508      0.132      -0.976       0.127\n",
      "task_conversation[T.cw_44]:model[T.td3]          0.1936      0.292      0.663      0.507      -0.379       0.766\n",
      "task_conversation[T.cw_45]:model[T.td3]         -0.1562      0.307     -0.510      0.610      -0.757       0.445\n",
      "task_conversation[T.cw_46]:model[T.td3]          0.2429      0.250      0.972      0.331      -0.247       0.733\n",
      "task_conversation[T.cw_47]:model[T.td3]          0.0804      0.254      0.317      0.751      -0.417       0.578\n",
      "task_conversation[T.cw_48]:model[T.td3]         -0.1962      0.329     -0.597      0.551      -0.840       0.448\n",
      "task_conversation[T.cw_49]:model[T.td3]         -0.3378      0.384     -0.879      0.379      -1.091       0.415\n",
      "task_conversation[T.cw_5]:model[T.td3]          -0.5582      0.327     -1.708      0.088      -1.199       0.082\n",
      "task_conversation[T.cw_50]:model[T.td3]         -0.3153      0.189     -1.670      0.095      -0.685       0.055\n",
      "task_conversation[T.cw_51]:model[T.td3]         -0.6756      0.268     -2.517      0.012      -1.202      -0.150\n",
      "task_conversation[T.cw_52]:model[T.td3]          0.0732      0.332      0.220      0.826      -0.578       0.724\n",
      "task_conversation[T.cw_53]:model[T.td3]         -0.5786      0.253     -2.291      0.022      -1.074      -0.084\n",
      "task_conversation[T.cw_54]:model[T.td3]         -0.0756      0.237     -0.320      0.749      -0.539       0.388\n",
      "task_conversation[T.cw_55]:model[T.td3]         -0.4905      0.372     -1.317      0.188      -1.220       0.239\n",
      "task_conversation[T.cw_56]:model[T.td3]         -0.4491      0.221     -2.028      0.043      -0.883      -0.015\n",
      "task_conversation[T.cw_57]:model[T.td3]         -0.3066      0.220     -1.391      0.164      -0.739       0.125\n",
      "task_conversation[T.cw_58]:model[T.td3]         -0.4665      0.339     -1.374      0.169      -1.132       0.199\n",
      "task_conversation[T.cw_59]:model[T.td3]         -0.8521      0.252     -3.378      0.001      -1.346      -0.358\n",
      "task_conversation[T.cw_6]:model[T.td3]          -0.2152      0.186     -1.157      0.247      -0.580       0.149\n",
      "task_conversation[T.cw_60]:model[T.td3]         -0.2864      0.189     -1.515      0.130      -0.657       0.084\n",
      "task_conversation[T.cw_61]:model[T.td3]         -0.5313      0.317     -1.675      0.094      -1.153       0.090\n",
      "task_conversation[T.cw_62]:model[T.td3]         -0.0565      0.258     -0.219      0.826      -0.561       0.448\n",
      "task_conversation[T.cw_63]:model[T.td3]         -0.4190      0.267     -1.572      0.116      -0.942       0.104\n",
      "task_conversation[T.cw_64]:model[T.td3]         -0.0389      0.254     -0.153      0.878      -0.537       0.459\n",
      "task_conversation[T.cw_65]:model[T.td3]         -0.6240      0.235     -2.659      0.008      -1.084      -0.164\n",
      "task_conversation[T.cw_66]:model[T.td3]          0.1326      0.308      0.430      0.667      -0.471       0.736\n",
      "task_conversation[T.cw_67]:model[T.td3]         -0.4492      0.227     -1.981      0.048      -0.894      -0.005\n",
      "task_conversation[T.cw_68]:model[T.td3]         -0.2133      0.323     -0.661      0.509      -0.846       0.420\n",
      "task_conversation[T.cw_69]:model[T.td3]         -0.3238      0.327     -0.990      0.322      -0.965       0.318\n",
      "task_conversation[T.cw_7]:model[T.td3]          -0.0467      0.318     -0.147      0.883      -0.670       0.577\n",
      "task_conversation[T.cw_70]:model[T.td3]         -0.7573      0.312     -2.429      0.015      -1.368      -0.146\n",
      "task_conversation[T.cw_71]:model[T.td3]         -0.2789      0.278     -1.003      0.316      -0.824       0.266\n",
      "task_conversation[T.cw_72]:model[T.td3]         -0.6431      0.331     -1.945      0.052      -1.291       0.005\n",
      "task_conversation[T.cw_73]:model[T.td3]         -0.3507      0.295     -1.189      0.234      -0.929       0.227\n",
      "task_conversation[T.cw_74]:model[T.td3]         -0.5844      0.284     -2.061      0.039      -1.140      -0.029\n",
      "task_conversation[T.cw_75]:model[T.td3]         -0.1765      0.397     -0.445      0.657      -0.955       0.601\n",
      "task_conversation[T.cw_76]:model[T.td3]         -0.0288      0.292     -0.098      0.922      -0.602       0.544\n",
      "task_conversation[T.cw_77]:model[T.td3]         -1.0793      0.231     -4.678      0.000      -1.531      -0.627\n",
      "task_conversation[T.cw_78]:model[T.td3]         -0.6679      0.249     -2.685      0.007      -1.156      -0.180\n",
      "task_conversation[T.cw_79]:model[T.td3]          0.0582      0.248      0.234      0.815      -0.428       0.545\n",
      "task_conversation[T.cw_8]:model[T.td3]          -0.5890      0.253     -2.331      0.020      -1.084      -0.094\n",
      "task_conversation[T.cw_80]:model[T.td3]          0.2817      0.290      0.972      0.331      -0.287       0.850\n",
      "task_conversation[T.cw_81]:model[T.td3]         -0.4956      0.216     -2.294      0.022      -0.919      -0.072\n",
      "task_conversation[T.cw_82]:model[T.td3]          0.2148      0.240      0.896      0.370      -0.255       0.685\n",
      "task_conversation[T.cw_83]:model[T.td3]         -0.3673      0.284     -1.292      0.196      -0.924       0.190\n",
      "task_conversation[T.cw_84]:model[T.td3]          0.0515      0.311      0.165      0.869      -0.559       0.661\n",
      "task_conversation[T.cw_85]:model[T.td3]         -0.8549      0.237     -3.614      0.000      -1.319      -0.391\n",
      "task_conversation[T.cw_86]:model[T.td3]         -0.4562      0.377     -1.209      0.227      -1.196       0.283\n",
      "task_conversation[T.cw_87]:model[T.td3]         -0.7951      0.250     -3.176      0.001      -1.286      -0.304\n",
      "task_conversation[T.cw_88]:model[T.td3]          0.0646      0.299      0.216      0.829      -0.521       0.650\n",
      "task_conversation[T.cw_89]:model[T.td3]         -0.2602      0.281     -0.927      0.354      -0.810       0.290\n",
      "task_conversation[T.cw_9]:model[T.td3]          -0.6862      0.318     -2.156      0.031      -1.310      -0.062\n",
      "task_conversation[T.cw_90]:model[T.td3]         -0.2268      0.320     -0.710      0.478      -0.853       0.400\n",
      "task_conversation[T.cw_91]:model[T.td3]         -0.1718      0.230     -0.746      0.456      -0.623       0.280\n",
      "task_conversation[T.cw_92]:model[T.td3]         -0.3780      0.313     -1.207      0.227      -0.992       0.236\n",
      "task_conversation[T.cw_93]:model[T.td3]         -0.2309      0.322     -0.717      0.473      -0.862       0.400\n",
      "task_conversation[T.cw_94]:model[T.td3]         -0.3221      0.383     -0.842      0.400      -1.072       0.428\n",
      "task_conversation[T.cw_95]:model[T.td3]         -0.8653      0.264     -3.272      0.001      -1.384      -0.347\n",
      "task_conversation[T.cw_96]:model[T.td3]          0.1274      0.271      0.471      0.638      -0.403       0.658\n",
      "task_conversation[T.cw_97]:model[T.td3]         -0.8772      0.229     -3.823      0.000      -1.327      -0.427\n",
      "task_conversation[T.cw_98]:model[T.td3]         -0.2992      0.278     -1.076      0.282      -0.844       0.246\n",
      "task_conversation[T.cw_99]:model[T.td3]          0.0785      0.253      0.310      0.757      -0.418       0.575\n",
      "conversation_length_thousands                   -0.0579      0.248     -0.233      0.815      -0.544       0.428\n",
      "conversation_length_thousands:model[T.td3]      -0.2764      0.424     -0.651      0.515      -1.108       0.555\n",
      "consolidated_num_steps_ideas                    -0.0234      0.020     -1.190      0.234      -0.062       0.015\n",
      "consolidated_num_steps_ideas:model[T.td3]        0.0029      0.042      0.069      0.945      -0.079       0.085\n",
      "conversation_length_thousands_2                 -0.0119      0.149     -0.080      0.936      -0.304       0.280\n",
      "conversation_length_thousands_2:model[T.td3]     0.0104      0.321      0.033      0.974      -0.619       0.640\n",
      "consolidated_num_steps_ideas_2                   0.0059      0.003      2.096      0.036       0.000       0.011\n",
      "consolidated_num_steps_ideas_2:model[T.td3]     -0.0051      0.009     -0.546      0.585      -0.024       0.013\n",
      "fres                                             0.0527      0.026      2.031      0.042       0.002       0.104\n",
      "fres:model[T.td3]                               -0.0035      0.046     -0.076      0.940      -0.094       0.087\n",
      "fres_2                                          -0.0004      0.000     -1.733      0.083      -0.001    4.59e-05\n",
      "fres_2:model[T.td3]                           4.859e-05      0.000      0.148      0.883      -0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      180.161   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               48.067\n",
      "Skew:                           0.062   Prob(JB):                     3.65e-11\n",
      "Kurtosis:                       2.112   Cond. No.                     1.38e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "[2] The condition number is large, 1.38e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the OLS model with clustered standard errors\n",
    "lpm_with_clustering_cw_compliance_model_interaction = smf.ols('compliance ~ conversation_length_thousands * model + consolidated_num_steps_ideas * model + conversation_length_thousands_2 * model + consolidated_num_steps_ideas_2 * model + fres * model + fres_2 * model + task_conversation * model', data=cw_data).fit(cov_type='cluster', cov_kwds={'groups': cw_data['task_conversation_method']})\n",
    "\n",
    "# Print the model summary\n",
    "print('lpm with clustering cw compliance')\n",
    "print(lpm_with_clustering_cw_compliance_model_interaction.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
