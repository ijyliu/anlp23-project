{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning GPT-3.5 - CW Coherence.ipynb\n",
        "\n",
        "Sources: https://blog.futuresmart.ai/fine-tuning-gpt-35-a-step-by-step-guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"bank_support_train.csv\")\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She6a_yOnVsI"
      },
      "source": [
        "### Format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9ZLRixKjVMZ",
        "outputId": "5e60c152-4196-4f76-8268-2f81d13d4eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': 'Can you explain the monthly maintenance fee on my account?'},\n",
              " {'role': 'assistant',\n",
              "  'content': '{\"Top Category\": \"Fees and Charges\", \"Sub Category\": \"Understanding Fees\"}'}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_to_gpt35_format(dataset):\n",
        "    fine_tuning_data = []\n",
        "    for _, row in dataset.iterrows():\n",
        "        json_response = '{\"Top Category\": \"' + row['Top Category'] + '\", \"Sub Category\": \"' + row['Sub Category'] + '\"}'\n",
        "        fine_tuning_data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": row['Support Query']},\n",
        "                {\"role\": \"assistant\", \"content\": json_response}\n",
        "            ]\n",
        "        })\n",
        "    return fine_tuning_data\n",
        "\n",
        "dataset = pd.read_csv('/content/back_support_train.csv')\n",
        "converted_data = convert_to_gpt35_format(dataset)\n",
        "converted_data[0]['messages']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzOSh9ZOjh6P",
        "outputId": "0f954c17-e689-442e-9bae-7d77661f7de5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Top Category': 'Fees and Charges', 'Sub Category': 'Understanding Fees'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "json.loads(converted_data[0]['messages'][-1]['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fM5yTsndjp"
      },
      "source": [
        "Create Train and Val Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jslTVNldj5Ml"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified splitting. Assuming 'Top Category' can be used for stratification\n",
        "train_data, val_data = train_test_split(\n",
        "    converted_data,\n",
        "    test_size=0.2,\n",
        "    stratify=dataset['Top Category'],\n",
        "    random_state=42  # for reproducibility\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_sf-jBwc5Y",
        "outputId": "45578907-f3b7-438b-aad3-322afb9004e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPNfP_GnrDq"
      },
      "source": [
        "Create JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "31vTBdJiitzX"
      },
      "outputs": [],
      "source": [
        "def write_to_jsonl(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for entry in data:\n",
        "            json.dump(entry, file)\n",
        "            file.write('\\n')\n",
        "\n",
        "\n",
        "training_file_name = \"train.jsonl\"\n",
        "validation_file_name = \"val.jsonl\"\n",
        "\n",
        "write_to_jsonl(train_data, training_file_name)\n",
        "write_to_jsonl(val_data, validation_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get and set API key\n",
        "with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "    my_api_key = file.read()\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=my_api_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHIVr7BAnyjC"
      },
      "source": [
        "Upload Training and Validation File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpCsg8I2ZxLK",
        "outputId": "9ce65740-674b-446b-9829-b9c04c6097c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-lH871kh5kCsKUV31vYjbxe7C\n",
            "Validation file id: file-jg2GAagSKpGN7mgicEiKdayI\n"
          ]
        }
      ],
      "source": [
        "training_file = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(\"Training file id:\", training_file.id)\n",
        "print(\"Validation file id:\", validation_file.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCwIEinan2il"
      },
      "source": [
        "Create Finetuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17X6KNaaIRJ",
        "outputId": "a66d283d-03f7-4ae3-f322-bd449042dfbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-dyySU8thbv5LBSdq1KrXZiki', created_at=1699779814, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-GopHvIe9DrH2zt9iInyLCoD8', result_files=[], status='validating_files', trained_tokens=None, training_file='file-lH871kh5kCsKUV31vYjbxe7C', validation_file='file-jg2GAagSKpGN7mgicEiKdayI')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "suffix_name = \"yt_tutorial\"\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    validation_file=validation_file.id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljw1wDrCn5gK"
      },
      "source": [
        "### All Finetuning  Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfDOr6apak7C",
        "outputId": "b88aed95-a9de-4863-fa59-b84c43ca81b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-dyySU8thbv5LBSdq1KrXZiki', created_at=1699779814, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-GopHvIe9DrH2zt9iInyLCoD8', result_files=[], status='running', trained_tokens=None, training_file='file-lH871kh5kCsKUV31vYjbxe7C', validation_file='file-jg2GAagSKpGN7mgicEiKdayI'), FineTuningJob(id='ftjob-h5P9gmmDXysjbOD99jz8TtYv', created_at=1699776576, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:futuresmart-ai:yt:8Jzz2CMc', finished_at=1699777187, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-GopHvIe9DrH2zt9iInyLCoD8', result_files=['file-94bTw4zTuPmEg5cDx8UbIg7S'], status='succeeded', trained_tokens=9123, training_file='file-xWkwYEZgnD9boGLZAR6ebpYO', validation_file='file-R4ZUTOca4nq1l3yzEhDIkbXR'), FineTuningJob(id='ftjob-iV3UJthlZrnTgGcXV2mRDD6g', created_at=1698443996, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:futuresmart-ai:belongai-test:8EPMULl2', finished_at=1698444773, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-GopHvIe9DrH2zt9iInyLCoD8', result_files=['file-3mzvwARFsJNiExT7zS1xtr0h'], status='succeeded', trained_tokens=21795, training_file='file-KPgqn6XJ2sCMxmuVPlqyq5de', validation_file=None), FineTuningJob(id='ftjob-JE5N4YBHKH5Pjq5FovyJf0h2', created_at=1698352493, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:futuresmart-ai:belongai-test:8E1YRjSV', finished_at=1698353258, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-GopHvIe9DrH2zt9iInyLCoD8', result_files=['file-5L6mU9LrnGF4qJdk0wKxVDuI'], status='succeeded', trained_tokens=21795, training_file='file-U6oK19UWmOQB7ybBJwUZeoW2', validation_file=None)], object='list', has_more=False)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.list(limit=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQVbt40voAOx"
      },
      "source": [
        "### Retrieve Specific Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5JBvahHanUd",
        "outputId": "c7b84d09-a133-43a3-ffee-6d10bc0e557e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-h5P9gmmDXysjbOD99jz8TtYv', created_at=1699776576, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:futuresmart-ai:yt:8Jzz2CMc', finished_at=1699777187, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-GopHvIe9DrH2zt9iInyLCoD8', result_files=['file-94bTw4zTuPmEg5cDx8UbIg7S'], status='succeeded', trained_tokens=9123, training_file='file-xWkwYEZgnD9boGLZAR6ebpYO', validation_file='file-R4ZUTOca4nq1l3yzEhDIkbXR')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.retrieve(\"ftjob-h5P9gmmDXysjbOD99jz8TtYv\")\n",
        "response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRWVAjGparfK",
        "outputId": "480ccb49-fb58-4e12-b6af-4468a4cef9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fine-tuned model id: ft:gpt-3.5-turbo-0613:futuresmart-ai:yt:8Jzz2CMc\n"
          ]
        }
      ],
      "source": [
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMsES5scoNTe"
      },
      "source": [
        "### Test Finetuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zApYdC-ibTVK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def format_test(row):\n",
        "\n",
        "    formatted_message = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": row['Support Query']\n",
        "        }\n",
        "    ]\n",
        "    return formatted_message\n",
        "\n",
        "\n",
        "def predict(test_messages, fine_tuned_model_id):\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=50\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l3f2IHkWbV1D"
      },
      "outputs": [],
      "source": [
        "def store_predictions(test_df, fine_tuned_model_id):\n",
        "\n",
        "    print(\"fine_tuned_model_id\",fine_tuned_model_id)\n",
        "    test_df['Prediction'] = None\n",
        "\n",
        "    for index, row in test_df.iterrows():\n",
        "        test_message = format_test(row)\n",
        "        prediction_result = predict(test_message, fine_tuned_model_id)\n",
        "        test_df.at[index, 'Prediction'] = prediction_result\n",
        "\n",
        "    test_df.to_csv(\"predictions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mksdNQ-DbMHO",
        "outputId": "0459f600-a44e-48b7-d100-ddf581b0b240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fine_tuned_model_id ft:gpt-3.5-turbo-0613:futuresmart-ai:yt:8Jzz2CMc\n"
          ]
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"test_queries.csv\")\n",
        "store_predictions(test_df, fine_tuned_model_id)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
