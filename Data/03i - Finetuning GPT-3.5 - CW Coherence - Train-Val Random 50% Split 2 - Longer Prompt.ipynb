{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning GPT-3.5 - CW Coherence.ipynb\n",
        "\n",
        "Sources: https://blog.futuresmart.ai/fine-tuning-gpt-35-a-step-by-step-guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Whether this notebook is random 50% split 1 or random 50% split 2\n",
        "this_nb = 'random_50_LP_2'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_task_method</th>\n",
              "      <th>conversation_number</th>\n",
              "      <th>response</th>\n",
              "      <th>coherence_1_incoherent_10_very_coherent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>1</td>\n",
              "      <td>Learning to do a handstand is a fun activity f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>2</td>\n",
              "      <td>The hawk was used to hunting what he needed fo...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>3</td>\n",
              "      <td>I love the smell of roasting almonds in the ki...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>4</td>\n",
              "      <td>Ralph's bedroom was routinely filled up with s...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>td3_cw_direct_prompting_responses</td>\n",
              "      <td>5</td>\n",
              "      <td>Joe had a unique way of dealing with the hospi...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   model_task_method  conversation_number  \\\n",
              "0  td3_cw_direct_prompting_responses                    1   \n",
              "1  td3_cw_direct_prompting_responses                    2   \n",
              "2  td3_cw_direct_prompting_responses                    3   \n",
              "3  td3_cw_direct_prompting_responses                    4   \n",
              "4  td3_cw_direct_prompting_responses                    5   \n",
              "\n",
              "                                            response  \\\n",
              "0  Learning to do a handstand is a fun activity f...   \n",
              "1  The hawk was used to hunting what he needed fo...   \n",
              "2  I love the smell of roasting almonds in the ki...   \n",
              "3  Ralph's bedroom was routinely filled up with s...   \n",
              "4  Joe had a unique way of dealing with the hospi...   \n",
              "\n",
              "   coherence_1_incoherent_10_very_coherent  \n",
              "0                                        1  \n",
              "1                                        7  \n",
              "2                                        1  \n",
              "3                                       10  \n",
              "4                                        4  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "full_human_data = pd.read_csv(\"full_human_data.csv\")\n",
        "full_human_data.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[91 57 19 66 30 74 86 67 29 83  7 31 13 89 65  1 62 93 44 76 92 85 59  6\n",
            " 11 45 22  4 25 34 12 39 49 47 69 18 51 97 64 55 46 10 58 82 79  3 96 84\n",
            " 70 14]\n"
          ]
        }
      ],
      "source": [
        "# Set seed to 201\n",
        "import numpy as np\n",
        "np.random.seed(201)\n",
        "\n",
        "# Draw 50 numbers from 1 to 100\n",
        "random_50 = np.random.choice(100, 50, replace=False)\n",
        "\n",
        "print(random_50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split\n",
        "if this_nb == 'random_50_LP_1':\n",
        "    this_notebook_train_validate = full_human_data.query('conversation_number in @random_50')\n",
        "    this_notebook_predictions = full_human_data.query('conversation_number not in @random_50')\n",
        "else:\n",
        "    this_notebook_train_validate = full_human_data.query('conversation_number not in @random_50')\n",
        "    this_notebook_predictions = full_human_data.query('conversation_number in @random_50')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save this notebook's predictions\n",
        "this_notebook_predictions.to_csv('items_to_predict_using_' + this_nb + '.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The hawk was used to hunting what he needed for food, but one day he decided to try and be friends with the ground squirrels in the park. He thought it would be a good way to pass the time and to fill his empty belly. He went out of his way to make nice with the squirrels, but they ran away from him. The hawk didn't understand why the ground squirrels didn't want to be his friend.\n",
            "The hawk was confused, but he soon learned an important lesson. Just like the ground squirrels, if I don't like something, I'll stay away from it. I may not understand what other people find attractive or interesting, but it's better to keep my distance and keep my opinion to myself. The lesson the hawk learned was to respect the boundaries of those around him.\n",
            "\n",
            "Joe had a unique way of dealing with the hospital noise. Instead of relying on traditional sound volume reducers, like earplugs and noise-cancelling headphones, Joe opted for a more creative way to reduce the sound. He decided to construct a makeshift megaphone using a handful of traffic cones and found that it worked perfectly! Joe discovered that traffic cones make excellent megaphones.\n",
            "The sound volume of the hospital was drastically reduced and Joe enjoyed the peace and quiet. However, the peace didn't last long as Grandpa Joe barged in the room, throwing down the gauntlet - a challenge to a round of tug-of-war. You realize you're not alone as you sit in your bedroom massaging your calves after a long day of playing tug-of-war with Grandpa Joe in the hospital.\n",
            "\n",
            "As I sit in my bedroom massaging my calves, I am reminded of the tug-of-war match I had with my grandpa Joe earlier today at the hospital. I remember his soft wrinkled hands clasping mine, and the smile he gave me as he easily pulled me across the line. I remember how I laughed, and how his warm and comforting embrace filled me with a content feeling of happiness. You realize you're not alone as you sit in your bedroom massaging your calves after a long day of playing tug-of-war with Grandpa Joe in the hospital.\n",
            "This morning started off in quite an eventful way. After dropping a few hints to my mom about the car being low on gas, she reminded me to fill it up before heading out. Little did I know that would not be necessary; with a loud crash, my car smashed through the garage door in what seemed like no time at all. Today arrived with a crash of my car through the garage door.\n",
            "\n",
            "John had been involved in some very shady business dealings. Problems were beginning to catch up with him and it was only a matter of time before he'd be arrested. He decided to fake his disappearance to avoid jail.\n",
            "John had collected quite a few clown suits over the years. Whenever he was in the suit people suddenly took him seriously. It was comical, but it was true: he was all business when he wore the clown suit.\n",
            "\n",
            "My neighbor recently purchased a huge box of glass for his home. When I asked him what he was going to do with it, he cryptically said he was going to build something with it. My curiosity is piqued and I offer to help, but he politely declines. Now I can hardly contain my curiosity as I look through my own cupboard and see the potential of what he could build. There's probably enough glass in my cupboard to build an undersea aquarium.\n",
            "My neighbor suggested that we go to the beach to watch the sunset one evening. I showed up with a blanket and a picnic dinner, but my neighbor was nowhere to be seen. When I finally found him, he was standing, surveying the scene in front of him with a bleak expression on his face. He was disappointed when he found the beach to be so sandy and the sun so sunny.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print responses for 5 observations\n",
        "for i in range(5):\n",
        "    print(this_notebook_train_validate.iloc[i, 2])\n",
        "    print('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She6a_yOnVsI"
      },
      "source": [
        "### Format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9ZLRixKjVMZ",
        "outputId": "5e60c152-4196-4f76-8268-2f81d13d4eed"
      },
      "outputs": [],
      "source": [
        "def convert_to_gpt35_format(dataset):\n",
        "    fine_tuning_data = []\n",
        "    for _, row in dataset.iterrows():\n",
        "        json_response = '{\"Score\": \"' + str(row['coherence_1_incoherent_10_very_coherent']) + '\"}'\n",
        "        fine_tuning_data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": row['response'] + \"\\nYour Task: Rate the coherence of the passage above on a scale of 1 to 10, 1 being incoherent and 10 being very coherent. If the passage is two unconnected pieces give it a score of 1. If it has sentences that seem to be randomly inserted, has abrupt change in characters, or has abrupt change in setting, give it a low score. If it has a continuous setting or characters and seems plausible, give it a high score. If it is as coherent as you believe is possible, give it a score of 10.\"},\n",
        "                {\"role\": \"assistant\", \"content\": json_response}\n",
        "            ]\n",
        "        })\n",
        "    return fine_tuning_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': \"The hawk was used to hunting what he needed for food, but one day he decided to try and be friends with the ground squirrels in the park. He thought it would be a good way to pass the time and to fill his empty belly. He went out of his way to make nice with the squirrels, but they ran away from him. The hawk didn't understand why the ground squirrels didn't want to be his friend.\\nThe hawk was confused, but he soon learned an important lesson. Just like the ground squirrels, if I don't like something, I'll stay away from it. I may not understand what other people find attractive or interesting, but it's better to keep my distance and keep my opinion to myself. The lesson the hawk learned was to respect the boundaries of those around him.\\nYour Task: Rate the coherence of the passage above on a scale of 1 to 10, 1 being incoherent and 10 being very coherent. If the passage is two unconnected pieces give it a score of 1. If it has sentences that seem to be randomly inserted, has abrupt change in characters, or has abrupt change in setting, give it a low score. If it has a continuous setting or characters and seems plausible, give it a high score. If it is as coherent as you believe is possible, give it a score of 10.\"},\n",
              " {'role': 'assistant', 'content': '{\"Score\": \"7\"}'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert entire dataset\n",
        "dataset = this_notebook_train_validate\n",
        "converted_data = convert_to_gpt35_format(dataset)\n",
        "converted_data[0]['messages']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzOSh9ZOjh6P",
        "outputId": "0f954c17-e689-442e-9bae-7d77661f7de5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Score': '7'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "json.loads(converted_data[0]['messages'][-1]['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fM5yTsndjp"
      },
      "source": [
        "Create Train and Val Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['td3_cw_direct_prompting_responses',\n",
              "       'td3_cw_zero_shot_cot_responses',\n",
              "       'td3_cw_ape_zero_shot_cot_responses',\n",
              "       'td3_cw_least_to_most_responses',\n",
              "       'td3_cw_manual_few_shot_responses', 'td3_cw_manual_cot_responses',\n",
              "       'td3_cw_tree_of_thought_responses', 'td3_cw_self_refine_responses',\n",
              "       'gpt4_cw_direct_prompting_responses',\n",
              "       'gpt4_cw_zero_shot_cot_responses',\n",
              "       'gpt4_cw_ape_zero_shot_cot_responses',\n",
              "       'gpt4_cw_tree_of_thought_responses',\n",
              "       'gpt4_cw_self_refine_responses', 'gpt4_cw_least_to_most_responses',\n",
              "       'gpt4_cw_manual_few_shot_responses',\n",
              "       'gpt4_cw_manual_cot_responses'], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print unique values of model_task_method\n",
        "this_notebook_train_validate['model_task_method'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jslTVNldj5Ml"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified splitting on model_task_method.\n",
        "train_data, val_data = train_test_split(\n",
        "    converted_data,\n",
        "    test_size=0.2,\n",
        "    stratify=this_notebook_train_validate['model_task_method'],\n",
        "    random_state=42  # for reproducibility\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_sf-jBwc5Y",
        "outputId": "45578907-f3b7-438b-aad3-322afb9004e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "640\n",
            "160\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPNfP_GnrDq"
      },
      "source": [
        "Create JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "31vTBdJiitzX"
      },
      "outputs": [],
      "source": [
        "def write_to_jsonl(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for entry in data:\n",
        "            json.dump(entry, file)\n",
        "            file.write('\\n')\n",
        "\n",
        "\n",
        "training_file_name = \"train_\" + this_nb + \".jsonl\"\n",
        "validation_file_name = \"val_\" + this_nb + \".jsonl\"\n",
        "\n",
        "write_to_jsonl(train_data, training_file_name)\n",
        "write_to_jsonl(val_data, validation_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Get and set API key\n",
        "# with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "#     api_key = file.read()\n",
        "# openai.api_key = api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Get and set API key\n",
        "with open('C:/Users/ijyli/Documents/OpenAI/anlp23-project.txt', 'r') as file:\n",
        "    my_api_key = file.read()\n",
        "\n",
        "#from openai import OpenAI\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=my_api_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHIVr7BAnyjC"
      },
      "source": [
        "Upload Training and Validation File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpCsg8I2ZxLK",
        "outputId": "9ce65740-674b-446b-9829-b9c04c6097c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-Q7sVj7gAhOajH3a8ImA2WtK4\n",
            "Validation file id: file-NN6qP50pZLQUnHVD8tA7KWqq\n"
          ]
        }
      ],
      "source": [
        "training_file = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(\"Training file id:\", training_file.id)\n",
        "print(\"Validation file id:\", validation_file.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCwIEinan2il"
      },
      "source": [
        "Create Finetuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17X6KNaaIRJ",
        "outputId": "a66d283d-03f7-4ae3-f322-bd449042dfbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-nqlGEuKrF6lcCsfoPEDlJDKo', created_at=1701290431, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-MdSScMkbTK60fqqIP4cio0Kx', result_files=[], status='validating_files', trained_tokens=None, training_file='file-Q7sVj7gAhOajH3a8ImA2WtK4', validation_file='file-NN6qP50pZLQUnHVD8tA7KWqq')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "suffix_name = this_nb\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    validation_file=validation_file.id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "response\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
