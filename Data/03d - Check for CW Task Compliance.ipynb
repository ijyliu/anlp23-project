{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for CW Task Compliance.ipynb\n",
    "\n",
    "Check for an exact match to the prompted sentences.\n",
    "\n",
    "Search all responses - odd conversation indices.\n",
    "\n",
    "First sentence plus \"\\n\" at the end.\n",
    "\n",
    "Second sentence plus end of response/end of trimmed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Grading_Functions import *\n",
    "from Evaluation_Functions import *\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Load conversations\n",
    "with open('Conversation_Lists.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "mtm_list = [mtm for mtm in loaded_data.keys()]\n",
    "conversations_list = [conversation for conversation in loaded_data.values()]\n",
    "\n",
    "print(len(mtm_list))\n",
    "print(len(conversations_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over elements of dictionary loaded_data\n",
    "# Load the list at that element\n",
    "# Each element in that list is a list (conversation)\n",
    "# Save fill lists to store model_task_method and the conversation number\n",
    "model_task_methods = []\n",
    "conversation_numbers = []\n",
    "flat_conversations = []\n",
    "for model_task_method, conversations in zip(mtm_list, conversations_list):\n",
    "    for i, conversation in enumerate(conversations):\n",
    "        model_task_methods.append(model_task_method)\n",
    "        conversation_numbers.append(i+1)\n",
    "        # Convert all conversation elements to strings\n",
    "        all_string_conversation = [str(element) for element in conversation]\n",
    "        flat_conversations.append(all_string_conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Q: Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\\nA:\", \"She makes $6 every day at the farmers' market.\"]\n"
     ]
    }
   ],
   "source": [
    "print(conversations_list[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in text file data_100_random_text.txt\n",
    "with open('Creative Writing/data_100_random_text.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Get lines\n",
    "lines = data.split('\\n')\n",
    "\n",
    "# Split each line on periods\n",
    "sentences = [line.split('.') for line in lines]\n",
    "\n",
    "# Keep first two sentences\n",
    "first_two = [sentence[0:2] for sentence in sentences]\n",
    "\n",
    "# Strip leading and trailing blanks and add periods back\n",
    "first_two_clean = [[sentence.strip() + '.' for sentence in sentence_pair] for sentence_pair in first_two]\n",
    "\n",
    "# Use unidecode to convert to ascii\n",
    "first_two_clean = [[unidecode(sentence) for sentence in sentence_pair] for sentence_pair in first_two_clean]\n",
    "\n",
    "# Append 1., 2. to the beginning of each sentence\n",
    "# numbered_sentences = []\n",
    "# for pair in first_two_clean:\n",
    "#     numbered_sentences_pair = []\n",
    "#     for index in range(len(pair)):\n",
    "#         numbered_sentences_pair.append(str(index + 1) + '. ' + pair[index])\n",
    "#     numbered_sentences.append(numbered_sentences_pair)\n",
    "    \n",
    "# print(numbered_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cw_conversations_list\n",
    "cw_model_task_methods = []\n",
    "cw_flat_conversations_no_metadata = []\n",
    "cw_conversation_numbers = []\n",
    "cw_sentences = []\n",
    "for index in range(len(flat_conversations)):\n",
    "    if 'cw' in model_task_methods[index]:\n",
    "        if 'gpt4' in model_task_methods[index]:\n",
    "            cw_model_task_methods.append(model_task_methods[index])\n",
    "            cw_flat_conversations_no_metadata.append(gpt4_cw_cleanup(flat_conversations[index]))\n",
    "            cw_conversation_numbers.append(conversation_numbers[index])\n",
    "            cw_sentences.append(first_two_clean[conversation_numbers[index]-1])\n",
    "        else:\n",
    "            cw_model_task_methods.append(model_task_methods[index])\n",
    "            cw_flat_conversations_no_metadata.append(td3_cw_cleanup(flat_conversations[index]))\n",
    "            cw_conversation_numbers.append(conversation_numbers[index])\n",
    "            cw_sentences.append(first_two_clean[conversation_numbers[index]-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Use the compliance checker\n",
    "compliance_list = []\n",
    "#for index in range(1000, 1001):\n",
    "for index in range(len(cw_flat_conversations_no_metadata)):\n",
    "    # Feed numbered sentences\n",
    "    # If self_refine or tree_of_thought is in the model_task_method, feed the third to last message\n",
    "    # Otherwise feed the last message\n",
    "    # print(cw_sentences[index][0])\n",
    "    # print(cw_sentences[index][1])\n",
    "    # print(cw_model_task_methods[index])\n",
    "    # print(cw_flat_conversations_no_metadata[index][-1])\n",
    "    # print(bool(re.search(cw_sentences[index][0], cw_flat_conversations_no_metadata[index][-1])))\n",
    "    # print(bool(re.search('\\\\n', cw_flat_conversations_no_metadata[index][-1])))\n",
    "    # print(cw_flat_conversations_no_metadata[index][-1].find(cw_sentences[index][0] + '\\\\n') > 0)\n",
    "    # print(bool(re.search(cw_sentences[index][0] + '\\\\n', cw_flat_conversations_no_metadata[index][-1])))\n",
    "    # print(bool(re.search(cw_sentences[index][1] + '$', cw_flat_conversations_no_metadata[index][-1])))\n",
    "    if 'gpt4' in cw_model_task_methods[index]:\n",
    "        if 'self_refine' in cw_model_task_methods[index] or 'tree_of_thought' in cw_model_task_methods[index]:\n",
    "            if (bool(cw_flat_conversations_no_metadata[index][-3].find(cw_sentences[index][0] + '\\\\n') > 0) or bool(cw_flat_conversations_no_metadata[index][-3].find(cw_sentences[index][0] + ' \\\\n') > 0)) and (bool(re.search(cw_sentences[index][1] + '$', cw_flat_conversations_no_metadata[index][-3])) or bool(re.search(cw_sentences[index][1] + '\\n$', cw_flat_conversations_no_metadata[index][-3]))):\n",
    "                compliance_list.append(1)\n",
    "            else:\n",
    "                compliance_list.append(0)\n",
    "            #compliance_list.append(grade_creative_writing_task_adherence(cw_sentences[index][0], cw_sentences[index][1], cw_flat_conversations[index][-3]))\n",
    "        else:\n",
    "            #compliance_list.append(grade_creative_writing_task_adherence(cw_sentences[index][0], cw_sentences[index][1], cw_flat_conversations[index][-1]))\n",
    "            if (bool(cw_flat_conversations_no_metadata[index][-1].find(cw_sentences[index][0] + '\\\\n') > 0) or bool(cw_flat_conversations_no_metadata[index][-1].find(cw_sentences[index][0] + ' \\\\n') > 0)) and (bool(re.search(cw_sentences[index][1] + '$', cw_flat_conversations_no_metadata[index][-1])) or bool(re.search(cw_sentences[index][1] + '\\n$', cw_flat_conversations_no_metadata[index][-1]))):\n",
    "                compliance_list.append(1)\n",
    "            else:\n",
    "                compliance_list.append(0)\n",
    "    else:\n",
    "        if 'self_refine' in cw_model_task_methods[index] or 'tree_of_thought' in cw_model_task_methods[index]:\n",
    "            if (bool(re.search(cw_sentences[index][0] + '\\n', cw_flat_conversations_no_metadata[index][-3])) or bool(re.search(cw_sentences[index][0] + ' \\n', cw_flat_conversations_no_metadata[index][-3]))) and bool(re.search(cw_sentences[index][1] + '$', cw_flat_conversations_no_metadata[index][-3])):\n",
    "                compliance_list.append(1)\n",
    "            else:\n",
    "                compliance_list.append(0)\n",
    "            #compliance_list.append(grade_creative_writing_task_adherence(cw_sentences[index][0], cw_sentences[index][1], cw_flat_conversations[index][-3]))\n",
    "        else:\n",
    "            #compliance_list.append(grade_creative_writing_task_adherence(cw_sentences[index][0], cw_sentences[index][1], cw_flat_conversations[index][-1]))\n",
    "            if (bool(re.search(cw_sentences[index][0] + '\\n', cw_flat_conversations_no_metadata[index][-1])) or bool(re.search(cw_sentences[index][0] + ' \\n', cw_flat_conversations_no_metadata[index][-1]))) and bool(re.search(cw_sentences[index][1] + '$', cw_flat_conversations_no_metadata[index][-1])):\n",
    "                compliance_list.append(1)\n",
    "            else:\n",
    "                compliance_list.append(0)\n",
    "        \n",
    "print(compliance_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete pre-existing file\n",
    "import os\n",
    "if os.path.exists('Creative Writing/Non-Compliant Conversations.txt'):\n",
    "    os.remove('Creative Writing/Non-Compliant Conversations.txt')\n",
    "\n",
    "# Output all non-compliant conversations to a text file\n",
    "for index in range(len(cw_flat_conversations_no_metadata)):\n",
    "    if compliance_list[index] == 0:\n",
    "        with open('Creative Writing/Non-Compliant Conversations.txt', 'a') as file:\n",
    "            if 'self_refine' in cw_model_task_methods[index] or 'tree_of_thought' in cw_model_task_methods[index]:\n",
    "                # Also condition on having cw_sentences[index][0] in the third to last message and cw_sentences[index][1] in the third to last message\n",
    "                if cw_sentences[index][0] in cw_flat_conversations_no_metadata[index][-3] and cw_sentences[index][1] in cw_flat_conversations_no_metadata[index][-3]:\n",
    "                    file.write('Conversation ' + str(cw_conversation_numbers[index]) + '\\n')\n",
    "                    file.write(cw_model_task_methods[index] + '\\n')\n",
    "                    file.write(cw_sentences[index][0] + '\\n')\n",
    "                    file.write(cw_sentences[index][1] + '\\n')\n",
    "                    file.write(cw_flat_conversations_no_metadata[index][-3] + '\\n')\n",
    "                    file.write('\\n')\n",
    "            else:\n",
    "                # Also condition on having cw_sentences[index][0] in the last message and cw_sentences[index][1] in the last message\n",
    "                if cw_sentences[index][0] in cw_flat_conversations_no_metadata[index][-1] and cw_sentences[index][1] in cw_flat_conversations_no_metadata[index][-1]:\n",
    "                    file.write('Conversation ' + str(cw_conversation_numbers[index]) + '\\n')\n",
    "                    file.write(cw_model_task_methods[index] + '\\n')\n",
    "                    file.write(cw_sentences[index][0] + '\\n')\n",
    "                    file.write(cw_sentences[index][1] + '\\n')\n",
    "                    file.write(cw_flat_conversations_no_metadata[index][-1] + '\\n')\n",
    "                    file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cw_model_task_methods, cw_conversation_numbers, compliance_list to Excel\n",
    "df = pd.DataFrame({'model_task_method': cw_model_task_methods, 'conversation_number': cw_conversation_numbers, 'compliance': compliance_list})\n",
    "df.to_excel('Creative_Writing_Compliance.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_task_method</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_manual_few_shot_responses</th>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_zero_shot_cot_responses</th>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_ape_zero_shot_cot_responses</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_direct_prompting_responses</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_least_to_most_responses</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_manual_cot_responses</th>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_direct_prompting_responses</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_self_refine_responses</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_ape_zero_shot_cot_responses</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_manual_few_shot_responses</th>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_zero_shot_cot_responses</th>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_self_refine_responses</th>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_least_to_most_responses</th>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4_cw_tree_of_thought_responses</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_manual_cot_responses</th>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td3_cw_tree_of_thought_responses</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     compliance\n",
       "model_task_method                              \n",
       "gpt4_cw_manual_few_shot_responses          0.63\n",
       "gpt4_cw_zero_shot_cot_responses            0.57\n",
       "gpt4_cw_ape_zero_shot_cot_responses        0.56\n",
       "gpt4_cw_direct_prompting_responses         0.56\n",
       "gpt4_cw_least_to_most_responses            0.52\n",
       "gpt4_cw_manual_cot_responses               0.51\n",
       "td3_cw_direct_prompting_responses          0.50\n",
       "gpt4_cw_self_refine_responses              0.48\n",
       "td3_cw_ape_zero_shot_cot_responses         0.48\n",
       "td3_cw_manual_few_shot_responses           0.45\n",
       "td3_cw_zero_shot_cot_responses             0.45\n",
       "td3_cw_self_refine_responses               0.33\n",
       "td3_cw_least_to_most_responses             0.28\n",
       "gpt4_cw_tree_of_thought_responses          0.26\n",
       "td3_cw_manual_cot_responses                0.21\n",
       "td3_cw_tree_of_thought_responses           0.05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate compliance by model_task_method - find means\n",
    "df.drop(columns = ['conversation_number']).groupby('model_task_method').mean().sort_values(by='compliance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4275"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall mean\n",
    "df['compliance'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values of compliance\n",
    "df['compliance'].isnull().sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
