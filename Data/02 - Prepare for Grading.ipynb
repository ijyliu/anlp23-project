{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare_for_Grading.ipynb\n",
    "\n",
    "Load in conversations.\n",
    "\n",
    "Output a text file with identifying information and conversation that will be easy to browse.\n",
    "\n",
    "Separately, will create Excel files with the identifying info that can be used for grading and variables that need to be filled in based on the model/task/method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load conversations\n",
    "with open('Conversation_Lists.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Get dictionary items\n",
    "# lists_dictionary = {'td3_gsm8k_direct_prompting_responses': td3_gsm8k_direct_prompting_responses,\n",
    "#                     'td3_gsm8k_zero_shot_cot_responses': td3_gsm8k_zero_shot_cot_responses,\n",
    "#                     'td3_gsm8k_ape_zero_shot_cot_responses': td3_gsm8k_ape_zero_shot_cot_responses,\n",
    "#                     'td3_gsm8k_tree_of_thought_responses': td3_gsm8k_tree_of_thought_responses,\n",
    "#                     'td3_gsm8k_self_refine_responses': td3_gsm8k_self_refine_responses,\n",
    "#                     'td3_gsm8k_least_to_most_responses': td3_gsm8k_least_to_most_responses,\n",
    "#                     'td3_gsm8k_manual_few_shot_responses': td3_gsm8k_manual_few_shot_responses,\n",
    "#                     'td3_gsm8k_manual_cot_responses': td3_gsm8k_manual_cot_responses,\n",
    "#                     'gpt4_gsm8k_direct_prompting_responses': gpt4_gsm8k_direct_prompting_responses,\n",
    "#                     'gpt4_gsm8k_zero_shot_cot_responses': gpt4_gsm8k_zero_shot_cot_responses,\n",
    "#                     'gpt4_gsm8k_ape_zero_shot_cot_responses': gpt4_gsm8k_ape_zero_shot_cot_responses,\n",
    "#                     'gpt4_gsm8k_tree_of_thought_responses': gpt4_gsm8k_tree_of_thought_responses,\n",
    "#                     'gpt4_gsm8k_self_refine_responses': gpt4_gsm8k_self_refine_responses,\n",
    "#                     'gpt4_gsm8k_least_to_most_responses': gpt4_gsm8k_least_to_most_responses,\n",
    "#                     'gpt4_gsm8k_manual_few_shot_responses': gpt4_gsm8k_manual_few_shot_responses,\n",
    "#                     'gpt4_gsm8k_manual_cot_responses': gpt4_gsm8k_manual_cot_responses,\n",
    "#                     'td3_cw_direct_prompting_responses': td3_cw_direct_prompting_responses,\n",
    "#                     'td3_cw_zero_shot_cot_responses': td3_cw_zero_shot_cot_responses,\n",
    "#                     'td3_cw_ape_zero_shot_cot_responses': td3_cw_ape_zero_shot_cot_responses,\n",
    "#                     'td3_cw_tree_of_thought_responses': td3_cw_tree_of_thought_responses,\n",
    "#                     'td3_cw_self_refine_responses': td3_cw_self_refine_responses,\n",
    "#                     'td3_cw_least_to_most_responses': td3_cw_least_to_most_responses,\n",
    "#                     'td3_cw_manual_few_shot_responses': td3_cw_manual_few_shot_responses,\n",
    "#                     'td3_cw_manual_cot_responses': td3_cw_manual_cot_responses,\n",
    "#                     'gpt4_cw_direct_prompting_responses': gpt4_cw_direct_prompting_responses,\n",
    "#                     'gpt4_cw_zero_shot_cot_responses': gpt4_cw_zero_shot_cot_responses,\n",
    "#                     'gpt4_cw_ape_zero_shot_cot_responses': gpt4_cw_ape_zero_shot_cot_responses,\n",
    "#                     'gpt4_cw_tree_of_thought_responses': gpt4_cw_tree_of_thought_responses,\n",
    "#                     'gpt4_cw_self_refine_responses': gpt4_cw_self_refine_responses,\n",
    "#                     'gpt4_cw_least_to_most_responses': gpt4_cw_least_to_most_responses,\n",
    "#                     'gpt4_cw_manual_few_shot_responses': gpt4_cw_manual_few_shot_responses,\n",
    "#                     'gpt4_cw_manual_cot_responses': gpt4_cw_manual_cot_responses}\n",
    "# td3_gsm8k_direct_prompting_responses = loaded_data['td3_gsm8k_direct_prompting_responses']\n",
    "# td3_gsm8k_zero_shot_cot_responses = loaded_data['td3_gsm8k_zero_shot_cot_responses']\n",
    "# td3_gsm8k_ape_zero_shot_cot_responses = loaded_data['td3_gsm8k_ape_zero_shot_cot_responses']\n",
    "# td3_gsm8k_tree_of_thought_responses = loaded_data['td3_gsm8k_tree_of_thought_responses']\n",
    "# td3_gsm8k_self_refine_responses = loaded_data['td3_gsm8k_self_refine_responses']\n",
    "# td3_gsm8k_least_to_most_responses = loaded_data['td3_gsm8k_least_to_most_responses']\n",
    "# td3_gsm8k_manual_few_shot_responses = loaded_data['td3_gsm8k_manual_few_shot_responses']\n",
    "# td3_gsm8k_manual_cot_responses = loaded_data['td3_gsm8k_manual_cot_responses']\n",
    "# gpt4_gsm8k_direct_prompting_responses = loaded_data['gpt4_gsm8k_direct_prompting_responses']\n",
    "# gpt4_gsm8k_zero_shot_cot_responses = loaded_data['gpt4_gsm8k_zero_shot_cot_responses']\n",
    "# gpt4_gsm8k_ape_zero_shot_cot_responses = loaded_data['gpt4_gsm8k_ape_zero_shot_cot_responses']\n",
    "# gpt4_gsm8k_tree_of_thought_responses = loaded_data['gpt4_gsm8k_tree_of_thought_responses']\n",
    "# gpt4_gsm8k_self_refine_responses = loaded_data['gpt4_gsm8k_self_refine_responses']\n",
    "# gpt4_gsm8k_least_to_most_responses = loaded_data['gpt4_gsm8k_least_to_most_responses']\n",
    "# gpt4_gsm8k_manual_few_shot_responses = loaded_data['gpt4_gsm8k_manual_few_shot_responses']\n",
    "# gpt4_gsm8k_manual_cot_responses = loaded_data['gpt4_gsm8k_manual_cot_responses']\n",
    "# td3_cw_direct_prompting_responses = loaded_data['td3_cw_direct_prompting_responses']\n",
    "# td3_cw_zero_shot_cot_responses = loaded_data['td3_cw_zero_shot_cot_responses']\n",
    "# td3_cw_ape_zero_shot_cot_responses = loaded_data['td3_cw_ape_zero_shot_cot_responses']\n",
    "# td3_cw_tree_of_thought_responses = loaded_data['td3_cw_tree_of_thought_responses']\n",
    "# td3_cw_self_refine_responses = loaded_data['td3_cw_self_refine_responses']\n",
    "# td3_cw_least_to_most_responses = loaded_data['td3_cw_least_to_most_responses']\n",
    "# td3_cw_manual_few_shot_responses = loaded_data['td3_cw_manual_few_shot_responses']\n",
    "# td3_cw_manual_cot_responses = loaded_data['td3_cw_manual_cot_responses']\n",
    "# gpt4_cw_direct_prompting_responses = loaded_data['gpt4_cw_direct_prompting_responses']\n",
    "# gpt4_cw_zero_shot_cot_responses = loaded_data['gpt4_cw_zero_shot_cot_responses']\n",
    "# gpt4_cw_ape_zero_shot_cot_responses = loaded_data['gpt4_cw_ape_zero_shot_cot_responses']\n",
    "# gpt4_cw_tree_of_thought_responses = loaded_data['gpt4_cw_tree_of_thought_responses']\n",
    "# gpt4_cw_self_refine_responses = loaded_data['gpt4_cw_self_refine_responses']\n",
    "# gpt4_cw_least_to_most_responses = loaded_data['gpt4_cw_least_to_most_responses']\n",
    "# gpt4_cw_manual_few_shot_responses = loaded_data['gpt4_cw_manual_few_shot_responses']\n",
    "# gpt4_cw_manual_cot_responses = loaded_data['gpt4_cw_manual_cot_responses']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over elements of dictionary loaded_data\n",
    "# Load the list at that element\n",
    "# Each element in that list is a list (conversation)\n",
    "# To a text file:\n",
    "# Output the name of the element of loaded_data and the index of the conversation\n",
    "# Output each element of the conversation on a new line\n",
    "# Also save fill lists to store model_task_method and the conversation number\n",
    "model_task_methods = []\n",
    "conversation_numbers = []\n",
    "with open(\"conversations_for_grading.txt\", \"w\") as file:\n",
    "    for model_task_method, conversations in loaded_data.items():\n",
    "        for i, conversation in enumerate(conversations):\n",
    "            file.write(f\"{model_task_method} - Conversation {i+1}\\n\")\n",
    "            for line in conversation:\n",
    "                file.write(line + \"\\n\")\n",
    "            file.write(\"\\n\")\n",
    "            model_task_methods.append(model_task_method)\n",
    "            conversation_numbers.append(i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For grading, create a dataframe of model_task_methods and conversation_numbers and output to Excel\n",
    "import pandas as pd\n",
    "\n",
    "grading_starter = pd.DataFrame({\"model_task_method\": model_task_methods, \"conversation_number\": conversation_numbers})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSM8K Grading\n",
    "# Accuracy (0 incorrect or 1 correct), Ease of Review (1 easy to 10 hard)\n",
    "\n",
    "# Select the model_task_method items containing gsm8k\n",
    "gsm8k_grading = grading_starter[grading_starter[\"model_task_method\"].str.contains(\"gsm8k\")]\n",
    "# Sort by model_task_method and conversation_number\n",
    "gsm8k_grading.sort_values([\"model_task_method\", \"conversation_number\"], inplace=True)\n",
    "\n",
    "# Add columns for accuracy and ease of review\n",
    "gsm8k_grading[\"correct\"] = \"\"\n",
    "gsm8k_grading[\"ease_of_review_1_easy_10_hard\"] = \"\"\n",
    "\n",
    "# Output to Excel\n",
    "gsm8k_grading.to_excel(\"gsm8k_grading.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creative Writing Grading\n",
    "# Coherence from 1 to 10 (1 being incoherent, 10 being very coherent), whether task constraints were followed (0 not followed, 1 followed), Ease of Review (1 easy to 10 hard)\n",
    "\n",
    "# Select the model_task_method items containing cw\n",
    "cw_grading = grading_starter[grading_starter[\"model_task_method\"].str.contains(\"cw\")]\n",
    "# Sort by model_task_method and conversation_number\n",
    "cw_grading.sort_values([\"model_task_method\", \"conversation_number\"], inplace=True)\n",
    "\n",
    "# Add columns for coherence, task constraints followed, and ease of review\n",
    "cw_grading[\"coherence_1_incoherent_10_very_coherent\"] = \"\"\n",
    "cw_grading[\"task_constraints_followed_0_not_followed_1_followed\"] = \"\"\n",
    "cw_grading[\"ease_of_review_1_easy_10_hard\"] = \"\"\n",
    "\n",
    "# Output to Excel\n",
    "cw_grading.to_excel(\"cw_grading.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
