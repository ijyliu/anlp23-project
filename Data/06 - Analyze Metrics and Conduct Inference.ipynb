{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Metrics and Conduct Inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Combined_Data.xlsx\n",
    "combined_data = pd.read_excel('Combined_Data.xlsx')\n",
    "\n",
    "# GSM8k data - limit to task = \"gsm8k\"\n",
    "gsm8k_data = combined_data[combined_data['task'] == 'gsm8k']\n",
    "\n",
    "# Creative writing data - limit to task = \"cw\"\n",
    "cw_data = combined_data[combined_data['task'] == 'cw']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy/Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>accuracy_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.210505</td>\n",
       "      <td>5.46 (6.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.065758</td>\n",
       "      <td>0.93 (0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>cw</td>\n",
       "      <td>5.71</td>\n",
       "      <td>7.298889</td>\n",
       "      <td>5.71 (7.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.199091</td>\n",
       "      <td>0.73 (0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>cw</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.907475</td>\n",
       "      <td>5.54 (5.91)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.95 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.33</td>\n",
       "      <td>5.193030</td>\n",
       "      <td>6.33 (5.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.065758</td>\n",
       "      <td>0.93 (0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.220101</td>\n",
       "      <td>6.11 (6.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.252424</td>\n",
       "      <td>0.49 (0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.04</td>\n",
       "      <td>7.412525</td>\n",
       "      <td>6.04 (7.41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.89 (0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5.012525</td>\n",
       "      <td>4.76 (5.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.4 (0.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.511010</td>\n",
       "      <td>6.29 (6.51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.95 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>3.9 (5.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.252424</td>\n",
       "      <td>0.49 (0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>td3</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.46</td>\n",
       "      <td>7.786263</td>\n",
       "      <td>4.46 (7.79)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>td3</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.178889</td>\n",
       "      <td>0.23 (0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.280303</td>\n",
       "      <td>4.45 (5.28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.950606</td>\n",
       "      <td>0.67 (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.889293</td>\n",
       "      <td>4.14 (4.89)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.6 (0.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.97</td>\n",
       "      <td>6.211212</td>\n",
       "      <td>4.97 (6.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.149091</td>\n",
       "      <td>0.18 (0.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>cw</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.343434</td>\n",
       "      <td>4.2 (6.34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.2 (0.16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>cw</td>\n",
       "      <td>3.37</td>\n",
       "      <td>4.114242</td>\n",
       "      <td>3.37 (4.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.178889</td>\n",
       "      <td>0.23 (0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>cw</td>\n",
       "      <td>3.86</td>\n",
       "      <td>6.404444</td>\n",
       "      <td>3.86 (6.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.237980</td>\n",
       "      <td>0.62 (0.24)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model             method   task  mean       var accuracy_quality\n",
       "0   gpt4  ape_zero_shot_cot     cw  5.46  6.210505      5.46 (6.21)\n",
       "1   gpt4  ape_zero_shot_cot  gsm8k  0.93  0.065758      0.93 (0.07)\n",
       "2   gpt4   direct_prompting     cw  5.71  7.298889       5.71 (7.3)\n",
       "3   gpt4   direct_prompting  gsm8k  0.73  0.199091       0.73 (0.2)\n",
       "4   gpt4      least_to_most     cw  5.54  5.907475      5.54 (5.91)\n",
       "5   gpt4      least_to_most  gsm8k  0.95  0.047980      0.95 (0.05)\n",
       "6   gpt4         manual_cot     cw  6.33  5.193030      6.33 (5.19)\n",
       "7   gpt4         manual_cot  gsm8k  0.93  0.065758      0.93 (0.07)\n",
       "8   gpt4    manual_few_shot     cw  6.11  6.220101      6.11 (6.22)\n",
       "9   gpt4    manual_few_shot  gsm8k  0.49  0.252424      0.49 (0.25)\n",
       "10  gpt4        self_refine     cw  6.04  7.412525      6.04 (7.41)\n",
       "11  gpt4        self_refine  gsm8k  0.89  0.098889       0.89 (0.1)\n",
       "12  gpt4    tree_of_thought     cw  4.76  5.012525      4.76 (5.01)\n",
       "13  gpt4    tree_of_thought  gsm8k  0.40  0.242424       0.4 (0.24)\n",
       "14  gpt4      zero_shot_cot     cw  6.29  6.511010      6.29 (6.51)\n",
       "15  gpt4      zero_shot_cot  gsm8k  0.95  0.047980      0.95 (0.05)\n",
       "16   td3  ape_zero_shot_cot     cw  3.90  5.363636       3.9 (5.36)\n",
       "17   td3  ape_zero_shot_cot  gsm8k  0.49  0.252424      0.49 (0.25)\n",
       "18   td3   direct_prompting     cw  4.46  7.786263      4.46 (7.79)\n",
       "19   td3   direct_prompting  gsm8k  0.23  0.178889      0.23 (0.18)\n",
       "20   td3      least_to_most     cw  4.45  5.280303      4.45 (5.28)\n",
       "21   td3      least_to_most  gsm8k  0.67  0.950606      0.67 (0.95)\n",
       "22   td3         manual_cot     cw  4.14  4.889293      4.14 (4.89)\n",
       "23   td3         manual_cot  gsm8k  0.60  0.242424       0.6 (0.24)\n",
       "24   td3    manual_few_shot     cw  4.97  6.211212      4.97 (6.21)\n",
       "25   td3    manual_few_shot  gsm8k  0.18  0.149091      0.18 (0.15)\n",
       "26   td3        self_refine     cw  4.20  6.343434       4.2 (6.34)\n",
       "27   td3        self_refine  gsm8k  0.20  0.161616       0.2 (0.16)\n",
       "28   td3    tree_of_thought     cw  3.37  4.114242      3.37 (4.11)\n",
       "29   td3    tree_of_thought  gsm8k  0.23  0.178889      0.23 (0.18)\n",
       "30   td3      zero_shot_cot     cw  3.86  6.404444       3.86 (6.4)\n",
       "31   td3      zero_shot_cot  gsm8k  0.62  0.237980      0.62 (0.24)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce table - one column for each method, one row for each model by task type\n",
    "# Average values of correct_or_incorrect and creative_writing_score\n",
    "# Also get variance\n",
    "\n",
    "# Column for combined accuracy_quality - correct_or_incorrect if task = \"gsm8k\", creative_writing_score if task = \"cw\"\n",
    "combined_data['accuracy_quality'] = combined_data.apply(lambda row: row['correct'] if row['task'] == 'gsm8k' else row['coherence_1_incoherent_10_very_coherent'], axis=1)\n",
    "\n",
    "# Average accuracy_quality by model, method, task\n",
    "# Also get variance\n",
    "avg_accuracy_quality_with_variance = combined_data[['model', 'method', 'task', 'accuracy_quality']].groupby(['model', 'method', 'task']).agg(['mean', 'var'])['accuracy_quality'].reset_index()\n",
    "\n",
    "# Combine mean and variance into one column that is a string with the mean and then the variance in parentheses\n",
    "avg_accuracy_quality_with_variance['accuracy_quality'] = avg_accuracy_quality_with_variance.apply(lambda row: str(round(row['mean'], 2)) + ' (' + str(round(row['var'], 2)) + ')', axis=1)\n",
    "\n",
    "avg_accuracy_quality_with_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(           'model',                  ''),\n",
      "            (            'task',                  ''),\n",
      "            ('accuracy_quality', 'ape_zero_shot_cot'),\n",
      "            ('accuracy_quality',  'direct_prompting'),\n",
      "            ('accuracy_quality',     'least_to_most'),\n",
      "            ('accuracy_quality',        'manual_cot'),\n",
      "            ('accuracy_quality',   'manual_few_shot'),\n",
      "            ('accuracy_quality',       'self_refine'),\n",
      "            ('accuracy_quality',   'tree_of_thought'),\n",
      "            ('accuracy_quality',     'zero_shot_cot')],\n",
      "           )\n",
      "  model   task ape_zero_shot_cot direct_prompting least_to_most   manual_cot  \\\n",
      "0  gpt4     cw       5.46 (6.21)       5.71 (7.3)   5.54 (5.91)  6.33 (5.19)   \n",
      "1   td3     cw        3.9 (5.36)      4.46 (7.79)   4.45 (5.28)  4.14 (4.89)   \n",
      "2  gpt4  gsm8k       0.93 (0.07)       0.73 (0.2)   0.95 (0.05)  0.93 (0.07)   \n",
      "3   td3  gsm8k       0.49 (0.25)      0.23 (0.18)   0.67 (0.95)   0.6 (0.24)   \n",
      "\n",
      "  manual_few_shot  self_refine tree_of_thought zero_shot_cot  \n",
      "0     6.11 (6.22)  6.04 (7.41)     4.76 (5.01)   6.29 (6.51)  \n",
      "1     4.97 (6.21)   4.2 (6.34)     3.37 (4.11)    3.86 (6.4)  \n",
      "2     0.49 (0.25)   0.89 (0.1)      0.4 (0.24)   0.95 (0.05)  \n",
      "3     0.18 (0.15)   0.2 (0.16)     0.23 (0.18)   0.62 (0.24)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_24204\\280831353.py:10: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  avg_accuracy_quality_pivot = avg_accuracy_quality_pivot.sort_values(by=['task', 'model'], ascending=[True, True]).reset_index().drop(columns=['index'])\n"
     ]
    }
   ],
   "source": [
    "# Pivot table - column method should go wide\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_with_variance.drop(columns=['mean', 'var']).set_index(['model', 'task', 'method']).unstack()\n",
    "#pivot_table(index=['model', 'task'], columns='method', values='accuracy_quality').reset_index()\n",
    "\n",
    "# Fix axis\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_pivot.rename_axis([None, None], axis=1).reset_index()\n",
    "\n",
    "# Sort rows by task - gsm8k task first, then cw\n",
    "# Sort by model - text-davinci-003 first, then gpt4\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_pivot.sort_values(by=['task', 'model'], ascending=[True, True]).reset_index().drop(columns=['index'])\n",
    "\n",
    "print(avg_accuracy_quality_pivot.columns)\n",
    "\n",
    "flattened_cols = [''.join(col).strip().replace('accuracy_quality', '') for col in avg_accuracy_quality_pivot.columns.values]\n",
    "avg_accuracy_quality_pivot.columns = flattened_cols\n",
    "\n",
    "print(avg_accuracy_quality_pivot)\n",
    "\n",
    "# Order columns: direct_prompting, zero_shot_cot, ape_zero_shot_cot, tree_of_thought, self_refine, least_to_most, manual_few_shot, manual_cot\n",
    "avg_accuracy_quality_pivot = avg_accuracy_quality_pivot[['model', 'task', 'direct_prompting', 'zero_shot_cot', 'ape_zero_shot_cot', 'tree_of_thought', 'self_refine', 'least_to_most', 'manual_few_shot', 'manual_cot']]\n",
    "\n",
    "# Output to LaTeX\n",
    "avg_accuracy_quality_pivot.to_latex('../Output/avg_accuracy_quality_pivot.tex', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>num_correct</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>num_incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>td3</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>23.0</td>\n",
       "      <td>100</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>67.0</td>\n",
       "      <td>100</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>23.0</td>\n",
       "      <td>100</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model             method   task  num_correct  num_obs  num_incorrect\n",
       "0   gpt4  ape_zero_shot_cot  gsm8k         93.0      100            7.0\n",
       "1   gpt4   direct_prompting  gsm8k         73.0      100           27.0\n",
       "2   gpt4      least_to_most  gsm8k         95.0      100            5.0\n",
       "3   gpt4         manual_cot  gsm8k         93.0      100            7.0\n",
       "4   gpt4    manual_few_shot  gsm8k         49.0      100           51.0\n",
       "5   gpt4        self_refine  gsm8k         89.0      100           11.0\n",
       "6   gpt4    tree_of_thought  gsm8k         40.0      100           60.0\n",
       "7   gpt4      zero_shot_cot  gsm8k         95.0      100            5.0\n",
       "8    td3  ape_zero_shot_cot  gsm8k         49.0      100           51.0\n",
       "9    td3   direct_prompting  gsm8k         23.0      100           77.0\n",
       "10   td3      least_to_most  gsm8k         67.0      100           33.0\n",
       "11   td3         manual_cot  gsm8k         60.0      100           40.0\n",
       "12   td3    manual_few_shot  gsm8k         18.0      100           82.0\n",
       "13   td3        self_refine  gsm8k         20.0      100           80.0\n",
       "14   td3    tree_of_thought  gsm8k         23.0      100           77.0\n",
       "15   td3      zero_shot_cot  gsm8k         62.0      100           38.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform McNemar's Test on GSM8k data\n",
    "\n",
    "# Get in terms of number of questions answered correctly: sum accuracy_quality column by model, method, task\n",
    "gsm8k_num_correct= gsm8k_data[['model', 'method', 'task', 'correct']].groupby(['model', 'method', 'task']).sum()['correct'].reset_index()\n",
    "# Rename column to num_correct\n",
    "gsm8k_num_correct = gsm8k_num_correct.rename(columns={'correct': 'num_correct'})\n",
    "\n",
    "# Make another table with counts of questions missed (number of observations minus accuracy_quality sum) by model, method, task\n",
    "gsm8k_num_obs = gsm8k_data[['model', 'method', 'task', 'correct']].groupby(['model', 'method', 'task']).count()['correct'].reset_index()\n",
    "# Rename column to num_obs\n",
    "gsm8k_num_obs = gsm8k_num_obs.rename(columns={'correct': 'num_obs'})\n",
    "# Join together by model, method, task\n",
    "gsm8k_correct_incorrect_obs = gsm8k_num_correct.merge(gsm8k_num_obs, on=['model', 'method', 'task'], how='left')\n",
    "# Table should have model, method, task, num_correct, num_incorrect, num_obs\n",
    "gsm8k_correct_incorrect_obs['num_incorrect'] = gsm8k_correct_incorrect_obs['num_obs'] - gsm8k_correct_incorrect_obs['num_correct']\n",
    "\n",
    "gsm8k_correct_incorrect_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform McNemar's test\n",
    "# Accepts argument of name of model, method, task\n",
    "\n",
    "def perform_mcnemar(model, method, task):\n",
    "\n",
    "    # Create variables for data of interest\n",
    "    # direct_prompting_correct\n",
    "    direct_prompting_correct = gsm8k_correct_incorrect_obs[(gsm8k_correct_incorrect_obs['model'] == model) & (gsm8k_correct_incorrect_obs['method'] == \"direct_prompting\") & (gsm8k_correct_incorrect_obs['task'] == task)]['num_correct'].values[0]\n",
    "    # direct_prompting_incorrect\n",
    "    direct_prompting_incorrect = gsm8k_correct_incorrect_obs[(gsm8k_correct_incorrect_obs['model'] == model) & (gsm8k_correct_incorrect_obs['method'] == \"direct_prompting\") & (gsm8k_correct_incorrect_obs['task'] == task)]['num_incorrect'].values[0]\n",
    "    # method_correct\n",
    "    method_correct = gsm8k_correct_incorrect_obs[(gsm8k_correct_incorrect_obs['model'] == model) & (gsm8k_correct_incorrect_obs['method'] == method) & (gsm8k_correct_incorrect_obs['task'] == task)]['num_correct'].values[0]\n",
    "    # method_incorrect\n",
    "    method_incorrect = gsm8k_correct_incorrect_obs[(gsm8k_correct_incorrect_obs['model'] == model) & (gsm8k_correct_incorrect_obs['method'] == method) & (gsm8k_correct_incorrect_obs['task'] == task)]['num_incorrect'].values[0]\n",
    "\n",
    "    # Create a dataset \n",
    "    # Row for direct prompting then method\n",
    "    # Column for correct then incorrect\n",
    "    data = [[direct_prompting_correct, direct_prompting_incorrect], \n",
    "            [method_correct, method_incorrect]] \n",
    "    \n",
    "    print('McNemar\\'s Test (Exact) for ' + model + ' ' + method + ' ' + task)\n",
    "    print(data)\n",
    "\n",
    "    # McNemar's Test, exact, without any continuity correction \n",
    "    print('No continuity correction')\n",
    "    print(mcnemar(data, exact=True, correction=False)) \n",
    "    ncc_result = mcnemar(data, exact=True, correction=False)\n",
    "    ncc_statistic = ncc_result.statistic\n",
    "    ncc_p_value = ncc_result.pvalue\n",
    "\n",
    "    #print(type(mcnemar(data, exact=True, correction=False)))\n",
    "    #print(str(mcnemar(data, exact=True, correction=False)[0]) + ' ' + str(mcnemar(data, exact=True, correction=False)[1]))\n",
    "    \n",
    "    # McNemar's Test with the continuity correction \n",
    "    print('With continuity correction')\n",
    "    print(mcnemar(data, exact=True, correction=True)) \n",
    "    cc_result = mcnemar(data, exact=True, correction=True)\n",
    "    cc_statistic = cc_result.statistic\n",
    "    cc_p_value = cc_result.pvalue\n",
    "\n",
    "    # Return data\n",
    "    return ncc_statistic, ncc_p_value, cc_statistic, cc_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's Test (Exact) for td3 zero_shot_cot gsm8k\n",
      "[[23.0, 77.0], [62.0, 38.0]]\n",
      "No continuity correction\n",
      "pvalue      0.23493150329059798\n",
      "statistic   62.0\n",
      "With continuity correction\n",
      "pvalue      0.23493150329059798\n",
      "statistic   62.0\n",
      "McNemar's Test (Exact) for td3 ape_zero_shot_cot gsm8k\n",
      "[[23.0, 77.0], [49.0, 51.0]]\n",
      "No continuity correction\n",
      "pvalue      0.01581820400805208\n",
      "statistic   49.0\n",
      "With continuity correction\n",
      "pvalue      0.01581820400805208\n",
      "statistic   49.0\n",
      "McNemar's Test (Exact) for td3 least_to_most gsm8k\n",
      "[[23.0, 77.0], [67.0, 33.0]]\n",
      "No continuity correction\n",
      "pvalue      0.4533716994309739\n",
      "statistic   67.0\n",
      "With continuity correction\n",
      "pvalue      0.4533716994309739\n",
      "statistic   67.0\n",
      "McNemar's Test (Exact) for td3 manual_few_shot gsm8k\n",
      "[[23.0, 77.0], [18.0, 82.0]]\n",
      "No continuity correction\n",
      "pvalue      7.252322160518573e-10\n",
      "statistic   18.0\n",
      "With continuity correction\n",
      "pvalue      7.252322160518573e-10\n",
      "statistic   18.0\n",
      "McNemar's Test (Exact) for td3 manual_cot gsm8k\n",
      "[[23.0, 77.0], [60.0, 40.0]]\n",
      "No continuity correction\n",
      "pvalue      0.17140890326024552\n",
      "statistic   60.0\n",
      "With continuity correction\n",
      "pvalue      0.17140890326024552\n",
      "statistic   60.0\n",
      "McNemar's Test (Exact) for td3 tree_of_thought gsm8k\n",
      "[[23.0, 77.0], [23.0, 77.0]]\n",
      "No continuity correction\n",
      "pvalue      5.513580775850052e-08\n",
      "statistic   23.0\n",
      "With continuity correction\n",
      "pvalue      5.513580775850052e-08\n",
      "statistic   23.0\n",
      "McNemar's Test (Exact) for td3 self_refine gsm8k\n",
      "[[23.0, 77.0], [20.0, 80.0]]\n",
      "No continuity correction\n",
      "pvalue      4.590760083258195e-09\n",
      "statistic   20.0\n",
      "With continuity correction\n",
      "pvalue      4.590760083258195e-09\n",
      "statistic   20.0\n",
      "McNemar's Test (Exact) for gpt4 zero_shot_cot gsm8k\n",
      "[[73.0, 27.0], [95.0, 5.0]]\n",
      "No continuity correction\n",
      "pvalue      4.563546874350736e-10\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      4.563546874350736e-10\n",
      "statistic   27.0\n",
      "McNemar's Test (Exact) for gpt4 ape_zero_shot_cot gsm8k\n",
      "[[73.0, 27.0], [93.0, 7.0]]\n",
      "No continuity correction\n",
      "pvalue      1.1130505022660528e-09\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      1.1130505022660528e-09\n",
      "statistic   27.0\n",
      "McNemar's Test (Exact) for gpt4 least_to_most gsm8k\n",
      "[[73.0, 27.0], [95.0, 5.0]]\n",
      "No continuity correction\n",
      "pvalue      4.563546874350736e-10\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      4.563546874350736e-10\n",
      "statistic   27.0\n",
      "McNemar's Test (Exact) for gpt4 manual_few_shot gsm8k\n",
      "[[73.0, 27.0], [49.0, 51.0]]\n",
      "No continuity correction\n",
      "pvalue      0.01544026202090637\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      0.01544026202090637\n",
      "statistic   27.0\n",
      "McNemar's Test (Exact) for gpt4 manual_cot gsm8k\n",
      "[[73.0, 27.0], [93.0, 7.0]]\n",
      "No continuity correction\n",
      "pvalue      1.1130505022660528e-09\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      1.1130505022660528e-09\n",
      "statistic   27.0\n",
      "McNemar's Test (Exact) for gpt4 tree_of_thought gsm8k\n",
      "[[73.0, 27.0], [40.0, 60.0]]\n",
      "No continuity correction\n",
      "pvalue      0.1420713794263756\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      0.1420713794263756\n",
      "statistic   27.0\n",
      "McNemar's Test (Exact) for gpt4 self_refine gsm8k\n",
      "[[73.0, 27.0], [89.0, 11.0]]\n",
      "No continuity correction\n",
      "pvalue      6.438995104259033e-09\n",
      "statistic   27.0\n",
      "With continuity correction\n",
      "pvalue      6.438995104259033e-09\n",
      "statistic   27.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>statistic_with_correction</th>\n",
       "      <th>pvalue_with_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.349315e-01</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.349315e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.581820e-02</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.581820e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.533717e-01</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.533717e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.252322e-10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.252322e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.714089e-01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.714089e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.513581e-08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.513581e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.590760e-09</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.590760e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.544026e-02</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.544026e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.420714e-01</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.420714e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.438995e-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.438995e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model             method   task  statistic        pvalue  \\\n",
       "0   td3      zero_shot_cot  gsm8k       62.0  2.349315e-01   \n",
       "0   td3  ape_zero_shot_cot  gsm8k       49.0  1.581820e-02   \n",
       "0   td3      least_to_most  gsm8k       67.0  4.533717e-01   \n",
       "0   td3    manual_few_shot  gsm8k       18.0  7.252322e-10   \n",
       "0   td3         manual_cot  gsm8k       60.0  1.714089e-01   \n",
       "0   td3    tree_of_thought  gsm8k       23.0  5.513581e-08   \n",
       "0   td3        self_refine  gsm8k       20.0  4.590760e-09   \n",
       "0  gpt4      zero_shot_cot  gsm8k       27.0  4.563547e-10   \n",
       "0  gpt4  ape_zero_shot_cot  gsm8k       27.0  1.113051e-09   \n",
       "0  gpt4      least_to_most  gsm8k       27.0  4.563547e-10   \n",
       "0  gpt4    manual_few_shot  gsm8k       27.0  1.544026e-02   \n",
       "0  gpt4         manual_cot  gsm8k       27.0  1.113051e-09   \n",
       "0  gpt4    tree_of_thought  gsm8k       27.0  1.420714e-01   \n",
       "0  gpt4        self_refine  gsm8k       27.0  6.438995e-09   \n",
       "\n",
       "   statistic_with_correction  pvalue_with_correction  \n",
       "0                       62.0            2.349315e-01  \n",
       "0                       49.0            1.581820e-02  \n",
       "0                       67.0            4.533717e-01  \n",
       "0                       18.0            7.252322e-10  \n",
       "0                       60.0            1.714089e-01  \n",
       "0                       23.0            5.513581e-08  \n",
       "0                       20.0            4.590760e-09  \n",
       "0                       27.0            4.563547e-10  \n",
       "0                       27.0            1.113051e-09  \n",
       "0                       27.0            4.563547e-10  \n",
       "0                       27.0            1.544026e-02  \n",
       "0                       27.0            1.113051e-09  \n",
       "0                       27.0            1.420714e-01  \n",
       "0                       27.0            6.438995e-09  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add McNemar's Test results to table\n",
    "# Iterate over all combinations of model, method, task\n",
    "# Except for method = \"direct_prompting\" and task = \"cw\"\n",
    "# For each combination, perform McNemar's Test and add to table\n",
    "\n",
    "# Create combos of model, method, task - all unique combinations of these three in combined_data\n",
    "# Get unique values of model, method, task\n",
    "models = combined_data['model'].unique()\n",
    "methods = combined_data['method'].unique()\n",
    "tasks = combined_data['task'].unique()\n",
    "# Create list of all combinations of model, method, task\n",
    "combinations = [(model, method, task) for model in models for method in methods for task in tasks]\n",
    "\n",
    "# Add as rows to a dataframe\n",
    "# Create empty dataframe\n",
    "mcnemars_results = pd.DataFrame(columns=['model', 'method', 'task', 'statistic', 'pvalue', 'statistic_with_correction', 'pvalue_with_correction'])\n",
    "\n",
    "# Iterate over combinations\n",
    "for model, method, task in combinations:\n",
    "    # Skip if method = \"direct_prompting\" or task = \"cw\"\n",
    "    if method == 'direct_prompting' or task == 'cw':\n",
    "        continue\n",
    "    # Perform McNemar's Test\n",
    "    statistic_without_correction, pvalue_without_correction, statistic_with_correction, pvalue_with_correction = perform_mcnemar(model, method, task)\n",
    "    # Add to table\n",
    "    mcnemars_results = pd.concat([mcnemars_results, pd.DataFrame([[model, method, task, statistic_without_correction, pvalue_without_correction, statistic_with_correction, pvalue_with_correction]], columns=['model', 'method', 'task', 'statistic', 'pvalue', 'statistic_with_correction', 'pvalue_with_correction'])])\n",
    "\n",
    "mcnemars_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>statistic_with_correction</th>\n",
       "      <th>pvalue_with_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.581820e-02</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.581820e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.252322e-10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.252322e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.513581e-08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.513581e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.590760e-09</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.590760e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.563547e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.544026e-02</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.544026e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.113051e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.438995e-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.438995e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model             method   task  statistic        pvalue  \\\n",
       "0   td3  ape_zero_shot_cot  gsm8k       49.0  1.581820e-02   \n",
       "0   td3    manual_few_shot  gsm8k       18.0  7.252322e-10   \n",
       "0   td3    tree_of_thought  gsm8k       23.0  5.513581e-08   \n",
       "0   td3        self_refine  gsm8k       20.0  4.590760e-09   \n",
       "0  gpt4      zero_shot_cot  gsm8k       27.0  4.563547e-10   \n",
       "0  gpt4  ape_zero_shot_cot  gsm8k       27.0  1.113051e-09   \n",
       "0  gpt4      least_to_most  gsm8k       27.0  4.563547e-10   \n",
       "0  gpt4    manual_few_shot  gsm8k       27.0  1.544026e-02   \n",
       "0  gpt4         manual_cot  gsm8k       27.0  1.113051e-09   \n",
       "0  gpt4        self_refine  gsm8k       27.0  6.438995e-09   \n",
       "\n",
       "   statistic_with_correction  pvalue_with_correction  \n",
       "0                       49.0            1.581820e-02  \n",
       "0                       18.0            7.252322e-10  \n",
       "0                       23.0            5.513581e-08  \n",
       "0                       20.0            4.590760e-09  \n",
       "0                       27.0            4.563547e-10  \n",
       "0                       27.0            1.113051e-09  \n",
       "0                       27.0            4.563547e-10  \n",
       "0                       27.0            1.544026e-02  \n",
       "0                       27.0            1.113051e-09  \n",
       "0                       27.0            6.438995e-09  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows that are significant at p < 0.05\n",
    "mcnemars_results[mcnemars_results['pvalue'] < 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>statistic_with_correction</th>\n",
       "      <th>pvalue_with_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.234932</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.234932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.453372</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.453372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.171409</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.171409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.142071</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.142071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model           method   task  statistic    pvalue  \\\n",
       "0   td3    zero_shot_cot  gsm8k       62.0  0.234932   \n",
       "0   td3    least_to_most  gsm8k       67.0  0.453372   \n",
       "0   td3       manual_cot  gsm8k       60.0  0.171409   \n",
       "0  gpt4  tree_of_thought  gsm8k       27.0  0.142071   \n",
       "\n",
       "   statistic_with_correction  pvalue_with_correction  \n",
       "0                       62.0                0.234932  \n",
       "0                       67.0                0.453372  \n",
       "0                       60.0                0.171409  \n",
       "0                       27.0                0.142071  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows that are not significant at p < 0.05\n",
    "mcnemars_results[mcnemars_results['pvalue'] >= 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>task</th>\n",
       "      <th>num_correct</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>num_incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>td3</td>\n",
       "      <td>ape_zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>td3</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>23.0</td>\n",
       "      <td>100</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>td3</td>\n",
       "      <td>least_to_most</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>67.0</td>\n",
       "      <td>100</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>td3</td>\n",
       "      <td>manual_few_shot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>td3</td>\n",
       "      <td>self_refine</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>td3</td>\n",
       "      <td>tree_of_thought</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>23.0</td>\n",
       "      <td>100</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>td3</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model             method   task  num_correct  num_obs  num_incorrect\n",
       "0   gpt4  ape_zero_shot_cot  gsm8k         93.0      100            7.0\n",
       "1   gpt4   direct_prompting  gsm8k         73.0      100           27.0\n",
       "2   gpt4      least_to_most  gsm8k         95.0      100            5.0\n",
       "3   gpt4         manual_cot  gsm8k         93.0      100            7.0\n",
       "4   gpt4    manual_few_shot  gsm8k         49.0      100           51.0\n",
       "5   gpt4        self_refine  gsm8k         89.0      100           11.0\n",
       "6   gpt4    tree_of_thought  gsm8k         40.0      100           60.0\n",
       "7   gpt4      zero_shot_cot  gsm8k         95.0      100            5.0\n",
       "8    td3  ape_zero_shot_cot  gsm8k         49.0      100           51.0\n",
       "9    td3   direct_prompting  gsm8k         23.0      100           77.0\n",
       "10   td3      least_to_most  gsm8k         67.0      100           33.0\n",
       "11   td3         manual_cot  gsm8k         60.0      100           40.0\n",
       "12   td3    manual_few_shot  gsm8k         18.0      100           82.0\n",
       "13   td3        self_refine  gsm8k         20.0      100           80.0\n",
       "14   td3    tree_of_thought  gsm8k         23.0      100           77.0\n",
       "15   td3      zero_shot_cot  gsm8k         62.0      100           38.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing gsm8k_correct_incorrect_obs again for reference\n",
    "gsm8k_correct_incorrect_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table for comparing each model/task/method with the appropriate direct prompting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_task_method</th>\n",
       "      <th>conversation_number</th>\n",
       "      <th>coherence_1_incoherent_10_very_coherent</th>\n",
       "      <th>task_constraints_followed_0_not_followed_1_followed</th>\n",
       "      <th>ease_of_review_1_easy_10_hard</th>\n",
       "      <th>correct</th>\n",
       "      <th>conversation_length</th>\n",
       "      <th>input_length</th>\n",
       "      <th>output_length</th>\n",
       "      <th>conversation_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_sentence_length_prompts</th>\n",
       "      <th>dp_fres_prompts</th>\n",
       "      <th>dp_num_linebreaks_provided</th>\n",
       "      <th>dp_num_sentences_provided</th>\n",
       "      <th>dp_num_step_i_provided</th>\n",
       "      <th>dp_num_1_dot_etc_provided</th>\n",
       "      <th>dp_model</th>\n",
       "      <th>dp_task</th>\n",
       "      <th>dp_method</th>\n",
       "      <th>dp_accuracy_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3_cw_zero_shot_cot_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>63</td>\n",
       "      <td>214</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>td3</td>\n",
       "      <td>cw</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>td3_cw_zero_shot_cot_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>63</td>\n",
       "      <td>214</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>86.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>td3</td>\n",
       "      <td>cw</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>td3_cw_zero_shot_cot_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>63</td>\n",
       "      <td>214</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>74.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>td3</td>\n",
       "      <td>cw</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>td3_cw_zero_shot_cot_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>63</td>\n",
       "      <td>214</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>69.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>td3</td>\n",
       "      <td>cw</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>td3_cw_zero_shot_cot_responses</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>63</td>\n",
       "      <td>214</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>74.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>td3</td>\n",
       "      <td>cw</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279995</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860</td>\n",
       "      <td>765</td>\n",
       "      <td>95</td>\n",
       "      <td>0.02865</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279996</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860</td>\n",
       "      <td>765</td>\n",
       "      <td>95</td>\n",
       "      <td>0.02865</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279997</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860</td>\n",
       "      <td>765</td>\n",
       "      <td>95</td>\n",
       "      <td>0.02865</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279998</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860</td>\n",
       "      <td>765</td>\n",
       "      <td>95</td>\n",
       "      <td>0.02865</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279999</th>\n",
       "      <td>gpt4_gsm8k_manual_cot_responses</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860</td>\n",
       "      <td>765</td>\n",
       "      <td>95</td>\n",
       "      <td>0.02865</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>gsm8k</td>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280000 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_task_method  conversation_number  \\\n",
       "0        td3_cw_zero_shot_cot_responses                    1   \n",
       "1        td3_cw_zero_shot_cot_responses                    1   \n",
       "2        td3_cw_zero_shot_cot_responses                    1   \n",
       "3        td3_cw_zero_shot_cot_responses                    1   \n",
       "4        td3_cw_zero_shot_cot_responses                    1   \n",
       "...                                 ...                  ...   \n",
       "279995  gpt4_gsm8k_manual_cot_responses                  100   \n",
       "279996  gpt4_gsm8k_manual_cot_responses                  100   \n",
       "279997  gpt4_gsm8k_manual_cot_responses                  100   \n",
       "279998  gpt4_gsm8k_manual_cot_responses                  100   \n",
       "279999  gpt4_gsm8k_manual_cot_responses                  100   \n",
       "\n",
       "        coherence_1_incoherent_10_very_coherent  \\\n",
       "0                                           2.0   \n",
       "1                                           2.0   \n",
       "2                                           2.0   \n",
       "3                                           2.0   \n",
       "4                                           2.0   \n",
       "...                                         ...   \n",
       "279995                                      NaN   \n",
       "279996                                      NaN   \n",
       "279997                                      NaN   \n",
       "279998                                      NaN   \n",
       "279999                                      NaN   \n",
       "\n",
       "        task_constraints_followed_0_not_followed_1_followed  \\\n",
       "0                                                     1.0     \n",
       "1                                                     1.0     \n",
       "2                                                     1.0     \n",
       "3                                                     1.0     \n",
       "4                                                     1.0     \n",
       "...                                                   ...     \n",
       "279995                                                NaN     \n",
       "279996                                                NaN     \n",
       "279997                                                NaN     \n",
       "279998                                                NaN     \n",
       "279999                                                NaN     \n",
       "\n",
       "        ease_of_review_1_easy_10_hard  correct  conversation_length  \\\n",
       "0                                 2.0      NaN                  278   \n",
       "1                                 2.0      NaN                  278   \n",
       "2                                 2.0      NaN                  278   \n",
       "3                                 2.0      NaN                  278   \n",
       "4                                 2.0      NaN                  278   \n",
       "...                               ...      ...                  ...   \n",
       "279995                            NaN      1.0                  860   \n",
       "279996                            NaN      1.0                  860   \n",
       "279997                            NaN      1.0                  860   \n",
       "279998                            NaN      1.0                  860   \n",
       "279999                            NaN      1.0                  860   \n",
       "\n",
       "        input_length  output_length  conversation_cost  ...  \\\n",
       "0                 63            214            0.00556  ...   \n",
       "1                 63            214            0.00556  ...   \n",
       "2                 63            214            0.00556  ...   \n",
       "3                 63            214            0.00556  ...   \n",
       "4                 63            214            0.00556  ...   \n",
       "...              ...            ...                ...  ...   \n",
       "279995           765             95            0.02865  ...   \n",
       "279996           765             95            0.02865  ...   \n",
       "279997           765             95            0.02865  ...   \n",
       "279998           765             95            0.02865  ...   \n",
       "279999           765             95            0.02865  ...   \n",
       "\n",
       "        dp_sentence_length_prompts dp_fres_prompts  \\\n",
       "0                             10.0           94.35   \n",
       "1                             11.4           86.20   \n",
       "2                             12.2           74.69   \n",
       "3                              9.0           69.99   \n",
       "4                             12.0           74.90   \n",
       "...                            ...             ...   \n",
       "279995                         NaN             NaN   \n",
       "279996                         NaN             NaN   \n",
       "279997                         NaN             NaN   \n",
       "279998                         NaN             NaN   \n",
       "279999                         NaN             NaN   \n",
       "\n",
       "        dp_num_linebreaks_provided  dp_num_sentences_provided  \\\n",
       "0                              NaN                        NaN   \n",
       "1                              NaN                        NaN   \n",
       "2                              NaN                        NaN   \n",
       "3                              NaN                        NaN   \n",
       "4                              NaN                        NaN   \n",
       "...                            ...                        ...   \n",
       "279995                         4.0                        5.0   \n",
       "279996                         2.0                        3.0   \n",
       "279997                         3.0                        4.0   \n",
       "279998                         2.0                        3.0   \n",
       "279999                         4.0                        3.0   \n",
       "\n",
       "        dp_num_step_i_provided  dp_num_1_dot_etc_provided  dp_model  dp_task  \\\n",
       "0                          NaN                        NaN       td3       cw   \n",
       "1                          NaN                        NaN       td3       cw   \n",
       "2                          NaN                        NaN       td3       cw   \n",
       "3                          NaN                        NaN       td3       cw   \n",
       "4                          NaN                        NaN       td3       cw   \n",
       "...                        ...                        ...       ...      ...   \n",
       "279995                     0.0                        1.0      gpt4    gsm8k   \n",
       "279996                     0.0                        0.0      gpt4    gsm8k   \n",
       "279997                     0.0                        0.0      gpt4    gsm8k   \n",
       "279998                     0.0                        0.0      gpt4    gsm8k   \n",
       "279999                     0.0                        0.0      gpt4    gsm8k   \n",
       "\n",
       "               dp_method  dp_accuracy_quality  \n",
       "0       direct_prompting                  1.0  \n",
       "1       direct_prompting                  7.0  \n",
       "2       direct_prompting                  1.0  \n",
       "3       direct_prompting                 10.0  \n",
       "4       direct_prompting                  4.0  \n",
       "...                  ...                  ...  \n",
       "279995  direct_prompting                  1.0  \n",
       "279996  direct_prompting                  0.0  \n",
       "279997  direct_prompting                  0.0  \n",
       "279998  direct_prompting                  1.0  \n",
       "279999  direct_prompting                  0.0  \n",
       "\n",
       "[280000 rows x 68 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset\n",
    "no_direct_prompting_data = combined_data[combined_data['method'] != 'direct_prompting']\n",
    "direct_prompting_data = combined_data[combined_data['method'] == 'direct_prompting']\n",
    "\n",
    "# Add prefix dp_ to columns in direct_prompting_data\n",
    "direct_prompting_data = direct_prompting_data.add_prefix('dp_')\n",
    "\n",
    "# Left join datasets on model = dp_model, task = dp_task\n",
    "direct_prompting_comparison = no_direct_prompting_data.merge(direct_prompting_data, left_on=['model', 'task'], right_on=['dp_model', 'dp_task'], how='left')\n",
    "\n",
    "direct_prompting_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-test for quality, means of other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dp_creative_writing_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dp_creative_writing_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ijyli\\repo\\anlp23-project\\Data\\06 - Analyze Metrics and Conduct Inference.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/06%20-%20Analyze%20Metrics%20and%20Conduct%20Inference.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m data \u001b[39m=\u001b[39m direct_prompting_comparison[(direct_prompting_comparison[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m model) \u001b[39m&\u001b[39m (direct_prompting_comparison[\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m task) \u001b[39m&\u001b[39m (direct_prompting_comparison[\u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m method)]\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mconversation_number\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/06%20-%20Analyze%20Metrics%20and%20Conduct%20Inference.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# direct_prompting holds the metric when using direct_prompting\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/06%20-%20Analyze%20Metrics%20and%20Conduct%20Inference.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m direct_prompting \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mdp_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m metric]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/06%20-%20Analyze%20Metrics%20and%20Conduct%20Inference.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# using_method holds the metric when using the method\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Data/06%20-%20Analyze%20Metrics%20and%20Conduct%20Inference.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m using_method \u001b[39m=\u001b[39m data[metric]\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dp_creative_writing_score'"
     ]
    }
   ],
   "source": [
    "# Perform paired t-test on creative writing data and all other metrics\n",
    "\n",
    "# Metrics to t-test: 'creative_writing_score', 'ease_of_evaluation_score', 'conversation_length', 'input_length', 'output_length', 'conversation_cost', 'gsm8k_length_vs_provided', 'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres', 'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts'\n",
    "metrics_to_t_test = ['creative_writing_score', 'ease_of_evaluation_score', 'conversation_length', 'input_length', 'output_length', 'conversation_cost', 'gsm8k_length_vs_provided', 'length_vs_direct_prompting', 'num_linebreaks', 'num_sentences', 'num_step_i', 'num_1_dot_etc', 'sentence_length', 'fres', 'num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts']\n",
    "\n",
    "# Create table to hold results\n",
    "# Columns of model, task, method, mean metric, mean dp_metric, statistic, pvalue\n",
    "t_test_results = pd.DataFrame(columns=['model', 'task', 'method', 'metric', 'dp_mean', 'using_method_mean', 'statistic', 'pvalue'])\n",
    "# Iterate over model, task, method\n",
    "for model, task, method in direct_prompting_comparison[['model', 'task', 'method']].values:\n",
    "    # Iterate over metrics_to_t_test\n",
    "    for metric in metrics_to_t_test:\n",
    "        # Get data\n",
    "        # Sort by conversation_number\n",
    "        data = direct_prompting_comparison[(direct_prompting_comparison['model'] == model) & (direct_prompting_comparison['task'] == task) & (direct_prompting_comparison['method'] == method)].sort_values(by=['conversation_number'])\n",
    "        # direct_prompting holds the metric when using direct_prompting\n",
    "        direct_prompting = data['dp_' + metric]\n",
    "        # using_method holds the metric when using the method\n",
    "        using_method = data[metric]\n",
    "        # Perform the paired sample t-test \n",
    "        statistic, pvalue = stats.ttest_rel(direct_prompting, using_method)\n",
    "        # Add to table\n",
    "        t_test_results = t_test_results.concat(pd.DataFrame([[model, task, method, metric, direct_prompting.mean(), using_method.mean(), statistic, pvalue]], columns=['model', 'task', 'method', 'metric', 'dp_mean', 'using_method_mean', 'statistic', 'pvalue']))\n",
    "\n",
    "t_test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows that are not significant at p < 0.05\n",
    "t_test_results[t_test_results['pvalue'] >= 0.05]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding release date to accuracy quality table (optional version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release date and gains versus direct prompting\n",
    "\n",
    "# Load Excel file \"..\\Selection of Prompt Engineering Methods\\Hand-Labeled Method and Implementation Considerations.xlsx\"\n",
    "hand_labeled_data = pd.read_excel('..\\Selection of Prompt Engineering Methods\\Hand-Labeled Method and Implementation Considerations.xlsx')\n",
    "\n",
    "# Keep columns ss_publication_date, \"Prompt Engineering Method\"\n",
    "hand_labeled_data = hand_labeled_data[['ss_publication_date', 'Prompt Engineering Method']]\n",
    "\n",
    "# Mapping names from this data to technqiue names\n",
    "# \"Few-Shot Learing\" -> \"manual_few_shot\"\n",
    "# \"Chain-of-Thought Prompting\" -> \"manual_cot\"\n",
    "# \"Zero-Shot Chain-of_Thought\" -> \"zero_shot_cot\"\n",
    "# \"Automatic Prompt Engineer\" -> \"ape_zero_shot_cot\"\n",
    "# \"Self-Refine\" -> \"self_refine\"\n",
    "# \"Least-to-Most Prompting\" -> \"least_to_most\"\n",
    "# \"Tree-of-Thought\" -> \"tree_of_thought\"\n",
    "# Set names in hand_labeled_data to these names\n",
    "hand_labeled_data['technique_name'] = hand_labeled_data['Prompt Engineering Method'].replace({'Few-Shot Learning': 'manual_few_shot', 'Chain-of-Thought Prompting': 'manual_cot', 'Zero-Shot Chain-of-Thought': 'zero_shot_cot', 'Automatic Prompt Engineer': 'ape_zero_shot_cot', 'Self-Refine': 'self_refine', 'Least-to-Most Prompting': 'least_to_most', 'Tree-of-Thought': 'tree_of_thought'})\n",
    "\n",
    "# Convert ss_publication_date to \"YYYY-MM-DD\"\n",
    "hand_labeled_data['ss_publication_date'] = hand_labeled_data['ss_publication_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Add ss_publication_date to avg_accuracy_quality_pivot\n",
    "# The value should be for each column, right below the column name\n",
    "# Transpose accuracy_quality_pivot\n",
    "avg_accuracy_quality_pivot_transposed = avg_accuracy_quality_pivot.transpose().reset_index()\n",
    "\n",
    "# Set name of first column to \"technique_name\"\n",
    "avg_accuracy_quality_pivot_transposed = avg_accuracy_quality_pivot_transposed.rename(columns={'index': 'technique_name'})\n",
    "\n",
    "# Left join hand_labeled_data to avg_accuracy_quality_pivot_transposed on technique_name\n",
    "avg_accuracy_quality_pivot_transposed = avg_accuracy_quality_pivot_transposed.merge(hand_labeled_data, on='technique_name', how='left')\n",
    "\n",
    "# Transpose back\n",
    "avg_accuracy_quality_pivot_with_date = avg_accuracy_quality_pivot_transposed.transpose().reset_index()\n",
    "\n",
    "# Output to LaTeX\n",
    "avg_accuracy_quality_pivot_with_date.to_latex('../Output/avg_accuracy_quality_pivot_with_date.tex', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Function for a table of means for a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_table(metric):\n",
    "\n",
    "    # Average combined_data metric by model, method, task\n",
    "    avg_combined_data_metric = combined_data[['model', 'method', 'task', metric]].groupby(['model', 'method', 'task']).agg(['mean'])[metric].reset_index()\n",
    "\n",
    "    # Pivot table - column method should go wide\n",
    "    avg_combined_data_metric_pivot = avg_combined_data_metric.pivot_table(index=['model', 'task'], columns='method', values=metric).reset_index()\n",
    "\n",
    "    # Sort rows by task - gsm8k task first, then cw\n",
    "    # Sort by model - text-davinci-003 first, then gpt4\n",
    "    avg_combined_data_metric_pivot = avg_combined_data_metric_pivot.sort_values(by=['task', 'model'], ascending=[True, True])\n",
    "\n",
    "    # Order columns: direct_prompting, zero_shot_cot, ape_zero_shot_cot, tree_of_thought, self_refine, least_to_most, manual_few_shot, manual_cot\n",
    "    avg_combined_data_metric_pivot = avg_combined_data_metric_pivot[['model', 'task', 'direct_prompting', 'zero_shot_cot', 'ape_zero_shot_cot', 'tree_of_thought', 'self_refine', 'least_to_most', 'manual_few_shot', 'manual_cot']]\n",
    "\n",
    "    # Output to LaTeX\n",
    "    avg_combined_data_metric_pivot.to_latex('../Output/avg_' + metric + '_pivot.tex', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length\n",
    "\n",
    "Run generic function for length of entire interaction, length of all prompts, financial cost\n",
    "\n",
    "Baseline comparison ratios, change in accuracy/quality plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_table('conversation_length')\n",
    "means_table('input_length')\n",
    "means_table('conversation_cost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gsm8k_length_vs_provided in a bar chart\n",
    "# Limit to gsm8k data\n",
    "# Get means by model, method\n",
    "gsm8k_length_vs_provided_means = gsm8k_data[['model', 'method', 'gsm8k_length_vs_provided']].groupby(['model', 'method']).agg(['mean'])['gsm8k_length_vs_provided'].reset_index()\n",
    "\n",
    "# Bar chart by model, method\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='model', y='mean', hue='method', data=gsm8k_length_vs_provided_means)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average GSM8k Length vs. Provided Length')\n",
    "plt.title('Average GSM8k Length vs. Provided Length by Model and Method')\n",
    "plt.savefig('../Output/gsm8k_length_vs_provided_means.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot length_vs_direct_prompting in a bar chart\n",
    "# Get means by model, method, task\n",
    "length_vs_direct_prompting_means = combined_data[['model', 'method', 'task', 'length_vs_direct_prompting']].groupby(['model', 'method', 'task']).agg(['mean'])['length_vs_direct_prompting'].reset_index()\n",
    "\n",
    "# Bar chart by model, method, task\n",
    "\n",
    "# GSM8k plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='model', y='mean', hue='method', data=length_vs_direct_prompting_means[length_vs_direct_prompting_means['task'] == 'gsm8k'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average GSM8k Length vs. Direct Prompting Length')\n",
    "plt.title('Average GSM8k Length vs. Direct Prompting Length by Model and Method')\n",
    "plt.savefig('../Output/gsm8k_length_vs_direct_prompting_means.png')\n",
    "plt.show()\n",
    "\n",
    "# Creative writing plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='model', y='mean', hue='method', data=length_vs_direct_prompting_means[length_vs_direct_prompting_means['task'] == 'cw'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Creative Writing Length vs. Direct Prompting Length')\n",
    "plt.title('Average Creative Writing Length vs. Direct Prompting Length by Model and Method')\n",
    "plt.savefig('../Output/cw_length_vs_direct_prompting_means.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute change in accuracy/quality per change in length (versus direct prompting)\n",
    "\n",
    "# In the direct_prompting_comparison table, get averages of conversation_length, dp_conversation_length, accuracy_quality, dp_accuracy_quality by model, method, task\n",
    "averages_for_changes = direct_prompting_comparison[['model', 'method', 'task', 'conversation_length', 'dp_conversation_length', 'accuracy_quality', 'dp_accuracy_quality']].groupby(['model', 'method', 'task']).agg(['mean']).reset_index()\n",
    "\n",
    "# Compute change in accuracy_quality per change in conversation_length\n",
    "# dp_accuracy_quality - accuracy_quality\n",
    "# divided by\n",
    "# dp_conversation_length - conversation_length\n",
    "averages_for_changes['change_in_accuracy_quality_per_change_in_conversation_length'] = (averages_for_changes['dp_accuracy_quality']['mean'] - averages_for_changes['accuracy_quality']['mean']) / (averages_for_changes['dp_conversation_length']['mean'] - averages_for_changes['conversation_length']['mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot change in accuracy_quality per change in conversation_length\n",
    "# Bar chart by model, method, task\n",
    "# GSM8k plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='model', y='change_in_accuracy_quality_per_change_in_conversation_length', hue='method', data=averages_for_changes[averages_for_changes['task'] == 'gsm8k'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Change in Accuracy/Quality per Change in Conversation Length')\n",
    "plt.title('Change in Accuracy/Quality per Change in Conversation Length by Model and Method')\n",
    "plt.savefig('../Output/gsm8k_change_in_accuracy_quality_per_change_in_conversation_length.png')\n",
    "plt.show()\n",
    "\n",
    "# Creative writing plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='model', y='change_in_accuracy_quality_per_change_in_conversation_length', hue='method', data=averages_for_changes[averages_for_changes['task'] == 'cw'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Change in Accuracy/Quality per Change in Conversation Length')\n",
    "plt.title('Change in Accuracy/Quality per Change in Conversation Length by Model and Method')\n",
    "plt.savefig('../Output/cw_change_in_accuracy_quality_per_change_in_conversation_length.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a table with the change in accuracy_quality per change in conversation_length\n",
    "\n",
    "# Sort and output table\n",
    "\n",
    "# Sort rows by task - gsm8k task first, then cw\n",
    "# Sort by model - text-davinci-003 first, then gpt4\n",
    "change_per_table = averages_for_changes.sort_values(by=['task', 'model'], ascending=[True, True])\n",
    "\n",
    "# Order columns: direct_prompting, zero_shot_cot, ape_zero_shot_cot, tree_of_thought, self_refine, least_to_most, manual_few_shot, manual_cot\n",
    "change_per_table = change_per_table[['model', 'task', 'direct_prompting', 'zero_shot_cot', 'ape_zero_shot_cot', 'tree_of_thought', 'self_refine', 'least_to_most', 'manual_few_shot', 'manual_cot']]\n",
    "\n",
    "# Output to LaTeX\n",
    "change_per_table.to_latex('../Output/change_per_table.tex', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "Run generic function for number of reasoning steps, sentence length, FRE\n",
    "\n",
    "Bar charts of differences\n",
    "\n",
    "Generic function for assessment of ease of review too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_table('num_linebreaks')\n",
    "means_table('num_sentences')\n",
    "means_table('num_step_i')\n",
    "means_table('num_1_dot_etc')\n",
    "means_table('sentence_length')\n",
    "means_table('fres')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences of scores \n",
    "# Responses versus prompts\n",
    "# Responses versus provided answer for GSM8k\n",
    "\n",
    "# Variables: \n",
    "# 'num_linebreaks_prompts': num_linebreaks_prompts,\n",
    "# 'num_sentences_prompts': num_sentences_prompts,\n",
    "# 'num_step_i_prompts': num_step_i_prompts,\n",
    "# 'num_1_dot_etc_prompts': num_1_dot_etc_prompts,\n",
    "# 'sentence_length_prompts': sentence_length_prompts,\n",
    "# 'fres_prompts': fres_prompts,\n",
    "# 'num_linebreaks_provided': num_linebreaks_provided,\n",
    "# 'num_sentences_provided': num_sentences_provided,\n",
    "# 'num_step_i_provided': num_step_i_provided,\n",
    "# 'num_1_dot_etc_provided': num_1_dot_etc_provided\n",
    "# Loop over variables and create differences variables\n",
    "comparison_vars = ['num_linebreaks_prompts', 'num_sentences_prompts', 'num_step_i_prompts', 'num_1_dot_etc_prompts', 'sentence_length_prompts', 'fres_prompts', 'num_linebreaks_provided', 'num_sentences_provided', 'num_step_i_provided', 'num_1_dot_etc_provided']\n",
    "for var in comparison_vars:\n",
    "    # Create a variable that is the difference between the prompts and responses\n",
    "    # var + '_diff'\n",
    "    combined_data[var + '_diff'] = combined_data[var] - combined_data[var.replace('_prompts', '').replace('_provided', '')]\n",
    "\n",
    "# Aggregate \"_diff\" variables by model, task, method\n",
    "differences = combined_data[['model', 'task', 'method', 'num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'sentence_length_prompts_diff', 'fres_prompts_diff', 'num_linebreaks_provided_diff', 'num_sentences_provided_diff', 'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff']].groupby(['model', 'task', 'method']).agg(['mean']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots of _diff variables by model, task, method\n",
    "\n",
    "# GSM8k plots\n",
    "# Loop over variables\n",
    "comparison_vars_gsm8k = ['num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'num_linebreaks_provided_diff', 'num_sentences_provided_diff', 'num_step_i_provided_diff', 'num_1_dot_etc_provided_diff']\n",
    "for var in comparison_vars_gsm8k:\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='model', y=var, hue='method', data=differences[differences['task'] == 'gsm8k'])\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Average ' + var + ' Difference')\n",
    "    plt.title('Average ' + var + ' Difference by Model and Method')\n",
    "    plt.savefig('../Output/gsm8k_' + var + '.png')\n",
    "    plt.show()\n",
    "\n",
    "# Creative writing plots\n",
    "# Loop over variables\n",
    "comparison_vars_cw = ['num_linebreaks_prompts_diff', 'num_sentences_prompts_diff', 'num_step_i_prompts_diff', 'num_1_dot_etc_prompts_diff', 'sentence_length_prompts_diff', 'fres_prompts_diff']\n",
    "for var in comparison_vars_cw:\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='model', y=var, hue='method', data=differences[differences['task'] == 'cw'])\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Average ' + var + ' Difference')\n",
    "    plt.title('Average ' + var + ' Difference by Model and Method')\n",
    "    plt.savefig('../Output/cw_' + var + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_table('ease_of_evaluation_score')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
