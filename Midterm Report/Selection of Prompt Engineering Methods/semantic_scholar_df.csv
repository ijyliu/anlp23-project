paper title,semantic scholar title,ss_publication_date,ss_year,citation_count,query,end_date,days_from_pub_to_10_8_2023,citations_per_day
Language Models are Few-Shot Learners ,Language Models are Few-Shot Learners,2020-05-28,2020,15624,Language Models are Few Shot Learners ,2023-10-08,1228.0,12.723127035830618
Chain of Thought Prompting Elicits Reasoning in Large Language Models ,Chain of Thought Prompting Elicits Reasoning in Large Language Models,2022-01-28,2022,1871,Chain of Thought Prompting Elicits Reasoning in Large Language Models ,2023-10-08,618.0,3.027508090614887
The Power of Scale for Parameter-Efficient Prompt Tuning ,The Power of Scale for Parameter-Efficient Prompt Tuning,2021-04-18,2021,1449,The Power of Scale for Parameter Efficient Prompt Tuning ,2023-10-08,903.0,1.6046511627906976
Large Language Models are Zero-Shot Reasoners ,Large Language Models are Zero-Shot Reasoners,2022-05-24,2022,776,Large Language Models are Zero Shot Reasoners ,2023-10-08,502.0,1.545816733067729
Tree of Thoughts: Deliberate Problem Solving with Large Language Models ,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,2023-05-17,2023,185,Tree of Thoughts: Deliberate Problem Solving with Large Language Models ,2023-10-08,144.0,1.2847222222222223
Making Pre-trained Language Models Better Few-shot Learners ,Making Pre-trained Language Models Better Few-shot Learners,2021-01-01,2021,1037,Making Pre trained Language Models Better Few shot Learners ,2023-10-08,1010.0,1.0267326732673268
Making Pre-trained Language Models Better Few-shot Learners ,Making Pre-trained Language Models Better Few-shot Learners,2021-01-01,2021,1037,Making Pre trained Language Models Better Few shot Learners ,2023-10-08,1010.0,1.0267326732673268
Self-Consistency Improves Chain of Thought Reasoning in Language Models ,Self-Consistency Improves Chain of Thought Reasoning in Language Models,2022-03-21,2022,578,Self Consistency Improves Chain of Thought Reasoning in Language Models ,2023-10-08,566.0,1.0212014134275618
Self-Refine: Iterative Refinement with Self-Feedback ,Self-Refine: Iterative Refinement with Self-Feedback,2023-03-30,2023,158,Self Refine: Iterative Refinement with Self Feedback ,2023-10-08,192.0,0.8229166666666666
ReAct: Synergizing Reasoning and Acting in Language Models ,ReAct: Synergizing Reasoning and Acting in Language Models,2022-10-06,2022,285,ReAct: Synergizing Reasoning and Acting in Language Models ,2023-10-08,367.0,0.776566757493188
Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? ,Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?,2022-02-25,2022,387,Rethinking the Role of Demonstrations: What Makes In Context Learning Work? ,2023-10-08,590.0,0.6559322033898305
A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT ,A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT,2023-02-21,2023,146,A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT ,2023-10-08,229.0,0.6375545851528385
Calibrate Before Use: Improving Few-Shot Performance of Language Models ,Calibrate Before Use: Improving Few-Shot Performance of Language Models,2021-02-19,2021,568,Calibrate Before Use: Improving Few Shot Performance of Language Models ,2023-10-08,961.0,0.5910509885535901
PAL: Program-aided Language Models ,PAL: Program-aided Language Models,2022-11-18,2022,172,PAL: Program aided Language Models ,2023-10-08,324.0,0.5308641975308642
How Can We Know What Language Models Know? ,How Can We Know What Language Models Know?,2019-11-28,2019,736,How Can We Know What Language Models Know? ,2023-10-08,1410.0,0.5219858156028369
Large Language Models Are Human-Level Prompt Engineers ,Large Language Models Are Human-Level Prompt Engineers,2022-11-03,2022,160,Large Language Models Are Human Level Prompt Engineers ,2023-10-08,339.0,0.471976401179941
Graph of Thoughts: Solving Elaborate Problems with Large Language Models ,Graph of Thoughts: Solving Elaborate Problems with Large Language Models,2023-08-18,2023,22,Graph of Thoughts: Solving Elaborate Problems with Large Language Models ,2023-10-08,51.0,0.43137254901960786
Atlas: Few-shot Learning with Retrieval Augmented Language Models ,Few-shot Learning with Retrieval Augmented Language Models,2022-08-05,2022,180,Atlas: Few shot Learning with Retrieval Augmented Language Models ,2023-10-08,429.0,0.4195804195804196
Let's Verify Step by Step ,Let's Verify Step by Step,2023-05-31,2023,51,Let's Verify Step by Step ,2023-10-08,130.0,0.3923076923076923
Larger language models do in-context learning differently ,Larger language models do in-context learning differently,2023-03-07,2023,72,Larger language models do in context learning differently ,2023-10-08,215.0,0.33488372093023255
"CAMEL: Communicative Agents for ""Mind"" Exploration of Large Scale Language Model Society ","CAMEL: Communicative Agents for ""Mind"" Exploration of Large Scale Language Model Society",2023-03-31,2023,56,"CAMEL: Communicative Agents for ""Mind"" Exploration of Large Scale Language Model Society ",2023-10-08,191.0,0.2931937172774869
Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT ,Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT,2023-02-19,2023,61,Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine tuned BERT ,2023-10-08,231.0,0.26406926406926406
Discovering Language Model Behaviors with Model-Written Evaluations ,Discovering Language Model Behaviors with Model-Written Evaluations,2022-12-19,2022,76,Discovering Language Model Behaviors with Model Written Evaluations ,2023-10-08,293.0,0.2593856655290102
Large Language Models Can Be Easily Distracted by Irrelevant Context ,Large Language Models Can Be Easily Distracted by Irrelevant Context,2023-01-31,2023,62,Large Language Models Can Be Easily Distracted by Irrelevant Context ,2023-10-08,250.0,0.248
Decomposed Prompting: A Modular Approach for Solving Complex Tasks ,Decomposed Prompting: A Modular Approach for Solving Complex Tasks,2022-10-05,2022,89,Decomposed Prompting: A Modular Approach for Solving Complex Tasks ,2023-10-08,368.0,0.2418478260869565
Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers ,Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers,2023-09-15,2023,5,Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers ,2023-10-08,23.0,0.21739130434782608
Reasoning with Language Model is Planning with World Model ,Reasoning with Language Model is Planning with World Model,2023-05-24,2023,28,Reasoning with Language Model is Planning with World Model ,2023-10-08,137.0,0.20437956204379562
AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts ,Eliciting Knowledge from Language Models Using Automatically Generated Prompts,2020-10-29,2020,215,AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts ,2023-10-08,1074.0,0.20018621973929238
ART: Automatic multi-step reasoning and tool-use for large language models ,ART: Automatic multi-step reasoning and tool-use for large language models,2023-03-16,2023,37,ART: Automatic multi step reasoning and tool use for large language models ,2023-10-08,206.0,0.1796116504854369
The Capacity for Moral Self-Correction in Large Language Models ,The Capacity for Moral Self-Correction in Large Language Models,2023-02-15,2023,42,The Capacity for Moral Self Correction in Large Language Models ,2023-10-08,235.0,0.17872340425531916
AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts ,AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts,2021-10-04,2021,130,AI Chains: Transparent and Controllable Human AI Interaction by Chaining Large Language Model Prompts ,2023-10-08,734.0,0.1771117166212534
Design Guidelines for Prompt Engineering Text-to-Image Generative Models ,Design Guidelines for Prompt Engineering Text-to-Image Generative Models,2021-09-14,2021,131,Design Guidelines for Prompt Engineering Text to Image Generative Models ,2023-10-08,754.0,0.17374005305039789
Promptagator: Few-shot Dense Retrieval From 8 Examples ,Promptagator: Few-shot Dense Retrieval From 8 Examples,2022-09-23,2022,64,Promptagator: Few shot Dense Retrieval From 8 Examples ,2023-10-08,380.0,0.16842105263157894
Chain-of-Verification Reduces Hallucination in Large Language Models ,Chain-of-Verification Reduces Hallucination in Large Language Models,2023-09-20,2023,3,Chain of Verification Reduces Hallucination in Large Language Models ,2023-10-08,18.0,0.16666666666666666
Ask Me Anything: A simple strategy for prompting language models ,Ask Me Anything: A simple strategy for prompting language models,2022-10-05,2022,60,Ask Me Anything: A simple strategy for prompting language models ,2023-10-08,368.0,0.16304347826086957
Prompting GPT-3 To Be Reliable ,Prompting GPT-3 To Be Reliable,2022-10-17,2022,57,Prompting GPT 3 To Be Reliable ,2023-10-08,356.0,0.1601123595505618
Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations ,Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations,2022-05-24,2022,79,Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations ,2023-10-08,502.0,0.15737051792828685
PromptChainer: Chaining Large Language Model Prompts through Visual Programming ,PromptChainer: Chaining Large Language Model Prompts through Visual Programming,2022-03-13,2022,69,PromptChainer: Chaining Large Language Model Prompts through Visual Programming ,2023-10-08,574.0,0.12020905923344948
"What In-Context Learning ""Learns"" In-Context: Disentangling Task Recognition and Task Learning ","What In-Context Learning ""Learns"" In-Context: Disentangling Task Recognition and Task Learning",2023-05-16,2023,16,"What In Context Learning ""Learns"" In Context: Disentangling Task Recognition and Task Learning ",2023-10-08,145.0,0.1103448275862069
Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models ,Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models,2023-02-01,2023,22,Synthetic Prompting: Generating Chain of Thought Demonstrations for Large Language Models ,2023-10-08,249.0,0.08835341365461848
Interactive Natural Language Processing ,Interactive Natural Language Processing,2023-05-22,2023,12,Interactive Natural Language Processing ,2023-10-08,139.0,0.08633093525179857
The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning ,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,2022-05-06,2022,44,The Unreliability of Explanations in Few shot Prompting for Textual Reasoning ,2023-10-08,520.0,0.08461538461538462
How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks ,How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks,2023-03-01,2023,18,How Robust is GPT 3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks ,2023-10-08,221.0,0.08144796380090498
Recitation-Augmented Language Models ,Recitation-Augmented Language Models,2022-10-04,2022,30,Recitation Augmented Language Models ,2023-10-08,369.0,0.08130081300813008
Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data ,Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data,2023-02-24,2023,18,Automatic Prompt Augmentation and Selection with Chain of Thought from Labeled Data ,2023-10-08,226.0,0.07964601769911504
Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning ,Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning,2023-03-06,2023,17,Multitask Prompt Tuning Enables Parameter Efficient Transfer Learning ,2023-10-08,216.0,0.0787037037037037
BERTese: Learning to Speak to BERT ,BERTese: Learning to Speak to BERT,2021-03-09,2021,74,BERTese: Learning to Speak to BERT ,2023-10-08,943.0,0.0784729586426299
A Taxonomy of Prompt Modifiers for Text-To-Image Generation ,A Taxonomy of Prompt Modifiers for Text-To-Image Generation,2022-04-20,2022,41,A Taxonomy of Prompt Modifiers for Text To Image Generation ,2023-10-08,536.0,0.07649253731343283
Context-faithful Prompting for Large Language Models ,Context-faithful Prompting for Large Language Models,2023-03-20,2023,15,Context faithful Prompting for Large Language Models ,2023-10-08,202.0,0.07425742574257425
Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding ,Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding,2023-07-28,2023,5,Skeleton of Thought: Large Language Models Can Do Parallel Decoding ,2023-10-08,72.0,0.06944444444444445
Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning ,Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning,2023-03-18,2023,14,Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning ,2023-10-08,204.0,0.06862745098039216
Progressive Prompts: Continual Learning for Language Models ,Progressive Prompts: Continual Learning for Language Models,2023-01-29,2023,17,Progressive Prompts: Continual Learning for Language Models ,2023-10-08,252.0,0.06746031746031746
"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning ","On Second Thought, Let’s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",2022-12-15,2022,20,"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero Shot Reasoning ",2023-10-08,297.0,0.06734006734006734
kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference ,kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference,2023-03-24,2023,13,kNN Prompting: Beyond Context Learning with Calibration Free Nearest Neighbor Inference ,2023-10-08,198.0,0.06565656565656566
Boosted Prompt Ensembles for Large Language Models ,Boosted Prompt Ensembles for Large Language Models,2023-04-12,2023,11,Boosted Prompt Ensembles for Large Language Models ,2023-10-08,179.0,0.061452513966480445
Learning from Task Descriptions ,Learning from Task Descriptions,2020-11-01,2020,63,Learning from Task Descriptions ,2023-10-08,1071.0,0.058823529411764705
DocPrompting: Generating Code by Retrieving the Docs ,DocPrompting: Generating Code by Retrieving the Docs,2022-07-13,2022,26,DocPrompting: Generating Code by Retrieving the Docs ,2023-10-08,452.0,0.05752212389380531
GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks ,GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks,2023-02-16,2023,13,GraphPrompt: Unifying Pre Training and Downstream Tasks for Graph Neural Networks ,2023-10-08,234.0,0.05555555555555555
"MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning ","MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning",2022-05-01,2022,29,"MRKL Systems: A modular, neuro symbolic architecture that combines large language models, external knowledge sources and discrete reasoning ",2023-10-08,525.0,0.05523809523809524
OpenICL: An Open-Source Framework for In-context Learning ,OpenICL: An Open-Source Framework for In-context Learning,2023-03-06,2023,11,OpenICL: An Open Source Framework for In context Learning ,2023-10-08,216.0,0.05092592592592592
Can We Edit Factual Knowledge by In-Context Learning? ,Can We Edit Factual Knowledge by In-Context Learning?,2023-05-22,2023,7,Can We Edit Factual Knowledge by In Context Learning? ,2023-10-08,139.0,0.050359712230215826
Visual-Language Prompt Tuning with Knowledge-guided Context Optimization ,Visual-Language Prompt Tuning with Knowledge-Guided Context Optimization,2023-03-23,2023,10,Visual Language Prompt Tuning with Knowledge guided Context Optimization ,2023-10-08,199.0,0.05025125628140704
Re-Reading Improves Reasoning in Language Models ,Re-Reading Improves Reasoning in Language Models,2023-09-12,2023,1,Re Reading Improves Reasoning in Language Models ,2023-10-08,26.0,0.038461538461538464
Guiding Large Language Models via Directional Stimulus Prompting ,Guiding Large Language Models via Directional Stimulus Prompting,2023-02-22,2023,8,Guiding Large Language Models via Directional Stimulus Prompting ,2023-10-08,228.0,0.03508771929824561
Efficient Prompting via Dynamic In-Context Learning ,Efficient Prompting via Dynamic In-Context Learning,2023-05-18,2023,5,Efficient Prompting via Dynamic In Context Learning ,2023-10-08,143.0,0.03496503496503497
Learning to Transfer Prompts for Text Generation ,Learning to Transfer Prompts for Text Generation,2022-05-03,2022,18,Learning to Transfer Prompts for Text Generation ,2023-10-08,523.0,0.03441682600382409
Batch Prompting: Efficient Inference with LLM APIs ,Batch Prompting: Efficient Inference with Large Language Model APIs,2023-01-19,2023,9,Batch Prompting: Efficient Inference with LLM APIs ,2023-10-08,262.0,0.03435114503816794
UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation ,UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation,2023-03-15,2023,7,UPRISE: Universal Prompt Retrieval for Improving Zero Shot Evaluation ,2023-10-08,207.0,0.033816425120772944
From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting ,From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting,2023-09-08,2023,1,From Sparse to Dense: GPT 4 Summarization with Chain of Density Prompting ,2023-10-08,30.0,0.03333333333333333
Better Zero-Shot Reasoning with Self-Adaptive Prompting ,Better Zero-Shot Reasoning with Self-Adaptive Prompting,2023-05-23,2023,4,Better Zero Shot Reasoning with Self Adaptive Prompting ,2023-10-08,138.0,0.028985507246376812
Meta-in-context learning in large language models ,Meta-in-context learning in large language models,2023-05-22,2023,4,Meta in context learning in large language models ,2023-10-08,139.0,0.02877697841726619
Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs ,Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs,2023-05-19,2023,4,Let's Sample Step by Step: Adaptive Consistency for Efficient Reasoning with LLMs ,2023-10-08,142.0,0.028169014084507043
Post Hoc Explanations of Language Models Can Improve Language Models ,Post Hoc Explanations of Language Models Can Improve Language Models,2023-05-19,2023,4,Post Hoc Explanations of Language Models Can Improve Language Models ,2023-10-08,142.0,0.028169014084507043
TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks ,TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks,2023-05-19,2023,4,TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks ,2023-10-08,142.0,0.028169014084507043
Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling ,Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling,2023-05-17,2023,4,Reprompting: Automated Chain of Thought Prompt Inference Through Gibbs Sampling ,2023-10-08,144.0,0.027777777777777776
Hierarchical Prompting Assists Large Language Model on Web Navigation ,Hierarchical Prompting Assists Large Language Model on Web Navigation,2023-05-23,2023,3,Hierarchical Prompting Assists Large Language Model on Web Navigation ,2023-10-08,138.0,0.021739130434782608
Self-Critique Prompting with Large Language Models for Inductive Instructions ,Self-Critique Prompting with Large Language Models for Inductive Instructions,2023-05-23,2023,3,Self Critique Prompting with Large Language Models for Inductive Instructions ,2023-10-08,138.0,0.021739130434782608
Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints ,Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints,2023-02-17,2023,5,Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints ,2023-10-08,233.0,0.02145922746781116
"Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt ","Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt",2023-05-17,2023,3,"Compress, Then Prompt: Improving Accuracy Efficiency Trade off of LLM Inference with Transferable Prompt ",2023-10-08,144.0,0.020833333333333332
Pre-Training to Learn in Context ,Pre-Training to Learn in Context,2023-05-16,2023,3,Pre Training to Learn in Context ,2023-10-08,145.0,0.020689655172413793
Toxicity Detection with Generative Prompt-based Inference ,Toxicity Detection with Generative Prompt-based Inference,2022-05-24,2022,10,Toxicity Detection with Generative Prompt based Inference ,2023-10-08,502.0,0.0199203187250996
Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer ,Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer,2023-03-03,2023,4,Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer ,2023-10-08,219.0,0.0182648401826484
Learning to Generate Task-Specific Adapters from Task Description ,Learning to Generate Task-Specific Adapters from Task Description,2021-01-02,2021,18,Learning to Generate Task Specific Adapters from Task Description ,2023-10-08,1009.0,0.017839444995044598
How Does In-Context Learning Help Prompt Tuning? ,How Does In-Context Learning Help Prompt Tuning?,2023-02-22,2023,4,How Does In Context Learning Help Prompt Tuning? ,2023-10-08,228.0,0.017543859649122806
À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting ,À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting,2023-02-15,2023,4,À la carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting ,2023-10-08,235.0,0.01702127659574468
PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents ,PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents,2023-05-23,2023,2,PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents ,2023-10-08,138.0,0.014492753623188406
In-Context Learning of Large Language Models Explained as Kernel Regression ,Explaining Emergent In-Context Learning as Kernel Regression,2023-05-22,2023,2,In Context Learning of Large Language Models Explained as Kernel Regression ,2023-10-08,139.0,0.014388489208633094
Model-tuning Via Prompts Makes NLP Models Adversarially Robust ,Model-tuning Via Prompts Makes NLP Models Adversarially Robust,2023-03-13,2023,3,Model tuning Via Prompts Makes NLP Models Adversarially Robust ,2023-10-08,209.0,0.014354066985645933
Dynamic Prompting: A Unified Framework for Prompt Tuning ,Dynamic Prompting: A Unified Framework for Prompt Tuning,2023-03-06,2023,3,Dynamic Prompting: A Unified Framework for Prompt Tuning ,2023-10-08,216.0,0.013888888888888888
CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge ,CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge,2023-05-17,2023,2,CooK: Empowering General Purpose Language Models with Modular and Collaborative Knowledge ,2023-10-08,144.0,0.013888888888888888
Satisfiability-Aided Language Models Using Declarative Prompting ,Satisfiability-Aided Language Models Using Declarative Prompting,2023-05-16,2023,2,Satisfiability Aided Language Models Using Declarative Prompting ,2023-10-08,145.0,0.013793103448275862
Fairness-guided Few-shot Prompting for Large Language Models ,Fairness-guided Few-shot Prompting for Large Language Models,2023-03-23,2023,2,Fairness guided Few shot Prompting for Large Language Models ,2023-10-08,199.0,0.010050251256281407
CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification ,CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification,2023-03-07,2023,2,CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification ,2023-10-08,215.0,0.009302325581395349
Mixture of Soft Prompts for Controllable Data Generation ,Mixture of Soft Prompts for Controllable Data Generation,2023-03-02,2023,2,Mixture of Soft Prompts for Controllable Data Generation ,2023-10-08,220.0,0.00909090909090909
Exploring Lottery Prompts for Pre-trained Language Models ,Exploring Lottery Prompts for Pre-trained Language Models,2023-05-31,2023,1,Exploring Lottery Prompts for Pre trained Language Models ,2023-10-08,130.0,0.007692307692307693
Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses ,Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses,2023-05-30,2023,1,Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses ,2023-10-08,131.0,0.007633587786259542
ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs ,ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs,2023-05-18,2023,1,ZeroPrompt: Streaming Acoustic Encoders are Zero Shot Masked LMs ,2023-10-08,143.0,0.006993006993006993
Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency ,Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency,2023-05-18,2023,1,Flatness Aware Prompt Selection Improves Accuracy and Sample Efficiency ,2023-10-08,143.0,0.006993006993006993
Scalable Prompt Generation for Semi-supervised Learning with Language Models ,Scalable Prompt Generation for Semi-supervised Learning with Language Models,2023-02-18,2023,1,Scalable Prompt Generation for Semi supervised Learning with Language Models ,2023-10-08,232.0,0.004310344827586207
Global Prompt Cell: A Portable Control Module for Effective Prompt ,Global Prompt Cell: A Portable Control Module for Effective Prompt,2023-04-12,2023,0,Global Prompt Cell: A Portable Control Module for Effective Prompt ,2023-10-08,179.0,0.0
Revisiting Automated Prompting: Are We Actually Doing Better? ,Revisiting Automated Prompting: Are We Actually Doing Better?,2023-04-07,2023,0,Revisiting Automated Prompting: Are We Actually Doing Better? ,2023-10-08,184.0,0.0
Focused Prefix Tuning for Controllable Text Generation ,Focused Prefix Tuning for Controllable Text Generation,2023-06-01,2023,0,Focused Prefix Tuning for Controllable Text Generation ,2023-10-08,129.0,0.0
The Web Can Be Your Oyster for Improving Large Language Models ,The Web Can Be Your Oyster for Improving Large Language Models,2023-05-18,2023,0,The Web Can Be Your Oyster for Improving Large Language Models ,2023-10-08,143.0,0.0
Universality and Limitations of Prompt Tuning ,Universality and Limitations of Prompt Tuning,2023-05-30,2023,0,Universality and Limitations of Prompt Tuning ,2023-10-08,131.0,0.0
MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting ,MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting,2023-05-26,2023,0,MultiTool CoT: GPT 3 Can Use Multiple External Tools with Chain of Thought Prompting ,2023-10-08,135.0,0.0
TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding ,TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding,2023-05-19,2023,0,TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding ,2023-10-08,142.0,0.0
Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models ,Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models,,2023,2,Chain of Symbol Prompting Elicits Planning in Large Langauge Models ,2023-10-08,,
Reflexion: an autonomous agent with dynamic memory and self-reflection ,Reflexion: an autonomous agent with dynamic memory and self-reflection,,2023,89,Reflexion: an autonomous agent with dynamic memory and self reflection ,2023-10-08,,
Effectiveness of Data Augmentation for Prefix Tuning with Limited Data ,Effectiveness of Data Augmentation for Prefix Tuning with Limited Data,,2023,0,Effectiveness of Data Augmentation for Prefix Tuning with Limited Data ,2023-10-08,,
On the Advance of Making Language Models Better Reasoners ,On the Advance of Making Language Models Better Reasoners,,2022,100,On the Advance of Making Language Models Better Reasoners ,2023-10-08,,
