{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Popularity of Prompt Engineering Methods\n",
    "\n",
    "This series of notebooks produces statistics on Semantic Scholar citations per day for all of the prompt engineering approaches listed at \"https://www.promptingguide.ai/papers\", \"https://en.wikipedia.org/wiki/Prompt_engineering#Text-to-text\", and the citations section for \"The Practicality of Prompt Engineering\".\n",
    "\n",
    "This file performs web scraping and an initial request for the citation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:54:45.361669\n"
     ]
    }
   ],
   "source": [
    "# Print current datetime/run as of date\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\"><head><script charset=\"utf-8\" src=\"//web-static.archive.org/_static/js/bundle-playback.js?v=6XRi73ky\" type=\"text/javascript\"></script>\n",
      "<script charset=\"utf-8\" src=\"//web-static.archive.org/_static/js/wombat.js?v=txqj7nKC\" type=\"text/javascript\"></script>\n",
      "<script>window.RufflePlayer=window.RufflePlayer||{};window.RufflePlayer.config={\"autoplay\":\"on\",\"unmuteOverlay\":\"hidden\"};</script>\n",
      "<script src=\"//web-static.archive.org/_static/js/ruffle.js\" type=\"text/javascript\"></script>\n",
      "<script type=\"text/javascript\">\n",
      "  __wm.init(\"https://web.archive.org/web\");\n",
      "  __wm.wombat(\"https://www.promptingguide.ai/papers\",\"20231022192048\",\"https://web.archive.org/\",\"web\",\"//web-static.archive.org/_static/\",\n",
      "\t      \"1698002448\");\n",
      "</script>\n",
      "<link href=\"//web-static.archive.org/_static/css/banner-styles.css?v=S1zqJCYt\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"//web-static.archive.org/_static/css/iconochive.css?v=qtvMKcIJ\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<!-- End Wayback Rewrite JS Include -->\n",
      "<meta charset=\"utf-8\"/><meta content=\"index,follow\" name=\"robots\"/><meta content=\"Papers â€“ Nextra\" property=\"og:title\"/><meta content=\"#111\" media=\"(prefers-color-scheme: dark)\" name=\"theme-color\"/><style>\n",
      "        :root {\n",
      "          --nextra-primary-hue: 212deg;\n",
      "          --nextra-primary-saturation: 100%;\n",
      "          --nextra-navbar-height: 4rem;\n",
      "          --nextra-menu-height: 3.75rem;\n",
      "          --nextra-banner-height: 2.5rem;\n",
      "        }\n",
      "        \n",
      "        .dark {\n",
      "          --nextra-primary-hue: 204deg;\n",
      "          --nextra-primary-saturation: 100%;\n",
      "        }\n",
      "      </style><title>Papers | Prompt Engineering Guide<!-- --> </title><meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/><meta content=\"Prompt Engineering Guide\" property=\"og:title\"/><meta content=\"A Comprehensive Overview of Prompt Engineering\" property=\"og:description\"/><meta content=\"Papers | Prompt Engineering Guide\" name=\"og:title\"/><link href=\"/web/20231022192048im_/https://www.promptingguide.ai/144-favicon.svg\" rel=\"icon\" type=\"image/svg+xml\"/><link href=\"/web/20231022192048im_/https://www.promptingguide.ai/144-favicon-dark.svg\" media=\"(prefers-color-scheme: dark)\" rel=\"icon\" type=\"image/svg+xml\"/><meta content=\"12\" name=\"next-head-count\"/><link as=\"style\" href=\"/web/20231022192048/https://www.promptingguide.ai/_next/static/css/01662fb982270926.css\" rel=\"preload\"/><link data-n-g=\"\" href=\"/web/20231022192048cs_/https://www.promptingguide.ai/_next/static/css/01662fb982270926.css\" rel=\"stylesheet\"/><link as=\"style\" href=\"/web/20231022192048/https://www.promptingguide.ai/_next/static/css/78d4b83747a207ea.css\" rel=\"preload\"/><link data-n-p=\"\" href=\"/web/20231022192048cs_/https://www.promptingguide.ai/_next/static/css/78d4b83747a207ea.css\" rel=\"stylesheet\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/webpack-52f729f10091b61d.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/framework-c8e271832a0ddee4.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/main-ace3164b2260599b.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/pages/_app-0cb34192a0a0be90.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/14221-49164cdaced62cfa.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/chunks/pages/papers.en-9ff16272dda05620.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/Tj-HSFLL6IMs8Gz9xA-Wi/_buildManifest.js\"></script><script defer=\"\" src=\"/web/20231022192048js_/https://www.promptingguide.ai/_next/static/Tj-HSFLL6IMs8Gz9xA-Wi/_ssgManifest.js\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div dir=\"ltr\"><script>document.documentElement.setAttribute('dir','ltr')</script><div class=\"nextra-nav-container nx-sticky nx-top-0 nx-z-20 nx-w-full nx-bg-transparent print:nx-hidden\"><div class=\"nextra-nav-container-blur nx-pointer-events-none nx-absolute nx-z-[-1] nx-h-full nx-w-full nx-bg-white dark:nx-bg-dark nx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] dark:nx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:nx-shadow-[0_0_0_1px_#000] contrast-more:dark:nx-shadow-[0_0_0_1px_#fff]\"></div><nav class=\"nx-mx-auto nx-flex nx-h-[var(--nextra-navbar-height)] nx-max-w-[90rem] nx-items-center nx-justify-end nx-gap-2 nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]\"><a class=\"nx-flex nx-items-center hover:nx-opacity-75 ltr:nx-mr-auto rtl:nx-ml-auto\" href=\"/web/20231022192048/https://www.promptingguide.ai/\"><svg fill=\"none\" height=\"24\" viewbox=\"0 0 206 246\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"40\" cy=\"40\" fill=\"currentColor\" r=\"40\"></circle><circle cx=\"40\" cy=\"206\" fill=\"currentColor\" r=\"40\"></circle><circle cx=\"166\" cy=\"120\" fill=\"currentColor\" r=\"40\"></circle></svg><span style=\"margin-left:.4em;font-weight:800\">Prompt Engineering Guide</span></a><a aria-current=\"false\" class=\"nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200\" href=\"/web/20231022192048/https://www.promptingguide.ai/course\"><span class=\"nx-absolute nx-inset-x-0 nx-text-center\">Prompt Engineering Course</span><span class=\"nx-invisible nx-font-medium\">Prompt Engineering Course</span></a><a aria-current=\"false\" class=\"nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200\" href=\"/web/20231022192048/https://www.promptingguide.ai/services\"><span class=\"nx-absolute nx-inset-x-0 nx-text-center\">Services</span><span class=\"nx-invisible nx-font-medium\">Services</span></a><a aria-current=\"false\" class=\"nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200\" href=\"/web/20231022192048/https://www.promptingguide.ai/about\"><span class=\"nx-absolute nx-inset-x-0 nx-text-center\">About</span><span class=\"nx-invisible nx-font-medium\">About</span></a><div class=\"nextra-search nx-relative md:nx-w-64 nx-hidden md:nx-inline-block mx-min-w-[200px]\"><div class=\"nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300\"><input class=\"nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current\" placeholder=\"Search...\" spellcheck=\"false\" type=\"search\" value=\"\"/></div></div><a class=\"nx-p-2 nx-text-current\" href=\"https://web.archive.org/web/20231022192048/https://github.com/dair-ai/Prompt-Engineering-Guide\" rel=\"noreferrer\" target=\"_blank\"><svg fill=\"currentColor\" height=\"24\" viewbox=\"3 3 18 18\" width=\"24\"><title>GitHub</title><path d=\"M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z\"></path></svg><span class=\"nx-sr-only\">GitHub</span><span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a><a class=\"nx-p-2 nx-text-current\" href=\"https://web.archive.org/web/20231022192048/https://discord.gg/FUyz9vPAwf\" rel=\"noreferrer\" target=\"_blank\"><svg fill=\"currentColor\" height=\"24\" viewbox=\"0 5 30.67 23.25\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\"><title>Discord</title><path d=\"M26.0015 6.9529C24.0021 6.03845 21.8787 5.37198 19.6623 5C19.3833 5.48048 19.0733 6.13144 18.8563 6.64292C16.4989 6.30193 14.1585 6.30193 11.8336 6.64292C11.6166 6.13144 11.2911 5.48048 11.0276 5C8.79575 5.37198 6.67235 6.03845 4.6869 6.9529C0.672601 12.8736 -0.41235 18.6548 0.130124 24.3585C2.79599 26.2959 5.36889 27.4739 7.89682 28.2489C8.51679 27.4119 9.07477 26.5129 9.55525 25.5675C8.64079 25.2265 7.77283 24.808 6.93587 24.312C7.15286 24.1571 7.36986 23.9866 7.57135 23.8161C12.6241 26.1255 18.0969 26.1255 23.0876 23.8161C23.3046 23.9866 23.5061 24.1571 23.7231 24.312C22.8861 24.808 22.0182 25.2265 21.1037 25.5675C21.5842 26.5129 22.1422 27.4119 22.7621 28.2489C25.2885 27.4739 27.8769 26.2959 30.5288 24.3585C31.1952 17.7559 29.4733 12.0212 26.0015 6.9529ZM10.2527 20.8402C8.73376 20.8402 7.49382 19.4608 7.49382 17.7714C7.49382 16.082 8.70276 14.7025 10.2527 14.7025C11.7871 14.7025 13.0425 16.082 13.0115 17.7714C13.0115 19.4608 11.7871 20.8402 10.2527 20.8402ZM20.4373 20.8402C18.9183 20.8402 17.6768 19.4608 17.6768 17.7714C17.6768 16.082 18.8873 14.7025 20.4373 14.7025C21.9717 14.7025 23.2271 16.082 23.1961 17.7714C23.1961 19.4608 21.9872 20.8402 20.4373 20.8402Z\"></path></svg><span class=\"nx-sr-only\">Discord</span><span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a><button aria-label=\"Menu\" class=\"nextra-hamburger -nx-mr-2 nx-rounded nx-p-2 active:nx-bg-gray-400/20 md:nx-hidden\" type=\"button\"><svg class=\"\" fill=\"none\" height=\"24\" stroke=\"currentColor\" viewbox=\"0 0 24 24\" width=\"24\"><g><path d=\"M4 6h16\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></g><path d=\"M4 12h16\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path><g><path d=\"M4 18h16\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></g></svg></button></nav></div><div class=\"nx-mx-auto nx-flex nx-max-w-[90rem]\"><div class=\"motion-reduce:nx-transition-none [transition:background-color_1.5s_ease] nx-bg-transparent\"></div><aside class=\"nextra-sidebar-container nx-flex nx-flex-col md:nx-top-16 md:nx-shrink-0 motion-reduce:nx-transform-none nx-transform-gpu nx-transition-all nx-ease-in-out print:nx-hidden md:nx-w-64 md:nx-sticky md:nx-self-start max-md:[transform:translate3d(0,-100%,0)]\"><div class=\"nx-px-4 nx-pt-4 md:nx-hidden\"><div class=\"nextra-search nx-relative md:nx-w-64\"><div class=\"nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300\"><input class=\"nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current\" placeholder=\"Search...\" spellcheck=\"false\" type=\"search\" value=\"\"/></div></div></div><div class=\"nx-overflow-y-auto nx-overflow-x-hidden nx-p-4 nx-grow md:nx-h-[calc(100vh-var(--nextra-navbar-height)-var(--nextra-menu-height))] nextra-scrollbar\"><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100\"><ul class=\"nx-flex nx-flex-col nx-gap-1 nextra-menu-desktop max-md:nx-hidden\"><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/\">Prompt Engineering</a></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/introduction\">Introduction<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/introduction/settings\">LLM Settings</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/introduction/basics\">Basics of Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/introduction/elements\">Prompt Elements</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/introduction/tips\">General Tips for Designing Prompts</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/introduction/examples\">Examples of Prompts</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques\">Techniques<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/zeroshot\">Zero-shot Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/fewshot\">Few-shot Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/cot\">Chain-of-Thought Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/consistency\">Self-Consistency</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/knowledge\">Generate Knowledge Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/tot\">Tree of Thoughts</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/rag\">Retrieval Augmented Generation</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/art\">Automatic Reasoning and Tool-use</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/ape\">Automatic Prompt Engineer</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/activeprompt\">Active-Prompt</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/dsp\">Directional Stimulus Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/react\">ReAct</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/multimodalcot\">Multimodal CoT</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/techniques/graph\">Graph Prompting</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications\">Applications<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/pal\">Program-Aided Language Models</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/generating\">Generating Data</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/synthetic_rag\">Generating Synthetic Dataset for RAG</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/generating_textbooks\">Tackling Generated Datasets Diversity</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/coding\">Generating Code</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/workplace_casestudy\">Graduate Job Classification Case Study</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/applications/pf\">Prompt Function</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/models\">Models<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/models/flan\">Flan</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/models/chatgpt\">ChatGPT</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/models/llama\">LLaMA</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/models/gpt-4\">GPT-4</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/models/collection\">LLM Collection</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/risks\">Risks &amp; Misuses<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/risks/adversarial\">Adversarial Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/risks/factuality\">Factuality</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/risks/biases\">Biases</a></li></ul></div></div></li><li class=\"nx-flex nx-flex-col nx-gap-1 active\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-bg-primary-100 nx-font-semibold nx-text-primary-800 dark:nx-bg-primary-400/10 dark:nx-text-primary-600 contrast-more:nx-border-primary-500 contrast-more:dark:nx-border-primary-500\" href=\"/web/20231022192048/https://www.promptingguide.ai/papers\">Papers</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/tools\">Tools</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/notebooks\">Notebooks</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/datasets\">Datasets</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231022192048/https://www.promptingguide.ai/readings\">Additional Readings</a></li></ul></div></div></div><div class=\"nx-sticky nx-bottom-0 nx-bg-white dark:nx-bg-dark nx-mx-4 nx-py-4 nx-shadow-[0_-12px_16px_#fff] nx-flex nx-items-center nx-gap-2 dark:nx-border-neutral-800 dark:nx-shadow-[0_-12px_16px_#111] contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-shadow-none nx-justify-end nx-border-t\" data-toggle-animation=\"off\"><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 nx-grow\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R4v6pm:\" title=\"Change language\" type=\"button\"><span class=\"nx-flex nx-items-center nx-gap-2\"><svg fill=\"currentColor\" height=\"12\" viewbox=\"2 2 16 16\" width=\"12\"><path clip-rule=\"evenodd\" d=\"M4.083 9h1.946c.089-1.546.383-2.97.837-4.118A6.004 6.004 0 004.083 9zM10 2a8 8 0 100 16 8 8 0 000-16zm0 2c-.076 0-.232.032-.465.262-.238.234-.497.623-.737 1.182-.389.907-.673 2.142-.766 3.556h3.936c-.093-1.414-.377-2.649-.766-3.556-.24-.56-.5-.948-.737-1.182C10.232 4.032 10.076 4 10 4zm3.971 5c-.089-1.546-.383-2.97-.837-4.118A6.004 6.004 0 0115.917 9h-1.946zm-2.003 2H8.032c.093 1.414.377 2.649.766 3.556.24.56.5.948.737 1.182.233.23.389.262.465.262.076 0 .232-.032.465-.262.238-.234.498-.623.737-1.182.389-.907.673-2.142.766-3.556zm1.166 4.118c.454-1.147.748-2.572.837-4.118h1.946a6.004 6.004 0 01-2.783 4.118zm-6.268 0C6.412 13.97 6.118 12.546 6.03 11H4.083a6.004 6.004 0 002.783 4.118z\" fill-rule=\"evenodd\"></path></svg><span class=\"\">English</span></span></button><div class=\"\"><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R5f6pm:\" title=\"Change theme\" type=\"button\"><div class=\"nx-flex nx-items-center nx-gap-2 nx-capitalize\"><svg fill=\"none\" height=\"12\" stroke=\"currentColor\" viewbox=\"3 3 18 18\" width=\"12\"><path d=\"M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg><span class=\"md:nx-hidden\">Light</span></div></button></div></div></aside><nav aria-label=\"table of contents\" class=\"nextra-toc nx-order-last nx-hidden nx-w-64 nx-shrink-0 xl:nx-block print:nx-hidden nx-px-4\"><div class=\"nextra-scrollbar nx-sticky nx-top-16 nx-overflow-y-auto nx-pr-4 nx-pt-6 nx-text-sm [hyphens:auto] nx-max-h-[calc(100vh-var(--nextra-navbar-height)-env(safe-area-inset-bottom))] ltr:-nx-mr-4 rtl:-nx-ml-4\"><p class=\"nx-mb-4 nx-font-semibold nx-tracking-tight\">On This Page</p><ul><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#overviews\">Overviews</a></li><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#approaches\">Approaches</a></li><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#applications\">Applications</a></li><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#collections\">Collections</a></li></ul><div class=\"nx-mt-8 nx-border-t nx-bg-white nx-pt-8 nx-shadow-[0_-12px_16px_white] dark:nx-bg-dark dark:nx-shadow-[0_-12px_16px_#111] nx-sticky nx-bottom-0 nx-flex nx-flex-col nx-items-start nx-gap-2 nx-pb-8 dark:nx-border-neutral-800 contrast-more:nx-border-t contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-border-neutral-400\"><a class=\"nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50\" href=\"https://web.archive.org/web/20231022192048/https://github.com/dair-ai/Prompt-Engineering-Guide/issues/new?title=Feedback%20for%20%E2%80%9CPapers%E2%80%9D&amp;labels=feedback\" rel=\"noreferrer\" target=\"_blank\">Question? Give us feedback â†’<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a><a class=\"nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50\" href=\"https://web.archive.org/web/20231022192048/https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/pages/papers.en.mdx\">Edit this page</a></div></div></nav><div id=\"reach-skip-nav\"></div><article class=\"nx-w-full nx-break-words nextra-content nx-flex nx-min-h-[calc(100vh-var(--nextra-navbar-height))] nx-min-w-0 nx-justify-center nx-pb-8 nx-pr-[calc(env(safe-area-inset-right)-1.5rem)]\"><main class=\"nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12\"><div class=\"nextra-breadcrumb nx-mt-1.5 nx-flex nx-items-center nx-gap-1 nx-overflow-hidden nx-text-sm nx-text-gray-500 dark:nx-text-gray-400 contrast-more:nx-text-current\"><div class=\"nx-whitespace-nowrap nx-transition-colors nx-font-medium nx-text-gray-700 contrast-more:nx-font-bold contrast-more:nx-text-current dark:nx-text-gray-100 contrast-more:dark:nx-text-current\" title=\"Papers\">Papers</div></div><h1 class=\"nx-mt-2 nx-text-4xl nx-font-bold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100\">Papers</h1>\n",
      "<p class=\"nx-mt-6 nx-leading-7 first:nx-mt-0\">The following are the latest papers (sorted by release date) on prompt engineering for large language models (LLMs). We update the list of papers on a daily/weekly basis.</p>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Overviews<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#overviews\" id=\"overviews\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2310.06147\" rel=\"noreferrer\" target=\"_blank\">An RL Perspective on RLHF, Prompting, and Beyond<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.16938\" rel=\"noreferrer\" target=\"_blank\">Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13860\" rel=\"noreferrer\" target=\"_blank\">Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.13712\" rel=\"noreferrer\" target=\"_blank\">Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.08354\" rel=\"noreferrer\" target=\"_blank\">Tool Learning with Foundation Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.06488\" rel=\"noreferrer\" target=\"_blank\">One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.02020\" rel=\"noreferrer\" target=\"_blank\">A Bibliometric Review of Large Language Models Research from 2017 to 2023<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.18223\" rel=\"noreferrer\" target=\"_blank\">A Survey of Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.14725\" rel=\"noreferrer\" target=\"_blank\">Nature Language Reasoning, A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.07842\" rel=\"noreferrer\" target=\"_blank\">Augmented Language Models: a Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2301.00234\" rel=\"noreferrer\" target=\"_blank\">A Survey for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.10403\" rel=\"noreferrer\" target=\"_blank\">Towards Reasoning in Large Language Models: A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.09597\" rel=\"noreferrer\" target=\"_blank\">Reasoning with Language Model Prompting: A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2206.07682\" rel=\"noreferrer\" target=\"_blank\">Emergent Abilities of Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2204.13988\" rel=\"noreferrer\" target=\"_blank\">A Taxonomy of Prompt Modifiers for Text-To-Image Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2107.13586\" rel=\"noreferrer\" target=\"_blank\">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2021)</li>\n",
      "</ul>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Approaches<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#approaches\" id=\"approaches\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.06653\" rel=\"noreferrer\" target=\"_blank\">Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.11495\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Verification Reduces Hallucination in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08532\" rel=\"noreferrer\" target=\"_blank\">Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.04269\" rel=\"noreferrer\" target=\"_blank\">From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.06275\" rel=\"noreferrer\" target=\"_blank\">Re-Reading Improves Reasoning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.09687v2\" rel=\"noreferrer\" target=\"_blank\">Graph of Thoughts: Solving Elaborate Problems with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2307.15337\" rel=\"noreferrer\" target=\"_blank\">Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00369\" rel=\"noreferrer\" target=\"_blank\">Focused Prefix Tuning for Controllable Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19500\" rel=\"noreferrer\" target=\"_blank\">Exploring Lottery Prompts for Pre-trained Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19339\" rel=\"noreferrer\" target=\"_blank\">Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.20050\" rel=\"noreferrer\" target=\"_blank\">Let's Verify Step by Step<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.18787\" rel=\"noreferrer\" target=\"_blank\">Universality and Limitations of Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.16896\" rel=\"noreferrer\" target=\"_blank\">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14564v1\" rel=\"noreferrer\" target=\"_blank\">PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14992v1\" rel=\"noreferrer\" target=\"_blank\">Reasoning with Language Model is Planning with World Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13733\" rel=\"noreferrer\" target=\"_blank\">Self-Critique Prompting with Large Language Models for Inductive Instructions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14106\" rel=\"noreferrer\" target=\"_blank\">Better Zero-Shot Reasoning with Self-Adaptive Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14257\" rel=\"noreferrer\" target=\"_blank\">Hierarchical Prompting Assists Large Language Model on Web Navigation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13246\" rel=\"noreferrer\" target=\"_blank\">Interactive Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12740\" rel=\"noreferrer\" target=\"_blank\">Can We Edit Factual Knowledge by In-Context Learning?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12766\" rel=\"noreferrer\" target=\"_blank\">In-Context Learning of Large Language Models Explained as Kernel Regression<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.04091v3\" rel=\"noreferrer\" target=\"_blank\">Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12907\" rel=\"noreferrer\" target=\"_blank\">Meta-in-context learning in large language models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11860\" rel=\"noreferrer\" target=\"_blank\">Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11426\" rel=\"noreferrer\" target=\"_blank\">Post Hoc Explanations of Language Models Can Improve Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11186\" rel=\"noreferrer\" target=\"_blank\">Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11497\" rel=\"noreferrer\" target=\"_blank\">TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11430\" rel=\"noreferrer\" target=\"_blank\">TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11170\" rel=\"noreferrer\" target=\"_blank\">Efficient Prompting via Dynamic In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10998\" rel=\"noreferrer\" target=\"_blank\">The Web Can Be Your Oyster for Improving Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10713\" rel=\"noreferrer\" target=\"_blank\">Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10601\" rel=\"noreferrer\" target=\"_blank\">Tree of Thoughts: Deliberate Problem Solving with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10649\" rel=\"noreferrer\" target=\"_blank\">ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10276\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09955\" rel=\"noreferrer\" target=\"_blank\">CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09731\" rel=\"noreferrer\" target=\"_blank\">What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09993\" rel=\"noreferrer\" target=\"_blank\">Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09656\" rel=\"noreferrer\" target=\"_blank\">Satisfiability-Aided Language Models Using Declarative Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09137\" rel=\"noreferrer\" target=\"_blank\">Pre-Training to Learn in Context<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.05970\" rel=\"noreferrer\" target=\"_blank\">Boosted Prompt Ensembles for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.05642\" rel=\"noreferrer\" target=\"_blank\">Global Prompt Cell: A Portable Control Module for Effective Prompt<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.03843\" rel=\"noreferrer\" target=\"_blank\">Why think step-by-step? Reasoning emerges from the locality of experience<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.03609\" rel=\"noreferrer\" target=\"_blank\">Revisiting Automated Prompting: Are We Actually Doing Better?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.01904\" rel=\"noreferrer\" target=\"_blank\">REFINER: Reasoning Feedback on Intermediate Representations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.11366\" rel=\"noreferrer\" target=\"_blank\">Reflexion: an autonomous agent with dynamic memory and self-reflection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.17760\" rel=\"noreferrer\" target=\"_blank\">CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.17651v1\" rel=\"noreferrer\" target=\"_blank\">Self-Refine: Iterative Refinement with Self-Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.13824\" rel=\"noreferrer\" target=\"_blank\">kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.13283\" rel=\"noreferrer\" target=\"_blank\">Visual-Language Prompt Tuning with Knowledge-guided Context Optimization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.13217\" rel=\"noreferrer\" target=\"_blank\">Fairness-guided Few-shot Prompting for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.11315\" rel=\"noreferrer\" target=\"_blank\">Context-faithful Prompting for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.10475\" rel=\"noreferrer\" target=\"_blank\">Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.08518\" rel=\"noreferrer\" target=\"_blank\">UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.07320\" rel=\"noreferrer\" target=\"_blank\">Model-tuning Via Prompts Makes NLP Models Adversarially Robust<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.03922\" rel=\"noreferrer\" target=\"_blank\">Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.03628\" rel=\"noreferrer\" target=\"_blank\">CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.03846\" rel=\"noreferrer\" target=\"_blank\">Larger language models do in-context learning differently<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.02913\" rel=\"noreferrer\" target=\"_blank\">OpenICL: An Open-Source Framework for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.02909\" rel=\"noreferrer\" target=\"_blank\">Dynamic Prompting: A Unified Framework for Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.09014\" rel=\"noreferrer\" target=\"_blank\">ART: Automatic multi-step reasoning and tool-use for large language models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.02861\" rel=\"noreferrer\" target=\"_blank\">Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.02577\" rel=\"noreferrer\" target=\"_blank\">Effectiveness of Data Augmentation for Prefix Tuning with Limited Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.01580\" rel=\"noreferrer\" target=\"_blank\">Mixture of Soft Prompts for Controllable Data Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.02151\" rel=\"noreferrer\" target=\"_blank\">Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.00293\" rel=\"noreferrer\" target=\"_blank\">How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/pdf/2302.10198.pdf\" rel=\"noreferrer\" target=\"_blank\">Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.14838\" rel=\"noreferrer\" target=\"_blank\">EvoPrompting: Language Models for Code-Level Neural Architecture Search<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.14691\" rel=\"noreferrer\" target=\"_blank\">In-Context Instruction Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.02676\" rel=\"noreferrer\" target=\"_blank\">Chain of Hindsight Aligns Language Models with Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.14045\" rel=\"noreferrer\" target=\"_blank\">Language Is Not All You Need: Aligning Perception with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12822\" rel=\"noreferrer\" target=\"_blank\">Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12246\" rel=\"noreferrer\" target=\"_blank\">Active Prompting with Chain-of-Thought for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12173\" rel=\"noreferrer\" target=\"_blank\">More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.11382\" rel=\"noreferrer\" target=\"_blank\">A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.11520\" rel=\"noreferrer\" target=\"_blank\">Guiding Large Language Models via Directional Stimulus Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.11521\" rel=\"noreferrer\" target=\"_blank\">How Does In-Context Learning Help Prompt Tuning?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.09236\" rel=\"noreferrer\" target=\"_blank\">Scalable Prompt Generation for Semi-supervised Learning with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.09185\" rel=\"noreferrer\" target=\"_blank\">Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.07994\" rel=\"noreferrer\" target=\"_blank\">Ã€-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.08043\" rel=\"noreferrer\" target=\"_blank\">GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.07459\" rel=\"noreferrer\" target=\"_blank\">The Capacity for Moral Self-Correction in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.06868\" rel=\"noreferrer\" target=\"_blank\">SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.05619\" rel=\"noreferrer\" target=\"_blank\">Evaluating the Robustness of Discrete Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.05698\" rel=\"noreferrer\" target=\"_blank\">Compositional Exemplars for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.03668\" rel=\"noreferrer\" target=\"_blank\">Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.00923\" rel=\"noreferrer\" target=\"_blank\">Multimodal Chain-of-Thought Reasoning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.00093\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Can Be Easily Distracted by Irrelevant Context<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.00618\" rel=\"noreferrer\" target=\"_blank\">Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2301.12314\" rel=\"noreferrer\" target=\"_blank\">Progressive Prompts: Continual Learning for Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2301.08721\" rel=\"noreferrer\" target=\"_blank\">Batch Prompting: Efficient Inference with LLM APIs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.14024\" rel=\"noreferrer\" target=\"_blank\">Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.08061\" rel=\"noreferrer\" target=\"_blank\">On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.08073\" rel=\"noreferrer\" target=\"_blank\">Constitutional AI: Harmlessness from AI Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.04092\" rel=\"noreferrer\" target=\"_blank\">Successive Prompting for Decomposing Complex Questions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.09561v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are reasoners with Self-Verification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.09251\" rel=\"noreferrer\" target=\"_blank\">Discovering Language Model Behaviors with Model-Written Evaluations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.06713\" rel=\"noreferrer\" target=\"_blank\">Structured Prompting: Scaling In-Context Learning to 1,000 Examples<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2211.10435\" rel=\"noreferrer\" target=\"_blank\">PAL: Program-aided Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2211.01910\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Are Human-Level Prompt Engineers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2211.09527\" rel=\"noreferrer\" target=\"_blank\">Ignore Previous Prompt: Attack Techniques For Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.07321\" rel=\"noreferrer\" target=\"_blank\">Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2211.09066\" rel=\"noreferrer\" target=\"_blank\">Teaching Algorithmic Reasoning via In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2211.11875\" rel=\"noreferrer\" target=\"_blank\">Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for\" rel=\"noreferrer\" target=\"_blank\">Ask Me Anything: A simple strategy for prompting language models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.01296\" rel=\"noreferrer\" target=\"_blank\">Recitation-Augmented Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.03629\" rel=\"noreferrer\" target=\"_blank\">ReAct: Synergizing Reasoning and Acting in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.09150\" rel=\"noreferrer\" target=\"_blank\">Prompting GPT-3 To Be Reliable<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.02406\" rel=\"noreferrer\" target=\"_blank\">Decomposed Prompting: A Modular Approach for Solving Complex Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.03493\" rel=\"noreferrer\" target=\"_blank\">Automatic Chain of Thought Prompting in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.01240v3\" rel=\"noreferrer\" target=\"_blank\">Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2209.02128\" rel=\"noreferrer\" target=\"_blank\">Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2209.14610\" rel=\"noreferrer\" target=\"_blank\">Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2209.11755\" rel=\"noreferrer\" target=\"_blank\">Promptagator: Few-shot Dense Retrieval From 8 Examples<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2208.03299\" rel=\"noreferrer\" target=\"_blank\">Atlas: Few-shot Learning with Retrieval Augmented Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2207.05987\" rel=\"noreferrer\" target=\"_blank\">DocPrompting: Generating Code by Retrieving the Docs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2206.02336\" rel=\"noreferrer\" target=\"_blank\">On the Advance of Making Language Models Better Reasoners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2205.11916\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are Zero-Shot Reasoners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2205.11822\" rel=\"noreferrer\" target=\"_blank\">Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2205.00445\" rel=\"noreferrer\" target=\"_blank\">MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://aclanthology.org/2022.acl-long.576/\" rel=\"noreferrer\" target=\"_blank\">PPT: Pre-trained Prompt Tuning for Few-shot Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (Mqy 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2205.12390\" rel=\"noreferrer\" target=\"_blank\">Toxicity Detection with Generative Prompt-based Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2205.01543\" rel=\"noreferrer\" target=\"_blank\">Learning to Transfer Prompts for Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2205.03401\" rel=\"noreferrer\" target=\"_blank\">The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2204.13988\" rel=\"noreferrer\" target=\"_blank\">A Taxonomy of Prompt Modifiers for Text-To-Image Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2203.06566\" rel=\"noreferrer\" target=\"_blank\">PromptChainer: Chaining Large Language Model Prompts through Visual Programming<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2203.11171\" rel=\"noreferrer\" target=\"_blank\">Self-Consistency Improves Chain of Thought Reasoning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2203.02155\" rel=\"noreferrer\" target=\"_blank\">Training language models to follow instructions with human feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2202.12837\" rel=\"noreferrer\" target=\"_blank\">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2201.11903\" rel=\"noreferrer\" target=\"_blank\">Chain of Thought Prompting Elicits Reasoning in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2112.00114\" rel=\"noreferrer\" target=\"_blank\">Show Your Work: Scratchpads for Intermediate Computation with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2110.01691\" rel=\"noreferrer\" target=\"_blank\">AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2110.08387\" rel=\"noreferrer\" target=\"_blank\">Generated Knowledge Prompting for Commonsense Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2110.08207\" rel=\"noreferrer\" target=\"_blank\">Multitask Prompted Training Enables Zero-Shot Task Generalization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2109.07830\" rel=\"noreferrer\" target=\"_blank\">Reframing Instructional Prompts to GPTk's Language<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2109.06977\" rel=\"noreferrer\" target=\"_blank\">Design Guidelines for Prompt Engineering Text-to-Image Generative Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://aclanthology.org/2021.acl-long.295\" rel=\"noreferrer\" target=\"_blank\">Making Pre-trained Language Models Better Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2104.08786\" rel=\"noreferrer\" target=\"_blank\">Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://aclanthology.org/2021.eacl-main.316\" rel=\"noreferrer\" target=\"_blank\">BERTese: Learning to Speak to BERT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2104.08691\" rel=\"noreferrer\" target=\"_blank\">The Power of Scale for Parameter-Efficient Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2102.07350\" rel=\"noreferrer\" target=\"_blank\">Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2102.09690\" rel=\"noreferrer\" target=\"_blank\">Calibrate Before Use: Improving Few-Shot Performance of Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2101.00190\" rel=\"noreferrer\" target=\"_blank\">Prefix-Tuning: Optimizing Continuous Prompts for Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2101.00420\" rel=\"noreferrer\" target=\"_blank\">Learning to Generate Task-Specific Adapters from Task Description<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2012.15723\" rel=\"noreferrer\" target=\"_blank\">Making Pre-trained Language Models Better Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://aclanthology.org/2020.emnlp-main.105/\" rel=\"noreferrer\" target=\"_blank\">Learning from Task Descriptions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2010.15980\" rel=\"noreferrer\" target=\"_blank\">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2005.14165\" rel=\"noreferrer\" target=\"_blank\">Language Models are Few-Shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know\" rel=\"noreferrer\" target=\"_blank\">How Can We Know What Language Models Know?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2001.08361\" rel=\"noreferrer\" target=\"_blank\">Scaling Laws for Neural Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2020)</li>\n",
      "</ul>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Applications<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#applications\" id=\"applications\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.15427\" rel=\"noreferrer\" target=\"_blank\">Graph Neural Prompting with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.15025\" rel=\"noreferrer\" target=\"_blank\">Large Language Model Alignment: A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.13339\" rel=\"noreferrer\" target=\"_blank\">Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.13205\" rel=\"noreferrer\" target=\"_blank\">A Practical Survey on Zero-shot Prompt Design for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.10687\" rel=\"noreferrer\" target=\"_blank\">EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.10359\" rel=\"noreferrer\" target=\"_blank\">Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.10238\" rel=\"noreferrer\" target=\"_blank\">PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.09708\" rel=\"noreferrer\" target=\"_blank\">LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.09558\" rel=\"noreferrer\" target=\"_blank\">Summarization is (Almost) Dead<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.09444\" rel=\"noreferrer\" target=\"_blank\">Investigating Zero- and Few-shot Generalization in Fact Verification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.09338\" rel=\"noreferrer\" target=\"_blank\">Performance of the Pre-Trained Large Language Model GPT-4 on Automated Short Answer Grading<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.09117\" rel=\"noreferrer\" target=\"_blank\">Contrastive Decoding Improves Reasoning in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08963\" rel=\"noreferrer\" target=\"_blank\">Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08590\" rel=\"noreferrer\" target=\"_blank\">Neural Machine Translation Models Can Learn to be Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08589\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Thought Reasoning is a Policy Improvement Operator<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08583\" rel=\"noreferrer\" target=\"_blank\">ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08541\" rel=\"noreferrer\" target=\"_blank\">When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08491\" rel=\"noreferrer\" target=\"_blank\">Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08303\" rel=\"noreferrer\" target=\"_blank\">Self-Consistent Narrative Prompts on Abductive Natural Language Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08210\" rel=\"noreferrer\" target=\"_blank\">Investigating Answerability of LLMs for Long-Form Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08140\" rel=\"noreferrer\" target=\"_blank\">PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.08008\" rel=\"noreferrer\" target=\"_blank\">An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.07990\" rel=\"noreferrer\" target=\"_blank\">Leveraging Contextual Information for Effective Entity Salience Detection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.06135\" rel=\"noreferrer\" target=\"_blank\">Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.05833\" rel=\"noreferrer\" target=\"_blank\">PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.04269\" rel=\"noreferrer\" target=\"_blank\">From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.04461\" rel=\"noreferrer\" target=\"_blank\">Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.02654\" rel=\"noreferrer\" target=\"_blank\">Zero-Resource Hallucination Prevention for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.02772\" rel=\"noreferrer\" target=\"_blank\">Certifying LLM Safety against Adversarial Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2309.02772\" rel=\"noreferrer\" target=\"_blank\">Improving Code Generation by Dynamic Temperature Sampling<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.13479\" rel=\"noreferrer\" target=\"_blank\">Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.13032\" rel=\"noreferrer\" target=\"_blank\">Financial News Analytics Using Fine-Tuned Llama 2 GPT Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.10335\" rel=\"noreferrer\" target=\"_blank\">A Study on Robustness and Reliability of Large Language Model Code Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.12890\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Vote: Prompting for Rare Disease Identification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.09583\" rel=\"noreferrer\" target=\"_blank\">WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.09658\" rel=\"noreferrer\" target=\"_blank\">Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.09687\" rel=\"noreferrer\" target=\"_blank\">Graph of Thoughts: Solving Elaborate Problems with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.09662\" rel=\"noreferrer\" target=\"_blank\">Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.08614\" rel=\"noreferrer\" target=\"_blank\">Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.05596\" rel=\"noreferrer\" target=\"_blank\">You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2308.05481\" rel=\"noreferrer\" target=\"_blank\">LLM As DBA<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00784\" rel=\"noreferrer\" target=\"_blank\">Interpretable Math Word Problem Solution Generation Via Step-by-step Planning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00774\" rel=\"noreferrer\" target=\"_blank\">In-Context Learning User Simulators for Task-Oriented Dialog Systems<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00739\" rel=\"noreferrer\" target=\"_blank\">SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00618\" rel=\"noreferrer\" target=\"_blank\">Effective Structured Prompting by Meta-Learning and Representative Verbalizer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00526\" rel=\"noreferrer\" target=\"_blank\">Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2306.00550\" rel=\"noreferrer\" target=\"_blank\">Chain-Of-Thought Prompting Under Streaming Batch: A Case Study<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19713\" rel=\"noreferrer\" target=\"_blank\">Red Teaming Language Model Detectors with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://shishirpatil.github.io/gorilla/\" rel=\"noreferrer\" target=\"_blank\">Gorilla: Large Language Model Connected with Massive APIs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19835\" rel=\"noreferrer\" target=\"_blank\">Deliberate then Generate: Enhanced Prompting Framework for Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19597\" rel=\"noreferrer\" target=\"_blank\">What does the Failure to Reason with \"Respectively\" in Zero/Few-Shot Settings Tell Us about Language Models?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19426\" rel=\"noreferrer\" target=\"_blank\">ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19308\" rel=\"noreferrer\" target=\"_blank\">SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19234\" rel=\"noreferrer\" target=\"_blank\">Grammar Prompting for Domain-Specific Language Generation with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19148\" rel=\"noreferrer\" target=\"_blank\">Mitigating Label Biases for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.18638\" rel=\"noreferrer\" target=\"_blank\">Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.19165\" rel=\"noreferrer\" target=\"_blank\">Strategic Reasoning with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.18869\" rel=\"noreferrer\" target=\"_blank\">Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.18189\" rel=\"noreferrer\" target=\"_blank\">Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.18170\" rel=\"noreferrer\" target=\"_blank\">Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.18156\" rel=\"noreferrer\" target=\"_blank\">Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17826\" rel=\"noreferrer\" target=\"_blank\">NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17812\" rel=\"noreferrer\" target=\"_blank\">Tab-CoT: Zero-shot Tabular Chain of Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17680\" rel=\"noreferrer\" target=\"_blank\">Evaluating GPT-3 Generated Explanations for Hateful Content Moderation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17653\" rel=\"noreferrer\" target=\"_blank\">Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\">[Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning]<a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17373\" rel=\"noreferrer\" target=\"_blank\">https://arxiv.org/abs/2305.17373<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a>) (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17306\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17256\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17147\" rel=\"noreferrer\" target=\"_blank\">Heterogeneous Value Evaluation for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17104\" rel=\"noreferrer\" target=\"_blank\">PromptNER: Prompt Locating and Typing for Named Entity Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13514v1\" rel=\"noreferrer\" target=\"_blank\">Small Language Models Improve Giants by Rewriting Their Outputs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.15771v1\" rel=\"noreferrer\" target=\"_blank\">On the Planning Abilities of Large Language Models -- A Critical Investigation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.16582\" rel=\"noreferrer\" target=\"_blank\">Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12600v1\" rel=\"noreferrer\" target=\"_blank\">PRODIGY: Enabling In-context Learning Over Graphs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.15525v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are Few-Shot Health Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.16367\" rel=\"noreferrer\" target=\"_blank\">Role-Play with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13299v1\" rel=\"noreferrer\" target=\"_blank\">Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12744v1\" rel=\"noreferrer\" target=\"_blank\">Fact-Checking Complex Claims with Program-Guided Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17126v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Models as Tool Makers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13016v2\" rel=\"noreferrer\" target=\"_blank\">Iterative Forward Tuning Boosts In-context Learning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.17390v1\" rel=\"noreferrer\" target=\"_blank\">SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13246v1\" rel=\"noreferrer\" target=\"_blank\">Interactive Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.02897v1\" rel=\"noreferrer\" target=\"_blank\">An automatically discovered chain-of-thought prompt generalizes to novel models and datasets<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.08291v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Model Guided Tree-of-Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.06983v1\" rel=\"noreferrer\" target=\"_blank\">Active Retrieval Augmented Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12544v1\" rel=\"noreferrer\" target=\"_blank\">A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.02317v1\" rel=\"noreferrer\" target=\"_blank\">Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09800v1\" rel=\"noreferrer\" target=\"_blank\">Mirages: On Anthropomorphism in Dialogue Systems<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.15324v1\" rel=\"noreferrer\" target=\"_blank\">Model evaluation for extreme risks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.04388v1\" rel=\"noreferrer\" target=\"_blank\">Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.02466v1\" rel=\"noreferrer\" target=\"_blank\">Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13723\" rel=\"noreferrer\" target=\"_blank\">PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.04757v2\" rel=\"noreferrer\" target=\"_blank\">Augmented Large Language Models with Parametric Knowledge Guiding<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13735\" rel=\"noreferrer\" target=\"_blank\">Aligning Large Language Models through Synthetic Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13775\" rel=\"noreferrer\" target=\"_blank\">Concept-aware Training Improves In-context Learning Ability of Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.05176v1\" rel=\"noreferrer\" target=\"_blank\">FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13785\" rel=\"noreferrer\" target=\"_blank\">Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13817\" rel=\"noreferrer\" target=\"_blank\">Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13826\" rel=\"noreferrer\" target=\"_blank\">\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13903\" rel=\"noreferrer\" target=\"_blank\">Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13917\" rel=\"noreferrer\" target=\"_blank\">Generating Data for Symbolic Language with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13972\" rel=\"noreferrer\" target=\"_blank\">Make a Choice! Knowledge Base Question Answering with In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14002\" rel=\"noreferrer\" target=\"_blank\">Improving Language Models via Plug-and-Play Retrieval Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14006\" rel=\"noreferrer\" target=\"_blank\">Multi-Granularity Prompts for Topic Shift Detection in Dialogue<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14045\" rel=\"noreferrer\" target=\"_blank\">The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14057\" rel=\"noreferrer\" target=\"_blank\">Can Language Models Understand Physical Concepts?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14069\" rel=\"noreferrer\" target=\"_blank\">Evaluating Factual Consistency of Summaries with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14128\" rel=\"noreferrer\" target=\"_blank\">Dr.ICL: Demonstration-Retrieved In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14171\" rel=\"noreferrer\" target=\"_blank\">Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14210\" rel=\"noreferrer\" target=\"_blank\">Skill-Based Few-Shot Selection for In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14215\" rel=\"noreferrer\" target=\"_blank\">Exploring Chain-of-Thought Style Prompting for Text-to-SQL<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14233\" rel=\"noreferrer\" target=\"_blank\">Enhancing Chat Language Models by Scaling High-quality Instructional Conversations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14239\" rel=\"noreferrer\" target=\"_blank\">On Learning to Summarize with Large Language Models as References<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14259\" rel=\"noreferrer\" target=\"_blank\">Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14264\" rel=\"noreferrer\" target=\"_blank\">Active Learning Principles for In-Context Learning with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14279\" rel=\"noreferrer\" target=\"_blank\">Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14325\" rel=\"noreferrer\" target=\"_blank\">Improving Factuality and Reasoning in Language Models through Multiagent Debate<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14323\" rel=\"noreferrer\" target=\"_blank\">ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on\\ Chat-based Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14292\" rel=\"noreferrer\" target=\"_blank\">WikiChat: A Few-Shot LLM-Based Chatbot Grounded with Wikipedia<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.14283\" rel=\"noreferrer\" target=\"_blank\">Query Rewriting for Retrieval-Augmented Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13729\" rel=\"noreferrer\" target=\"_blank\">Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13412\" rel=\"noreferrer\" target=\"_blank\">Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13514\" rel=\"noreferrer\" target=\"_blank\">Small Language Models Improve Giants by Rewriting Their Outputs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13626\" rel=\"noreferrer\" target=\"_blank\">Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13660\" rel=\"noreferrer\" target=\"_blank\">Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13669\" rel=\"noreferrer\" target=\"_blank\">Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13068\" rel=\"noreferrer\" target=\"_blank\">Making Language Models Better Tool Learners with Execution Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13073\" rel=\"noreferrer\" target=\"_blank\">Text-to-SQL Error Correction with Language Models of Code<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13085\" rel=\"noreferrer\" target=\"_blank\">Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13235\" rel=\"noreferrer\" target=\"_blank\">SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13252\" rel=\"noreferrer\" target=\"_blank\">\"According to ...\" Prompting Language Models Improves Quoting from Pre-Training Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13264\" rel=\"noreferrer\" target=\"_blank\">Prompt-based methods may underestimate large language models' linguistic generalizations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13269\" rel=\"noreferrer\" target=\"_blank\">Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.13299\" rel=\"noreferrer\" target=\"_blank\">Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12576\" rel=\"noreferrer\" target=\"_blank\">Automated Few-shot Classification with Instruction-Finetuned Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12586\" rel=\"noreferrer\" target=\"_blank\">Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12627\" rel=\"noreferrer\" target=\"_blank\">MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12696\" rel=\"noreferrer\" target=\"_blank\">Learning Interpretable Style Embeddings via Prompting LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12723\" rel=\"noreferrer\" target=\"_blank\">Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12744\" rel=\"noreferrer\" target=\"_blank\">Fact-Checking Complex Claims with Program-Guided Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12749\" rel=\"noreferrer\" target=\"_blank\">A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12757\" rel=\"noreferrer\" target=\"_blank\">This Prompt is Measuring &lt;MASK&gt;: Evaluating Bias Evaluation in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12761\" rel=\"noreferrer\" target=\"_blank\">Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12900\" rel=\"noreferrer\" target=\"_blank\">Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12535\" rel=\"noreferrer\" target=\"_blank\">Explaining How Transformers Use Context to Build Predictions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12392\" rel=\"noreferrer\" target=\"_blank\">PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12217\" rel=\"noreferrer\" target=\"_blank\">PromptNER: A Prompting Method for Few-shot Named Entity Recognition via k Nearest Neighbor Search<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12295\" rel=\"noreferrer\" target=\"_blank\">Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11791\" rel=\"noreferrer\" target=\"_blank\">Enhancing Few-shot NER with Prompt Ordering based Data Augmentation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11792\" rel=\"noreferrer\" target=\"_blank\">Chain-of-thought prompting for responding to in-depth dialogue questions with LLM<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11853\" rel=\"noreferrer\" target=\"_blank\">How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11991\" rel=\"noreferrer\" target=\"_blank\">Evaluation of medium-large Language Models at zero-shot closed book generative question answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12077\" rel=\"noreferrer\" target=\"_blank\">Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.12096\" rel=\"noreferrer\" target=\"_blank\">Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11255\" rel=\"noreferrer\" target=\"_blank\">Reasoning Implicit Sentiment with Chain-of-Thought Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11334\" rel=\"noreferrer\" target=\"_blank\">Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11366\" rel=\"noreferrer\" target=\"_blank\">AutoTrial: Prompting Language Models for Clinical Trial Design<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11738\" rel=\"noreferrer\" target=\"_blank\">CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11759\" rel=\"noreferrer\" target=\"_blank\">Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11790\" rel=\"noreferrer\" target=\"_blank\">Prompting with Pseudo-Code Instructions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11171\" rel=\"noreferrer\" target=\"_blank\">TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11159\" rel=\"noreferrer\" target=\"_blank\">Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11140\" rel=\"noreferrer\" target=\"_blank\">Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11038\" rel=\"noreferrer\" target=\"_blank\">Learning In-context Learning for Named Entity Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10907\" rel=\"noreferrer\" target=\"_blank\">Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10866\" rel=\"noreferrer\" target=\"_blank\">TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10847\" rel=\"noreferrer\" target=\"_blank\">Large Language Models can be Guided to Evade AI-Generated Text Detection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10613\" rel=\"noreferrer\" target=\"_blank\">Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.11095\" rel=\"noreferrer\" target=\"_blank\">Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10679\" rel=\"noreferrer\" target=\"_blank\">Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.10142\" rel=\"noreferrer\" target=\"_blank\">Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09770\" rel=\"noreferrer\" target=\"_blank\">ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09645\" rel=\"noreferrer\" target=\"_blank\">StructGPT: A General Framework for Large Language Model to Reason over Structured Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09617\" rel=\"noreferrer\" target=\"_blank\">Towards Expert-Level Medical Question Answering with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09612\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are Built-in Autoregressive Search Engines<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09335\" rel=\"noreferrer\" target=\"_blank\">MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09312\" rel=\"noreferrer\" target=\"_blank\">Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09067\" rel=\"noreferrer\" target=\"_blank\">SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09333\" rel=\"noreferrer\" target=\"_blank\">Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2305.09025\" rel=\"noreferrer\" target=\"_blank\">Soft Prompt Decoding for Multilingual Dense Retrieval<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://ai.google/static/documents/palm2techreport.pdf\" rel=\"noreferrer\" target=\"_blank\">PaLM 2 Technical Report<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.06556\" rel=\"noreferrer\" target=\"_blank\">Are LLMs All You Need for Task-Oriented Dialogue?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.05973\" rel=\"noreferrer\" target=\"_blank\">HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.05253\" rel=\"noreferrer\" target=\"_blank\">Approximating Human Evaluation of Social Chatbots with Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.04616\" rel=\"noreferrer\" target=\"_blank\">Automated Reading Passage Generation with OpenAI's Large Language Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.04358\" rel=\"noreferrer\" target=\"_blank\">WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.04704\" rel=\"noreferrer\" target=\"_blank\">Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.02819\" rel=\"noreferrer\" target=\"_blank\">GPT detectors are biased against non-native English writers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.03153\" rel=\"noreferrer\" target=\"_blank\">Zero-Shot Next-Item Recommendation using Large Pretrained Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.02213\" rel=\"noreferrer\" target=\"_blank\">Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.01295\" rel=\"noreferrer\" target=\"_blank\">Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.01228\" rel=\"noreferrer\" target=\"_blank\">Better Language Models of Code through Self-Improvement<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.01209\" rel=\"noreferrer\" target=\"_blank\">PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\">Assessing Language Model Deployment with Risk Cards</a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2304.00116\" rel=\"noreferrer\" target=\"_blank\">Enhancing Large Language Models with Climate Resources<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.17564\" rel=\"noreferrer\" target=\"_blank\">BloombergGPT: A Large Language Model for Finance<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.17408\" rel=\"noreferrer\" target=\"_blank\">Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.15846\" rel=\"noreferrer\" target=\"_blank\">Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.16434\" rel=\"noreferrer\" target=\"_blank\">TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.16445\" rel=\"noreferrer\" target=\"_blank\">Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.15587\" rel=\"noreferrer\" target=\"_blank\">Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.14375\" rel=\"noreferrer\" target=\"_blank\">Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.15413\" rel=\"noreferrer\" target=\"_blank\">Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.15441\" rel=\"noreferrer\" target=\"_blank\">Zero-shot Model Diagnosis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.13592\" rel=\"noreferrer\" target=\"_blank\">Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.13035\" rel=\"noreferrer\" target=\"_blank\">SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.11455\" rel=\"noreferrer\" target=\"_blank\">Large Language Models and Simple, Stupid Bugs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.09325\" rel=\"noreferrer\" target=\"_blank\">Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.08896\" rel=\"noreferrer\" target=\"_blank\">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.07142\" rel=\"noreferrer\" target=\"_blank\">Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.05063\" rel=\"noreferrer\" target=\"_blank\">ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.05398\" rel=\"noreferrer\" target=\"_blank\">MathPrompter: Mathematical Reasoning using Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.05400\" rel=\"noreferrer\" target=\"_blank\">Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.03199\" rel=\"noreferrer\" target=\"_blank\">Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.01903\" rel=\"noreferrer\" target=\"_blank\">Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.00815\" rel=\"noreferrer\" target=\"_blank\">Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2303.00733\" rel=\"noreferrer\" target=\"_blank\">SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.14233\" rel=\"noreferrer\" target=\"_blank\">Goal Driven Discovery of Distributional Differences via Language Descriptions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.13439\" rel=\"noreferrer\" target=\"_blank\">Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.14169\" rel=\"noreferrer\" target=\"_blank\">TabGenie: A Toolkit for Table-to-Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12449\" rel=\"noreferrer\" target=\"_blank\">SGL-PT: A Strong Graph Learner with Graph Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12468\" rel=\"noreferrer\" target=\"_blank\">Few-Shot Table-to-Text Generation with Prompt-based Adapter<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12692\" rel=\"noreferrer\" target=\"_blank\">Language Models Are Few-shot Learners for Prognostic Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12784\" rel=\"noreferrer\" target=\"_blank\">STA: Self-controlled Text Augmentation for Improving Text Classifications<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.12813\" rel=\"noreferrer\" target=\"_blank\">Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.10916\" rel=\"noreferrer\" target=\"_blank\">How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.08961\" rel=\"noreferrer\" target=\"_blank\">Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.08068\" rel=\"noreferrer\" target=\"_blank\">LabelPrompt: Effective Prompt-based Learning for Relation Classification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.09236\" rel=\"noreferrer\" target=\"_blank\">Language Model Crossover: Variation through Few-Shot Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.08102\" rel=\"noreferrer\" target=\"_blank\">Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.07459\" rel=\"noreferrer\" target=\"_blank\">The Capacity for Moral Self-Correction in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.04156\" rel=\"noreferrer\" target=\"_blank\">Prompting for Multimodal Hateful Meme Classification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.03269\" rel=\"noreferrer\" target=\"_blank\">PLACES: Prompting Language Models for Social Conversation Synthesis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.04761\" rel=\"noreferrer\" target=\"_blank\">Toolformer: Language Models Can Teach Themselves to Use Tools<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2302.01441\" rel=\"noreferrer\" target=\"_blank\">Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2301.12810\" rel=\"noreferrer\" target=\"_blank\">Crawling the Internal Knowledge-Base of Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2212.02199\" rel=\"noreferrer\" target=\"_blank\">Legal Prompt Engineering for Multilingual Legal Judgement Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2211.15462\" rel=\"noreferrer\" target=\"_blank\">Investigating Prompt Engineering in Diffusion Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2209.09513v2\" rel=\"noreferrer\" target=\"_blank\">Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.15157\" rel=\"noreferrer\" target=\"_blank\">Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2210.14699\" rel=\"noreferrer\" target=\"_blank\">Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://aclanthology.org/2022.inlg-main.5\" rel=\"noreferrer\" target=\"_blank\">Plot Writing From Scratch Pre-Trained Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://arxiv.org/abs/2202.03629\" rel=\"noreferrer\" target=\"_blank\">Survey of Hallucination in Natural Language Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2022)</li>\n",
      "</ul>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Collections<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#collections\" id=\"collections\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://github.com/Timothyxxx/Chain-of-ThoughtsPapers\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Thought Papers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://paperswithcode.com/task/prompt-engineering\" rel=\"noreferrer\" target=\"_blank\">Papers with Code<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231022192048/https://github.com/thunlp/PromptPapers#papers\" rel=\"noreferrer\" target=\"_blank\">Prompt Papers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "</ul><div class=\"nx-mt-16\"></div><div class=\"nx-mb-8 nx-flex nx-items-center nx-border-t nx-pt-8 dark:nx-border-neutral-800 contrast-more:nx-border-neutral-400 dark:contrast-more:nx-border-neutral-400 print:nx-hidden\"><a class=\"nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-pr-4 rtl:nx-pl-4\" href=\"/web/20231022192048/https://www.promptingguide.ai/risks/biases\" title=\"Biases\"><svg class=\"nx-inline nx-h-5 nx-shrink-0 ltr:nx-rotate-180\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg>Biases</a><a class=\"nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-ml-auto ltr:nx-pl-4 ltr:nx-text-right rtl:nx-mr-auto rtl:nx-pr-4 rtl:nx-text-left\" href=\"/web/20231022192048/https://www.promptingguide.ai/tools\" title=\"Tools\">Tools<svg class=\"nx-inline nx-h-5 nx-shrink-0 rtl:nx-rotate-180\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a></div></main></article></div><footer class=\"nx-bg-gray-100 nx-pb-[env(safe-area-inset-bottom)] dark:nx-bg-neutral-900 print:nx-bg-transparent\"><div class=\"nx-mx-auto nx-flex nx-max-w-[90rem] nx-gap-2 nx-py-2 nx-px-4 nx-hidden\"><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R4n9m:\" title=\"Change language\" type=\"button\"><span class=\"nx-flex nx-items-center nx-gap-2\"><svg fill=\"currentColor\" height=\"12\" viewbox=\"2 2 16 16\" width=\"12\"><path clip-rule=\"evenodd\" d=\"M4.083 9h1.946c.089-1.546.383-2.97.837-4.118A6.004 6.004 0 004.083 9zM10 2a8 8 0 100 16 8 8 0 000-16zm0 2c-.076 0-.232.032-.465.262-.238.234-.497.623-.737 1.182-.389.907-.673 2.142-.766 3.556h3.936c-.093-1.414-.377-2.649-.766-3.556-.24-.56-.5-.948-.737-1.182C10.232 4.032 10.076 4 10 4zm3.971 5c-.089-1.546-.383-2.97-.837-4.118A6.004 6.004 0 0115.917 9h-1.946zm-2.003 2H8.032c.093 1.414.377 2.649.766 3.556.24.56.5.948.737 1.182.233.23.389.262.465.262.076 0 .232-.032.465-.262.238-.234.498-.623.737-1.182.389-.907.673-2.142.766-3.556zm1.166 4.118c.454-1.147.748-2.572.837-4.118h1.946a6.004 6.004 0 01-2.783 4.118zm-6.268 0C6.412 13.97 6.118 12.546 6.03 11H4.083a6.004 6.004 0 002.783 4.118z\" fill-rule=\"evenodd\"></path></svg><span class=\"\">English</span></span></button><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R579m:\" title=\"Change theme\" type=\"button\"><div class=\"nx-flex nx-items-center nx-gap-2 nx-capitalize\"><svg fill=\"none\" height=\"12\" stroke=\"currentColor\" viewbox=\"3 3 18 18\" width=\"12\"><path d=\"M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg><span class=\"\">Light</span></div></button></div><hr class=\"dark:nx-border-neutral-800\"/><div class=\"nx-mx-auto nx-flex nx-max-w-[90rem] nx-justify-center nx-py-12 nx-text-gray-600 dark:nx-text-gray-400 md:nx-justify-start nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]\">Copyright Â© 2023 DAIR.AI</div></footer></div></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{}},\"page\":\"/papers.en\",\"query\":{},\"buildId\":\"Tj-HSFLL6IMs8Gz9xA-Wi\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false,\"locale\":\"en\",\"locales\":[\"en\",\"zh\",\"jp\",\"pt\",\"tr\",\"es\",\"it\",\"fr\",\"kr\",\"ca\",\"fi\",\"ru\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script></body></html><!--\n",
      "     FILE ARCHIVED ON 19:20:48 Oct 22, 2023 AND RETRIEVED FROM THE\n",
      "     INTERNET ARCHIVE ON 19:54:46 Oct 22, 2023.\n",
      "     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.\n",
      "\n",
      "     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.\n",
      "     SECTION 108(a)(3)).\n",
      "-->\n",
      "<!--\n",
      "playback timings (ms):\n",
      "  captures_list: 427.246\n",
      "  exclusion.robots: 0.132\n",
      "  exclusion.robots.policy: 0.121\n",
      "  cdx.remote: 0.053\n",
      "  esindex: 0.009\n",
      "  LoadShardBlock: 402.931 (3)\n",
      "  PetaboxLoader3.datanode: 380.558 (4)\n",
      "  load_resource: 106.1\n",
      "  PetaboxLoader3.resolve: 34.835\n",
      "-->\n"
     ]
    }
   ],
   "source": [
    "# Scrape list of \"Approaches\" papers on \"https://www.promptingguide.ai/papers\"\n",
    "# Use the Internet Archive copy\n",
    "url = \"https://web.archive.org/web/20231022192048/https://www.promptingguide.ai/papers\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Papers | Prompt Engineering Guide Prompt Engineering GuidePrompt Engineering CoursePrompt Engineering CourseServicesServicesAboutAboutGitHubGitHub (opens in a new tab)DiscordDiscord (opens in a new tab)Prompt EngineeringIntroductionLLM SettingsBasics of PromptingPrompt ElementsGeneral Tips for Designing PromptsExamples of PromptsTechniquesZero-shot PromptingFew-shot PromptingChain-of-Thought PromptingSelf-ConsistencyGenerate Knowledge PromptingTree of ThoughtsRetrieval Augmented GenerationAutomatic Reasoning and Tool-useAutomatic Prompt EngineerActive-PromptDirectional Stimulus PromptingReActMultimodal CoTGraph PromptingApplicationsProgram-Aided Language ModelsGenerating DataGenerating Synthetic Dataset for RAGTackling Generated Datasets DiversityGenerating CodeGraduate Job Classification Case StudyPrompt FunctionModelsFlanChatGPTLLaMAGPT-4LLM CollectionRisks & MisusesAdversarial PromptingFactualityBiasesPapersToolsNotebooksDatasetsAdditional ReadingsEnglishLightOn This PageOverviewsApproachesApplicationsCollectionsQuestion? Give us feedback â†’ (opens in a new tab)Edit this pagePapersPapers\n",
      "The following are the latest papers (sorted by release date) on prompt engineering for large language models (LLMs). We update the list of papers on a daily/weekly basis.\n",
      "Overviews\n",
      "\n",
      "An RL Perspective on RLHF, Prompting, and Beyond (opens in a new tab) (October 2023)\n",
      "Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation (opens in a new tab) (May 2023)\n",
      "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study (opens in a new tab) (May 2023)\n",
      "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond (opens in a new tab) (April 2023)\n",
      "Tool Learning with Foundation Models (opens in a new tab) (April 2023)\n",
      "One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era (opens in a new tab) (April 2023)\n",
      "A Bibliometric Review of Large Language Models Research from 2017 to 2023 (opens in a new tab) (April 2023)\n",
      "A Survey of Large Language Models (opens in a new tab) (April 2023)\n",
      "Nature Language Reasoning, A Survey (opens in a new tab) (March 2023)\n",
      "Augmented Language Models: a Survey (opens in a new tab) (February 2023)\n",
      "A Survey for In-context Learning (opens in a new tab) (December 2022)\n",
      "Towards Reasoning in Large Language Models: A Survey (opens in a new tab) (December 2022)\n",
      "Reasoning with Language Model Prompting: A Survey (opens in a new tab) (December 2022)\n",
      "Emergent Abilities of Large Language Models (opens in a new tab) (June 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing (opens in a new tab) (July 2021)\n",
      "\n",
      "Approaches\n",
      "\n",
      "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL (opens in a new tab) (September 2023)\n",
      "Chain-of-Verification Reduces Hallucination in Large Language Models (opens in a new tab) (September 2023)\n",
      "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Re-Reading Improves Reasoning in Language Models (opens in a new tab) (September 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (opens in a new tab) (July 2023)\n",
      "Focused Prefix Tuning for Controllable Text Generation (opens in a new tab) (June 2023)\n",
      "Exploring Lottery Prompts for Pre-trained Language Models (opens in a new tab) (May 2023)\n",
      "Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses (opens in a new tab) (May 2023)\n",
      "Let's Verify Step by Step (opens in a new tab) (May 2023)\n",
      "Universality and Limitations of Prompt Tuning (opens in a new tab) (May 2023)\n",
      "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting (opens in a new tab) (May 2023)\n",
      "PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents (opens in a new tab) (May 2023)\n",
      "Reasoning with Language Model is Planning with World Model (opens in a new tab) (May 2023)\n",
      "Self-Critique Prompting with Large Language Models for Inductive Instructions (opens in a new tab) (May 2023)\n",
      "Better Zero-Shot Reasoning with Self-Adaptive Prompting (opens in a new tab) (May 2023)\n",
      "Hierarchical Prompting Assists Large Language Model on Web Navigation (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "Can We Edit Factual Knowledge by In-Context Learning? (opens in a new tab) (May 2023)\n",
      "In-Context Learning of Large Language Models Explained as Kernel Regression (opens in a new tab) (May 2023)\n",
      "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (opens in a new tab) (May 2023)\n",
      "Meta-in-context learning in large language models (opens in a new tab) (May 2023)\n",
      "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs (opens in a new tab) (May 2023)\n",
      "Post Hoc Explanations of Language Models Can Improve Language Models (opens in a new tab) (May 2023)\n",
      "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt (opens in a new tab) (May 2023)\n",
      "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding (opens in a new tab) (May 2023)\n",
      "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (opens in a new tab) (May 2023)\n",
      "Efficient Prompting via Dynamic In-Context Learning (opens in a new tab) (May 2023)\n",
      "The Web Can Be Your Oyster for Improving Large Language Models (opens in a new tab) (May 2023)\n",
      "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (opens in a new tab) (May 2023)\n",
      "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (opens in a new tab) (May 2023)\n",
      "ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs (opens in a new tab) (May 2023)\n",
      "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models (opens in a new tab) (May 2023)\n",
      "CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge (opens in a new tab) (May 2023)\n",
      "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning (opens in a new tab) (May 2023)\n",
      "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (opens in a new tab) (May 2023)\n",
      "Satisfiability-Aided Language Models Using Declarative Prompting (opens in a new tab) (May 2023)\n",
      "Pre-Training to Learn in Context (opens in a new tab) (May 2023)\n",
      "Boosted Prompt Ensembles for Large Language Models (opens in a new tab) (April 2023)\n",
      "Global Prompt Cell: A Portable Control Module for Effective Prompt (opens in a new tab) (April 2023)\n",
      "Why think step-by-step? Reasoning emerges from the locality of experience (opens in a new tab) (April 2023)\n",
      "Revisiting Automated Prompting: Are We Actually Doing Better? (opens in a new tab) (April 2023)\n",
      "REFINER: Reasoning Feedback on Intermediate Representations (opens in a new tab) (April 2023)\n",
      "Reflexion: an autonomous agent with dynamic memory and self-reflection (opens in a new tab) (March 2023)\n",
      "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society (opens in a new tab) (March 2023)\n",
      "Self-Refine: Iterative Refinement with Self-Feedback (opens in a new tab) (March 2023)\n",
      "kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference (opens in a new tab) (March 2023)\n",
      "Visual-Language Prompt Tuning with Knowledge-guided Context Optimization (opens in a new tab) (March 2023)\n",
      "Fairness-guided Few-shot Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Context-faithful Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning (opens in a new tab) (March 2023)\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (opens in a new tab) (March 2023)\n",
      "Model-tuning Via Prompts Makes NLP Models Adversarially Robust (opens in a new tab) (March 2023)\n",
      "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer (opens in a new tab) (March 2023)\n",
      "CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification (opens in a new tab) (March 2023)\n",
      "Larger language models do in-context learning differently (opens in a new tab) (March 2023)\n",
      "OpenICL: An Open-Source Framework for In-context Learning (opens in a new tab) (March 2023)\n",
      "Dynamic Prompting: A Unified Framework for Prompt Tuning (opens in a new tab) (March 2023)\n",
      "ART: Automatic multi-step reasoning and tool-use for large language models (opens in a new tab) (March 2023)\n",
      "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning (opens in a new tab) (March 2023)\n",
      "Effectiveness of Data Augmentation for Prefix Tuning with Limited Data (opens in a new tab) (March 2023)\n",
      "Mixture of Soft Prompts for Controllable Data Generation (opens in a new tab) (March 2023)\n",
      "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners (opens in a new tab) (March 2023)\n",
      "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks (opens in a new tab) (March 2023)\n",
      "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT (opens in a new tab) (February 2023)\n",
      "EvoPrompting: Language Models for Code-Level Neural Architecture Search (opens in a new tab) (February 2023)\n",
      "In-Context Instruction Learning (opens in a new tab) (February 2023)\n",
      "Chain of Hindsight Aligns Language Models with Feedback (opens in a new tab) (February 2023)\n",
      "Language Is Not All You Need: Aligning Perception with Language Models (opens in a new tab) (February 2023)\n",
      "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (opens in a new tab) (February 2023)\n",
      "Active Prompting with Chain-of-Thought for Large Language Models (opens in a new tab) (February 2023)\n",
      "More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models (opens in a new tab) (February 2023)\n",
      "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (opens in a new tab) (February 2023)\n",
      "Guiding Large Language Models via Directional Stimulus Prompting (opens in a new tab) (February 2023)\n",
      "How Does In-Context Learning Help Prompt Tuning? (opens in a new tab) (February 2023)\n",
      "Scalable Prompt Generation for Semi-supervised Learning with Language Models (opens in a new tab) (February 2023)\n",
      "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints (opens in a new tab) (February 2023)\n",
      "Ã€-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting (opens in a new tab) (February 2023)\n",
      "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains (opens in a new tab) (February 2023)\n",
      "Evaluating the Robustness of Discrete Prompts (opens in a new tab) (February 2023)\n",
      "Compositional Exemplars for In-context Learning (opens in a new tab) (February 2023)\n",
      "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (opens in a new tab) (February 2023)\n",
      "Multimodal Chain-of-Thought Reasoning in Language Models (opens in a new tab) (February 2023)\n",
      "Large Language Models Can Be Easily Distracted by Irrelevant Context (opens in a new tab) (February 2023)\n",
      "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models (opens in a new tab) (February 2023)\n",
      "Progressive Prompts: Continual Learning for Language Models (opens in a new tab) (January 2023)\n",
      "Batch Prompting: Efficient Inference with LLM APIs (opens in a new tab) (January 2023)\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (opens in a new tab) (December 2022)\n",
      "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning (opens in a new tab) (December 2022)\n",
      "Constitutional AI: Harmlessness from AI Feedback (opens in a new tab) (December 2022)\n",
      "Successive Prompting for Decomposing Complex Questions (opens in a new tab) (December 2022)\n",
      "Large Language Models are reasoners with Self-Verification (opens in a new tab) (December 2022)\n",
      "Discovering Language Model Behaviors with Model-Written Evaluations (opens in a new tab) (December 2022)\n",
      "Structured Prompting: Scaling In-Context Learning to 1,000 Examples (opens in a new tab) (December 2022)\n",
      "PAL: Program-aided Language Models (opens in a new tab) (November 2022)\n",
      "Large Language Models Are Human-Level Prompt Engineers (opens in a new tab) (November 2022)\n",
      "Ignore Previous Prompt: Attack Techniques For Language Models (opens in a new tab) (November 2022)\n",
      "Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods (opens in a new tab) (November 2022)\n",
      "Teaching Algorithmic Reasoning via In-context Learning (opens in a new tab) (November 2022)\n",
      "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference (opens in a new tab) (November 2022)\n",
      "Ask Me Anything: A simple strategy for prompting language models (opens in a new tab) (October 2022)\n",
      "Recitation-Augmented Language Models (opens in a new tab) (October 2022)\n",
      "ReAct: Synergizing Reasoning and Acting in Language Models (opens in a new tab) (October 2022)\n",
      "Prompting GPT-3 To Be Reliable (opens in a new tab) (October 2022)\n",
      "Decomposed Prompting: A Modular Approach for Solving Complex Tasks (opens in a new tab) (October 2022)\n",
      "Automatic Chain of Thought Prompting in Large Language Models (opens in a new tab) (October 2022)\n",
      "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought (opens in a new tab) (October 2022)\n",
      "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples (opens in a new tab) (September 2022)\n",
      "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning (opens in a new tab) (September 2022)\n",
      "Promptagator: Few-shot Dense Retrieval From 8 Examples (opens in a new tab) (September 2022)\n",
      "Atlas: Few-shot Learning with Retrieval Augmented Language Models (opens in a new tab) (November 2022)\n",
      "DocPrompting: Generating Code by Retrieving the Docs (opens in a new tab) (July 2022)\n",
      "On the Advance of Making Language Models Better Reasoners (opens in a new tab) (June 2022)\n",
      "Large Language Models are Zero-Shot Reasoners (opens in a new tab) (May 2022)\n",
      "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations (opens in a new tab) (May 2022)\n",
      "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (opens in a new tab) (May 2022)\n",
      "PPT: Pre-trained Prompt Tuning for Few-shot Learning (opens in a new tab) (Mqy 2022)\n",
      "Toxicity Detection with Generative Prompt-based Inference (opens in a new tab) (May 2022)\n",
      "Learning to Transfer Prompts for Text Generation (opens in a new tab) (May 2022)\n",
      "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (opens in a new tab) (May 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "PromptChainer: Chaining Large Language Model Prompts through Visual Programming (opens in a new tab) (March 2022)\n",
      "Self-Consistency Improves Chain of Thought Reasoning in Language Models (opens in a new tab) (March 2022)\n",
      "Training language models to follow instructions with human feedback (opens in a new tab)\n",
      "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (opens in a new tab) (February 2022)\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models (opens in a new tab) (January 2022)\n",
      "Show Your Work: Scratchpads for Intermediate Computation with Language Models (opens in a new tab) (November 2021)\n",
      "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts (opens in a new tab) (October 2021)\n",
      "Generated Knowledge Prompting for Commonsense Reasoning (opens in a new tab) (October 2021)\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization (opens in a new tab) (October 2021)\n",
      "Reframing Instructional Prompts to GPTk's Language (opens in a new tab) (September 2021)\n",
      "Design Guidelines for Prompt Engineering Text-to-Image Generative Models (opens in a new tab) (September 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (August 2021)\n",
      "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity (opens in a new tab) (April 2021)\n",
      "BERTese: Learning to Speak to BERT (opens in a new tab) (April 2021)\n",
      "The Power of Scale for Parameter-Efficient Prompt Tuning (opens in a new tab) (April 2021)\n",
      "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (opens in a new tab) (February 2021)\n",
      "Calibrate Before Use: Improving Few-Shot Performance of Language Models (opens in a new tab) (February 2021)\n",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation (opens in a new tab) (January 2021)\n",
      "Learning to Generate Task-Specific Adapters from Task Description (opens in a new tab) (January 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (December 2020)\n",
      "Learning from Task Descriptions (opens in a new tab) (November 2020)\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts (opens in a new tab) (October 2020)\n",
      "Language Models are Few-Shot Learners (opens in a new tab) (May 2020)\n",
      "How Can We Know What Language Models Know? (opens in a new tab) (July 2020)\n",
      "Scaling Laws for Neural Language Models (opens in a new tab) (January 2020)\n",
      "\n",
      "Applications\n",
      "\n",
      "Graph Neural Prompting with Large Language Models (opens in a new tab) (September 2023)\n",
      "Large Language Model Alignment: A Survey (opens in a new tab) (September 2023)\n",
      "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic (opens in a new tab) (September 2023)\n",
      "A Practical Survey on Zero-shot Prompt Design for In-context Learning (opens in a new tab) (September 2023)\n",
      "EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning (opens in a new tab) (September 2023)\n",
      "Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning (opens in a new tab) (September 2023)\n",
      "PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models (opens in a new tab) (September 2023)\n",
      "LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models (opens in a new tab) (September 2023)\n",
      "Summarization is (Almost) Dead (opens in a new tab) (September 2023)\n",
      "Investigating Zero- and Few-shot Generalization in Fact Verification (opens in a new tab) (September 2023)\n",
      "Performance of the Pre-Trained Large Language Model GPT-4 on Automated Short Answer Grading (opens in a new tab) (September 2023)\n",
      "Contrastive Decoding Improves Reasoning in Large Language Models (opens in a new tab) (September 2023)\n",
      "Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data? (opens in a new tab) (September 2023)\n",
      "Neural Machine Translation Models Can Learn to be Few-shot Learners (opens in a new tab) (September 2023)\n",
      "Chain-of-Thought Reasoning is a Policy Improvement Operator (opens in a new tab) (September 2023)\n",
      "ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer (opens in a new tab) (September 2023)\n",
      "When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets (opens in a new tab) (September 2023)\n",
      "Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata (opens in a new tab) (September 2023)\n",
      "Self-Consistent Narrative Prompts on Abductive Natural Language Inference (opens in a new tab) (September 2023)\n",
      "Investigating Answerability of LLMs for Long-Form Question Answering (opens in a new tab) (September 2023)\n",
      "PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions (opens in a new tab) (September 2023)\n",
      "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing (opens in a new tab) (September 2023)\n",
      "Leveraging Contextual Information for Effective Entity Salience Detection (opens in a new tab) (September 2023)\n",
      "Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts (opens in a new tab) (September 2023)\n",
      "PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models (opens in a new tab) (September 2023)\n",
      "Zero-Resource Hallucination Prevention for Large Language Models (opens in a new tab) (September 2023)\n",
      "Certifying LLM Safety against Adversarial Prompting (opens in a new tab) (September 2023)\n",
      "Improving Code Generation by Dynamic Temperature Sampling (opens in a new tab) (September 2023)\n",
      "Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages (opens in a new tab) (August 2023)\n",
      "Financial News Analytics Using Fine-Tuned Llama 2 GPT Model (opens in a new tab) (August 2023)\n",
      "A Study on Robustness and Reliability of Large Language Model Code Generation (opens in a new tab) (August 2023)\n",
      "Large Language Models Vote: Prompting for Rare Disease Identification (opens in a new tab) (August 2023)\n",
      "WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct (opens in a new tab) (August 2023)\n",
      "Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning (opens in a new tab) (August 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment (opens in a new tab) (August 2023)\n",
      "Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought (opens in a new tab) (August 2023)\n",
      "You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content (opens in a new tab) (August 2023)\n",
      "LLM As DBA (opens in a new tab) (August 2023)\n",
      "Interpretable Math Word Problem Solution Generation Via Step-by-step Planning (opens in a new tab) (June 2023)\n",
      "In-Context Learning User Simulators for Task-Oriented Dialog Systems (opens in a new tab) (June 2023)\n",
      "SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL (opens in a new tab) (June 2023)\n",
      "Effective Structured Prompting by Meta-Learning and Representative Verbalizer (opens in a new tab) (June 2023)\n",
      "Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering (opens in a new tab) (June 2023)\n",
      "Chain-Of-Thought Prompting Under Streaming Batch: A Case Study (opens in a new tab) (June 2023)\n",
      "Red Teaming Language Model Detectors with Language Models (opens in a new tab) (May 2023)\n",
      "Gorilla: Large Language Model Connected with Massive APIs (opens in a new tab) (May 2023)\n",
      "Deliberate then Generate: Enhanced Prompting Framework for Text Generation (opens in a new tab) (May 2023)\n",
      "What does the Failure to Reason with \"Respectively\" in Zero/Few-Shot Settings Tell Us about Language Models? (opens in a new tab) (May 2023)\n",
      "ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning (opens in a new tab) (May 2023)\n",
      "SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models (opens in a new tab) (May 2023)\n",
      "Grammar Prompting for Domain-Specific Language Generation with Large Language Models (opens in a new tab) (May 2023)\n",
      "Mitigating Label Biases for In-context Learning (opens in a new tab) (May 2023)\n",
      "Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model (opens in a new tab) (May 2023)\n",
      "Strategic Reasoning with Language Models (opens in a new tab) (May 2023)\n",
      "Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs (opens in a new tab) (May 2023)\n",
      "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models (opens in a new tab) (May 2023)\n",
      "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning (opens in a new tab) (May 2023)\n",
      "Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods (opens in a new tab) (May 2023)\n",
      "NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models (opens in a new tab) (May 2023)\n",
      "Tab-CoT: Zero-shot Tabular Chain of Thought (opens in a new tab) (May 2023)\n",
      "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation (opens in a new tab) (May 2023)\n",
      "Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks (opens in a new tab) (May 2023)\n",
      "[Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning]https://arxiv.org/abs/2305.17373 (opens in a new tab)) (May 2023)\n",
      "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance (opens in a new tab) (May 2023)\n",
      "Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning (opens in a new tab) (May 2023)\n",
      "Heterogeneous Value Evaluation for Large Language Models (opens in a new tab) (May 2023)\n",
      "PromptNER: Prompt Locating and Typing for Named Entity Recognition (opens in a new tab) (May 2023)\n",
      "Small Language Models Improve Giants by Rewriting Their Outputs (opens in a new tab) (May 2023)\n",
      "On the Planning Abilities of Large Language Models -- A Critical Investigation (opens in a new tab) (May 2023)\n",
      "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models (opens in a new tab) (May 2023)\n",
      "PRODIGY: Enabling In-context Learning Over Graphs (opens in a new tab) (May 2023)\n",
      "Large Language Models are Few-Shot Health Learners (opens in a new tab) (May 2023)\n",
      "Role-Play with Large Language Models (opens in a new tab) (May 2023)\n",
      "Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations (opens in a new tab) (May 2023)\n",
      "Fact-Checking Complex Claims with Program-Guided Reasoning (opens in a new tab) (May 2023)\n",
      "Large Language Models as Tool Makers (opens in a new tab) (May 2023)\n",
      "Iterative Forward Tuning Boosts In-context Learning in Language Models (opens in a new tab) (May 2023)\n",
      "SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "An automatically discovered chain-of-thought prompt generalizes to novel models and datasets (opens in a new tab) (May 2023)\n",
      "Large Language Model Guided Tree-of-Thought (opens in a new tab) (May 2023)\n",
      "Active Retrieval Augmented Generation (opens in a new tab) (May 2023)\n",
      "A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models (opens in a new tab) (May 2023)\n",
      "Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings (opens in a new tab) (May 2023)\n",
      "Mirages: On Anthropomorphism in Dialogue Systems (opens in a new tab) (May 2023)\n",
      "Model evaluation for extreme risks (opens in a new tab) (May 2023)\n",
      "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting (opens in a new tab) (May 2023)\n",
      "Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction (opens in a new tab) (May 2023)\n",
      "PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training (opens in a new tab) (May 2023)\n",
      "Augmented Large Language Models with Parametric Knowledge Guiding (opens in a new tab) (May 2023)\n",
      "Aligning Large Language Models through Synthetic Feedback (opens in a new tab) (May 2023)\n",
      "Concept-aware Training Improves In-context Learning Ability of Language Models (opens in a new tab) (May 2023)\n",
      "FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance (opens in a new tab) (May 2023)\n",
      "Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation (opens in a new tab) (May 2023)\n",
      "Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing (opens in a new tab) (May 2023)\n",
      "\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures (opens in a new tab) (May 2023)\n",
      "Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction (opens in a new tab) (May 2023)\n",
      "Generating Data for Symbolic Language with Large Language Models (opens in a new tab) (May 2023)\n",
      "Make a Choice! Knowledge Base Question Answering with In-Context Learning (opens in a new tab) (May 2023)\n",
      "Improving Language Models via Plug-and-Play Retrieval Feedback (opens in a new tab) (May 2023)\n",
      "Multi-Granularity Prompts for Topic Shift Detection in Dialogue (opens in a new tab) (May 2023)\n",
      "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning (opens in a new tab) (May 2023)\n",
      "Can Language Models Understand Physical Concepts? (opens in a new tab) (May 2023)\n",
      "Evaluating Factual Consistency of Summaries with Large Language Models (opens in a new tab) (May 2023)\n",
      "Dr.ICL: Demonstration-Retrieved In-context Learning (opens in a new tab) (May 2023)\n",
      "Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models (opens in a new tab) (May 2023)\n",
      "Skill-Based Few-Shot Selection for In-Context Learning (opens in a new tab) (May 2023)\n",
      "Exploring Chain-of-Thought Style Prompting for Text-to-SQL (opens in a new tab) (May 2023)\n",
      "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations (opens in a new tab) (May 2023)\n",
      "On Learning to Summarize with Large Language Models as References (opens in a new tab) (May 2023)\n",
      "Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery (opens in a new tab) (May 2023)\n",
      "Active Learning Principles for In-Context Learning with Large Language Models (opens in a new tab) (May 2023)\n",
      "Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs (opens in a new tab) (May 2023)\n",
      "Improving Factuality and Reasoning in Language Models through Multiagent Debate (opens in a new tab) (May 2023)\n",
      "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on\\ Chat-based Large Language Models (opens in a new tab) (May 2023)\n",
      "WikiChat: A Few-Shot LLM-Based Chatbot Grounded with Wikipedia (opens in a new tab) (May 2023)\n",
      "Query Rewriting for Retrieval-Augmented Large Language Models (opens in a new tab) (May 2023)\n",
      "Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker (opens in a new tab) (May 2023)\n",
      "Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method (opens in a new tab) (May 2023)\n",
      "Small Language Models Improve Giants by Rewriting Their Outputs (opens in a new tab) (May 2023)\n",
      "Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration (opens in a new tab) (May 2023)\n",
      "Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning (opens in a new tab) (May 2023)\n",
      "Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment (opens in a new tab) (May 2023)\n",
      "Making Language Models Better Tool Learners with Execution Feedback (opens in a new tab) (May 2023)\n",
      "Text-to-SQL Error Correction with Language Models of Code (opens in a new tab) (May 2023)\n",
      "Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models (opens in a new tab) (May 2023)\n",
      "SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations (opens in a new tab) (May 2023)\n",
      "\"According to ...\" Prompting Language Models Improves Quoting from Pre-Training Data (opens in a new tab) (May 2023)\n",
      "Prompt-based methods may underestimate large language models' linguistic generalizations (opens in a new tab) (May 2023)\n",
      "Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases (opens in a new tab) (May 2023)\n",
      "Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations (opens in a new tab) (May 2023)\n",
      "Automated Few-shot Classification with Instruction-Finetuned Language Models (opens in a new tab) (May 2023)\n",
      "Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies (opens in a new tab) (May 2023)\n",
      "MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction (opens in a new tab) (May 2023)\n",
      "Learning Interpretable Style Embeddings via Prompting LLMs (opens in a new tab) (May 2023)\n",
      "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting (opens in a new tab) (May 2023)\n",
      "Fact-Checking Complex Claims with Program-Guided Reasoning (opens in a new tab) (May 2023)\n",
      "A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches (opens in a new tab) (May 2023)\n",
      "This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language Models (opens in a new tab) (May 2023)\n",
      "Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer (opens in a new tab) (May 2023)\n",
      "Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph (opens in a new tab) (May 2023)\n",
      "Explaining How Transformers Use Context to Build Predictions (opens in a new tab) (May 2023)\n",
      "PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs (opens in a new tab) (May 2023)\n",
      "PromptNER: A Prompting Method for Few-shot Named Entity Recognition via k Nearest Neighbor Search (opens in a new tab) (May 2023)\n",
      "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning (opens in a new tab) (May 2023)\n",
      "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation (opens in a new tab) (May 2023)\n",
      "Chain-of-thought prompting for responding to in-depth dialogue questions with LLM (opens in a new tab) (May 2023)\n",
      "How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings (opens in a new tab) (May 2023)\n",
      "Evaluation of medium-large Language Models at zero-shot closed book generative question answering (opens in a new tab) (May 2023)\n",
      "Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer (opens in a new tab) (May 2023)\n",
      "Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions? (opens in a new tab) (May 2023)\n",
      "Reasoning Implicit Sentiment with Chain-of-Thought Prompting (opens in a new tab) (May 2023)\n",
      "Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs (opens in a new tab) (May 2023)\n",
      "AutoTrial: Prompting Language Models for Clinical Trial Design (opens in a new tab) (May 2023)\n",
      "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing (opens in a new tab) (May 2023)\n",
      "Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning (opens in a new tab) (May 2023)\n",
      "Prompting with Pseudo-Code Instructions (opens in a new tab) (May 2023)\n",
      "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models (opens in a new tab) (May 2023)\n",
      "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors (opens in a new tab) (May 2023)\n",
      "Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model (opens in a new tab) (May 2023)\n",
      "Learning In-context Learning for Named Entity Recognition (opens in a new tab) (May 2023)\n",
      "Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation (opens in a new tab) (May 2023)\n",
      "TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition (opens in a new tab) (May 2023)\n",
      "Large Language Models can be Guided to Evade AI-Generated Text Detection (opens in a new tab) (May 2023)\n",
      "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning (opens in a new tab) (May 2023)\n",
      "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization (opens in a new tab) (May 2023)\n",
      "Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation (opens in a new tab) (May 2023)\n",
      "Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback (opens in a new tab) (May 2023)\n",
      "ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing (opens in a new tab) (May 2023)\n",
      "StructGPT: A General Framework for Large Language Model to Reason over Structured Data (opens in a new tab) (May 2023)\n",
      "Towards Expert-Level Medical Question Answering with Large Language Models (opens in a new tab) (May 2023)\n",
      "Large Language Models are Built-in Autoregressive Search Engines (opens in a new tab) (May 2023)\n",
      "MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection (opens in a new tab) (May 2023)\n",
      "Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation (opens in a new tab) (May 2023)\n",
      "SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting (opens in a new tab) (May 2023)\n",
      "Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image (opens in a new tab) (May 2023)\n",
      "Soft Prompt Decoding for Multilingual Dense Retrieval (opens in a new tab) (May 2023)\n",
      "PaLM 2 Technical Report (opens in a new tab) (May 2023)\n",
      "Are LLMs All You Need for Task-Oriented Dialogue? (opens in a new tab) (April 2023)\n",
      "HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting (opens in a new tab) (April 2023)\n",
      "Approximating Human Evaluation of Social Chatbots with Prompting (opens in a new tab) (April 2023)\n",
      "Automated Reading Passage Generation with OpenAI's Large Language Model (opens in a new tab) (April 2023)\n",
      "WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus (opens in a new tab) (April 2023)\n",
      "Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition (opens in a new tab) (April 2023)\n",
      "GPT detectors are biased against non-native English writers (opens in a new tab) (April 2023)\n",
      "Zero-Shot Next-Item Recommendation using Large Pretrained Language Models (opens in a new tab) (April 2023)\n",
      "Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT (opens in a new tab) (April 2023)\n",
      "Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning (opens in a new tab) (April 2023)\n",
      "Better Language Models of Code through Self-Improvement (opens in a new tab) (April 2023)\n",
      "PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction (opens in a new tab) (April 2023)\n",
      "Assessing Language Model Deployment with Risk Cards (April 2023)\n",
      "Enhancing Large Language Models with Climate Resources (opens in a new tab) (March 2023)\n",
      "BloombergGPT: A Large Language Model for Finance (opens in a new tab) (March 2023)\n",
      "Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts (opens in a new tab) (March 2023)\n",
      "Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes (opens in a new tab) (March 2023)\n",
      "TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs (opens in a new tab) (March 2023)\n",
      "Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning (opens in a new tab) (March 2023)\n",
      "Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses (opens in a new tab) (March 2023)\n",
      "Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning (opens in a new tab) (March 2023)\n",
      "Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation (opens in a new tab) (March 2023)\n",
      "Zero-shot Model Diagnosis (opens in a new tab) (March 2023)\n",
      "Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages (opens in a new tab) (March 2023)\n",
      "SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization (opens in a new tab) (March 2023)\n",
      "Large Language Models and Simple, Stupid Bugs (opens in a new tab) (March 2023)\n",
      "Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses? (opens in a new tab) (March 2023)\n",
      "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models (opens in a new tab) (March 2023)\n",
      "Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification (opens in a new tab) (March 2023)\n",
      "ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction (opens in a new tab) (March 2023)\n",
      "MathPrompter: Mathematical Reasoning using Large Language Models (opens in a new tab) (March 2023)\n",
      "Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums (opens in a new tab) (March 2023)\n",
      "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting (opens in a new tab) (March 2023)\n",
      "Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering (opens in a new tab) (March 2023)\n",
      "Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis (opens in a new tab) (March 2023)\n",
      "SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks (opens in a new tab) (March 2023)\n",
      "Goal Driven Discovery of Distributional Differences via Language Descriptions (opens in a new tab) (February 2023)\n",
      "Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models (opens in a new tab) (February 2023)\n",
      "TabGenie: A Toolkit for Table-to-Text Generation (opens in a new tab) (February 2023)\n",
      "SGL-PT: A Strong Graph Learner with Graph Prompt Tuning (opens in a new tab) (February 2023)\n",
      "Few-Shot Table-to-Text Generation with Prompt-based Adapter (opens in a new tab) (February 2023)\n",
      "Language Models Are Few-shot Learners for Prognostic Prediction (opens in a new tab) (February 2023)\n",
      "STA: Self-controlled Text Augmentation for Improving Text Classifications (opens in a new tab) (February 2023)\n",
      "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback (opens in a new tab) (February 2023)\n",
      "How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study (opens in a new tab) (February 2023)\n",
      "Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales (opens in a new tab) (February 2023)\n",
      "LabelPrompt: Effective Prompt-based Learning for Relation Classification (opens in a new tab) (February 2023)\n",
      "Language Model Crossover: Variation through Few-Shot Prompting (opens in a new tab) (February 2023)\n",
      "Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "Prompting for Multimodal Hateful Meme Classification (opens in a new tab) (February 2023)\n",
      "PLACES: Prompting Language Models for Social Conversation Synthesis (opens in a new tab) (February 2023)\n",
      "Toolformer: Language Models Can Teach Themselves to Use Tools (opens in a new tab) (February 2023)\n",
      "Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation (opens in a new tab) (February 2023)\n",
      "Crawling the Internal Knowledge-Base of Language Models (opens in a new tab) (January 2023)\n",
      "Legal Prompt Engineering for Multilingual Legal Judgement Prediction (opens in a new tab) (December 2022)\n",
      "Investigating Prompt Engineering in Diffusion Models (opens in a new tab) (November 2022)\n",
      "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering (opens in a new tab) (September 2022)\n",
      "Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language (opens in a new tab) (October 2022)\n",
      "Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic? (opens in a new tab) (October 2022)\n",
      "Plot Writing From Scratch Pre-Trained Language Models (opens in a new tab) (July 2022)\n",
      "Survey of Hallucination in Natural Language Generation (opens in a new tab) (February 2022)\n",
      "\n",
      "Collections\n",
      "\n",
      "Chain-of-Thought Papers (opens in a new tab)\n",
      "Papers with Code (opens in a new tab)\n",
      "Prompt Papers (opens in a new tab)\n",
      "BiasesToolsEnglishLightCopyright Â© 2023 DAIR.AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strip html tags\n",
    "no_tags = soup.get_text()\n",
    "print(no_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL (opens in a new tab) (September 2023)\n",
      "Chain-of-Verification Reduces Hallucination in Large Language Models (opens in a new tab) (September 2023)\n",
      "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Re-Reading Improves Reasoning in Language Models (opens in a new tab) (September 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (opens in a new tab) (July 2023)\n",
      "Focused Prefix Tuning for Controllable Text Generation (opens in a new tab) (June 2023)\n",
      "Exploring Lottery Prompts for Pre-trained Language Models (opens in a new tab) (May 2023)\n",
      "Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses (opens in a new tab) (May 2023)\n",
      "Let's Verify Step by Step (opens in a new tab) (May 2023)\n",
      "Universality and Limitations of Prompt Tuning (opens in a new tab) (May 2023)\n",
      "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting (opens in a new tab) (May 2023)\n",
      "PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents (opens in a new tab) (May 2023)\n",
      "Reasoning with Language Model is Planning with World Model (opens in a new tab) (May 2023)\n",
      "Self-Critique Prompting with Large Language Models for Inductive Instructions (opens in a new tab) (May 2023)\n",
      "Better Zero-Shot Reasoning with Self-Adaptive Prompting (opens in a new tab) (May 2023)\n",
      "Hierarchical Prompting Assists Large Language Model on Web Navigation (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "Can We Edit Factual Knowledge by In-Context Learning? (opens in a new tab) (May 2023)\n",
      "In-Context Learning of Large Language Models Explained as Kernel Regression (opens in a new tab) (May 2023)\n",
      "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (opens in a new tab) (May 2023)\n",
      "Meta-in-context learning in large language models (opens in a new tab) (May 2023)\n",
      "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs (opens in a new tab) (May 2023)\n",
      "Post Hoc Explanations of Language Models Can Improve Language Models (opens in a new tab) (May 2023)\n",
      "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt (opens in a new tab) (May 2023)\n",
      "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding (opens in a new tab) (May 2023)\n",
      "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (opens in a new tab) (May 2023)\n",
      "Efficient Prompting via Dynamic In-Context Learning (opens in a new tab) (May 2023)\n",
      "The Web Can Be Your Oyster for Improving Large Language Models (opens in a new tab) (May 2023)\n",
      "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (opens in a new tab) (May 2023)\n",
      "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (opens in a new tab) (May 2023)\n",
      "ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs (opens in a new tab) (May 2023)\n",
      "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models (opens in a new tab) (May 2023)\n",
      "CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge (opens in a new tab) (May 2023)\n",
      "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning (opens in a new tab) (May 2023)\n",
      "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (opens in a new tab) (May 2023)\n",
      "Satisfiability-Aided Language Models Using Declarative Prompting (opens in a new tab) (May 2023)\n",
      "Pre-Training to Learn in Context (opens in a new tab) (May 2023)\n",
      "Boosted Prompt Ensembles for Large Language Models (opens in a new tab) (April 2023)\n",
      "Global Prompt Cell: A Portable Control Module for Effective Prompt (opens in a new tab) (April 2023)\n",
      "Why think step-by-step? Reasoning emerges from the locality of experience (opens in a new tab) (April 2023)\n",
      "Revisiting Automated Prompting: Are We Actually Doing Better? (opens in a new tab) (April 2023)\n",
      "REFINER: Reasoning Feedback on Intermediate Representations (opens in a new tab) (April 2023)\n",
      "Reflexion: an autonomous agent with dynamic memory and self-reflection (opens in a new tab) (March 2023)\n",
      "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society (opens in a new tab) (March 2023)\n",
      "Self-Refine: Iterative Refinement with Self-Feedback (opens in a new tab) (March 2023)\n",
      "kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference (opens in a new tab) (March 2023)\n",
      "Visual-Language Prompt Tuning with Knowledge-guided Context Optimization (opens in a new tab) (March 2023)\n",
      "Fairness-guided Few-shot Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Context-faithful Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning (opens in a new tab) (March 2023)\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (opens in a new tab) (March 2023)\n",
      "Model-tuning Via Prompts Makes NLP Models Adversarially Robust (opens in a new tab) (March 2023)\n",
      "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer (opens in a new tab) (March 2023)\n",
      "CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification (opens in a new tab) (March 2023)\n",
      "Larger language models do in-context learning differently (opens in a new tab) (March 2023)\n",
      "OpenICL: An Open-Source Framework for In-context Learning (opens in a new tab) (March 2023)\n",
      "Dynamic Prompting: A Unified Framework for Prompt Tuning (opens in a new tab) (March 2023)\n",
      "ART: Automatic multi-step reasoning and tool-use for large language models (opens in a new tab) (March 2023)\n",
      "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning (opens in a new tab) (March 2023)\n",
      "Effectiveness of Data Augmentation for Prefix Tuning with Limited Data (opens in a new tab) (March 2023)\n",
      "Mixture of Soft Prompts for Controllable Data Generation (opens in a new tab) (March 2023)\n",
      "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners (opens in a new tab) (March 2023)\n",
      "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks (opens in a new tab) (March 2023)\n",
      "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT (opens in a new tab) (February 2023)\n",
      "EvoPrompting: Language Models for Code-Level Neural Architecture Search (opens in a new tab) (February 2023)\n",
      "In-Context Instruction Learning (opens in a new tab) (February 2023)\n",
      "Chain of Hindsight Aligns Language Models with Feedback (opens in a new tab) (February 2023)\n",
      "Language Is Not All You Need: Aligning Perception with Language Models (opens in a new tab) (February 2023)\n",
      "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (opens in a new tab) (February 2023)\n",
      "Active Prompting with Chain-of-Thought for Large Language Models (opens in a new tab) (February 2023)\n",
      "More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models (opens in a new tab) (February 2023)\n",
      "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (opens in a new tab) (February 2023)\n",
      "Guiding Large Language Models via Directional Stimulus Prompting (opens in a new tab) (February 2023)\n",
      "How Does In-Context Learning Help Prompt Tuning? (opens in a new tab) (February 2023)\n",
      "Scalable Prompt Generation for Semi-supervised Learning with Language Models (opens in a new tab) (February 2023)\n",
      "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints (opens in a new tab) (February 2023)\n",
      "Ã€-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting (opens in a new tab) (February 2023)\n",
      "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains (opens in a new tab) (February 2023)\n",
      "Evaluating the Robustness of Discrete Prompts (opens in a new tab) (February 2023)\n",
      "Compositional Exemplars for In-context Learning (opens in a new tab) (February 2023)\n",
      "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (opens in a new tab) (February 2023)\n",
      "Multimodal Chain-of-Thought Reasoning in Language Models (opens in a new tab) (February 2023)\n",
      "Large Language Models Can Be Easily Distracted by Irrelevant Context (opens in a new tab) (February 2023)\n",
      "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models (opens in a new tab) (February 2023)\n",
      "Progressive Prompts: Continual Learning for Language Models (opens in a new tab) (January 2023)\n",
      "Batch Prompting: Efficient Inference with LLM APIs (opens in a new tab) (January 2023)\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (opens in a new tab) (December 2022)\n",
      "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning (opens in a new tab) (December 2022)\n",
      "Constitutional AI: Harmlessness from AI Feedback (opens in a new tab) (December 2022)\n",
      "Successive Prompting for Decomposing Complex Questions (opens in a new tab) (December 2022)\n",
      "Large Language Models are reasoners with Self-Verification (opens in a new tab) (December 2022)\n",
      "Discovering Language Model Behaviors with Model-Written Evaluations (opens in a new tab) (December 2022)\n",
      "Structured Prompting: Scaling In-Context Learning to 1,000 Examples (opens in a new tab) (December 2022)\n",
      "PAL: Program-aided Language Models (opens in a new tab) (November 2022)\n",
      "Large Language Models Are Human-Level Prompt Engineers (opens in a new tab) (November 2022)\n",
      "Ignore Previous Prompt: Attack Techniques For Language Models (opens in a new tab) (November 2022)\n",
      "Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods (opens in a new tab) (November 2022)\n",
      "Teaching Algorithmic Reasoning via In-context Learning (opens in a new tab) (November 2022)\n",
      "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference (opens in a new tab) (November 2022)\n",
      "Ask Me Anything: A simple strategy for prompting language models (opens in a new tab) (October 2022)\n",
      "Recitation-Augmented Language Models (opens in a new tab) (October 2022)\n",
      "ReAct: Synergizing Reasoning and Acting in Language Models (opens in a new tab) (October 2022)\n",
      "Prompting GPT-3 To Be Reliable (opens in a new tab) (October 2022)\n",
      "Decomposed Prompting: A Modular Approach for Solving Complex Tasks (opens in a new tab) (October 2022)\n",
      "Automatic Chain of Thought Prompting in Large Language Models (opens in a new tab) (October 2022)\n",
      "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought (opens in a new tab) (October 2022)\n",
      "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples (opens in a new tab) (September 2022)\n",
      "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning (opens in a new tab) (September 2022)\n",
      "Promptagator: Few-shot Dense Retrieval From 8 Examples (opens in a new tab) (September 2022)\n",
      "Atlas: Few-shot Learning with Retrieval Augmented Language Models (opens in a new tab) (November 2022)\n",
      "DocPrompting: Generating Code by Retrieving the Docs (opens in a new tab) (July 2022)\n",
      "On the Advance of Making Language Models Better Reasoners (opens in a new tab) (June 2022)\n",
      "Large Language Models are Zero-Shot Reasoners (opens in a new tab) (May 2022)\n",
      "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations (opens in a new tab) (May 2022)\n",
      "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (opens in a new tab) (May 2022)\n",
      "PPT: Pre-trained Prompt Tuning for Few-shot Learning (opens in a new tab) (Mqy 2022)\n",
      "Toxicity Detection with Generative Prompt-based Inference (opens in a new tab) (May 2022)\n",
      "Learning to Transfer Prompts for Text Generation (opens in a new tab) (May 2022)\n",
      "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (opens in a new tab) (May 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "PromptChainer: Chaining Large Language Model Prompts through Visual Programming (opens in a new tab) (March 2022)\n",
      "Self-Consistency Improves Chain of Thought Reasoning in Language Models (opens in a new tab) (March 2022)\n",
      "Training language models to follow instructions with human feedback (opens in a new tab)\n",
      "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (opens in a new tab) (February 2022)\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models (opens in a new tab) (January 2022)\n",
      "Show Your Work: Scratchpads for Intermediate Computation with Language Models (opens in a new tab) (November 2021)\n",
      "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts (opens in a new tab) (October 2021)\n",
      "Generated Knowledge Prompting for Commonsense Reasoning (opens in a new tab) (October 2021)\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization (opens in a new tab) (October 2021)\n",
      "Reframing Instructional Prompts to GPTk's Language (opens in a new tab) (September 2021)\n",
      "Design Guidelines for Prompt Engineering Text-to-Image Generative Models (opens in a new tab) (September 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (August 2021)\n",
      "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity (opens in a new tab) (April 2021)\n",
      "BERTese: Learning to Speak to BERT (opens in a new tab) (April 2021)\n",
      "The Power of Scale for Parameter-Efficient Prompt Tuning (opens in a new tab) (April 2021)\n",
      "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (opens in a new tab) (February 2021)\n",
      "Calibrate Before Use: Improving Few-Shot Performance of Language Models (opens in a new tab) (February 2021)\n",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation (opens in a new tab) (January 2021)\n",
      "Learning to Generate Task-Specific Adapters from Task Description (opens in a new tab) (January 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (December 2020)\n",
      "Learning from Task Descriptions (opens in a new tab) (November 2020)\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts (opens in a new tab) (October 2020)\n",
      "Language Models are Few-Shot Learners (opens in a new tab) (May 2020)\n",
      "How Can We Know What Language Models Know? (opens in a new tab) (July 2020)\n",
      "Scaling Laws for Neural Language Models (opens in a new tab) (January 2020)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get approaches by taking text after the line \"Approaches\" and before the line \"Applications\"\n",
    "\n",
    "approaches = no_tags.split(\"\\nApproaches\")[1].split(\"\\nApplications\")[0]\n",
    "print(approaches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL (opens in a new tab) (September 2023)\n",
      "Chain-of-Verification Reduces Hallucination in Large Language Models (opens in a new tab) (September 2023)\n",
      "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Re-Reading Improves Reasoning in Language Models (opens in a new tab) (September 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (opens in a new tab) (July 2023)\n",
      "Focused Prefix Tuning for Controllable Text Generation (opens in a new tab) (June 2023)\n",
      "Exploring Lottery Prompts for Pre-trained Language Models (opens in a new tab) (May 2023)\n",
      "Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses (opens in a new tab) (May 2023)\n",
      "Let's Verify Step by Step (opens in a new tab) (May 2023)\n",
      "Universality and Limitations of Prompt Tuning (opens in a new tab) (May 2023)\n",
      "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting (opens in a new tab) (May 2023)\n",
      "PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents (opens in a new tab) (May 2023)\n",
      "Reasoning with Language Model is Planning with World Model (opens in a new tab) (May 2023)\n",
      "Self-Critique Prompting with Large Language Models for Inductive Instructions (opens in a new tab) (May 2023)\n",
      "Better Zero-Shot Reasoning with Self-Adaptive Prompting (opens in a new tab) (May 2023)\n",
      "Hierarchical Prompting Assists Large Language Model on Web Navigation (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "Can We Edit Factual Knowledge by In-Context Learning? (opens in a new tab) (May 2023)\n",
      "In-Context Learning of Large Language Models Explained as Kernel Regression (opens in a new tab) (May 2023)\n",
      "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (opens in a new tab) (May 2023)\n",
      "Meta-in-context learning in large language models (opens in a new tab) (May 2023)\n",
      "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs (opens in a new tab) (May 2023)\n",
      "Post Hoc Explanations of Language Models Can Improve Language Models (opens in a new tab) (May 2023)\n",
      "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt (opens in a new tab) (May 2023)\n",
      "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding (opens in a new tab) (May 2023)\n",
      "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (opens in a new tab) (May 2023)\n",
      "Efficient Prompting via Dynamic In-Context Learning (opens in a new tab) (May 2023)\n",
      "The Web Can Be Your Oyster for Improving Large Language Models (opens in a new tab) (May 2023)\n",
      "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (opens in a new tab) (May 2023)\n",
      "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (opens in a new tab) (May 2023)\n",
      "ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs (opens in a new tab) (May 2023)\n",
      "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models (opens in a new tab) (May 2023)\n",
      "CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge (opens in a new tab) (May 2023)\n",
      "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning (opens in a new tab) (May 2023)\n",
      "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (opens in a new tab) (May 2023)\n",
      "Satisfiability-Aided Language Models Using Declarative Prompting (opens in a new tab) (May 2023)\n",
      "Pre-Training to Learn in Context (opens in a new tab) (May 2023)\n",
      "Boosted Prompt Ensembles for Large Language Models (opens in a new tab) (April 2023)\n",
      "Global Prompt Cell: A Portable Control Module for Effective Prompt (opens in a new tab) (April 2023)\n",
      "Why think step-by-step? Reasoning emerges from the locality of experience (opens in a new tab) (April 2023)\n",
      "Revisiting Automated Prompting: Are We Actually Doing Better? (opens in a new tab) (April 2023)\n",
      "REFINER: Reasoning Feedback on Intermediate Representations (opens in a new tab) (April 2023)\n",
      "Reflexion: an autonomous agent with dynamic memory and self-reflection (opens in a new tab) (March 2023)\n",
      "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society (opens in a new tab) (March 2023)\n",
      "Self-Refine: Iterative Refinement with Self-Feedback (opens in a new tab) (March 2023)\n",
      "kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference (opens in a new tab) (March 2023)\n",
      "Visual-Language Prompt Tuning with Knowledge-guided Context Optimization (opens in a new tab) (March 2023)\n",
      "Fairness-guided Few-shot Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Context-faithful Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning (opens in a new tab) (March 2023)\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (opens in a new tab) (March 2023)\n",
      "Model-tuning Via Prompts Makes NLP Models Adversarially Robust (opens in a new tab) (March 2023)\n",
      "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer (opens in a new tab) (March 2023)\n",
      "CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification (opens in a new tab) (March 2023)\n",
      "Larger language models do in-context learning differently (opens in a new tab) (March 2023)\n",
      "OpenICL: An Open-Source Framework for In-context Learning (opens in a new tab) (March 2023)\n",
      "Dynamic Prompting: A Unified Framework for Prompt Tuning (opens in a new tab) (March 2023)\n",
      "ART: Automatic multi-step reasoning and tool-use for large language models (opens in a new tab) (March 2023)\n",
      "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning (opens in a new tab) (March 2023)\n",
      "Effectiveness of Data Augmentation for Prefix Tuning with Limited Data (opens in a new tab) (March 2023)\n",
      "Mixture of Soft Prompts for Controllable Data Generation (opens in a new tab) (March 2023)\n",
      "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners (opens in a new tab) (March 2023)\n",
      "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks (opens in a new tab) (March 2023)\n",
      "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT (opens in a new tab) (February 2023)\n",
      "EvoPrompting: Language Models for Code-Level Neural Architecture Search (opens in a new tab) (February 2023)\n",
      "In-Context Instruction Learning (opens in a new tab) (February 2023)\n",
      "Chain of Hindsight Aligns Language Models with Feedback (opens in a new tab) (February 2023)\n",
      "Language Is Not All You Need: Aligning Perception with Language Models (opens in a new tab) (February 2023)\n",
      "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (opens in a new tab) (February 2023)\n",
      "Active Prompting with Chain-of-Thought for Large Language Models (opens in a new tab) (February 2023)\n",
      "More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models (opens in a new tab) (February 2023)\n",
      "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (opens in a new tab) (February 2023)\n",
      "Guiding Large Language Models via Directional Stimulus Prompting (opens in a new tab) (February 2023)\n",
      "How Does In-Context Learning Help Prompt Tuning? (opens in a new tab) (February 2023)\n",
      "Scalable Prompt Generation for Semi-supervised Learning with Language Models (opens in a new tab) (February 2023)\n",
      "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints (opens in a new tab) (February 2023)\n",
      "Ã€-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting (opens in a new tab) (February 2023)\n",
      "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains (opens in a new tab) (February 2023)\n",
      "Evaluating the Robustness of Discrete Prompts (opens in a new tab) (February 2023)\n",
      "Compositional Exemplars for In-context Learning (opens in a new tab) (February 2023)\n",
      "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (opens in a new tab) (February 2023)\n",
      "Multimodal Chain-of-Thought Reasoning in Language Models (opens in a new tab) (February 2023)\n",
      "Large Language Models Can Be Easily Distracted by Irrelevant Context (opens in a new tab) (February 2023)\n",
      "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models (opens in a new tab) (February 2023)\n",
      "Progressive Prompts: Continual Learning for Language Models (opens in a new tab) (January 2023)\n",
      "Batch Prompting: Efficient Inference with LLM APIs (opens in a new tab) (January 2023)\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (opens in a new tab) (December 2022)\n",
      "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning (opens in a new tab) (December 2022)\n",
      "Constitutional AI: Harmlessness from AI Feedback (opens in a new tab) (December 2022)\n",
      "Successive Prompting for Decomposing Complex Questions (opens in a new tab) (December 2022)\n",
      "Large Language Models are reasoners with Self-Verification (opens in a new tab) (December 2022)\n",
      "Discovering Language Model Behaviors with Model-Written Evaluations (opens in a new tab) (December 2022)\n",
      "Structured Prompting: Scaling In-Context Learning to 1,000 Examples (opens in a new tab) (December 2022)\n",
      "PAL: Program-aided Language Models (opens in a new tab) (November 2022)\n",
      "Large Language Models Are Human-Level Prompt Engineers (opens in a new tab) (November 2022)\n",
      "Ignore Previous Prompt: Attack Techniques For Language Models (opens in a new tab) (November 2022)\n",
      "Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods (opens in a new tab) (November 2022)\n",
      "Teaching Algorithmic Reasoning via In-context Learning (opens in a new tab) (November 2022)\n",
      "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference (opens in a new tab) (November 2022)\n",
      "Ask Me Anything: A simple strategy for prompting language models (opens in a new tab) (October 2022)\n",
      "Recitation-Augmented Language Models (opens in a new tab) (October 2022)\n",
      "ReAct: Synergizing Reasoning and Acting in Language Models (opens in a new tab) (October 2022)\n",
      "Prompting GPT-3 To Be Reliable (opens in a new tab) (October 2022)\n",
      "Decomposed Prompting: A Modular Approach for Solving Complex Tasks (opens in a new tab) (October 2022)\n",
      "Automatic Chain of Thought Prompting in Large Language Models (opens in a new tab) (October 2022)\n",
      "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought (opens in a new tab) (October 2022)\n",
      "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples (opens in a new tab) (September 2022)\n",
      "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning (opens in a new tab) (September 2022)\n",
      "Promptagator: Few-shot Dense Retrieval From 8 Examples (opens in a new tab) (September 2022)\n",
      "Atlas: Few-shot Learning with Retrieval Augmented Language Models (opens in a new tab) (November 2022)\n",
      "DocPrompting: Generating Code by Retrieving the Docs (opens in a new tab) (July 2022)\n",
      "On the Advance of Making Language Models Better Reasoners (opens in a new tab) (June 2022)\n",
      "Large Language Models are Zero-Shot Reasoners (opens in a new tab) (May 2022)\n",
      "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations (opens in a new tab) (May 2022)\n",
      "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (opens in a new tab) (May 2022)\n",
      "PPT: Pre-trained Prompt Tuning for Few-shot Learning (opens in a new tab) (Mqy 2022)\n",
      "Toxicity Detection with Generative Prompt-based Inference (opens in a new tab) (May 2022)\n",
      "Learning to Transfer Prompts for Text Generation (opens in a new tab) (May 2022)\n",
      "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (opens in a new tab) (May 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "PromptChainer: Chaining Large Language Model Prompts through Visual Programming (opens in a new tab) (March 2022)\n",
      "Self-Consistency Improves Chain of Thought Reasoning in Language Models (opens in a new tab) (March 2022)\n",
      "Training language models to follow instructions with human feedback (opens in a new tab)\n",
      "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (opens in a new tab) (February 2022)\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models (opens in a new tab) (January 2022)\n",
      "Show Your Work: Scratchpads for Intermediate Computation with Language Models (opens in a new tab) (November 2021)\n",
      "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts (opens in a new tab) (October 2021)\n",
      "Generated Knowledge Prompting for Commonsense Reasoning (opens in a new tab) (October 2021)\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization (opens in a new tab) (October 2021)\n",
      "Reframing Instructional Prompts to GPTk's Language (opens in a new tab) (September 2021)\n",
      "Design Guidelines for Prompt Engineering Text-to-Image Generative Models (opens in a new tab) (September 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (August 2021)\n",
      "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity (opens in a new tab) (April 2021)\n",
      "BERTese: Learning to Speak to BERT (opens in a new tab) (April 2021)\n",
      "The Power of Scale for Parameter-Efficient Prompt Tuning (opens in a new tab) (April 2021)\n",
      "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (opens in a new tab) (February 2021)\n",
      "Calibrate Before Use: Improving Few-Shot Performance of Language Models (opens in a new tab) (February 2021)\n",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation (opens in a new tab) (January 2021)\n",
      "Learning to Generate Task-Specific Adapters from Task Description (opens in a new tab) (January 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (December 2020)\n",
      "Learning from Task Descriptions (opens in a new tab) (November 2020)\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts (opens in a new tab) (October 2020)\n",
      "Language Models are Few-Shot Learners (opens in a new tab) (May 2020)\n",
      "How Can We Know What Language Models Know? (opens in a new tab) (July 2020)\n",
      "Scaling Laws for Neural Language Models (opens in a new tab) (January 2020)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove fully empty lines\n",
    "no_empty_lines = approaches.replace(\"\\n\\n\", \"\\n\")\n",
    "print(no_empty_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title              Month\n",
      "0    Query-Dependent Prompt Evaluation and Optimiza...   (September 2023)\n",
      "1    Chain-of-Verification Reduces Hallucination in...   (September 2023)\n",
      "2    Connecting Large Language Models with Evolutio...   (September 2023)\n",
      "3    From Sparse to Dense: GPT-4 Summarization with...   (September 2023)\n",
      "4    Re-Reading Improves Reasoning in Language Models    (September 2023)\n",
      "..                                                 ...                ...\n",
      "144                   Learning from Task Descriptions     (November 2020)\n",
      "145  AutoPrompt: Eliciting Knowledge from Language ...     (October 2020)\n",
      "146             Language Models are Few-Shot Learners          (May 2020)\n",
      "147        How Can We Know What Language Models Know?         (July 2020)\n",
      "148           Scaling Laws for Neural Language Models      (January 2020)\n",
      "\n",
      "[149 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of approaches\n",
    "# First column is title (content before \"(opens in a new tab)\")\n",
    "# Second column is month (content after \"(opens in a new tab)\")\n",
    "\n",
    "approaches_papers = pd.DataFrame(columns=[\"Title\", \"Month\"])\n",
    "for line in no_empty_lines.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        title = line.split(\"(opens in a new tab)\")[0]\n",
    "        month = line.split(\"(opens in a new tab)\")[1]\n",
    "        new_record = pd.DataFrame([{\"Title\": title, \"Month\": month}])\n",
    "        approaches_papers = pd.concat([approaches_papers, new_record], ignore_index=True)\n",
    "\n",
    "print(approaches_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column \"Source\" that is \"Prompt Engineering Guide\"\n",
    "approaches_papers[\"Source\"] = \"Prompt Engineering Guide\"\n",
    "\n",
    "# Limit columns to \"Title\" and \"Source\"\n",
    "approaches_papers = approaches_papers[[\"Title\", \"Source\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chain-of-Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Least-to-most promptingÂ enables complex reason...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Self-consistencyÂ improves chain of thought rea...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Self-Refine: Iterative Refinement with Self-Fe...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Large Language Model Guided Tree-of-Thought</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving w...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reaso...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Guiding Large Language Models via Directional ...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Large Language Models Are Human-Level Prompt E...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Web Archive Source: https://web.archive.org/we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Included are all academic papers cited from th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Chain-of-Thought Prompting Elicits Reasoning i...   \n",
       "1       Large Language Models are Zero-Shot Reasoners   \n",
       "2       Scaling Instruction-Finetuned Language Models   \n",
       "3   Generated Knowledge Prompting for Commonsense ...   \n",
       "4   Least-to-most promptingÂ enables complex reason...   \n",
       "5   Self-consistencyÂ improves chain of thought rea...   \n",
       "6   Active Prompting with Chain-of-Thought for Lar...   \n",
       "7   Complexity-Based Prompting for Multi-Step Reas...   \n",
       "8   Self-Refine: Iterative Refinement with Self-Fe...   \n",
       "9         Large Language Model Guided Tree-of-Thought   \n",
       "10  Tree of Thoughts: Deliberate Problem Solving w...   \n",
       "11  Maieutic Prompting: Logically Consistent Reaso...   \n",
       "12  Guiding Large Language Models via Directional ...   \n",
       "13                             GPT-4 Technical Report   \n",
       "14  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "15  Large Language Models Are Human-Level Prompt E...   \n",
       "16  Automatic Chain of Thought Prompting in Large ...   \n",
       "17                                                NaN   \n",
       "18  Web Archive Source: https://web.archive.org/we...   \n",
       "19  Included are all academic papers cited from th...   \n",
       "\n",
       "                            Source  \n",
       "0   Prompt engineering - Wikipedia  \n",
       "1   Prompt engineering - Wikipedia  \n",
       "2   Prompt engineering - Wikipedia  \n",
       "3   Prompt engineering - Wikipedia  \n",
       "4   Prompt engineering - Wikipedia  \n",
       "5   Prompt engineering - Wikipedia  \n",
       "6   Prompt engineering - Wikipedia  \n",
       "7   Prompt engineering - Wikipedia  \n",
       "8   Prompt engineering - Wikipedia  \n",
       "9   Prompt engineering - Wikipedia  \n",
       "10  Prompt engineering - Wikipedia  \n",
       "11  Prompt engineering - Wikipedia  \n",
       "12  Prompt engineering - Wikipedia  \n",
       "13  Prompt engineering - Wikipedia  \n",
       "14  Prompt engineering - Wikipedia  \n",
       "15  Prompt engineering - Wikipedia  \n",
       "16  Prompt engineering - Wikipedia  \n",
       "17                             NaN  \n",
       "18                             NaN  \n",
       "19                             NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in Excel file \"Papers From Wikipedia.xlsx\"\n",
    "\n",
    "papers_from_wikipedia = pd.read_excel(\"Papers From Wikipedia.xlsx\")\n",
    "\n",
    "papers_from_wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chain-of-Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Least-to-most promptingÂ enables complex reason...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Self-consistencyÂ improves chain of thought rea...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Self-Refine: Iterative Refinement with Self-Fe...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Large Language Model Guided Tree-of-Thought</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving w...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reaso...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Guiding Large Language Models via Directional ...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Large Language Models Are Human-Level Prompt E...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Chain-of-Thought Prompting Elicits Reasoning i...   \n",
       "1       Large Language Models are Zero-Shot Reasoners   \n",
       "2       Scaling Instruction-Finetuned Language Models   \n",
       "3   Generated Knowledge Prompting for Commonsense ...   \n",
       "4   Least-to-most promptingÂ enables complex reason...   \n",
       "5   Self-consistencyÂ improves chain of thought rea...   \n",
       "6   Active Prompting with Chain-of-Thought for Lar...   \n",
       "7   Complexity-Based Prompting for Multi-Step Reas...   \n",
       "8   Self-Refine: Iterative Refinement with Self-Fe...   \n",
       "9         Large Language Model Guided Tree-of-Thought   \n",
       "10  Tree of Thoughts: Deliberate Problem Solving w...   \n",
       "11  Maieutic Prompting: Logically Consistent Reaso...   \n",
       "12  Guiding Large Language Models via Directional ...   \n",
       "13                             GPT-4 Technical Report   \n",
       "14  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "15  Large Language Models Are Human-Level Prompt E...   \n",
       "16  Automatic Chain of Thought Prompting in Large ...   \n",
       "\n",
       "                            Source  \n",
       "0   Prompt engineering - Wikipedia  \n",
       "1   Prompt engineering - Wikipedia  \n",
       "2   Prompt engineering - Wikipedia  \n",
       "3   Prompt engineering - Wikipedia  \n",
       "4   Prompt engineering - Wikipedia  \n",
       "5   Prompt engineering - Wikipedia  \n",
       "6   Prompt engineering - Wikipedia  \n",
       "7   Prompt engineering - Wikipedia  \n",
       "8   Prompt engineering - Wikipedia  \n",
       "9   Prompt engineering - Wikipedia  \n",
       "10  Prompt engineering - Wikipedia  \n",
       "11  Prompt engineering - Wikipedia  \n",
       "12  Prompt engineering - Wikipedia  \n",
       "13  Prompt engineering - Wikipedia  \n",
       "14  Prompt engineering - Wikipedia  \n",
       "15  Prompt engineering - Wikipedia  \n",
       "16  Prompt engineering - Wikipedia  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns with NaN values in the Source column\n",
    "papers_from_wikipedia = papers_from_wikipedia.dropna(subset=[\"Source\"])\n",
    "\n",
    "papers_from_wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication Title</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Url</th>\n",
       "      <th>...</th>\n",
       "      <th>Programming Language</th>\n",
       "      <th>Version</th>\n",
       "      <th>System</th>\n",
       "      <th>Code</th>\n",
       "      <th>Code Number</th>\n",
       "      <th>Section</th>\n",
       "      <th>Session</th>\n",
       "      <th>Committee</th>\n",
       "      <th>History</th>\n",
       "      <th>Legislative Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355F8MSY</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2303.08774</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F37GLVE7</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Cheng, Liying; Li, Xingxuan; Bing, Lidong</td>\n",
       "      <td>Is GPT-4 a Good Data Analyst?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2305.15038</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65DI4GGM</td>\n",
       "      <td>newspaperArticle</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Roose, Kevin</td>\n",
       "      <td>A Conversation With Bingâ€™s Chatbot Left Me Dee...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0362-4331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nytimes.com/2023/02/16/technology/...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HLYY654Y</td>\n",
       "      <td>forumPost</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Ethan Mollick [@emollick]</td>\n",
       "      <td>I have a strong suspicion that â€œprompt enginee...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/emollick/status/1627804798...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H445H9N6</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Wu, Tongshuang; Terry, Michael; Cai, Carrie Jun</td>\n",
       "      <td>AI Chains: Transparent and Controllable Human-...</td>\n",
       "      <td>CHI Conference on Human Factors in Computing S...</td>\n",
       "      <td>978-1-4503-9157-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1145/3491102.3517582</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3491102.3517582</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U6WJMRWZ</td>\n",
       "      <td>magazineArticle</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Acar, Oguz A.</td>\n",
       "      <td>AI Prompt Engineering Isnâ€™t the Future</td>\n",
       "      <td>Harvard Business Review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0017-8012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://hbr.org/2023/06/ai-prompt-engineering-...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5YYT9DF3</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Diao, Shizhe; Wang, Pengcheng; Lin, Yong; Zhan...</td>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2302.12246</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4BILARCH</td>\n",
       "      <td>webpage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PromptBase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://promptbase.com</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MI32YKHN</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Hebenstreit, Konstantin; Praas, Robert; Kiesew...</td>\n",
       "      <td>An automatically discovered chain-of-thought p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2305.02897</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HBGCI5CT</td>\n",
       "      <td>journalArticle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bo...</td>\n",
       "      <td>Chain-of-Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LURSUVRC</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Zhang, Zhuosheng; Zhang, Aston; Li, Mu; Smola,...</td>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2210.03493</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46IQXEII</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Dhuliawala, Shehzaad; Komeili, Mojtaba; Xu, Ji...</td>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2309.11495</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N3RXJ67P</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Liu, Jiacheng; Liu, Alisa; Lu, Ximing; Welleck...</td>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2110.08387</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PE8QEAAL</td>\n",
       "      <td>webpage</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Shackell, Cameron</td>\n",
       "      <td>Prompt engineering: is being an AI 'whisperer'...</td>\n",
       "      <td>The Conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://theconversation.com/prompt-engineering-...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA6C7W8Q</td>\n",
       "      <td>webpage</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Martineau, Kim</td>\n",
       "      <td>What is prompt tuning?</td>\n",
       "      <td>IBM Research Blog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://research.ibm.com/blog/what-is-ai-promp...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2JB7XDT8</td>\n",
       "      <td>webpage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mann, Jyoti</td>\n",
       "      <td>Microsoft limits Bing chat exchanges and conve...</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.businessinsider.com/microsoft-limi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WP3MGPDG</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Zhou, Yongchao; Muresanu, Andrei Ioan; Han, Zi...</td>\n",
       "      <td>Large Language Models are Human-Level Prompt E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://openreview.net/forum?id=92gvk82DE-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KCBUP4JK</td>\n",
       "      <td>computerProgram</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Hulbert, Dave</td>\n",
       "      <td>Using Tree-of-Thought Prompting to boost ChatG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/dave1010/tree-of-thought-pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CUZTYUFC</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Chen, Mark; Tworek, Jerry; Jun, Heewoo; Yuan, ...</td>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2107.03374</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Z87LTXAL</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Min, Sewon; Lyu, Xinxi; Holtzman, Ari; Artetxe...</td>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2202.12837</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WB62ZY7S</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Su...</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2005.14165</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2PJH4SLP</td>\n",
       "      <td>webpage</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Flesch, Rudolf</td>\n",
       "      <td>How to Write Plain English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://web.archive.org/web/20160712094308/htt...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>G6TVY4QN</td>\n",
       "      <td>computerProgram</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aggarwal, Shivam Bansal, Chaitanya</td>\n",
       "      <td>textstat: Calculate statistical features from ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/shivam5992/textstat</td>\n",
       "      <td>...</td>\n",
       "      <td>Python</td>\n",
       "      <td>0.7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LT4HAYH3</td>\n",
       "      <td>computerProgram</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lacchia, Michele</td>\n",
       "      <td>radon: Code Metrics in Python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://radon.readthedocs.org/</td>\n",
       "      <td>...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6.0.1</td>\n",
       "      <td>OS Independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>R5JINY9X</td>\n",
       "      <td>journalArticle</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Gardner, Dee; Davies, Mark</td>\n",
       "      <td>A New Academic Vocabulary List</td>\n",
       "      <td>Applied Linguistics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0142-6001</td>\n",
       "      <td>10.1093/applin/amt015</td>\n",
       "      <td>https://doi.org/10.1093/applin/amt015</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>H3CSSUL8</td>\n",
       "      <td>webpage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semantic Scholar | AI-Powered Research Tool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.semanticscholar.org/</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CY35X7AQ</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Gao, Andrew</td>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2139/ssrn.4504303</td>\n",
       "      <td>https://papers.ssrn.com/abstract=4504303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QAGSI2WP</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Fu, Yao; Peng, Hao; Sabharwal, Ashish; Clark, ...</td>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2210.00720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XCA83MMZ</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Shum, KaShun; Diao, Shizhe; Zhang, Tong</td>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2302.12822</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PPQDHPUF</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Adams, Griffin; Fabbri, Alexander; Ladhak, Fai...</td>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2309.04269</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HFMLMG8R</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Pu, Dongqi; Demberg, Vera</td>\n",
       "      <td>ChatGPT vs Human-authored Text: Insights into ...</td>\n",
       "      <td>Proceedings of the 61st Annual Meeting of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.acl-srw.1</td>\n",
       "      <td>https://aclanthology.org/2023.acl-srw.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q2G4VQCP</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Imperial, Joseph Marvin; Madabushi, Harish Tayyar</td>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2309.05454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2TTZLM4K</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Bhaskar, Adithya; Fabbri, Alex; Durrett, Greg</td>\n",
       "      <td>Prompted Opinion Summarization with GPT-3.5</td>\n",
       "      <td>Findings of the Association for Computational ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.591</td>\n",
       "      <td>https://aclanthology.org/2023.findings-acl.591</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Key         Item Type  Publication Year  \\\n",
       "0   355F8MSY          preprint            2023.0   \n",
       "1   F37GLVE7          preprint            2023.0   \n",
       "2   65DI4GGM  newspaperArticle            2023.0   \n",
       "3   HLYY654Y         forumPost            2023.0   \n",
       "4   H445H9N6   conferencePaper            2022.0   \n",
       "5   U6WJMRWZ   magazineArticle            2023.0   \n",
       "6   5YYT9DF3          preprint            2023.0   \n",
       "7   4BILARCH           webpage               NaN   \n",
       "8   MI32YKHN          preprint            2023.0   \n",
       "9   HBGCI5CT    journalArticle               NaN   \n",
       "10  LURSUVRC          preprint            2022.0   \n",
       "11  46IQXEII          preprint            2023.0   \n",
       "12  N3RXJ67P          preprint            2022.0   \n",
       "13  PE8QEAAL           webpage            2023.0   \n",
       "14  CA6C7W8Q           webpage            2021.0   \n",
       "15  2JB7XDT8           webpage               NaN   \n",
       "16  WP3MGPDG   conferencePaper            2022.0   \n",
       "17  KCBUP4JK   computerProgram            2023.0   \n",
       "18  CUZTYUFC          preprint            2021.0   \n",
       "19  Z87LTXAL          preprint            2022.0   \n",
       "20  WB62ZY7S          preprint            2020.0   \n",
       "21  2PJH4SLP           webpage            2016.0   \n",
       "22  G6TVY4QN   computerProgram               NaN   \n",
       "23  LT4HAYH3   computerProgram               NaN   \n",
       "24  R5JINY9X    journalArticle            2014.0   \n",
       "25  H3CSSUL8           webpage               NaN   \n",
       "26  CY35X7AQ          preprint            2023.0   \n",
       "27  QAGSI2WP          preprint            2023.0   \n",
       "28  XCA83MMZ          preprint            2023.0   \n",
       "29  PPQDHPUF          preprint            2023.0   \n",
       "30  HFMLMG8R   conferencePaper            2023.0   \n",
       "31  Q2G4VQCP          preprint            2023.0   \n",
       "32  2TTZLM4K   conferencePaper            2023.0   \n",
       "\n",
       "                                               Author  \\\n",
       "0                                              OpenAI   \n",
       "1           Cheng, Liying; Li, Xingxuan; Bing, Lidong   \n",
       "2                                        Roose, Kevin   \n",
       "3                           Ethan Mollick [@emollick]   \n",
       "4     Wu, Tongshuang; Terry, Michael; Cai, Carrie Jun   \n",
       "5                                       Acar, Oguz A.   \n",
       "6   Diao, Shizhe; Wang, Pengcheng; Lin, Yong; Zhan...   \n",
       "7                                                 NaN   \n",
       "8   Hebenstreit, Konstantin; Praas, Robert; Kiesew...   \n",
       "9   Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bo...   \n",
       "10  Zhang, Zhuosheng; Zhang, Aston; Li, Mu; Smola,...   \n",
       "11  Dhuliawala, Shehzaad; Komeili, Mojtaba; Xu, Ji...   \n",
       "12  Liu, Jiacheng; Liu, Alisa; Lu, Ximing; Welleck...   \n",
       "13                                  Shackell, Cameron   \n",
       "14                                     Martineau, Kim   \n",
       "15                                        Mann, Jyoti   \n",
       "16  Zhou, Yongchao; Muresanu, Andrei Ioan; Han, Zi...   \n",
       "17                                      Hulbert, Dave   \n",
       "18  Chen, Mark; Tworek, Jerry; Jun, Heewoo; Yuan, ...   \n",
       "19  Min, Sewon; Lyu, Xinxi; Holtzman, Ari; Artetxe...   \n",
       "20  Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Su...   \n",
       "21                                     Flesch, Rudolf   \n",
       "22                 Aggarwal, Shivam Bansal, Chaitanya   \n",
       "23                                   Lacchia, Michele   \n",
       "24                         Gardner, Dee; Davies, Mark   \n",
       "25                                                NaN   \n",
       "26                                        Gao, Andrew   \n",
       "27  Fu, Yao; Peng, Hao; Sabharwal, Ashish; Clark, ...   \n",
       "28            Shum, KaShun; Diao, Shizhe; Zhang, Tong   \n",
       "29  Adams, Griffin; Fabbri, Alexander; Ladhak, Fai...   \n",
       "30                          Pu, Dongqi; Demberg, Vera   \n",
       "31  Imperial, Joseph Marvin; Madabushi, Harish Tayyar   \n",
       "32      Bhaskar, Adithya; Fabbri, Alex; Durrett, Greg   \n",
       "\n",
       "                                                Title  \\\n",
       "0                              GPT-4 Technical Report   \n",
       "1                       Is GPT-4 a Good Data Analyst?   \n",
       "2   A Conversation With Bingâ€™s Chatbot Left Me Dee...   \n",
       "3   I have a strong suspicion that â€œprompt enginee...   \n",
       "4   AI Chains: Transparent and Controllable Human-...   \n",
       "5              AI Prompt Engineering Isnâ€™t the Future   \n",
       "6   Active Prompting with Chain-of-Thought for Lar...   \n",
       "7                                          PromptBase   \n",
       "8   An automatically discovered chain-of-thought p...   \n",
       "9   Chain-of-Thought Prompting Elicits Reasoning i...   \n",
       "10  Automatic Chain of Thought Prompting in Large ...   \n",
       "11  Chain-of-Verification Reduces Hallucination in...   \n",
       "12  Generated Knowledge Prompting for Commonsense ...   \n",
       "13  Prompt engineering: is being an AI 'whisperer'...   \n",
       "14                             What is prompt tuning?   \n",
       "15  Microsoft limits Bing chat exchanges and conve...   \n",
       "16  Large Language Models are Human-Level Prompt E...   \n",
       "17  Using Tree-of-Thought Prompting to boost ChatG...   \n",
       "18   Evaluating Large Language Models Trained on Code   \n",
       "19  Rethinking the Role of Demonstrations: What Ma...   \n",
       "20              Language Models are Few-Shot Learners   \n",
       "21                         How to Write Plain English   \n",
       "22  textstat: Calculate statistical features from ...   \n",
       "23                      radon: Code Metrics in Python   \n",
       "24                     A New Academic Vocabulary List   \n",
       "25        Semantic Scholar | AI-Powered Research Tool   \n",
       "26       Prompt Engineering for Large Language Models   \n",
       "27  Complexity-Based Prompting for Multi-Step Reas...   \n",
       "28  Automatic Prompt Augmentation and Selection wi...   \n",
       "29  From Sparse to Dense: GPT-4 Summarization with...   \n",
       "30  ChatGPT vs Human-authored Text: Insights into ...   \n",
       "31  Flesch or Fumble? Evaluating Readability Stand...   \n",
       "32        Prompted Opinion Summarization with GPT-3.5   \n",
       "\n",
       "                                    Publication Title               ISBN  \\\n",
       "0                                                 NaN                NaN   \n",
       "1                                                 NaN                NaN   \n",
       "2                                  The New York Times                NaN   \n",
       "3                                             Twitter                NaN   \n",
       "4   CHI Conference on Human Factors in Computing S...  978-1-4503-9157-3   \n",
       "5                             Harvard Business Review                NaN   \n",
       "6                                                 NaN                NaN   \n",
       "7                                                 NaN                NaN   \n",
       "8                                                 NaN                NaN   \n",
       "9                                                 NaN                NaN   \n",
       "10                                                NaN                NaN   \n",
       "11                                                NaN                NaN   \n",
       "12                                                NaN                NaN   \n",
       "13                                   The Conversation                NaN   \n",
       "14                                  IBM Research Blog                NaN   \n",
       "15                                   Business Insider                NaN   \n",
       "16                                                NaN                NaN   \n",
       "17                                                NaN                NaN   \n",
       "18                                                NaN                NaN   \n",
       "19                                                NaN                NaN   \n",
       "20                                                NaN                NaN   \n",
       "21                                                NaN                NaN   \n",
       "22                                                NaN                NaN   \n",
       "23                                                NaN                NaN   \n",
       "24                                Applied Linguistics                NaN   \n",
       "25                                                NaN                NaN   \n",
       "26                                                NaN                NaN   \n",
       "27                                                NaN                NaN   \n",
       "28                                                NaN                NaN   \n",
       "29                                                NaN                NaN   \n",
       "30  Proceedings of the 61st Annual Meeting of the ...                NaN   \n",
       "31                                                NaN                NaN   \n",
       "32  Findings of the Association for Computational ...                NaN   \n",
       "\n",
       "         ISSN                                DOI  \\\n",
       "0         NaN                                NaN   \n",
       "1         NaN                                NaN   \n",
       "2   0362-4331                                NaN   \n",
       "3         NaN                                NaN   \n",
       "4         NaN            10.1145/3491102.3517582   \n",
       "5   0017-8012                                NaN   \n",
       "6         NaN                                NaN   \n",
       "7         NaN                                NaN   \n",
       "8         NaN                                NaN   \n",
       "9         NaN                                NaN   \n",
       "10        NaN                                NaN   \n",
       "11        NaN                                NaN   \n",
       "12        NaN                                NaN   \n",
       "13        NaN                                NaN   \n",
       "14        NaN                                NaN   \n",
       "15        NaN                                NaN   \n",
       "16        NaN                                NaN   \n",
       "17        NaN                                NaN   \n",
       "18        NaN                                NaN   \n",
       "19        NaN                                NaN   \n",
       "20        NaN                                NaN   \n",
       "21        NaN                                NaN   \n",
       "22        NaN                                NaN   \n",
       "23        NaN                                NaN   \n",
       "24  0142-6001              10.1093/applin/amt015   \n",
       "25        NaN                                NaN   \n",
       "26        NaN               10.2139/ssrn.4504303   \n",
       "27        NaN                                NaN   \n",
       "28        NaN                                NaN   \n",
       "29        NaN                                NaN   \n",
       "30        NaN         10.18653/v1/2023.acl-srw.1   \n",
       "31        NaN                                NaN   \n",
       "32        NaN  10.18653/v1/2023.findings-acl.591   \n",
       "\n",
       "                                                  Url  ...  \\\n",
       "0                     http://arxiv.org/abs/2303.08774  ...   \n",
       "1                     http://arxiv.org/abs/2305.15038  ...   \n",
       "2   https://www.nytimes.com/2023/02/16/technology/...  ...   \n",
       "3   https://twitter.com/emollick/status/1627804798...  ...   \n",
       "4      https://dl.acm.org/doi/10.1145/3491102.3517582  ...   \n",
       "5   https://hbr.org/2023/06/ai-prompt-engineering-...  ...   \n",
       "6                     http://arxiv.org/abs/2302.12246  ...   \n",
       "7                              https://promptbase.com  ...   \n",
       "8                     http://arxiv.org/abs/2305.02897  ...   \n",
       "9                                                 NaN  ...   \n",
       "10                    http://arxiv.org/abs/2210.03493  ...   \n",
       "11                    http://arxiv.org/abs/2309.11495  ...   \n",
       "12                    http://arxiv.org/abs/2110.08387  ...   \n",
       "13  http://theconversation.com/prompt-engineering-...  ...   \n",
       "14  https://research.ibm.com/blog/what-is-ai-promp...  ...   \n",
       "15  https://www.businessinsider.com/microsoft-limi...  ...   \n",
       "16         https://openreview.net/forum?id=92gvk82DE-  ...   \n",
       "17  https://github.com/dave1010/tree-of-thought-pr...  ...   \n",
       "18                    http://arxiv.org/abs/2107.03374  ...   \n",
       "19                    http://arxiv.org/abs/2202.12837  ...   \n",
       "20                    http://arxiv.org/abs/2005.14165  ...   \n",
       "21  https://web.archive.org/web/20160712094308/htt...  ...   \n",
       "22             https://github.com/shivam5992/textstat  ...   \n",
       "23                     https://radon.readthedocs.org/  ...   \n",
       "24              https://doi.org/10.1093/applin/amt015  ...   \n",
       "25                   https://www.semanticscholar.org/  ...   \n",
       "26           https://papers.ssrn.com/abstract=4504303  ...   \n",
       "27                    http://arxiv.org/abs/2210.00720  ...   \n",
       "28                    http://arxiv.org/abs/2302.12822  ...   \n",
       "29                    http://arxiv.org/abs/2309.04269  ...   \n",
       "30            https://aclanthology.org/2023.acl-srw.1  ...   \n",
       "31                    http://arxiv.org/abs/2309.05454  ...   \n",
       "32     https://aclanthology.org/2023.findings-acl.591  ...   \n",
       "\n",
       "   Programming Language Version          System Code Code Number     Section  \\\n",
       "0                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "1                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "2                   NaN     NaN             NaN  NaN         NaN  Technology   \n",
       "3                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "4                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "5                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "6                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "7                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "8                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "9                   NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "10                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "11                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "12                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "13                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "14                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "15                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "16                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "17                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "18                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "19                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "20                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "21                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "22               Python   0.7.3             NaN  NaN         NaN         NaN   \n",
       "23               Python   6.0.1  OS Independent  NaN         NaN         NaN   \n",
       "24                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "25                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "26                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "27                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "28                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "29                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "30                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "31                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "32                  NaN     NaN             NaN  NaN         NaN         NaN   \n",
       "\n",
       "    Session  Committee  History  Legislative Body  \n",
       "0       NaN        NaN      NaN               NaN  \n",
       "1       NaN        NaN      NaN               NaN  \n",
       "2       NaN        NaN      NaN               NaN  \n",
       "3       NaN        NaN      NaN               NaN  \n",
       "4       NaN        NaN      NaN               NaN  \n",
       "5       NaN        NaN      NaN               NaN  \n",
       "6       NaN        NaN      NaN               NaN  \n",
       "7       NaN        NaN      NaN               NaN  \n",
       "8       NaN        NaN      NaN               NaN  \n",
       "9       NaN        NaN      NaN               NaN  \n",
       "10      NaN        NaN      NaN               NaN  \n",
       "11      NaN        NaN      NaN               NaN  \n",
       "12      NaN        NaN      NaN               NaN  \n",
       "13      NaN        NaN      NaN               NaN  \n",
       "14      NaN        NaN      NaN               NaN  \n",
       "15      NaN        NaN      NaN               NaN  \n",
       "16      NaN        NaN      NaN               NaN  \n",
       "17      NaN        NaN      NaN               NaN  \n",
       "18      NaN        NaN      NaN               NaN  \n",
       "19      NaN        NaN      NaN               NaN  \n",
       "20      NaN        NaN      NaN               NaN  \n",
       "21      NaN        NaN      NaN               NaN  \n",
       "22      NaN        NaN      NaN               NaN  \n",
       "23      NaN        NaN      NaN               NaN  \n",
       "24      NaN        NaN      NaN               NaN  \n",
       "25      NaN        NaN      NaN               NaN  \n",
       "26      NaN        NaN      NaN               NaN  \n",
       "27      NaN        NaN      NaN               NaN  \n",
       "28      NaN        NaN      NaN               NaN  \n",
       "29      NaN        NaN      NaN               NaN  \n",
       "30      NaN        NaN      NaN               NaN  \n",
       "31      NaN        NaN      NaN               NaN  \n",
       "32      NaN        NaN      NaN               NaN  \n",
       "\n",
       "[33 rows x 87 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in CSV file \"Zotero Citations.csv\"\n",
    "\n",
    "zotero_citations = pd.read_csv(\"Zotero Citations.csv\")\n",
    "\n",
    "zotero_citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3660\\2473372652.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  zotero_citations_limited = zotero_citations_limited[~zotero_citations[\"Publication Title\"].isin([\"Business Insider\", \"IBM Research Blog\", \"The Conversation\"])]\n",
      "C:\\Users\\ijyli\\AppData\\Local\\Temp\\ipykernel_3660\\2473372652.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  zotero_citations_limited = zotero_citations_limited[~zotero_citations[\"Title\"].isin([\"PromptBase\", \"How to Write Plain English\", \"Semantic Scholar | AI-Powered Research Tool\", \"A New Academic Vocabulary List\", \"radon: Code Metrics in Python\"])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication Title</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Url</th>\n",
       "      <th>...</th>\n",
       "      <th>Programming Language</th>\n",
       "      <th>Version</th>\n",
       "      <th>System</th>\n",
       "      <th>Code</th>\n",
       "      <th>Code Number</th>\n",
       "      <th>Section</th>\n",
       "      <th>Session</th>\n",
       "      <th>Committee</th>\n",
       "      <th>History</th>\n",
       "      <th>Legislative Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355F8MSY</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2303.08774</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F37GLVE7</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Cheng, Liying; Li, Xingxuan; Bing, Lidong</td>\n",
       "      <td>Is GPT-4 a Good Data Analyst?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2305.15038</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H445H9N6</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Wu, Tongshuang; Terry, Michael; Cai, Carrie Jun</td>\n",
       "      <td>AI Chains: Transparent and Controllable Human-...</td>\n",
       "      <td>CHI Conference on Human Factors in Computing S...</td>\n",
       "      <td>978-1-4503-9157-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1145/3491102.3517582</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/3491102.3517582</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5YYT9DF3</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Diao, Shizhe; Wang, Pengcheng; Lin, Yong; Zhan...</td>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2302.12246</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MI32YKHN</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Hebenstreit, Konstantin; Praas, Robert; Kiesew...</td>\n",
       "      <td>An automatically discovered chain-of-thought p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2305.02897</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HBGCI5CT</td>\n",
       "      <td>journalArticle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bo...</td>\n",
       "      <td>Chain-of-Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LURSUVRC</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Zhang, Zhuosheng; Zhang, Aston; Li, Mu; Smola,...</td>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2210.03493</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46IQXEII</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Dhuliawala, Shehzaad; Komeili, Mojtaba; Xu, Ji...</td>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2309.11495</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N3RXJ67P</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Liu, Jiacheng; Liu, Alisa; Lu, Ximing; Welleck...</td>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2110.08387</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WP3MGPDG</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Zhou, Yongchao; Muresanu, Andrei Ioan; Han, Zi...</td>\n",
       "      <td>Large Language Models are Human-Level Prompt E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://openreview.net/forum?id=92gvk82DE-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KCBUP4JK</td>\n",
       "      <td>computerProgram</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Hulbert, Dave</td>\n",
       "      <td>Using Tree-of-Thought Prompting to boost ChatG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/dave1010/tree-of-thought-pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CUZTYUFC</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Chen, Mark; Tworek, Jerry; Jun, Heewoo; Yuan, ...</td>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2107.03374</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Z87LTXAL</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Min, Sewon; Lyu, Xinxi; Holtzman, Ari; Artetxe...</td>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2202.12837</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WB62ZY7S</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Su...</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2005.14165</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CY35X7AQ</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Gao, Andrew</td>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2139/ssrn.4504303</td>\n",
       "      <td>https://papers.ssrn.com/abstract=4504303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QAGSI2WP</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Fu, Yao; Peng, Hao; Sabharwal, Ashish; Clark, ...</td>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2210.00720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XCA83MMZ</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Shum, KaShun; Diao, Shizhe; Zhang, Tong</td>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2302.12822</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PPQDHPUF</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Adams, Griffin; Fabbri, Alexander; Ladhak, Fai...</td>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2309.04269</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HFMLMG8R</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Pu, Dongqi; Demberg, Vera</td>\n",
       "      <td>ChatGPT vs Human-authored Text: Insights into ...</td>\n",
       "      <td>Proceedings of the 61st Annual Meeting of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.acl-srw.1</td>\n",
       "      <td>https://aclanthology.org/2023.acl-srw.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q2G4VQCP</td>\n",
       "      <td>preprint</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Imperial, Joseph Marvin; Madabushi, Harish Tayyar</td>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://arxiv.org/abs/2309.05454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2TTZLM4K</td>\n",
       "      <td>conferencePaper</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Bhaskar, Adithya; Fabbri, Alex; Durrett, Greg</td>\n",
       "      <td>Prompted Opinion Summarization with GPT-3.5</td>\n",
       "      <td>Findings of the Association for Computational ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.591</td>\n",
       "      <td>https://aclanthology.org/2023.findings-acl.591</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Key        Item Type  Publication Year  \\\n",
       "0   355F8MSY         preprint            2023.0   \n",
       "1   F37GLVE7         preprint            2023.0   \n",
       "4   H445H9N6  conferencePaper            2022.0   \n",
       "6   5YYT9DF3         preprint            2023.0   \n",
       "8   MI32YKHN         preprint            2023.0   \n",
       "9   HBGCI5CT   journalArticle               NaN   \n",
       "10  LURSUVRC         preprint            2022.0   \n",
       "11  46IQXEII         preprint            2023.0   \n",
       "12  N3RXJ67P         preprint            2022.0   \n",
       "16  WP3MGPDG  conferencePaper            2022.0   \n",
       "17  KCBUP4JK  computerProgram            2023.0   \n",
       "18  CUZTYUFC         preprint            2021.0   \n",
       "19  Z87LTXAL         preprint            2022.0   \n",
       "20  WB62ZY7S         preprint            2020.0   \n",
       "26  CY35X7AQ         preprint            2023.0   \n",
       "27  QAGSI2WP         preprint            2023.0   \n",
       "28  XCA83MMZ         preprint            2023.0   \n",
       "29  PPQDHPUF         preprint            2023.0   \n",
       "30  HFMLMG8R  conferencePaper            2023.0   \n",
       "31  Q2G4VQCP         preprint            2023.0   \n",
       "32  2TTZLM4K  conferencePaper            2023.0   \n",
       "\n",
       "                                               Author  \\\n",
       "0                                              OpenAI   \n",
       "1           Cheng, Liying; Li, Xingxuan; Bing, Lidong   \n",
       "4     Wu, Tongshuang; Terry, Michael; Cai, Carrie Jun   \n",
       "6   Diao, Shizhe; Wang, Pengcheng; Lin, Yong; Zhan...   \n",
       "8   Hebenstreit, Konstantin; Praas, Robert; Kiesew...   \n",
       "9   Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bo...   \n",
       "10  Zhang, Zhuosheng; Zhang, Aston; Li, Mu; Smola,...   \n",
       "11  Dhuliawala, Shehzaad; Komeili, Mojtaba; Xu, Ji...   \n",
       "12  Liu, Jiacheng; Liu, Alisa; Lu, Ximing; Welleck...   \n",
       "16  Zhou, Yongchao; Muresanu, Andrei Ioan; Han, Zi...   \n",
       "17                                      Hulbert, Dave   \n",
       "18  Chen, Mark; Tworek, Jerry; Jun, Heewoo; Yuan, ...   \n",
       "19  Min, Sewon; Lyu, Xinxi; Holtzman, Ari; Artetxe...   \n",
       "20  Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Su...   \n",
       "26                                        Gao, Andrew   \n",
       "27  Fu, Yao; Peng, Hao; Sabharwal, Ashish; Clark, ...   \n",
       "28            Shum, KaShun; Diao, Shizhe; Zhang, Tong   \n",
       "29  Adams, Griffin; Fabbri, Alexander; Ladhak, Fai...   \n",
       "30                          Pu, Dongqi; Demberg, Vera   \n",
       "31  Imperial, Joseph Marvin; Madabushi, Harish Tayyar   \n",
       "32      Bhaskar, Adithya; Fabbri, Alex; Durrett, Greg   \n",
       "\n",
       "                                                Title  \\\n",
       "0                              GPT-4 Technical Report   \n",
       "1                       Is GPT-4 a Good Data Analyst?   \n",
       "4   AI Chains: Transparent and Controllable Human-...   \n",
       "6   Active Prompting with Chain-of-Thought for Lar...   \n",
       "8   An automatically discovered chain-of-thought p...   \n",
       "9   Chain-of-Thought Prompting Elicits Reasoning i...   \n",
       "10  Automatic Chain of Thought Prompting in Large ...   \n",
       "11  Chain-of-Verification Reduces Hallucination in...   \n",
       "12  Generated Knowledge Prompting for Commonsense ...   \n",
       "16  Large Language Models are Human-Level Prompt E...   \n",
       "17  Using Tree-of-Thought Prompting to boost ChatG...   \n",
       "18   Evaluating Large Language Models Trained on Code   \n",
       "19  Rethinking the Role of Demonstrations: What Ma...   \n",
       "20              Language Models are Few-Shot Learners   \n",
       "26       Prompt Engineering for Large Language Models   \n",
       "27  Complexity-Based Prompting for Multi-Step Reas...   \n",
       "28  Automatic Prompt Augmentation and Selection wi...   \n",
       "29  From Sparse to Dense: GPT-4 Summarization with...   \n",
       "30  ChatGPT vs Human-authored Text: Insights into ...   \n",
       "31  Flesch or Fumble? Evaluating Readability Stand...   \n",
       "32        Prompted Opinion Summarization with GPT-3.5   \n",
       "\n",
       "                                    Publication Title               ISBN ISSN  \\\n",
       "0                                                 NaN                NaN  NaN   \n",
       "1                                                 NaN                NaN  NaN   \n",
       "4   CHI Conference on Human Factors in Computing S...  978-1-4503-9157-3  NaN   \n",
       "6                                                 NaN                NaN  NaN   \n",
       "8                                                 NaN                NaN  NaN   \n",
       "9                                                 NaN                NaN  NaN   \n",
       "10                                                NaN                NaN  NaN   \n",
       "11                                                NaN                NaN  NaN   \n",
       "12                                                NaN                NaN  NaN   \n",
       "16                                                NaN                NaN  NaN   \n",
       "17                                                NaN                NaN  NaN   \n",
       "18                                                NaN                NaN  NaN   \n",
       "19                                                NaN                NaN  NaN   \n",
       "20                                                NaN                NaN  NaN   \n",
       "26                                                NaN                NaN  NaN   \n",
       "27                                                NaN                NaN  NaN   \n",
       "28                                                NaN                NaN  NaN   \n",
       "29                                                NaN                NaN  NaN   \n",
       "30  Proceedings of the 61st Annual Meeting of the ...                NaN  NaN   \n",
       "31                                                NaN                NaN  NaN   \n",
       "32  Findings of the Association for Computational ...                NaN  NaN   \n",
       "\n",
       "                                  DOI  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "4             10.1145/3491102.3517582   \n",
       "6                                 NaN   \n",
       "8                                 NaN   \n",
       "9                                 NaN   \n",
       "10                                NaN   \n",
       "11                                NaN   \n",
       "12                                NaN   \n",
       "16                                NaN   \n",
       "17                                NaN   \n",
       "18                                NaN   \n",
       "19                                NaN   \n",
       "20                                NaN   \n",
       "26               10.2139/ssrn.4504303   \n",
       "27                                NaN   \n",
       "28                                NaN   \n",
       "29                                NaN   \n",
       "30         10.18653/v1/2023.acl-srw.1   \n",
       "31                                NaN   \n",
       "32  10.18653/v1/2023.findings-acl.591   \n",
       "\n",
       "                                                  Url  ...  \\\n",
       "0                     http://arxiv.org/abs/2303.08774  ...   \n",
       "1                     http://arxiv.org/abs/2305.15038  ...   \n",
       "4      https://dl.acm.org/doi/10.1145/3491102.3517582  ...   \n",
       "6                     http://arxiv.org/abs/2302.12246  ...   \n",
       "8                     http://arxiv.org/abs/2305.02897  ...   \n",
       "9                                                 NaN  ...   \n",
       "10                    http://arxiv.org/abs/2210.03493  ...   \n",
       "11                    http://arxiv.org/abs/2309.11495  ...   \n",
       "12                    http://arxiv.org/abs/2110.08387  ...   \n",
       "16         https://openreview.net/forum?id=92gvk82DE-  ...   \n",
       "17  https://github.com/dave1010/tree-of-thought-pr...  ...   \n",
       "18                    http://arxiv.org/abs/2107.03374  ...   \n",
       "19                    http://arxiv.org/abs/2202.12837  ...   \n",
       "20                    http://arxiv.org/abs/2005.14165  ...   \n",
       "26           https://papers.ssrn.com/abstract=4504303  ...   \n",
       "27                    http://arxiv.org/abs/2210.00720  ...   \n",
       "28                    http://arxiv.org/abs/2302.12822  ...   \n",
       "29                    http://arxiv.org/abs/2309.04269  ...   \n",
       "30            https://aclanthology.org/2023.acl-srw.1  ...   \n",
       "31                    http://arxiv.org/abs/2309.05454  ...   \n",
       "32     https://aclanthology.org/2023.findings-acl.591  ...   \n",
       "\n",
       "   Programming Language Version System Code Code Number Section  Session  \\\n",
       "0                   NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "1                   NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "4                   NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "6                   NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "8                   NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "9                   NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "10                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "11                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "12                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "16                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "17                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "18                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "19                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "20                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "26                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "27                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "28                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "29                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "30                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "31                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "32                  NaN     NaN    NaN  NaN         NaN     NaN      NaN   \n",
       "\n",
       "    Committee  History  Legislative Body  \n",
       "0         NaN      NaN               NaN  \n",
       "1         NaN      NaN               NaN  \n",
       "4         NaN      NaN               NaN  \n",
       "6         NaN      NaN               NaN  \n",
       "8         NaN      NaN               NaN  \n",
       "9         NaN      NaN               NaN  \n",
       "10        NaN      NaN               NaN  \n",
       "11        NaN      NaN               NaN  \n",
       "12        NaN      NaN               NaN  \n",
       "16        NaN      NaN               NaN  \n",
       "17        NaN      NaN               NaN  \n",
       "18        NaN      NaN               NaN  \n",
       "19        NaN      NaN               NaN  \n",
       "20        NaN      NaN               NaN  \n",
       "26        NaN      NaN               NaN  \n",
       "27        NaN      NaN               NaN  \n",
       "28        NaN      NaN               NaN  \n",
       "29        NaN      NaN               NaN  \n",
       "30        NaN      NaN               NaN  \n",
       "31        NaN      NaN               NaN  \n",
       "32        NaN      NaN               NaN  \n",
       "\n",
       "[21 rows x 87 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove some items that are clearly not of interest - Item Type values of \"forumPost\", \"newspaperArticle\", \"magazineArticle\"\n",
    "# Publication title \"Business Insider\", \"IBM Research Blog\", \"The Conversation\"\n",
    "# Specific item titles \"PromptBase\", \"How to Write Plain English\", \"Semantic Scholar | AI-Powered Research Tool\", \"A New Academic Vocabulary List\", \"radon: Code Metrics in Python\"\n",
    "# Items with \"Programming Language\" value not NaN\n",
    "zotero_citations_limited = zotero_citations[~zotero_citations[\"Item Type\"].isin([\"forumPost\", \"newspaperArticle\", \"magazineArticle\"])]\n",
    "zotero_citations_limited = zotero_citations_limited[~zotero_citations[\"Publication Title\"].isin([\"Business Insider\", \"IBM Research Blog\", \"The Conversation\"])]\n",
    "zotero_citations_limited = zotero_citations_limited[~zotero_citations[\"Title\"].isin([\"PromptBase\", \"How to Write Plain English\", \"Semantic Scholar | AI-Powered Research Tool\", \"A New Academic Vocabulary List\", \"radon: Code Metrics in Python\"])]\n",
    "zotero_citations_limited = zotero_citations_limited[zotero_citations_limited[\"Programming Language\"].isna()]\n",
    "\n",
    "zotero_citations_limited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is GPT-4 a Good Data Analyst?</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Chains: Transparent and Controllable Human-...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>An automatically discovered chain-of-thought p...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chain-of-Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Large Language Models are Human-Level Prompt E...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Using Tree-of-Thought Prompting to boost ChatG...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ChatGPT vs Human-authored Text: Insights into ...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Prompted Opinion Summarization with GPT-3.5</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title            Source\n",
       "0                              GPT-4 Technical Report  Zotero Citations\n",
       "1                       Is GPT-4 a Good Data Analyst?  Zotero Citations\n",
       "4   AI Chains: Transparent and Controllable Human-...  Zotero Citations\n",
       "6   Active Prompting with Chain-of-Thought for Lar...  Zotero Citations\n",
       "8   An automatically discovered chain-of-thought p...  Zotero Citations\n",
       "9   Chain-of-Thought Prompting Elicits Reasoning i...  Zotero Citations\n",
       "10  Automatic Chain of Thought Prompting in Large ...  Zotero Citations\n",
       "11  Chain-of-Verification Reduces Hallucination in...  Zotero Citations\n",
       "12  Generated Knowledge Prompting for Commonsense ...  Zotero Citations\n",
       "16  Large Language Models are Human-Level Prompt E...  Zotero Citations\n",
       "17  Using Tree-of-Thought Prompting to boost ChatG...  Zotero Citations\n",
       "18   Evaluating Large Language Models Trained on Code  Zotero Citations\n",
       "19  Rethinking the Role of Demonstrations: What Ma...  Zotero Citations\n",
       "20              Language Models are Few-Shot Learners  Zotero Citations\n",
       "26       Prompt Engineering for Large Language Models  Zotero Citations\n",
       "27  Complexity-Based Prompting for Multi-Step Reas...  Zotero Citations\n",
       "28  Automatic Prompt Augmentation and Selection wi...  Zotero Citations\n",
       "29  From Sparse to Dense: GPT-4 Summarization with...  Zotero Citations\n",
       "30  ChatGPT vs Human-authored Text: Insights into ...  Zotero Citations\n",
       "31  Flesch or Fumble? Evaluating Readability Stand...  Zotero Citations\n",
       "32        Prompted Opinion Summarization with GPT-3.5  Zotero Citations"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set value of \"Source\" column to \"Zotero Citations\"\n",
    "zotero_citations_limited[\"Source\"] = \"Zotero Citations\"\n",
    "\n",
    "# Limit columns to \"Title\" and \"Source\"\n",
    "zotero_citations_limited = zotero_citations_limited[[\"Title\", \"Source\"]]\n",
    "zotero_citations_limited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Prompt Pattern Catalog to Enhance Prompt Eng...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Taxonomy of Prompt Modifiers for Text-To-Ima...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Chains: Transparent and Controllable Human-...</td>\n",
       "      <td>Prompt Engineering Guide, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ART: Automatic multi-step reasoning and tool-u...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An automatically discovered chain-of-thought p...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ask Me Anything: A simple strategy for prompti...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Atlas: Few-shot Learning with Retrieval Augmen...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>Prompt Engineering Guide, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BERTese: Learning to Speak to BERT</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Batch Prompting: Efficient Inference with LLM ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Better Zero-Shot Reasoning with Self-Adaptive ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Boosted Prompt Ensembles for Large Language Mo...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bounding the Capabilities of Large Language Mo...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAMEL: Communicative Agents for \"Mind\" Explora...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Calibrate Before Use: Improving Few-Shot Perfo...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Can ChatGPT Understand Too? A Comparative Stud...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Can We Edit Factual Knowledge by In-Context Le...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chain of Hindsight Aligns Language Models with...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chain-of-Symbol Prompting Elicits Planning in ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>Prompt Engineering Guide, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ChatGPT vs Human-authored Text: Insights into ...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CoTEVer: Chain of Thought Prompting Annotation...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>Prompt engineering - Wikipedia, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Compositional Exemplars for In-context Learning</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Compress, Then Prompt: Improving Accuracy-Effi...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Constitutional AI: Harmlessness from AI Feedback</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Context-faithful Prompting for Large Language ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CooK: Empowering General-Purpose Language Mode...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Decomposed Prompting: A Modular Approach for S...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Demonstrate-Search-Predict: Composing retrieva...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Design Guidelines for Prompt Engineering Text-...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Discovering Language Model Behaviors with Mode...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DocPrompting: Generating Code by Retrieving th...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dynamic Prompt Learning via Policy Gradient fo...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Dynamic Prompting: A Unified Framework for Pro...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Effectiveness of Data Augmentation for Prefix ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Efficient Prompting via Dynamic In-Context Lea...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Enhancing Self-Consistency and Performance of ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Evaluating the Robustness of Discrete Prompts</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Evaluating the Susceptibility of Pre-Trained L...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>EvoPrompting: Language Models for Code-Level N...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Exploring Lottery Prompts for Pre-trained Lang...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Fairness-guided Few-shot Prompting for Large L...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Fantastically Ordered Prompts and Where to Fin...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Flatness-Aware Prompt Selection Improves Accur...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Focused Prefix Tuning for Controllable Text Ge...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>Prompt Engineering Guide, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>Prompt engineering - Wikipedia, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Global Prompt Cell: A Portable Control Module ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GraphPrompt: Unifying Pre-Training and Downstr...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Guiding Large Language Models via Directional ...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Hard Prompts Made Easy: Gradient-Based Discret...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Hierarchical Prompting Assists Large Language ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>How Does In-Context Learning Help Prompt Tuning?</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>How Robust is GPT-3.5 to Predecessors? A Compr...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ignore Previous Prompt: Attack Techniques For ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>In-Context Instruction Learning</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>In-Context Learning of Large Language Models E...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Interactive Natural Language Processing</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Is GPT-4 a Good Data Analyst?</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Is Prompt All You Need? No. A Comprehensive an...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Language Is Not All You Need: Aligning Percept...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Language Models Are Greedy Reasoners: A System...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Prompt Engineering Guide, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Large Language Model Guided Tree-of-Thought</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Large Language Models Are Human-Level Prompt E...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Large Language Models Can Be Easily Distracted...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Large Language Models are reasoners with Self-...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Larger language models do in-context learning ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Learning to Generate Task-Specific Adapters fr...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Learning to Transfer Prompts for Text Generation</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Least-to-most promptingÂ enables complex reason...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Less Likely Brainstorming: Using Language Mode...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Let's Sample Step by Step: Adaptive-Consistenc...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Let's Verify Step by Step</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>MRKL Systems: A modular, neuro-symbolic archit...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Machine Generated Text: A Comprehensive Survey...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reaso...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt Engineering G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Meta-in-context learning in large language models</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Mixture of Soft Prompts for Controllable Data ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Model-tuning Via Prompts Makes NLP Models Adve...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>More than you've asked for: A Comprehensive An...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MultiTool-CoT: GPT-3 Can Use Multiple External...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Multimodal Chain-of-Thought Reasoning in Langu...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Multitask Prompt Tuning Enables Parameter-Effi...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Multitask Prompted Training Enables Zero-Shot ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>On Second Thought, Let's Not Think Step by Ste...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>On the Advance of Making Language Models Bette...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>OpenICL: An Open-Source Framework for In-conte...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>PAL: Program-aided Language Models</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>PEARL: Prompting Large Language Models to Plan...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>PPT: Pre-trained Prompt Tuning for Few-shot Le...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Plan-and-Solve Prompting: Improving Zero-Shot ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Post Hoc Explanations of Language Models Can I...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Pre-Training to Learn in Context</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Prefix-Tuning: Optimizing Continuous Prompts f...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Progressive Prompts: Continual Learning for La...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Prompt Programming for Large Language Models: ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Prompt, Generate, then Cache: Cascade of Found...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>PromptChainer: Chaining Large Language Model P...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Promptagator: Few-shot Dense Retrieval From 8 ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Prompted Opinion Summarization with GPT-3.5</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Prompting GPT-3 To Be Reliable</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Query-Dependent Prompt Evaluation and Optimiza...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>REFINER: Reasoning Feedback on Intermediate Re...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ReAct: Synergizing Reasoning and Acting in Lan...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Reasoning with Language Model is Planning with...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Recitation-Augmented Language Models</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Reflexion: an autonomous agent with dynamic me...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Reframing Instructional Prompts to GPTk's Lang...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Reprompting: Automated Chain-of-Thought Prompt...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>Prompt Engineering Guide, Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Revisiting Automated Prompting: Are We Actuall...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Satisfiability-Aided Language Models Using Dec...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Scalable Prompt Generation for Semi-supervised...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>Prompt engineering - Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Scaling Laws for Neural Language Models</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Self-Consistency Improves Chain of Thought Rea...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Self-Critique Prompting with Large Language Mo...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Self-Refine: Iterative Refinement with Self-Fe...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Show Your Work: Scratchpads for Intermediate C...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Skeleton-of-Thought: Large Language Models Can...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Structure Pretraining and Prompt Tuning for Kn...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Structured Prompting: Scaling In-Context Learn...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Successive Prompting for Decomposing Complex Q...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>SwitchPrompt: Learning Domain-Specific Gated S...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Synthetic Prompting: Generating Chain-of-Thoug...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>TELeR: A General Taxonomy of LLM Prompts for B...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Teaching Algorithmic Reasoning via In-context ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>The Capacity for Moral Self-Correction in Larg...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>The Power of Scale for Parameter-Efficient Pro...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>The Unreliability of Explanations in Few-shot ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>The Web Can Be Your Oyster for Improving Large...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Toxicity Detection with Generative Prompt-base...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Training language models to follow instruction...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving w...</td>\n",
       "      <td>Prompt Engineering Guide, Prompt engineering -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>TreePrompt: Learning to Compose Tree Prompts f...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>UPRISE: Universal Prompt Retrieval for Improvi...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Universality and Limitations of Prompt Tuning</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Using Tree-of-Thought Prompting to boost ChatG...</td>\n",
       "      <td>Zotero Citations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Visual-Language Prompt Tuning with Knowledge-g...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>What In-Context Learning \"Learns\" In-Context: ...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Why think step-by-step? Reasoning emerges from...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ZeroPrompt: Streaming Acoustic Encoders are Ze...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>kNN Prompting: Beyond-Context Learning with Ca...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Ã€-la-carte Prompt Tuning (APT): Combining Dist...</td>\n",
       "      <td>Prompt Engineering Guide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    A Prompt Pattern Catalog to Enhance Prompt Eng...   \n",
       "1    A Taxonomy of Prompt Modifiers for Text-To-Ima...   \n",
       "2    AI Chains: Transparent and Controllable Human-...   \n",
       "3    ART: Automatic multi-step reasoning and tool-u...   \n",
       "4    Active Prompting with Chain-of-Thought for Lar...   \n",
       "5    An automatically discovered chain-of-thought p...   \n",
       "6    Ask Me Anything: A simple strategy for prompti...   \n",
       "7    Atlas: Few-shot Learning with Retrieval Augmen...   \n",
       "8    AutoPrompt: Eliciting Knowledge from Language ...   \n",
       "9    Automatic Chain of Thought Prompting in Large ...   \n",
       "10   Automatic Prompt Augmentation and Selection wi...   \n",
       "11                  BERTese: Learning to Speak to BERT   \n",
       "12   Batch Prompting: Efficient Inference with LLM ...   \n",
       "13   Better Zero-Shot Reasoning with Self-Adaptive ...   \n",
       "14   Boosted Prompt Ensembles for Large Language Mo...   \n",
       "15   Bounding the Capabilities of Large Language Mo...   \n",
       "16   CAMEL: Communicative Agents for \"Mind\" Explora...   \n",
       "17   Calibrate Before Use: Improving Few-Shot Perfo...   \n",
       "18   Can ChatGPT Understand Too? A Comparative Stud...   \n",
       "19   Can We Edit Factual Knowledge by In-Context Le...   \n",
       "20   Chain of Hindsight Aligns Language Models with...   \n",
       "21   Chain of Thought Prompting Elicits Reasoning i...   \n",
       "22   Chain-of-Symbol Prompting Elicits Planning in ...   \n",
       "23   Chain-of-Verification Reduces Hallucination in...   \n",
       "24   ChatGPT vs Human-authored Text: Insights into ...   \n",
       "25   CoTEVer: Chain of Thought Prompting Annotation...   \n",
       "26   Complexity-Based Prompting for Multi-Step Reas...   \n",
       "27     Compositional Exemplars for In-context Learning   \n",
       "28   Compress, Then Prompt: Improving Accuracy-Effi...   \n",
       "29   Connecting Large Language Models with Evolutio...   \n",
       "30    Constitutional AI: Harmlessness from AI Feedback   \n",
       "31   Context-faithful Prompting for Large Language ...   \n",
       "32   CooK: Empowering General-Purpose Language Mode...   \n",
       "33   Decomposed Prompting: A Modular Approach for S...   \n",
       "34   Demonstrate-Search-Predict: Composing retrieva...   \n",
       "35   Design Guidelines for Prompt Engineering Text-...   \n",
       "36   Discovering Language Model Behaviors with Mode...   \n",
       "37   DocPrompting: Generating Code by Retrieving th...   \n",
       "38   Dynamic Prompt Learning via Policy Gradient fo...   \n",
       "39   Dynamic Prompting: A Unified Framework for Pro...   \n",
       "40   Effectiveness of Data Augmentation for Prefix ...   \n",
       "41   Efficient Prompting via Dynamic In-Context Lea...   \n",
       "42   Enhancing Self-Consistency and Performance of ...   \n",
       "43    Evaluating Large Language Models Trained on Code   \n",
       "44       Evaluating the Robustness of Discrete Prompts   \n",
       "45   Evaluating the Susceptibility of Pre-Trained L...   \n",
       "46   EvoPrompting: Language Models for Code-Level N...   \n",
       "47   Exploring Lottery Prompts for Pre-trained Lang...   \n",
       "48   Fairness-guided Few-shot Prompting for Large L...   \n",
       "49   Fantastically Ordered Prompts and Where to Fin...   \n",
       "50   Flatness-Aware Prompt Selection Improves Accur...   \n",
       "51   Flesch or Fumble? Evaluating Readability Stand...   \n",
       "52   Focused Prefix Tuning for Controllable Text Ge...   \n",
       "53   From Sparse to Dense: GPT-4 Summarization with...   \n",
       "54                              GPT-4 Technical Report   \n",
       "55   Generated Knowledge Prompting for Commonsense ...   \n",
       "56   Global Prompt Cell: A Portable Control Module ...   \n",
       "57   Graph of Thoughts: Solving Elaborate Problems ...   \n",
       "58   GraphPrompt: Unifying Pre-Training and Downstr...   \n",
       "59   Guiding Large Language Models via Directional ...   \n",
       "60   Hard Prompts Made Easy: Gradient-Based Discret...   \n",
       "61   Hierarchical Prompting Assists Large Language ...   \n",
       "62          How Can We Know What Language Models Know?   \n",
       "63    How Does In-Context Learning Help Prompt Tuning?   \n",
       "64   How Robust is GPT-3.5 to Predecessors? A Compr...   \n",
       "65   Ignore Previous Prompt: Attack Techniques For ...   \n",
       "66                     In-Context Instruction Learning   \n",
       "67   In-Context Learning of Large Language Models E...   \n",
       "68             Interactive Natural Language Processing   \n",
       "69                       Is GPT-4 a Good Data Analyst?   \n",
       "70   Is Prompt All You Need? No. A Comprehensive an...   \n",
       "71   Language Is Not All You Need: Aligning Percept...   \n",
       "72   Language Models Are Greedy Reasoners: A System...   \n",
       "73               Language Models are Few-Shot Learners   \n",
       "74         Large Language Model Guided Tree-of-Thought   \n",
       "75   Large Language Models Are Human-Level Prompt E...   \n",
       "76   Large Language Models Can Be Easily Distracted...   \n",
       "77       Large Language Models are Zero-Shot Reasoners   \n",
       "78   Large Language Models are reasoners with Self-...   \n",
       "79   Larger language models do in-context learning ...   \n",
       "80                     Learning from Task Descriptions   \n",
       "81   Learning to Generate Task-Specific Adapters fr...   \n",
       "82    Learning to Transfer Prompts for Text Generation   \n",
       "83   Least-to-most promptingÂ enables complex reason...   \n",
       "84   Less Likely Brainstorming: Using Language Mode...   \n",
       "85   Let's Sample Step by Step: Adaptive-Consistenc...   \n",
       "86                           Let's Verify Step by Step   \n",
       "87   MRKL Systems: A modular, neuro-symbolic archit...   \n",
       "88   Machine Generated Text: A Comprehensive Survey...   \n",
       "89   Maieutic Prompting: Logically Consistent Reaso...   \n",
       "90   Making Pre-trained Language Models Better Few-...   \n",
       "91   Meta-in-context learning in large language models   \n",
       "92   Mixture of Soft Prompts for Controllable Data ...   \n",
       "93   Model-tuning Via Prompts Makes NLP Models Adve...   \n",
       "94   More than you've asked for: A Comprehensive An...   \n",
       "95   MultiTool-CoT: GPT-3 Can Use Multiple External...   \n",
       "96   Multimodal Chain-of-Thought Reasoning in Langu...   \n",
       "97   Multitask Prompt Tuning Enables Parameter-Effi...   \n",
       "98   Multitask Prompted Training Enables Zero-Shot ...   \n",
       "99   On Second Thought, Let's Not Think Step by Ste...   \n",
       "100  On the Advance of Making Language Models Bette...   \n",
       "101  OpenICL: An Open-Source Framework for In-conte...   \n",
       "102                 PAL: Program-aided Language Models   \n",
       "103  PEARL: Prompting Large Language Models to Plan...   \n",
       "104  PPT: Pre-trained Prompt Tuning for Few-shot Le...   \n",
       "105  Plan-and-Solve Prompting: Improving Zero-Shot ...   \n",
       "106  Post Hoc Explanations of Language Models Can I...   \n",
       "107                   Pre-Training to Learn in Context   \n",
       "108  Prefix-Tuning: Optimizing Continuous Prompts f...   \n",
       "109  Progressive Prompts: Continual Learning for La...   \n",
       "110       Prompt Engineering for Large Language Models   \n",
       "111  Prompt Programming for Large Language Models: ...   \n",
       "112  Prompt, Generate, then Cache: Cascade of Found...   \n",
       "113  PromptChainer: Chaining Large Language Model P...   \n",
       "114  Promptagator: Few-shot Dense Retrieval From 8 ...   \n",
       "115        Prompted Opinion Summarization with GPT-3.5   \n",
       "116                     Prompting GPT-3 To Be Reliable   \n",
       "117  Query-Dependent Prompt Evaluation and Optimiza...   \n",
       "118  REFINER: Reasoning Feedback on Intermediate Re...   \n",
       "119   Re-Reading Improves Reasoning in Language Models   \n",
       "120  ReAct: Synergizing Reasoning and Acting in Lan...   \n",
       "121  Reasoning with Language Model is Planning with...   \n",
       "122               Recitation-Augmented Language Models   \n",
       "123  Reflexion: an autonomous agent with dynamic me...   \n",
       "124  Reframing Instructional Prompts to GPTk's Lang...   \n",
       "125  Reprompting: Automated Chain-of-Thought Prompt...   \n",
       "126  Rethinking the Role of Demonstrations: What Ma...   \n",
       "127  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "128  Revisiting Automated Prompting: Are We Actuall...   \n",
       "129  Satisfiability-Aided Language Models Using Dec...   \n",
       "130  Scalable Prompt Generation for Semi-supervised...   \n",
       "131      Scaling Instruction-Finetuned Language Models   \n",
       "132            Scaling Laws for Neural Language Models   \n",
       "133  Self-Consistency Improves Chain of Thought Rea...   \n",
       "134  Self-Critique Prompting with Large Language Mo...   \n",
       "135  Self-Refine: Iterative Refinement with Self-Fe...   \n",
       "136  Show Your Work: Scratchpads for Intermediate C...   \n",
       "137  Skeleton-of-Thought: Large Language Models Can...   \n",
       "138  Structure Pretraining and Prompt Tuning for Kn...   \n",
       "139  Structured Prompting: Scaling In-Context Learn...   \n",
       "140  Successive Prompting for Decomposing Complex Q...   \n",
       "141  SwitchPrompt: Learning Domain-Specific Gated S...   \n",
       "142  Synthetic Prompting: Generating Chain-of-Thoug...   \n",
       "143  TELeR: A General Taxonomy of LLM Prompts for B...   \n",
       "144  Teaching Algorithmic Reasoning via In-context ...   \n",
       "145  The Capacity for Moral Self-Correction in Larg...   \n",
       "146  The Power of Scale for Parameter-Efficient Pro...   \n",
       "147  The Unreliability of Explanations in Few-shot ...   \n",
       "148  The Web Can Be Your Oyster for Improving Large...   \n",
       "149  Toxicity Detection with Generative Prompt-base...   \n",
       "150  Training language models to follow instruction...   \n",
       "151  Tree of Thoughts: Deliberate Problem Solving w...   \n",
       "152  TreePrompt: Learning to Compose Tree Prompts f...   \n",
       "153  UPRISE: Universal Prompt Retrieval for Improvi...   \n",
       "154      Universality and Limitations of Prompt Tuning   \n",
       "155  Using Tree-of-Thought Prompting to boost ChatG...   \n",
       "156  Visual-Language Prompt Tuning with Knowledge-g...   \n",
       "157  What In-Context Learning \"Learns\" In-Context: ...   \n",
       "158  Why think step-by-step? Reasoning emerges from...   \n",
       "159  ZeroPrompt: Streaming Acoustic Encoders are Ze...   \n",
       "160  kNN Prompting: Beyond-Context Learning with Ca...   \n",
       "161  Ã€-la-carte Prompt Tuning (APT): Combining Dist...   \n",
       "\n",
       "                                                Source  \n",
       "0                             Prompt Engineering Guide  \n",
       "1                             Prompt Engineering Guide  \n",
       "2           Prompt Engineering Guide, Zotero Citations  \n",
       "3                             Prompt Engineering Guide  \n",
       "4    Prompt Engineering Guide, Prompt engineering -...  \n",
       "5                                     Zotero Citations  \n",
       "6                             Prompt Engineering Guide  \n",
       "7                             Prompt Engineering Guide  \n",
       "8                             Prompt Engineering Guide  \n",
       "9    Prompt Engineering Guide, Prompt engineering -...  \n",
       "10          Prompt Engineering Guide, Zotero Citations  \n",
       "11                            Prompt Engineering Guide  \n",
       "12                            Prompt Engineering Guide  \n",
       "13                            Prompt Engineering Guide  \n",
       "14                            Prompt Engineering Guide  \n",
       "15                            Prompt Engineering Guide  \n",
       "16                            Prompt Engineering Guide  \n",
       "17                            Prompt Engineering Guide  \n",
       "18                            Prompt Engineering Guide  \n",
       "19                            Prompt Engineering Guide  \n",
       "20                            Prompt Engineering Guide  \n",
       "21   Prompt Engineering Guide, Prompt engineering -...  \n",
       "22                            Prompt Engineering Guide  \n",
       "23          Prompt Engineering Guide, Zotero Citations  \n",
       "24                                    Zotero Citations  \n",
       "25                            Prompt Engineering Guide  \n",
       "26    Prompt engineering - Wikipedia, Zotero Citations  \n",
       "27                            Prompt Engineering Guide  \n",
       "28                            Prompt Engineering Guide  \n",
       "29                            Prompt Engineering Guide  \n",
       "30                            Prompt Engineering Guide  \n",
       "31                            Prompt Engineering Guide  \n",
       "32                            Prompt Engineering Guide  \n",
       "33                            Prompt Engineering Guide  \n",
       "34                            Prompt Engineering Guide  \n",
       "35                            Prompt Engineering Guide  \n",
       "36                            Prompt Engineering Guide  \n",
       "37                            Prompt Engineering Guide  \n",
       "38                            Prompt Engineering Guide  \n",
       "39                            Prompt Engineering Guide  \n",
       "40                            Prompt Engineering Guide  \n",
       "41                            Prompt Engineering Guide  \n",
       "42                            Prompt Engineering Guide  \n",
       "43                                    Zotero Citations  \n",
       "44                            Prompt Engineering Guide  \n",
       "45                            Prompt Engineering Guide  \n",
       "46                            Prompt Engineering Guide  \n",
       "47                            Prompt Engineering Guide  \n",
       "48                            Prompt Engineering Guide  \n",
       "49                            Prompt Engineering Guide  \n",
       "50                            Prompt Engineering Guide  \n",
       "51                                    Zotero Citations  \n",
       "52                            Prompt Engineering Guide  \n",
       "53          Prompt Engineering Guide, Zotero Citations  \n",
       "54    Prompt engineering - Wikipedia, Zotero Citations  \n",
       "55   Prompt Engineering Guide, Prompt engineering -...  \n",
       "56                            Prompt Engineering Guide  \n",
       "57                            Prompt Engineering Guide  \n",
       "58                            Prompt Engineering Guide  \n",
       "59   Prompt Engineering Guide, Prompt engineering -...  \n",
       "60                            Prompt Engineering Guide  \n",
       "61                            Prompt Engineering Guide  \n",
       "62                            Prompt Engineering Guide  \n",
       "63                            Prompt Engineering Guide  \n",
       "64                            Prompt Engineering Guide  \n",
       "65                            Prompt Engineering Guide  \n",
       "66                            Prompt Engineering Guide  \n",
       "67                            Prompt Engineering Guide  \n",
       "68                            Prompt Engineering Guide  \n",
       "69                                    Zotero Citations  \n",
       "70                            Prompt Engineering Guide  \n",
       "71                            Prompt Engineering Guide  \n",
       "72                            Prompt Engineering Guide  \n",
       "73          Prompt Engineering Guide, Zotero Citations  \n",
       "74                      Prompt engineering - Wikipedia  \n",
       "75   Prompt Engineering Guide, Prompt engineering -...  \n",
       "76                            Prompt Engineering Guide  \n",
       "77   Prompt Engineering Guide, Prompt engineering -...  \n",
       "78                            Prompt Engineering Guide  \n",
       "79                            Prompt Engineering Guide  \n",
       "80                            Prompt Engineering Guide  \n",
       "81                            Prompt Engineering Guide  \n",
       "82                            Prompt Engineering Guide  \n",
       "83                      Prompt engineering - Wikipedia  \n",
       "84                            Prompt Engineering Guide  \n",
       "85                            Prompt Engineering Guide  \n",
       "86                            Prompt Engineering Guide  \n",
       "87                            Prompt Engineering Guide  \n",
       "88                            Prompt Engineering Guide  \n",
       "89   Prompt Engineering Guide, Prompt engineering -...  \n",
       "90   Prompt Engineering Guide, Prompt Engineering G...  \n",
       "91                            Prompt Engineering Guide  \n",
       "92                            Prompt Engineering Guide  \n",
       "93                            Prompt Engineering Guide  \n",
       "94                            Prompt Engineering Guide  \n",
       "95                            Prompt Engineering Guide  \n",
       "96                            Prompt Engineering Guide  \n",
       "97                            Prompt Engineering Guide  \n",
       "98                            Prompt Engineering Guide  \n",
       "99                            Prompt Engineering Guide  \n",
       "100                           Prompt Engineering Guide  \n",
       "101                           Prompt Engineering Guide  \n",
       "102                           Prompt Engineering Guide  \n",
       "103                           Prompt Engineering Guide  \n",
       "104                           Prompt Engineering Guide  \n",
       "105                           Prompt Engineering Guide  \n",
       "106                           Prompt Engineering Guide  \n",
       "107                           Prompt Engineering Guide  \n",
       "108                           Prompt Engineering Guide  \n",
       "109                           Prompt Engineering Guide  \n",
       "110                                   Zotero Citations  \n",
       "111                           Prompt Engineering Guide  \n",
       "112                           Prompt Engineering Guide  \n",
       "113                           Prompt Engineering Guide  \n",
       "114                           Prompt Engineering Guide  \n",
       "115                                   Zotero Citations  \n",
       "116                           Prompt Engineering Guide  \n",
       "117                           Prompt Engineering Guide  \n",
       "118                           Prompt Engineering Guide  \n",
       "119                           Prompt Engineering Guide  \n",
       "120                           Prompt Engineering Guide  \n",
       "121                           Prompt Engineering Guide  \n",
       "122                           Prompt Engineering Guide  \n",
       "123                           Prompt Engineering Guide  \n",
       "124                           Prompt Engineering Guide  \n",
       "125                           Prompt Engineering Guide  \n",
       "126         Prompt Engineering Guide, Zotero Citations  \n",
       "127                     Prompt engineering - Wikipedia  \n",
       "128                           Prompt Engineering Guide  \n",
       "129                           Prompt Engineering Guide  \n",
       "130                           Prompt Engineering Guide  \n",
       "131                     Prompt engineering - Wikipedia  \n",
       "132                           Prompt Engineering Guide  \n",
       "133  Prompt Engineering Guide, Prompt engineering -...  \n",
       "134                           Prompt Engineering Guide  \n",
       "135  Prompt Engineering Guide, Prompt engineering -...  \n",
       "136                           Prompt Engineering Guide  \n",
       "137                           Prompt Engineering Guide  \n",
       "138                           Prompt Engineering Guide  \n",
       "139                           Prompt Engineering Guide  \n",
       "140                           Prompt Engineering Guide  \n",
       "141                           Prompt Engineering Guide  \n",
       "142                           Prompt Engineering Guide  \n",
       "143                           Prompt Engineering Guide  \n",
       "144                           Prompt Engineering Guide  \n",
       "145                           Prompt Engineering Guide  \n",
       "146                           Prompt Engineering Guide  \n",
       "147                           Prompt Engineering Guide  \n",
       "148                           Prompt Engineering Guide  \n",
       "149                           Prompt Engineering Guide  \n",
       "150                           Prompt Engineering Guide  \n",
       "151  Prompt Engineering Guide, Prompt engineering -...  \n",
       "152                           Prompt Engineering Guide  \n",
       "153                           Prompt Engineering Guide  \n",
       "154                           Prompt Engineering Guide  \n",
       "155                                   Zotero Citations  \n",
       "156                           Prompt Engineering Guide  \n",
       "157                           Prompt Engineering Guide  \n",
       "158                           Prompt Engineering Guide  \n",
       "159                           Prompt Engineering Guide  \n",
       "160                           Prompt Engineering Guide  \n",
       "161                           Prompt Engineering Guide  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate together\n",
    "all_papers = pd.concat([approaches_papers, papers_from_wikipedia, zotero_citations_limited], ignore_index=True)\n",
    "\n",
    "# Strip extra whitespace from Title column\n",
    "all_papers[\"Title\"] = all_papers[\"Title\"].str.strip()\n",
    "\n",
    "# Replace \"Chain-of-Thought Prompting Elicits\" with \"Chain of Thought Prompting Elicits\"\n",
    "all_papers[\"Title\"] = all_papers[\"Title\"].str.replace(\"Chain-of-Thought Prompting Elicits\", \"Chain of Thought Prompting Elicits\")\n",
    "\n",
    "# Replace \"Large Language Models are Human\" with \"Large Language Models Are Human\"\n",
    "all_papers[\"Title\"] = all_papers[\"Title\"].str.replace(\"Large Language Models are Human\", \"Large Language Models Are Human\")\n",
    "\n",
    "# Replace \"Self-consistencyÂ improves chain of thought reasoning in language models\" with \"Self-Consistency Improves Chain of Thought Reasoning in Language Models\"\n",
    "all_papers[\"Title\"] = all_papers[\"Title\"].str.replace(\"Self-consistencyÂ improves chain of thought reasoning in language models\", \"Self-Consistency Improves Chain of Thought Reasoning in Language Models\")\n",
    "\n",
    "# Collapse items by Title\n",
    "# Concatenate Source values together, separated by \", \"\n",
    "all_papers = all_papers.groupby(\"Title\").agg({\"Source\": lambda x: \", \".join(x)}).reset_index()\n",
    "\n",
    "# Sort by Title\n",
    "all_papers = all_papers.sort_values(by=\"Title\").reset_index(drop=True)\n",
    "\n",
    "# Print all rows in the dataframe\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "all_papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get semantic scholar citations\n",
    "\n",
    "# For sleep to avoid API limit\n",
    "import time\n",
    "\n",
    "# Semantic scholar dataframe\n",
    "semantic_scholar_df = pd.DataFrame()\n",
    "no_results_df = pd.DataFrame()\n",
    "\n",
    "# Today's date\n",
    "today = date.today()\n",
    "\n",
    "# Loop over papers\n",
    "for paper_title in all_papers[\"Title\"]:\n",
    "    # Replace hyphens with a space (per documentation)\n",
    "    query = paper_title.replace(\"-\", \" \")\n",
    "    # Query semantic scholar\n",
    "    r = requests.get(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/search?query=' + query + '&fields=title,citationCount,publicationDate,year&limit=1'\n",
    "    )\n",
    "    # Attempt for a returned result\n",
    "    try:\n",
    "        semantic_scholar_title = r.json()['data'][0]['title']\n",
    "        semantic_scholar_citation_count = r.json()['data'][0]['citationCount']\n",
    "        ss_publication_date = r.json()['data'][0]['publicationDate']\n",
    "        ss_year = r.json()['data'][0]['year']\n",
    "        new_record = pd.DataFrame([{\"paper title\":paper_title, \"semantic scholar title\": semantic_scholar_title, \"ss_publication_date\": ss_publication_date, \"ss_year\": ss_year, \"citation_count\": semantic_scholar_citation_count, \"query\": query, \"day_queried\": today}])\n",
    "        semantic_scholar_df = pd.concat([semantic_scholar_df, new_record], ignore_index=True)\n",
    "    # Error catch for no results\n",
    "    except:\n",
    "        new_record = pd.DataFrame([{\"paper title\":paper_title, \"query\": query}])\n",
    "        no_results_df = pd.concat([no_results_df, new_record], ignore_index=True)\n",
    "    # Wait one second to avoid exceeding API limit\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper title</th>\n",
       "      <th>semantic scholar title</th>\n",
       "      <th>ss_publication_date</th>\n",
       "      <th>ss_year</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>query</th>\n",
       "      <th>day_queried</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Prompt Pattern Catalog to Enhance Prompt Eng...</td>\n",
       "      <td>A Prompt Pattern Catalog to Enhance Prompt Eng...</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023</td>\n",
       "      <td>163</td>\n",
       "      <td>A Prompt Pattern Catalog to Enhance Prompt Eng...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Taxonomy of Prompt Modifiers for Text-To-Ima...</td>\n",
       "      <td>A Taxonomy of Prompt Modifiers for Text-To-Ima...</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>2022</td>\n",
       "      <td>43</td>\n",
       "      <td>A Taxonomy of Prompt Modifiers for Text To Ima...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Chains: Transparent and Controllable Human-...</td>\n",
       "      <td>AI Chains: Transparent and Controllable Human-...</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2021</td>\n",
       "      <td>146</td>\n",
       "      <td>AI Chains: Transparent and Controllable Human ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ART: Automatic multi-step reasoning and tool-u...</td>\n",
       "      <td>ART: Automatic multi-step reasoning and tool-u...</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>ART: Automatic multi step reasoning and tool u...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>Active Prompting with Chain-of-Thought for Lar...</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>34</td>\n",
       "      <td>Active Prompting with Chain of Thought for Lar...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An automatically discovered chain-of-thought p...</td>\n",
       "      <td>An automatically discovered chain-of-thought p...</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>An automatically discovered chain of thought p...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ask Me Anything: A simple strategy for prompti...</td>\n",
       "      <td>Ask Me Anything: A simple strategy for prompti...</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>65</td>\n",
       "      <td>Ask Me Anything: A simple strategy for prompti...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Atlas: Few-shot Learning with Retrieval Augmen...</td>\n",
       "      <td>Few-shot Learning with Retrieval Augmented Lan...</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>202</td>\n",
       "      <td>Atlas: Few shot Learning with Retrieval Augmen...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>Eliciting Knowledge from Language Models Using...</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>217</td>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>2022</td>\n",
       "      <td>201</td>\n",
       "      <td>Automatic Chain of Thought Prompting in Large ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>2023</td>\n",
       "      <td>21</td>\n",
       "      <td>Automatic Prompt Augmentation and Selection wi...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BERTese: Learning to Speak to BERT</td>\n",
       "      <td>BERTese: Learning to Speak to BERT</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>2021</td>\n",
       "      <td>74</td>\n",
       "      <td>BERTese: Learning to Speak to BERT</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Batch Prompting: Efficient Inference with LLM ...</td>\n",
       "      <td>Batch Prompting: Efficient Inference with Larg...</td>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>Batch Prompting: Efficient Inference with LLM ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Better Zero-Shot Reasoning with Self-Adaptive ...</td>\n",
       "      <td>Better Zero-Shot Reasoning with Self-Adaptive ...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>Better Zero Shot Reasoning with Self Adaptive ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Boosted Prompt Ensembles for Large Language Mo...</td>\n",
       "      <td>Boosted Prompt Ensembles for Large Language Mo...</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>Boosted Prompt Ensembles for Large Language Mo...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bounding the Capabilities of Large Language Mo...</td>\n",
       "      <td>Bounding the Capabilities of Large Language Mo...</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>Bounding the Capabilities of Large Language Mo...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAMEL: Communicative Agents for \"Mind\" Explora...</td>\n",
       "      <td>CAMEL: Communicative Agents for \"Mind\" Explora...</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>64</td>\n",
       "      <td>CAMEL: Communicative Agents for \"Mind\" Explora...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Calibrate Before Use: Improving Few-Shot Perfo...</td>\n",
       "      <td>Calibrate Before Use: Improving Few-Shot Perfo...</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>2021</td>\n",
       "      <td>616</td>\n",
       "      <td>Calibrate Before Use: Improving Few Shot Perfo...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Can ChatGPT Understand Too? A Comparative Stud...</td>\n",
       "      <td>Can ChatGPT Understand Too? A Comparative Stud...</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>2023</td>\n",
       "      <td>73</td>\n",
       "      <td>Can ChatGPT Understand Too? A Comparative Stud...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Can We Edit Factual Knowledge by In-Context Le...</td>\n",
       "      <td>Can We Edit Factual Knowledge by In-Context Le...</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>Can We Edit Factual Knowledge by In Context Le...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chain of Hindsight Aligns Language Models with...</td>\n",
       "      <td>Chain of Hindsight Aligns Language Models with...</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>37</td>\n",
       "      <td>Chain of Hindsight Aligns Language Models with...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>2022</td>\n",
       "      <td>2105</td>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning i...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chain-of-Symbol Prompting Elicits Planning in ...</td>\n",
       "      <td>Chain-of-Symbol Prompting Elicits Planning in ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Chain of Symbol Prompting Elicits Planning in ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>Chain of Verification Reduces Hallucination in...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ChatGPT vs Human-authored Text: Insights into ...</td>\n",
       "      <td>ChatGPT vs Human-authored Text: Insights into ...</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>ChatGPT vs Human authored Text: Insights into ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CoTEVer: Chain of Thought Prompting Annotation...</td>\n",
       "      <td>CoTEVer: Chain of Thought Prompting Annotation...</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>CoTEVer: Chain of Thought Prompting Annotation...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reas...</td>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>2022</td>\n",
       "      <td>116</td>\n",
       "      <td>Complexity Based Prompting for Multi Step Reas...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Compositional Exemplars for In-context Learning</td>\n",
       "      <td>Compositional Exemplars for In-context Learning</td>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>2023</td>\n",
       "      <td>24</td>\n",
       "      <td>Compositional Exemplars for In context Learning</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Compress, Then Prompt: Improving Accuracy-Effi...</td>\n",
       "      <td>Compress, Then Prompt: Improving Accuracy-Effi...</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Compress, Then Prompt: Improving Accuracy Effi...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>2023-09-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Constitutional AI: Harmlessness from AI Feedback</td>\n",
       "      <td>Constitutional AI: Harmlessness from AI Feedback</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>2022</td>\n",
       "      <td>307</td>\n",
       "      <td>Constitutional AI: Harmlessness from AI Feedback</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Context-faithful Prompting for Large Language ...</td>\n",
       "      <td>Context-faithful Prompting for Large Language ...</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>2023</td>\n",
       "      <td>21</td>\n",
       "      <td>Context faithful Prompting for Large Language ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CooK: Empowering General-Purpose Language Mode...</td>\n",
       "      <td>SHARED OPEN VOCABULARIES AND SEMANTIC MEDIA</td>\n",
       "      <td>None</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>CooK: Empowering General Purpose Language Mode...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Decomposed Prompting: A Modular Approach for S...</td>\n",
       "      <td>Decomposed Prompting: A Modular Approach for S...</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>104</td>\n",
       "      <td>Decomposed Prompting: A Modular Approach for S...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Demonstrate-Search-Predict: Composing retrieva...</td>\n",
       "      <td>Demonstrate-Search-Predict: Composing retrieva...</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>2022</td>\n",
       "      <td>57</td>\n",
       "      <td>Demonstrate Search Predict: Composing retrieva...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Design Guidelines for Prompt Engineering Text-...</td>\n",
       "      <td>Design Guidelines for Prompt Engineering Text-...</td>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>2021</td>\n",
       "      <td>142</td>\n",
       "      <td>Design Guidelines for Prompt Engineering Text ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Discovering Language Model Behaviors with Mode...</td>\n",
       "      <td>Discovering Language Model Behaviors with Mode...</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>2022</td>\n",
       "      <td>87</td>\n",
       "      <td>Discovering Language Model Behaviors with Mode...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DocPrompting: Generating Code by Retrieving th...</td>\n",
       "      <td>DocPrompting: Generating Code by Retrieving th...</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2022</td>\n",
       "      <td>27</td>\n",
       "      <td>DocPrompting: Generating Code by Retrieving th...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dynamic Prompt Learning via Policy Gradient fo...</td>\n",
       "      <td>Dynamic Prompt Learning via Policy Gradient fo...</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>2022</td>\n",
       "      <td>51</td>\n",
       "      <td>Dynamic Prompt Learning via Policy Gradient fo...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Dynamic Prompting: A Unified Framework for Pro...</td>\n",
       "      <td>Dynamic Prompting: A Unified Framework for Pro...</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>Dynamic Prompting: A Unified Framework for Pro...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Effectiveness of Data Augmentation for Prefix ...</td>\n",
       "      <td>Effectiveness of Data Augmentation for Prefix ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>Effectiveness of Data Augmentation for Prefix ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Efficient Prompting via Dynamic In-Context Lea...</td>\n",
       "      <td>Efficient Prompting via Dynamic In-Context Lea...</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Efficient Prompting via Dynamic In Context Lea...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Enhancing Self-Consistency and Performance of ...</td>\n",
       "      <td>Enhancing Self-Consistency and Performance of ...</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>Enhancing Self Consistency and Performance of ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>2021</td>\n",
       "      <td>1617</td>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Evaluating the Robustness of Discrete Prompts</td>\n",
       "      <td>Evaluating the Robustness of Discrete Prompts</td>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>Evaluating the Robustness of Discrete Prompts</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Evaluating the Susceptibility of Pre-Trained L...</td>\n",
       "      <td>Evaluating the Susceptibility of Pre-Trained L...</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Evaluating the Susceptibility of Pre Trained L...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>EvoPrompting: Language Models for Code-Level N...</td>\n",
       "      <td>EvoPrompting: Language Models for Code-Level N...</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>EvoPrompting: Language Models for Code Level N...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Exploring Lottery Prompts for Pre-trained Lang...</td>\n",
       "      <td>Exploring Lottery Prompts for Pre-trained Lang...</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Exploring Lottery Prompts for Pre trained Lang...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Fairness-guided Few-shot Prompting for Large L...</td>\n",
       "      <td>Fairness-guided Few-shot Prompting for Large L...</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Fairness guided Few shot Prompting for Large L...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Fantastically Ordered Prompts and Where to Fin...</td>\n",
       "      <td>Fantastically Ordered Prompts and Where to Fin...</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>2021</td>\n",
       "      <td>408</td>\n",
       "      <td>Fantastically Ordered Prompts and Where to Fin...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Flatness-Aware Prompt Selection Improves Accur...</td>\n",
       "      <td>Flatness-Aware Prompt Selection Improves Accur...</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Flatness Aware Prompt Selection Improves Accur...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesch or Fumble? Evaluating Readability Stand...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Focused Prefix Tuning for Controllable Text Ge...</td>\n",
       "      <td>Focused Prefix Tuning for Controllable Text Ge...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>Focused Prefix Tuning for Controllable Text Ge...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>From Sparse to Dense: GPT 4 Summarization with...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>1529</td>\n",
       "      <td>GPT 4 Technical Report</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>2021</td>\n",
       "      <td>114</td>\n",
       "      <td>Generated Knowledge Prompting for Commonsense ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Global Prompt Cell: A Portable Control Module ...</td>\n",
       "      <td>Global Prompt Cell: A Portable Control Module ...</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>Global Prompt Cell: A Portable Control Module ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GraphPrompt: Unifying Pre-Training and Downstr...</td>\n",
       "      <td>GraphPrompt: Unifying Pre-Training and Downstr...</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>GraphPrompt: Unifying Pre Training and Downstr...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Guiding Large Language Models via Directional ...</td>\n",
       "      <td>Guiding Large Language Models via Directional ...</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>Guiding Large Language Models via Directional ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Hard Prompts Made Easy: Gradient-Based Discret...</td>\n",
       "      <td>Hard Prompts Made Easy: Gradient-Based Discret...</td>\n",
       "      <td>2023-02-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>38</td>\n",
       "      <td>Hard Prompts Made Easy: Gradient Based Discret...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Hierarchical Prompting Assists Large Language ...</td>\n",
       "      <td>Hierarchical Prompting Assists Large Language ...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Hierarchical Prompting Assists Large Language ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>763</td>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>How Does In-Context Learning Help Prompt Tuning?</td>\n",
       "      <td>How Does In-Context Learning Help Prompt Tuning?</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>How Does In Context Learning Help Prompt Tuning?</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>How Robust is GPT-3.5 to Predecessors? A Compr...</td>\n",
       "      <td>How Robust is GPT-3.5 to Predecessors? A Compr...</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>24</td>\n",
       "      <td>How Robust is GPT 3.5 to Predecessors? A Compr...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ignore Previous Prompt: Attack Techniques For ...</td>\n",
       "      <td>Ignore Previous Prompt: Attack Techniques For ...</td>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>2022</td>\n",
       "      <td>68</td>\n",
       "      <td>Ignore Previous Prompt: Attack Techniques For ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>In-Context Instruction Learning</td>\n",
       "      <td>In-Context Instruction Learning</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023</td>\n",
       "      <td>19</td>\n",
       "      <td>In Context Instruction Learning</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>In-Context Learning of Large Language Models E...</td>\n",
       "      <td>In-Context Learning of Large Language Models E...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>In Context Learning of Large Language Models E...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Interactive Natural Language Processing</td>\n",
       "      <td>Interactive Natural Language Processing</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>14</td>\n",
       "      <td>Interactive Natural Language Processing</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Is GPT-4 a Good Data Analyst?</td>\n",
       "      <td>Is GPT-4 a Good Data Analyst?</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>Is GPT 4 a Good Data Analyst?</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Is Prompt All You Need? No. A Comprehensive an...</td>\n",
       "      <td>Is Prompt All You Need? No. A Comprehensive an...</td>\n",
       "      <td>2023-03-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>Is Prompt All You Need? No. A Comprehensive an...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Language Is Not All You Need: Aligning Percept...</td>\n",
       "      <td>Language Is Not All You Need: Aligning Percept...</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>154</td>\n",
       "      <td>Language Is Not All You Need: Aligning Percept...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Language Models Are Greedy Reasoners: A System...</td>\n",
       "      <td>Language Models Are Greedy Reasoners: A System...</td>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>2022</td>\n",
       "      <td>58</td>\n",
       "      <td>Language Models Are Greedy Reasoners: A System...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>16440</td>\n",
       "      <td>Language Models are Few Shot Learners</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Large Language Model Guided Tree-of-Thought</td>\n",
       "      <td>Large Language Model Guided Tree-of-Thought</td>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>26</td>\n",
       "      <td>Large Language Model Guided Tree of Thought</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Large Language Models Are Human-Level Prompt E...</td>\n",
       "      <td>Large Language Models Are Human-Level Prompt E...</td>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>2022</td>\n",
       "      <td>194</td>\n",
       "      <td>Large Language Models Are Human Level Prompt E...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Large Language Models Can Be Easily Distracted...</td>\n",
       "      <td>Large Language Models Can Be Easily Distracted...</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>70</td>\n",
       "      <td>Large Language Models Can Be Easily Distracted...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>882</td>\n",
       "      <td>Large Language Models are Zero Shot Reasoners</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Large Language Models are reasoners with Self-...</td>\n",
       "      <td>Large Language Models are reasoners with Self-...</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>Large Language Models are reasoners with Self ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Larger language models do in-context learning ...</td>\n",
       "      <td>Larger language models do in-context learning ...</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>87</td>\n",
       "      <td>Larger language models do in context learning ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>64</td>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Learning to Generate Task-Specific Adapters fr...</td>\n",
       "      <td>Learning to Generate Task-Specific Adapters fr...</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021</td>\n",
       "      <td>18</td>\n",
       "      <td>Learning to Generate Task Specific Adapters fr...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Learning to Transfer Prompts for Text Generation</td>\n",
       "      <td>Learning to Transfer Prompts for Text Generation</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>Learning to Transfer Prompts for Text Generation</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Least-to-most promptingÂ enables complex reason...</td>\n",
       "      <td>Least-to-Most Prompting Enables Complex Reason...</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>2022</td>\n",
       "      <td>369</td>\n",
       "      <td>Least to most promptingÂ enables complex reason...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Less Likely Brainstorming: Using Language Mode...</td>\n",
       "      <td>Less Likely Brainstorming: Using Language Mode...</td>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Less Likely Brainstorming: Using Language Mode...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Let's Sample Step by Step: Adaptive-Consistenc...</td>\n",
       "      <td>Let's Sample Step by Step: Adaptive-Consistenc...</td>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>Let's Sample Step by Step: Adaptive Consistenc...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Let's Verify Step by Step</td>\n",
       "      <td>Let's Verify Step by Step</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>64</td>\n",
       "      <td>Let's Verify Step by Step</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>MRKL Systems: A modular, neuro-symbolic archit...</td>\n",
       "      <td>MRKL Systems: A modular, neuro-symbolic archit...</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>MRKL Systems: A modular, neuro symbolic archit...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Machine Generated Text: A Comprehensive Survey...</td>\n",
       "      <td>Machine-Generated Text: A Comprehensive Survey...</td>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>2022</td>\n",
       "      <td>28</td>\n",
       "      <td>Machine Generated Text: A Comprehensive Survey...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reaso...</td>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reaso...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>86</td>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reaso...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>1082</td>\n",
       "      <td>Making Pre trained Language Models Better Few ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Meta-in-context learning in large language models</td>\n",
       "      <td>Meta-in-context learning in large language models</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Meta in context learning in large language models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Mixture of Soft Prompts for Controllable Data ...</td>\n",
       "      <td>Mixture of Soft Prompts for Controllable Data ...</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Mixture of Soft Prompts for Controllable Data ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Model-tuning Via Prompts Makes NLP Models Adve...</td>\n",
       "      <td>Model-tuning Via Prompts Makes NLP Models Adve...</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Model tuning Via Prompts Makes NLP Models Adve...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>More than you've asked for: A Comprehensive An...</td>\n",
       "      <td>More than you've asked for: A Comprehensive An...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "      <td>37</td>\n",
       "      <td>More than you've asked for: A Comprehensive An...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MultiTool-CoT: GPT-3 Can Use Multiple External...</td>\n",
       "      <td>MultiTool-CoT: GPT-3 Can Use Multiple External...</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>MultiTool CoT: GPT 3 Can Use Multiple External...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Multimodal Chain-of-Thought Reasoning in Langu...</td>\n",
       "      <td>Multimodal Chain-of-Thought Reasoning in Langu...</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>2023</td>\n",
       "      <td>91</td>\n",
       "      <td>Multimodal Chain of Thought Reasoning in Langu...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Multitask Prompt Tuning Enables Parameter-Effi...</td>\n",
       "      <td>Multitask Prompt Tuning Enables Parameter-Effi...</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>21</td>\n",
       "      <td>Multitask Prompt Tuning Enables Parameter Effi...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Multitask Prompted Training Enables Zero-Shot ...</td>\n",
       "      <td>Multitask Prompted Training Enables Zero-Shot ...</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>2021</td>\n",
       "      <td>924</td>\n",
       "      <td>Multitask Prompted Training Enables Zero Shot ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>On Second Thought, Let's Not Think Step by Ste...</td>\n",
       "      <td>On Second Thought, Letâ€™s Not Think Step by Ste...</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>2022</td>\n",
       "      <td>23</td>\n",
       "      <td>On Second Thought, Let's Not Think Step by Ste...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>On the Advance of Making Language Models Bette...</td>\n",
       "      <td>On the Advance of Making Language Models Bette...</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "      <td>106</td>\n",
       "      <td>On the Advance of Making Language Models Bette...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>OpenICL: An Open-Source Framework for In-conte...</td>\n",
       "      <td>OpenICL: An Open-Source Framework for In-conte...</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>OpenICL: An Open Source Framework for In conte...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>PAL: Program-aided Language Models</td>\n",
       "      <td>PAL: Program-aided Language Models</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>2022</td>\n",
       "      <td>198</td>\n",
       "      <td>PAL: Program aided Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>PEARL: Prompting Large Language Models to Plan...</td>\n",
       "      <td>PEARL: Prompting Large Language Models to Plan...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>PEARL: Prompting Large Language Models to Plan...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>PPT: Pre-trained Prompt Tuning for Few-shot Le...</td>\n",
       "      <td>PPT: Pre-trained Prompt Tuning for Few-shot Le...</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>2021</td>\n",
       "      <td>234</td>\n",
       "      <td>PPT: Pre trained Prompt Tuning for Few shot Le...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Plan-and-Solve Prompting: Improving Zero-Shot ...</td>\n",
       "      <td>Plan-and-Solve Prompting: Improving Zero-Shot ...</td>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>2023</td>\n",
       "      <td>46</td>\n",
       "      <td>Plan and Solve Prompting: Improving Zero Shot ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Post Hoc Explanations of Language Models Can I...</td>\n",
       "      <td>Post Hoc Explanations of Language Models Can I...</td>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Post Hoc Explanations of Language Models Can I...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Pre-Training to Learn in Context</td>\n",
       "      <td>Pre-Training to Learn in Context</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Pre Training to Learn in Context</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Prefix-Tuning: Optimizing Continuous Prompts f...</td>\n",
       "      <td>Prefix-Tuning: Optimizing Continuous Prompts f...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "      <td>1682</td>\n",
       "      <td>Prefix Tuning: Optimizing Continuous Prompts f...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Progressive Prompts: Continual Learning for La...</td>\n",
       "      <td>Progressive Prompts: Continual Learning for La...</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>2023</td>\n",
       "      <td>20</td>\n",
       "      <td>Progressive Prompts: Continual Learning for La...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Prompt Programming for Large Language Models: ...</td>\n",
       "      <td>Prompt Programming for Large Language Models: ...</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>2021</td>\n",
       "      <td>317</td>\n",
       "      <td>Prompt Programming for Large Language Models: ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Prompt, Generate, then Cache: Cascade of Found...</td>\n",
       "      <td>Prompt, Generate, Then Cache: Cascade of Found...</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>Prompt, Generate, then Cache: Cascade of Found...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>PromptChainer: Chaining Large Language Model P...</td>\n",
       "      <td>PromptChainer: Chaining Large Language Model P...</td>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>2022</td>\n",
       "      <td>78</td>\n",
       "      <td>PromptChainer: Chaining Large Language Model P...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Promptagator: Few-shot Dense Retrieval From 8 ...</td>\n",
       "      <td>Promptagator: Few-shot Dense Retrieval From 8 ...</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>66</td>\n",
       "      <td>Promptagator: Few shot Dense Retrieval From 8 ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Prompted Opinion Summarization with GPT-3.5</td>\n",
       "      <td>Prompted Opinion Summarization with GPT-3.5</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>Prompted Opinion Summarization with GPT 3.5</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Prompting GPT-3 To Be Reliable</td>\n",
       "      <td>Prompting GPT-3 To Be Reliable</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>2022</td>\n",
       "      <td>72</td>\n",
       "      <td>Prompting GPT 3 To Be Reliable</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Query-Dependent Prompt Evaluation and Optimiza...</td>\n",
       "      <td>Query-Dependent Prompt Evaluation and Optimiza...</td>\n",
       "      <td>2023-09-13</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Query Dependent Prompt Evaluation and Optimiza...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>REFINER: Reasoning Feedback on Intermediate Re...</td>\n",
       "      <td>REFINER: Reasoning Feedback on Intermediate Re...</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "      <td>REFINER: Reasoning Feedback on Intermediate Re...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Re Reading Improves Reasoning in Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ReAct: Synergizing Reasoning and Acting in Lan...</td>\n",
       "      <td>ReAct: Synergizing Reasoning and Acting in Lan...</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>2022</td>\n",
       "      <td>332</td>\n",
       "      <td>ReAct: Synergizing Reasoning and Acting in Lan...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Reasoning with Language Model is Planning with...</td>\n",
       "      <td>Reasoning with Language Model is Planning with...</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>2023</td>\n",
       "      <td>34</td>\n",
       "      <td>Reasoning with Language Model is Planning with...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Recitation-Augmented Language Models</td>\n",
       "      <td>Recitation-Augmented Language Models</td>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>2022</td>\n",
       "      <td>37</td>\n",
       "      <td>Recitation Augmented Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Reflexion: an autonomous agent with dynamic me...</td>\n",
       "      <td>Reflexion: an autonomous agent with dynamic me...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023</td>\n",
       "      <td>105</td>\n",
       "      <td>Reflexion: an autonomous agent with dynamic me...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Reframing Instructional Prompts to GPTk's Lang...</td>\n",
       "      <td>Reframing Instructional Prompts to GPTkâ€™s Lang...</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>2021</td>\n",
       "      <td>121</td>\n",
       "      <td>Reframing Instructional Prompts to GPTk's Lang...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Reprompting: Automated Chain-of-Thought Prompt...</td>\n",
       "      <td>Reprompting: Automated Chain-of-Thought Prompt...</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Reprompting: Automated Chain of Thought Prompt...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>2022</td>\n",
       "      <td>431</td>\n",
       "      <td>Rethinking the Role of Demonstrations: What Ma...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>Retrieval-Augmented Generation for Knowledge-I...</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020</td>\n",
       "      <td>956</td>\n",
       "      <td>Retrieval Augmented Generation for Knowledge I...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Revisiting Automated Prompting: Are We Actuall...</td>\n",
       "      <td>Revisiting Automated Prompting: Are We Actuall...</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>Revisiting Automated Prompting: Are We Actuall...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Satisfiability-Aided Language Models Using Dec...</td>\n",
       "      <td>Satisfiability-Aided Language Models Using Dec...</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Satisfiability Aided Language Models Using Dec...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Scalable Prompt Generation for Semi-supervised...</td>\n",
       "      <td>Scalable Prompt Generation for Semi-supervised...</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Scalable Prompt Generation for Semi supervised...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>2022</td>\n",
       "      <td>823</td>\n",
       "      <td>Scaling Instruction Finetuned Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Scaling Laws for Neural Language Models</td>\n",
       "      <td>Scaling Laws for Neural Language Models</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2020</td>\n",
       "      <td>1530</td>\n",
       "      <td>Scaling Laws for Neural Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Self-Consistency Improves Chain of Thought Rea...</td>\n",
       "      <td>Self-Consistency Improves Chain of Thought Rea...</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>2022</td>\n",
       "      <td>659</td>\n",
       "      <td>Self Consistency Improves Chain of Thought Rea...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Self-Critique Prompting with Large Language Mo...</td>\n",
       "      <td>Self-Critique Prompting with Large Language Mo...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Self Critique Prompting with Large Language Mo...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Self-Refine: Iterative Refinement with Self-Fe...</td>\n",
       "      <td>Self-Refine: Iterative Refinement with Self-Fe...</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>2023</td>\n",
       "      <td>201</td>\n",
       "      <td>Self Refine: Iterative Refinement with Self Fe...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Show Your Work: Scratchpads for Intermediate C...</td>\n",
       "      <td>Show Your Work: Scratchpads for Intermediate C...</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>2021</td>\n",
       "      <td>315</td>\n",
       "      <td>Show Your Work: Scratchpads for Intermediate C...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Skeleton-of-Thought: Large Language Models Can...</td>\n",
       "      <td>Skeleton-of-Thought: Large Language Models Can...</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Skeleton of Thought: Large Language Models Can...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Structure Pretraining and Prompt Tuning for Kn...</td>\n",
       "      <td>Structure Pretraining and Prompt Tuning for Kn...</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>Structure Pretraining and Prompt Tuning for Kn...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Successive Prompting for Decomposing Complex Q...</td>\n",
       "      <td>Successive Prompting for Decomposing Complex Q...</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>2022</td>\n",
       "      <td>40</td>\n",
       "      <td>Successive Prompting for Decomposing Complex Q...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>SwitchPrompt: Learning Domain-Specific Gated S...</td>\n",
       "      <td>SwitchPrompt: Learning Domain-Specific Gated S...</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>SwitchPrompt: Learning Domain Specific Gated S...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Synthetic Prompting: Generating Chain-of-Thoug...</td>\n",
       "      <td>Synthetic Prompting: Generating Chain-of-Thoug...</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>26</td>\n",
       "      <td>Synthetic Prompting: Generating Chain of Thoug...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>TELeR: A General Taxonomy of LLM Prompts for B...</td>\n",
       "      <td>TELeR: A General Taxonomy of LLM Prompts for B...</td>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>TELeR: A General Taxonomy of LLM Prompts for B...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Teaching Algorithmic Reasoning via In-context ...</td>\n",
       "      <td>Teaching Algorithmic Reasoning via In-context ...</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>2022</td>\n",
       "      <td>52</td>\n",
       "      <td>Teaching Algorithmic Reasoning via In context ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>The Capacity for Moral Self-Correction in Larg...</td>\n",
       "      <td>The Capacity for Moral Self-Correction in Larg...</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>49</td>\n",
       "      <td>The Capacity for Moral Self Correction in Larg...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>The Power of Scale for Parameter-Efficient Pro...</td>\n",
       "      <td>The Power of Scale for Parameter-Efficient Pro...</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>2021</td>\n",
       "      <td>1530</td>\n",
       "      <td>The Power of Scale for Parameter Efficient Pro...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>The Unreliability of Explanations in Few-shot ...</td>\n",
       "      <td>The Unreliability of Explanations in Few-shot ...</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>2022</td>\n",
       "      <td>47</td>\n",
       "      <td>The Unreliability of Explanations in Few shot ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>The Web Can Be Your Oyster for Improving Large...</td>\n",
       "      <td>The Web Can Be Your Oyster for Improving Large...</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>The Web Can Be Your Oyster for Improving Large...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Toxicity Detection with Generative Prompt-base...</td>\n",
       "      <td>Toxicity Detection with Generative Prompt-base...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>Toxicity Detection with Generative Prompt base...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Training language models to follow instruction...</td>\n",
       "      <td>Training language models to follow instruction...</td>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>2022</td>\n",
       "      <td>3009</td>\n",
       "      <td>Training language models to follow instruction...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving w...</td>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving w...</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023</td>\n",
       "      <td>227</td>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving w...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>TreePrompt: Learning to Compose Tree Prompts f...</td>\n",
       "      <td>TreePrompt: Learning to Compose Tree Prompts f...</td>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>TreePrompt: Learning to Compose Tree Prompts f...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>UPRISE: Universal Prompt Retrieval for Improvi...</td>\n",
       "      <td>UPRISE: Universal Prompt Retrieval for Improvi...</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>UPRISE: Universal Prompt Retrieval for Improvi...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Universality and Limitations of Prompt Tuning</td>\n",
       "      <td>Universality and Limitations of Prompt Tuning</td>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>Universality and Limitations of Prompt Tuning</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Visual-Language Prompt Tuning with Knowledge-g...</td>\n",
       "      <td>Visual-Language Prompt Tuning with Knowledge-G...</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>Visual Language Prompt Tuning with Knowledge g...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>What In-Context Learning \"Learns\" In-Context: ...</td>\n",
       "      <td>What In-Context Learning \"Learns\" In-Context: ...</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2023</td>\n",
       "      <td>19</td>\n",
       "      <td>What In Context Learning \"Learns\" In Context: ...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Why think step-by-step? Reasoning emerges from...</td>\n",
       "      <td>Why think step-by-step? Reasoning emerges from...</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>Why think step by step? Reasoning emerges from...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>ZeroPrompt: Streaming Acoustic Encoders are Ze...</td>\n",
       "      <td>ZeroPrompt: Streaming Acoustic Encoders are Ze...</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>ZeroPrompt: Streaming Acoustic Encoders are Ze...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>kNN Prompting: Beyond-Context Learning with Ca...</td>\n",
       "      <td>kNN Prompting: Beyond-Context Learning with Ca...</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>kNN Prompting: Beyond Context Learning with Ca...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Ã€-la-carte Prompt Tuning (APT): Combining Dist...</td>\n",
       "      <td>Ã€-la-carte Prompt Tuning (APT): Combining Dist...</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>Ã€ la carte Prompt Tuning (APT): Combining Dist...</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper title  \\\n",
       "0    A Prompt Pattern Catalog to Enhance Prompt Eng...   \n",
       "1    A Taxonomy of Prompt Modifiers for Text-To-Ima...   \n",
       "2    AI Chains: Transparent and Controllable Human-...   \n",
       "3    ART: Automatic multi-step reasoning and tool-u...   \n",
       "4    Active Prompting with Chain-of-Thought for Lar...   \n",
       "5    An automatically discovered chain-of-thought p...   \n",
       "6    Ask Me Anything: A simple strategy for prompti...   \n",
       "7    Atlas: Few-shot Learning with Retrieval Augmen...   \n",
       "8    AutoPrompt: Eliciting Knowledge from Language ...   \n",
       "9    Automatic Chain of Thought Prompting in Large ...   \n",
       "10   Automatic Prompt Augmentation and Selection wi...   \n",
       "11                  BERTese: Learning to Speak to BERT   \n",
       "12   Batch Prompting: Efficient Inference with LLM ...   \n",
       "13   Better Zero-Shot Reasoning with Self-Adaptive ...   \n",
       "14   Boosted Prompt Ensembles for Large Language Mo...   \n",
       "15   Bounding the Capabilities of Large Language Mo...   \n",
       "16   CAMEL: Communicative Agents for \"Mind\" Explora...   \n",
       "17   Calibrate Before Use: Improving Few-Shot Perfo...   \n",
       "18   Can ChatGPT Understand Too? A Comparative Stud...   \n",
       "19   Can We Edit Factual Knowledge by In-Context Le...   \n",
       "20   Chain of Hindsight Aligns Language Models with...   \n",
       "21   Chain of Thought Prompting Elicits Reasoning i...   \n",
       "22   Chain-of-Symbol Prompting Elicits Planning in ...   \n",
       "23   Chain-of-Verification Reduces Hallucination in...   \n",
       "24   ChatGPT vs Human-authored Text: Insights into ...   \n",
       "25   CoTEVer: Chain of Thought Prompting Annotation...   \n",
       "26   Complexity-Based Prompting for Multi-Step Reas...   \n",
       "27     Compositional Exemplars for In-context Learning   \n",
       "28   Compress, Then Prompt: Improving Accuracy-Effi...   \n",
       "29   Connecting Large Language Models with Evolutio...   \n",
       "30    Constitutional AI: Harmlessness from AI Feedback   \n",
       "31   Context-faithful Prompting for Large Language ...   \n",
       "32   CooK: Empowering General-Purpose Language Mode...   \n",
       "33   Decomposed Prompting: A Modular Approach for S...   \n",
       "34   Demonstrate-Search-Predict: Composing retrieva...   \n",
       "35   Design Guidelines for Prompt Engineering Text-...   \n",
       "36   Discovering Language Model Behaviors with Mode...   \n",
       "37   DocPrompting: Generating Code by Retrieving th...   \n",
       "38   Dynamic Prompt Learning via Policy Gradient fo...   \n",
       "39   Dynamic Prompting: A Unified Framework for Pro...   \n",
       "40   Effectiveness of Data Augmentation for Prefix ...   \n",
       "41   Efficient Prompting via Dynamic In-Context Lea...   \n",
       "42   Enhancing Self-Consistency and Performance of ...   \n",
       "43    Evaluating Large Language Models Trained on Code   \n",
       "44       Evaluating the Robustness of Discrete Prompts   \n",
       "45   Evaluating the Susceptibility of Pre-Trained L...   \n",
       "46   EvoPrompting: Language Models for Code-Level N...   \n",
       "47   Exploring Lottery Prompts for Pre-trained Lang...   \n",
       "48   Fairness-guided Few-shot Prompting for Large L...   \n",
       "49   Fantastically Ordered Prompts and Where to Fin...   \n",
       "50   Flatness-Aware Prompt Selection Improves Accur...   \n",
       "51   Flesch or Fumble? Evaluating Readability Stand...   \n",
       "52   Focused Prefix Tuning for Controllable Text Ge...   \n",
       "53   From Sparse to Dense: GPT-4 Summarization with...   \n",
       "54                              GPT-4 Technical Report   \n",
       "55   Generated Knowledge Prompting for Commonsense ...   \n",
       "56   Global Prompt Cell: A Portable Control Module ...   \n",
       "57   Graph of Thoughts: Solving Elaborate Problems ...   \n",
       "58   GraphPrompt: Unifying Pre-Training and Downstr...   \n",
       "59   Guiding Large Language Models via Directional ...   \n",
       "60   Hard Prompts Made Easy: Gradient-Based Discret...   \n",
       "61   Hierarchical Prompting Assists Large Language ...   \n",
       "62          How Can We Know What Language Models Know?   \n",
       "63    How Does In-Context Learning Help Prompt Tuning?   \n",
       "64   How Robust is GPT-3.5 to Predecessors? A Compr...   \n",
       "65   Ignore Previous Prompt: Attack Techniques For ...   \n",
       "66                     In-Context Instruction Learning   \n",
       "67   In-Context Learning of Large Language Models E...   \n",
       "68             Interactive Natural Language Processing   \n",
       "69                       Is GPT-4 a Good Data Analyst?   \n",
       "70   Is Prompt All You Need? No. A Comprehensive an...   \n",
       "71   Language Is Not All You Need: Aligning Percept...   \n",
       "72   Language Models Are Greedy Reasoners: A System...   \n",
       "73               Language Models are Few-Shot Learners   \n",
       "74         Large Language Model Guided Tree-of-Thought   \n",
       "75   Large Language Models Are Human-Level Prompt E...   \n",
       "76   Large Language Models Can Be Easily Distracted...   \n",
       "77       Large Language Models are Zero-Shot Reasoners   \n",
       "78   Large Language Models are reasoners with Self-...   \n",
       "79   Larger language models do in-context learning ...   \n",
       "80                     Learning from Task Descriptions   \n",
       "81   Learning to Generate Task-Specific Adapters fr...   \n",
       "82    Learning to Transfer Prompts for Text Generation   \n",
       "83   Least-to-most promptingÂ enables complex reason...   \n",
       "84   Less Likely Brainstorming: Using Language Mode...   \n",
       "85   Let's Sample Step by Step: Adaptive-Consistenc...   \n",
       "86                           Let's Verify Step by Step   \n",
       "87   MRKL Systems: A modular, neuro-symbolic archit...   \n",
       "88   Machine Generated Text: A Comprehensive Survey...   \n",
       "89   Maieutic Prompting: Logically Consistent Reaso...   \n",
       "90   Making Pre-trained Language Models Better Few-...   \n",
       "91   Meta-in-context learning in large language models   \n",
       "92   Mixture of Soft Prompts for Controllable Data ...   \n",
       "93   Model-tuning Via Prompts Makes NLP Models Adve...   \n",
       "94   More than you've asked for: A Comprehensive An...   \n",
       "95   MultiTool-CoT: GPT-3 Can Use Multiple External...   \n",
       "96   Multimodal Chain-of-Thought Reasoning in Langu...   \n",
       "97   Multitask Prompt Tuning Enables Parameter-Effi...   \n",
       "98   Multitask Prompted Training Enables Zero-Shot ...   \n",
       "99   On Second Thought, Let's Not Think Step by Ste...   \n",
       "100  On the Advance of Making Language Models Bette...   \n",
       "101  OpenICL: An Open-Source Framework for In-conte...   \n",
       "102                 PAL: Program-aided Language Models   \n",
       "103  PEARL: Prompting Large Language Models to Plan...   \n",
       "104  PPT: Pre-trained Prompt Tuning for Few-shot Le...   \n",
       "105  Plan-and-Solve Prompting: Improving Zero-Shot ...   \n",
       "106  Post Hoc Explanations of Language Models Can I...   \n",
       "107                   Pre-Training to Learn in Context   \n",
       "108  Prefix-Tuning: Optimizing Continuous Prompts f...   \n",
       "109  Progressive Prompts: Continual Learning for La...   \n",
       "110       Prompt Engineering for Large Language Models   \n",
       "111  Prompt Programming for Large Language Models: ...   \n",
       "112  Prompt, Generate, then Cache: Cascade of Found...   \n",
       "113  PromptChainer: Chaining Large Language Model P...   \n",
       "114  Promptagator: Few-shot Dense Retrieval From 8 ...   \n",
       "115        Prompted Opinion Summarization with GPT-3.5   \n",
       "116                     Prompting GPT-3 To Be Reliable   \n",
       "117  Query-Dependent Prompt Evaluation and Optimiza...   \n",
       "118  REFINER: Reasoning Feedback on Intermediate Re...   \n",
       "119   Re-Reading Improves Reasoning in Language Models   \n",
       "120  ReAct: Synergizing Reasoning and Acting in Lan...   \n",
       "121  Reasoning with Language Model is Planning with...   \n",
       "122               Recitation-Augmented Language Models   \n",
       "123  Reflexion: an autonomous agent with dynamic me...   \n",
       "124  Reframing Instructional Prompts to GPTk's Lang...   \n",
       "125  Reprompting: Automated Chain-of-Thought Prompt...   \n",
       "126  Rethinking the Role of Demonstrations: What Ma...   \n",
       "127  Retrieval-Augmented Generation for Knowledge-I...   \n",
       "128  Revisiting Automated Prompting: Are We Actuall...   \n",
       "129  Satisfiability-Aided Language Models Using Dec...   \n",
       "130  Scalable Prompt Generation for Semi-supervised...   \n",
       "131      Scaling Instruction-Finetuned Language Models   \n",
       "132            Scaling Laws for Neural Language Models   \n",
       "133  Self-Consistency Improves Chain of Thought Rea...   \n",
       "134  Self-Critique Prompting with Large Language Mo...   \n",
       "135  Self-Refine: Iterative Refinement with Self-Fe...   \n",
       "136  Show Your Work: Scratchpads for Intermediate C...   \n",
       "137  Skeleton-of-Thought: Large Language Models Can...   \n",
       "138  Structure Pretraining and Prompt Tuning for Kn...   \n",
       "139  Successive Prompting for Decomposing Complex Q...   \n",
       "140  SwitchPrompt: Learning Domain-Specific Gated S...   \n",
       "141  Synthetic Prompting: Generating Chain-of-Thoug...   \n",
       "142  TELeR: A General Taxonomy of LLM Prompts for B...   \n",
       "143  Teaching Algorithmic Reasoning via In-context ...   \n",
       "144  The Capacity for Moral Self-Correction in Larg...   \n",
       "145  The Power of Scale for Parameter-Efficient Pro...   \n",
       "146  The Unreliability of Explanations in Few-shot ...   \n",
       "147  The Web Can Be Your Oyster for Improving Large...   \n",
       "148  Toxicity Detection with Generative Prompt-base...   \n",
       "149  Training language models to follow instruction...   \n",
       "150  Tree of Thoughts: Deliberate Problem Solving w...   \n",
       "151  TreePrompt: Learning to Compose Tree Prompts f...   \n",
       "152  UPRISE: Universal Prompt Retrieval for Improvi...   \n",
       "153      Universality and Limitations of Prompt Tuning   \n",
       "154  Visual-Language Prompt Tuning with Knowledge-g...   \n",
       "155  What In-Context Learning \"Learns\" In-Context: ...   \n",
       "156  Why think step-by-step? Reasoning emerges from...   \n",
       "157  ZeroPrompt: Streaming Acoustic Encoders are Ze...   \n",
       "158  kNN Prompting: Beyond-Context Learning with Ca...   \n",
       "159  Ã€-la-carte Prompt Tuning (APT): Combining Dist...   \n",
       "\n",
       "                                semantic scholar title ss_publication_date  \\\n",
       "0    A Prompt Pattern Catalog to Enhance Prompt Eng...          2023-02-21   \n",
       "1    A Taxonomy of Prompt Modifiers for Text-To-Ima...          2022-04-20   \n",
       "2    AI Chains: Transparent and Controllable Human-...          2021-10-04   \n",
       "3    ART: Automatic multi-step reasoning and tool-u...          2023-03-16   \n",
       "4    Active Prompting with Chain-of-Thought for Lar...          2023-02-23   \n",
       "5    An automatically discovered chain-of-thought p...          2023-05-04   \n",
       "6    Ask Me Anything: A simple strategy for prompti...          2022-10-05   \n",
       "7    Few-shot Learning with Retrieval Augmented Lan...          2022-08-05   \n",
       "8    Eliciting Knowledge from Language Models Using...          2020-10-29   \n",
       "9    Automatic Chain of Thought Prompting in Large ...          2022-10-07   \n",
       "10   Automatic Prompt Augmentation and Selection wi...          2023-02-24   \n",
       "11                  BERTese: Learning to Speak to BERT          2021-03-09   \n",
       "12   Batch Prompting: Efficient Inference with Larg...          2023-01-19   \n",
       "13   Better Zero-Shot Reasoning with Self-Adaptive ...          2023-05-23   \n",
       "14   Boosted Prompt Ensembles for Large Language Mo...          2023-04-12   \n",
       "15   Bounding the Capabilities of Large Language Mo...          2023-02-17   \n",
       "16   CAMEL: Communicative Agents for \"Mind\" Explora...          2023-03-31   \n",
       "17   Calibrate Before Use: Improving Few-Shot Perfo...          2021-02-19   \n",
       "18   Can ChatGPT Understand Too? A Comparative Stud...          2023-02-19   \n",
       "19   Can We Edit Factual Knowledge by In-Context Le...          2023-05-22   \n",
       "20   Chain of Hindsight Aligns Language Models with...          2023-02-06   \n",
       "21   Chain of Thought Prompting Elicits Reasoning i...          2022-01-28   \n",
       "22   Chain-of-Symbol Prompting Elicits Planning in ...                None   \n",
       "23   Chain-of-Verification Reduces Hallucination in...          2023-09-20   \n",
       "24   ChatGPT vs Human-authored Text: Insights into ...          2023-06-13   \n",
       "25   CoTEVer: Chain of Thought Prompting Annotation...          2023-03-07   \n",
       "26   Complexity-Based Prompting for Multi-Step Reas...          2022-10-03   \n",
       "27     Compositional Exemplars for In-context Learning          2023-02-11   \n",
       "28   Compress, Then Prompt: Improving Accuracy-Effi...          2023-05-17   \n",
       "29   Connecting Large Language Models with Evolutio...          2023-09-15   \n",
       "30    Constitutional AI: Harmlessness from AI Feedback          2022-12-15   \n",
       "31   Context-faithful Prompting for Large Language ...          2023-03-20   \n",
       "32         SHARED OPEN VOCABULARIES AND SEMANTIC MEDIA                None   \n",
       "33   Decomposed Prompting: A Modular Approach for S...          2022-10-05   \n",
       "34   Demonstrate-Search-Predict: Composing retrieva...          2022-12-28   \n",
       "35   Design Guidelines for Prompt Engineering Text-...          2021-09-14   \n",
       "36   Discovering Language Model Behaviors with Mode...          2022-12-19   \n",
       "37   DocPrompting: Generating Code by Retrieving th...          2022-07-13   \n",
       "38   Dynamic Prompt Learning via Policy Gradient fo...          2022-09-29   \n",
       "39   Dynamic Prompting: A Unified Framework for Pro...          2023-03-06   \n",
       "40   Effectiveness of Data Augmentation for Prefix ...                None   \n",
       "41   Efficient Prompting via Dynamic In-Context Lea...          2023-05-18   \n",
       "42   Enhancing Self-Consistency and Performance of ...          2022-11-21   \n",
       "43    Evaluating Large Language Models Trained on Code          2021-07-07   \n",
       "44       Evaluating the Robustness of Discrete Prompts          2023-02-11   \n",
       "45   Evaluating the Susceptibility of Pre-Trained L...          2022-09-05   \n",
       "46   EvoPrompting: Language Models for Code-Level N...          2023-02-28   \n",
       "47   Exploring Lottery Prompts for Pre-trained Lang...          2023-05-31   \n",
       "48   Fairness-guided Few-shot Prompting for Large L...          2023-03-23   \n",
       "49   Fantastically Ordered Prompts and Where to Fin...          2021-04-18   \n",
       "50   Flatness-Aware Prompt Selection Improves Accur...          2023-05-18   \n",
       "51   Flesch or Fumble? Evaluating Readability Stand...          2023-09-11   \n",
       "52   Focused Prefix Tuning for Controllable Text Ge...          2023-06-01   \n",
       "53   From Sparse to Dense: GPT-4 Summarization with...          2023-09-08   \n",
       "54                              GPT-4 Technical Report          2023-03-15   \n",
       "55   Generated Knowledge Prompting for Commonsense ...          2021-10-15   \n",
       "56   Global Prompt Cell: A Portable Control Module ...          2023-04-12   \n",
       "57   Graph of Thoughts: Solving Elaborate Problems ...          2023-08-18   \n",
       "58   GraphPrompt: Unifying Pre-Training and Downstr...          2023-02-16   \n",
       "59   Guiding Large Language Models via Directional ...          2023-02-22   \n",
       "60   Hard Prompts Made Easy: Gradient-Based Discret...          2023-02-07   \n",
       "61   Hierarchical Prompting Assists Large Language ...          2023-05-23   \n",
       "62          How Can We Know What Language Models Know?          2019-11-28   \n",
       "63    How Does In-Context Learning Help Prompt Tuning?          2023-02-22   \n",
       "64   How Robust is GPT-3.5 to Predecessors? A Compr...          2023-03-01   \n",
       "65   Ignore Previous Prompt: Attack Techniques For ...          2022-11-17   \n",
       "66                     In-Context Instruction Learning          2023-02-28   \n",
       "67   In-Context Learning of Large Language Models E...                None   \n",
       "68             Interactive Natural Language Processing          2023-05-22   \n",
       "69                       Is GPT-4 a Good Data Analyst?          2023-05-24   \n",
       "70   Is Prompt All You Need? No. A Comprehensive an...          2023-03-18   \n",
       "71   Language Is Not All You Need: Aligning Percept...          2023-02-27   \n",
       "72   Language Models Are Greedy Reasoners: A System...          2022-10-03   \n",
       "73               Language Models are Few-Shot Learners          2020-05-28   \n",
       "74         Large Language Model Guided Tree-of-Thought          2023-05-15   \n",
       "75   Large Language Models Are Human-Level Prompt E...          2022-11-03   \n",
       "76   Large Language Models Can Be Easily Distracted...          2023-01-31   \n",
       "77       Large Language Models are Zero-Shot Reasoners          2022-05-24   \n",
       "78   Large Language Models are reasoners with Self-...                None   \n",
       "79   Larger language models do in-context learning ...          2023-03-07   \n",
       "80                     Learning from Task Descriptions          2020-11-01   \n",
       "81   Learning to Generate Task-Specific Adapters fr...          2021-01-02   \n",
       "82    Learning to Transfer Prompts for Text Generation          2022-05-03   \n",
       "83   Least-to-Most Prompting Enables Complex Reason...          2022-05-21   \n",
       "84   Less Likely Brainstorming: Using Language Mode...          2023-05-30   \n",
       "85   Let's Sample Step by Step: Adaptive-Consistenc...          2023-05-19   \n",
       "86                           Let's Verify Step by Step          2023-05-31   \n",
       "87   MRKL Systems: A modular, neuro-symbolic archit...          2022-05-01   \n",
       "88   Machine-Generated Text: A Comprehensive Survey...          2022-10-13   \n",
       "89   Maieutic Prompting: Logically Consistent Reaso...          2022-05-24   \n",
       "90   Making Pre-trained Language Models Better Few-...          2021-01-01   \n",
       "91   Meta-in-context learning in large language models          2023-05-22   \n",
       "92   Mixture of Soft Prompts for Controllable Data ...          2023-03-02   \n",
       "93   Model-tuning Via Prompts Makes NLP Models Adve...          2023-03-13   \n",
       "94   More than you've asked for: A Comprehensive An...                None   \n",
       "95   MultiTool-CoT: GPT-3 Can Use Multiple External...          2023-05-26   \n",
       "96   Multimodal Chain-of-Thought Reasoning in Langu...          2023-02-02   \n",
       "97   Multitask Prompt Tuning Enables Parameter-Effi...          2023-03-06   \n",
       "98   Multitask Prompted Training Enables Zero-Shot ...          2021-10-15   \n",
       "99   On Second Thought, Letâ€™s Not Think Step by Ste...          2022-12-15   \n",
       "100  On the Advance of Making Language Models Bette...                None   \n",
       "101  OpenICL: An Open-Source Framework for In-conte...          2023-03-06   \n",
       "102                 PAL: Program-aided Language Models          2022-11-18   \n",
       "103  PEARL: Prompting Large Language Models to Plan...          2023-05-23   \n",
       "104  PPT: Pre-trained Prompt Tuning for Few-shot Le...          2021-09-09   \n",
       "105  Plan-and-Solve Prompting: Improving Zero-Shot ...          2023-05-06   \n",
       "106  Post Hoc Explanations of Language Models Can I...          2023-05-19   \n",
       "107                   Pre-Training to Learn in Context          2023-05-16   \n",
       "108  Prefix-Tuning: Optimizing Continuous Prompts f...                None   \n",
       "109  Progressive Prompts: Continual Learning for La...          2023-01-29   \n",
       "110       Prompt Engineering for Large Language Models                None   \n",
       "111  Prompt Programming for Large Language Models: ...          2021-02-15   \n",
       "112  Prompt, Generate, Then Cache: Cascade of Found...          2023-03-03   \n",
       "113  PromptChainer: Chaining Large Language Model P...          2022-03-13   \n",
       "114  Promptagator: Few-shot Dense Retrieval From 8 ...          2022-09-23   \n",
       "115        Prompted Opinion Summarization with GPT-3.5          2022-11-29   \n",
       "116                     Prompting GPT-3 To Be Reliable          2022-10-17   \n",
       "117  Query-Dependent Prompt Evaluation and Optimiza...          2023-09-13   \n",
       "118  REFINER: Reasoning Feedback on Intermediate Re...          2023-04-04   \n",
       "119   Re-Reading Improves Reasoning in Language Models          2023-09-12   \n",
       "120  ReAct: Synergizing Reasoning and Acting in Lan...          2022-10-06   \n",
       "121  Reasoning with Language Model is Planning with...          2023-05-24   \n",
       "122               Recitation-Augmented Language Models          2022-10-04   \n",
       "123  Reflexion: an autonomous agent with dynamic me...                None   \n",
       "124  Reframing Instructional Prompts to GPTkâ€™s Lang...          2021-09-16   \n",
       "125  Reprompting: Automated Chain-of-Thought Prompt...          2023-05-17   \n",
       "126  Rethinking the Role of Demonstrations: What Ma...          2022-02-25   \n",
       "127  Retrieval-Augmented Generation for Knowledge-I...          2020-05-22   \n",
       "128  Revisiting Automated Prompting: Are We Actuall...          2023-04-07   \n",
       "129  Satisfiability-Aided Language Models Using Dec...          2023-05-16   \n",
       "130  Scalable Prompt Generation for Semi-supervised...          2023-02-18   \n",
       "131      Scaling Instruction-Finetuned Language Models          2022-10-20   \n",
       "132            Scaling Laws for Neural Language Models          2020-01-23   \n",
       "133  Self-Consistency Improves Chain of Thought Rea...          2022-03-21   \n",
       "134  Self-Critique Prompting with Large Language Mo...          2023-05-23   \n",
       "135  Self-Refine: Iterative Refinement with Self-Fe...          2023-03-30   \n",
       "136  Show Your Work: Scratchpads for Intermediate C...          2021-11-30   \n",
       "137  Skeleton-of-Thought: Large Language Models Can...          2023-07-28   \n",
       "138  Structure Pretraining and Prompt Tuning for Kn...          2023-03-03   \n",
       "139  Successive Prompting for Decomposing Complex Q...          2022-12-08   \n",
       "140  SwitchPrompt: Learning Domain-Specific Gated S...          2023-02-14   \n",
       "141  Synthetic Prompting: Generating Chain-of-Thoug...          2023-02-01   \n",
       "142  TELeR: A General Taxonomy of LLM Prompts for B...          2023-05-19   \n",
       "143  Teaching Algorithmic Reasoning via In-context ...          2022-11-15   \n",
       "144  The Capacity for Moral Self-Correction in Larg...          2023-02-15   \n",
       "145  The Power of Scale for Parameter-Efficient Pro...          2021-04-18   \n",
       "146  The Unreliability of Explanations in Few-shot ...          2022-05-06   \n",
       "147  The Web Can Be Your Oyster for Improving Large...          2023-05-18   \n",
       "148  Toxicity Detection with Generative Prompt-base...          2022-05-24   \n",
       "149  Training language models to follow instruction...          2022-03-04   \n",
       "150  Tree of Thoughts: Deliberate Problem Solving w...          2023-05-17   \n",
       "151  TreePrompt: Learning to Compose Tree Prompts f...          2023-05-19   \n",
       "152  UPRISE: Universal Prompt Retrieval for Improvi...          2023-03-15   \n",
       "153      Universality and Limitations of Prompt Tuning          2023-05-30   \n",
       "154  Visual-Language Prompt Tuning with Knowledge-G...          2023-03-23   \n",
       "155  What In-Context Learning \"Learns\" In-Context: ...          2023-05-16   \n",
       "156  Why think step-by-step? Reasoning emerges from...          2023-04-07   \n",
       "157  ZeroPrompt: Streaming Acoustic Encoders are Ze...          2023-05-18   \n",
       "158  kNN Prompting: Beyond-Context Learning with Ca...          2023-03-24   \n",
       "159  Ã€-la-carte Prompt Tuning (APT): Combining Dist...          2023-02-15   \n",
       "\n",
       "     ss_year  citation_count  \\\n",
       "0       2023             163   \n",
       "1       2022              43   \n",
       "2       2021             146   \n",
       "3       2023              39   \n",
       "4       2023              34   \n",
       "5       2023               6   \n",
       "6       2022              65   \n",
       "7       2022             202   \n",
       "8       2020             217   \n",
       "9       2022             201   \n",
       "10      2023              21   \n",
       "11      2021              74   \n",
       "12      2023              10   \n",
       "13      2023               8   \n",
       "14      2023              12   \n",
       "15      2023               6   \n",
       "16      2023              64   \n",
       "17      2021             616   \n",
       "18      2023              73   \n",
       "19      2023              11   \n",
       "20      2023              37   \n",
       "21      2022            2105   \n",
       "22      2023               2   \n",
       "23      2023              10   \n",
       "24      2023              12   \n",
       "25      2023               3   \n",
       "26      2022             116   \n",
       "27      2023              24   \n",
       "28      2023               3   \n",
       "29      2023               8   \n",
       "30      2022             307   \n",
       "31      2023              21   \n",
       "32      2012               1   \n",
       "33      2022             104   \n",
       "34      2022              57   \n",
       "35      2021             142   \n",
       "36      2022              87   \n",
       "37      2022              27   \n",
       "38      2022              51   \n",
       "39      2023               4   \n",
       "40      2023               0   \n",
       "41      2023               5   \n",
       "42      2022              16   \n",
       "43      2021            1617   \n",
       "44      2023               4   \n",
       "45      2022              12   \n",
       "46      2023              12   \n",
       "47      2023               1   \n",
       "48      2023               2   \n",
       "49      2021             408   \n",
       "50      2023               1   \n",
       "51      2023               0   \n",
       "52      2023               0   \n",
       "53      2023               2   \n",
       "54      2023            1529   \n",
       "55      2021             114   \n",
       "56      2023               0   \n",
       "57      2023              35   \n",
       "58      2023              16   \n",
       "59      2023              10   \n",
       "60      2023              38   \n",
       "61      2023               3   \n",
       "62      2019             763   \n",
       "63      2023               5   \n",
       "64      2023              24   \n",
       "65      2022              68   \n",
       "66      2023              19   \n",
       "67      2023               4   \n",
       "68      2023              14   \n",
       "69      2023              17   \n",
       "70      2023              16   \n",
       "71      2023             154   \n",
       "72      2022              58   \n",
       "73      2020           16440   \n",
       "74      2023              26   \n",
       "75      2022             194   \n",
       "76      2023              70   \n",
       "77      2022             882   \n",
       "78      2022              31   \n",
       "79      2023              87   \n",
       "80      2020              64   \n",
       "81      2021              18   \n",
       "82      2022              18   \n",
       "83      2022             369   \n",
       "84      2023               1   \n",
       "85      2023               6   \n",
       "86      2023              64   \n",
       "87      2022              31   \n",
       "88      2022              28   \n",
       "89      2022              86   \n",
       "90      2021            1082   \n",
       "91      2023               5   \n",
       "92      2023               3   \n",
       "93      2023               3   \n",
       "94      2023              37   \n",
       "95      2023               1   \n",
       "96      2023              91   \n",
       "97      2023              21   \n",
       "98      2021             924   \n",
       "99      2022              23   \n",
       "100     2022             106   \n",
       "101     2023              12   \n",
       "102     2022             198   \n",
       "103     2023               4   \n",
       "104     2021             234   \n",
       "105     2023              46   \n",
       "106     2023               5   \n",
       "107     2023               5   \n",
       "108     2021            1682   \n",
       "109     2023              20   \n",
       "110     2023               3   \n",
       "111     2021             317   \n",
       "112     2023              30   \n",
       "113     2022              78   \n",
       "114     2022              66   \n",
       "115     2022               8   \n",
       "116     2022              72   \n",
       "117     2023               1   \n",
       "118     2023              35   \n",
       "119     2023               2   \n",
       "120     2022             332   \n",
       "121     2023              34   \n",
       "122     2022              37   \n",
       "123     2023             105   \n",
       "124     2021             121   \n",
       "125     2023               5   \n",
       "126     2022             431   \n",
       "127     2020             956   \n",
       "128     2023               0   \n",
       "129     2023               3   \n",
       "130     2023               1   \n",
       "131     2022             823   \n",
       "132     2020            1530   \n",
       "133     2022             659   \n",
       "134     2023               3   \n",
       "135     2023             201   \n",
       "136     2021             315   \n",
       "137     2023               5   \n",
       "138     2023               4   \n",
       "139     2022              40   \n",
       "140     2023               2   \n",
       "141     2023              26   \n",
       "142     2023               4   \n",
       "143     2022              52   \n",
       "144     2023              49   \n",
       "145     2021            1530   \n",
       "146     2022              47   \n",
       "147     2023               0   \n",
       "148     2022              11   \n",
       "149     2022            3009   \n",
       "150     2023             227   \n",
       "151     2023               0   \n",
       "152     2023               8   \n",
       "153     2023               0   \n",
       "154     2023              11   \n",
       "155     2023              19   \n",
       "156     2023               8   \n",
       "157     2023               1   \n",
       "158     2023              16   \n",
       "159     2023               4   \n",
       "\n",
       "                                                 query day_queried  \n",
       "0    A Prompt Pattern Catalog to Enhance Prompt Eng...  2023-10-22  \n",
       "1    A Taxonomy of Prompt Modifiers for Text To Ima...  2023-10-22  \n",
       "2    AI Chains: Transparent and Controllable Human ...  2023-10-22  \n",
       "3    ART: Automatic multi step reasoning and tool u...  2023-10-22  \n",
       "4    Active Prompting with Chain of Thought for Lar...  2023-10-22  \n",
       "5    An automatically discovered chain of thought p...  2023-10-22  \n",
       "6    Ask Me Anything: A simple strategy for prompti...  2023-10-22  \n",
       "7    Atlas: Few shot Learning with Retrieval Augmen...  2023-10-22  \n",
       "8    AutoPrompt: Eliciting Knowledge from Language ...  2023-10-22  \n",
       "9    Automatic Chain of Thought Prompting in Large ...  2023-10-22  \n",
       "10   Automatic Prompt Augmentation and Selection wi...  2023-10-22  \n",
       "11                  BERTese: Learning to Speak to BERT  2023-10-22  \n",
       "12   Batch Prompting: Efficient Inference with LLM ...  2023-10-22  \n",
       "13   Better Zero Shot Reasoning with Self Adaptive ...  2023-10-22  \n",
       "14   Boosted Prompt Ensembles for Large Language Mo...  2023-10-22  \n",
       "15   Bounding the Capabilities of Large Language Mo...  2023-10-22  \n",
       "16   CAMEL: Communicative Agents for \"Mind\" Explora...  2023-10-22  \n",
       "17   Calibrate Before Use: Improving Few Shot Perfo...  2023-10-22  \n",
       "18   Can ChatGPT Understand Too? A Comparative Stud...  2023-10-22  \n",
       "19   Can We Edit Factual Knowledge by In Context Le...  2023-10-22  \n",
       "20   Chain of Hindsight Aligns Language Models with...  2023-10-22  \n",
       "21   Chain of Thought Prompting Elicits Reasoning i...  2023-10-22  \n",
       "22   Chain of Symbol Prompting Elicits Planning in ...  2023-10-22  \n",
       "23   Chain of Verification Reduces Hallucination in...  2023-10-22  \n",
       "24   ChatGPT vs Human authored Text: Insights into ...  2023-10-22  \n",
       "25   CoTEVer: Chain of Thought Prompting Annotation...  2023-10-22  \n",
       "26   Complexity Based Prompting for Multi Step Reas...  2023-10-22  \n",
       "27     Compositional Exemplars for In context Learning  2023-10-22  \n",
       "28   Compress, Then Prompt: Improving Accuracy Effi...  2023-10-22  \n",
       "29   Connecting Large Language Models with Evolutio...  2023-10-22  \n",
       "30    Constitutional AI: Harmlessness from AI Feedback  2023-10-22  \n",
       "31   Context faithful Prompting for Large Language ...  2023-10-22  \n",
       "32   CooK: Empowering General Purpose Language Mode...  2023-10-22  \n",
       "33   Decomposed Prompting: A Modular Approach for S...  2023-10-22  \n",
       "34   Demonstrate Search Predict: Composing retrieva...  2023-10-22  \n",
       "35   Design Guidelines for Prompt Engineering Text ...  2023-10-22  \n",
       "36   Discovering Language Model Behaviors with Mode...  2023-10-22  \n",
       "37   DocPrompting: Generating Code by Retrieving th...  2023-10-22  \n",
       "38   Dynamic Prompt Learning via Policy Gradient fo...  2023-10-22  \n",
       "39   Dynamic Prompting: A Unified Framework for Pro...  2023-10-22  \n",
       "40   Effectiveness of Data Augmentation for Prefix ...  2023-10-22  \n",
       "41   Efficient Prompting via Dynamic In Context Lea...  2023-10-22  \n",
       "42   Enhancing Self Consistency and Performance of ...  2023-10-22  \n",
       "43    Evaluating Large Language Models Trained on Code  2023-10-22  \n",
       "44       Evaluating the Robustness of Discrete Prompts  2023-10-22  \n",
       "45   Evaluating the Susceptibility of Pre Trained L...  2023-10-22  \n",
       "46   EvoPrompting: Language Models for Code Level N...  2023-10-22  \n",
       "47   Exploring Lottery Prompts for Pre trained Lang...  2023-10-22  \n",
       "48   Fairness guided Few shot Prompting for Large L...  2023-10-22  \n",
       "49   Fantastically Ordered Prompts and Where to Fin...  2023-10-22  \n",
       "50   Flatness Aware Prompt Selection Improves Accur...  2023-10-22  \n",
       "51   Flesch or Fumble? Evaluating Readability Stand...  2023-10-22  \n",
       "52   Focused Prefix Tuning for Controllable Text Ge...  2023-10-22  \n",
       "53   From Sparse to Dense: GPT 4 Summarization with...  2023-10-22  \n",
       "54                              GPT 4 Technical Report  2023-10-22  \n",
       "55   Generated Knowledge Prompting for Commonsense ...  2023-10-22  \n",
       "56   Global Prompt Cell: A Portable Control Module ...  2023-10-22  \n",
       "57   Graph of Thoughts: Solving Elaborate Problems ...  2023-10-22  \n",
       "58   GraphPrompt: Unifying Pre Training and Downstr...  2023-10-22  \n",
       "59   Guiding Large Language Models via Directional ...  2023-10-22  \n",
       "60   Hard Prompts Made Easy: Gradient Based Discret...  2023-10-22  \n",
       "61   Hierarchical Prompting Assists Large Language ...  2023-10-22  \n",
       "62          How Can We Know What Language Models Know?  2023-10-22  \n",
       "63    How Does In Context Learning Help Prompt Tuning?  2023-10-22  \n",
       "64   How Robust is GPT 3.5 to Predecessors? A Compr...  2023-10-22  \n",
       "65   Ignore Previous Prompt: Attack Techniques For ...  2023-10-22  \n",
       "66                     In Context Instruction Learning  2023-10-22  \n",
       "67   In Context Learning of Large Language Models E...  2023-10-22  \n",
       "68             Interactive Natural Language Processing  2023-10-22  \n",
       "69                       Is GPT 4 a Good Data Analyst?  2023-10-22  \n",
       "70   Is Prompt All You Need? No. A Comprehensive an...  2023-10-22  \n",
       "71   Language Is Not All You Need: Aligning Percept...  2023-10-22  \n",
       "72   Language Models Are Greedy Reasoners: A System...  2023-10-22  \n",
       "73               Language Models are Few Shot Learners  2023-10-22  \n",
       "74         Large Language Model Guided Tree of Thought  2023-10-22  \n",
       "75   Large Language Models Are Human Level Prompt E...  2023-10-22  \n",
       "76   Large Language Models Can Be Easily Distracted...  2023-10-22  \n",
       "77       Large Language Models are Zero Shot Reasoners  2023-10-22  \n",
       "78   Large Language Models are reasoners with Self ...  2023-10-22  \n",
       "79   Larger language models do in context learning ...  2023-10-22  \n",
       "80                     Learning from Task Descriptions  2023-10-22  \n",
       "81   Learning to Generate Task Specific Adapters fr...  2023-10-22  \n",
       "82    Learning to Transfer Prompts for Text Generation  2023-10-22  \n",
       "83   Least to most promptingÂ enables complex reason...  2023-10-22  \n",
       "84   Less Likely Brainstorming: Using Language Mode...  2023-10-22  \n",
       "85   Let's Sample Step by Step: Adaptive Consistenc...  2023-10-22  \n",
       "86                           Let's Verify Step by Step  2023-10-22  \n",
       "87   MRKL Systems: A modular, neuro symbolic archit...  2023-10-22  \n",
       "88   Machine Generated Text: A Comprehensive Survey...  2023-10-22  \n",
       "89   Maieutic Prompting: Logically Consistent Reaso...  2023-10-22  \n",
       "90   Making Pre trained Language Models Better Few ...  2023-10-22  \n",
       "91   Meta in context learning in large language models  2023-10-22  \n",
       "92   Mixture of Soft Prompts for Controllable Data ...  2023-10-22  \n",
       "93   Model tuning Via Prompts Makes NLP Models Adve...  2023-10-22  \n",
       "94   More than you've asked for: A Comprehensive An...  2023-10-22  \n",
       "95   MultiTool CoT: GPT 3 Can Use Multiple External...  2023-10-22  \n",
       "96   Multimodal Chain of Thought Reasoning in Langu...  2023-10-22  \n",
       "97   Multitask Prompt Tuning Enables Parameter Effi...  2023-10-22  \n",
       "98   Multitask Prompted Training Enables Zero Shot ...  2023-10-22  \n",
       "99   On Second Thought, Let's Not Think Step by Ste...  2023-10-22  \n",
       "100  On the Advance of Making Language Models Bette...  2023-10-22  \n",
       "101  OpenICL: An Open Source Framework for In conte...  2023-10-22  \n",
       "102                 PAL: Program aided Language Models  2023-10-22  \n",
       "103  PEARL: Prompting Large Language Models to Plan...  2023-10-22  \n",
       "104  PPT: Pre trained Prompt Tuning for Few shot Le...  2023-10-22  \n",
       "105  Plan and Solve Prompting: Improving Zero Shot ...  2023-10-22  \n",
       "106  Post Hoc Explanations of Language Models Can I...  2023-10-22  \n",
       "107                   Pre Training to Learn in Context  2023-10-22  \n",
       "108  Prefix Tuning: Optimizing Continuous Prompts f...  2023-10-22  \n",
       "109  Progressive Prompts: Continual Learning for La...  2023-10-22  \n",
       "110       Prompt Engineering for Large Language Models  2023-10-22  \n",
       "111  Prompt Programming for Large Language Models: ...  2023-10-22  \n",
       "112  Prompt, Generate, then Cache: Cascade of Found...  2023-10-22  \n",
       "113  PromptChainer: Chaining Large Language Model P...  2023-10-22  \n",
       "114  Promptagator: Few shot Dense Retrieval From 8 ...  2023-10-22  \n",
       "115        Prompted Opinion Summarization with GPT 3.5  2023-10-22  \n",
       "116                     Prompting GPT 3 To Be Reliable  2023-10-22  \n",
       "117  Query Dependent Prompt Evaluation and Optimiza...  2023-10-22  \n",
       "118  REFINER: Reasoning Feedback on Intermediate Re...  2023-10-22  \n",
       "119   Re Reading Improves Reasoning in Language Models  2023-10-22  \n",
       "120  ReAct: Synergizing Reasoning and Acting in Lan...  2023-10-22  \n",
       "121  Reasoning with Language Model is Planning with...  2023-10-22  \n",
       "122               Recitation Augmented Language Models  2023-10-22  \n",
       "123  Reflexion: an autonomous agent with dynamic me...  2023-10-22  \n",
       "124  Reframing Instructional Prompts to GPTk's Lang...  2023-10-22  \n",
       "125  Reprompting: Automated Chain of Thought Prompt...  2023-10-22  \n",
       "126  Rethinking the Role of Demonstrations: What Ma...  2023-10-22  \n",
       "127  Retrieval Augmented Generation for Knowledge I...  2023-10-22  \n",
       "128  Revisiting Automated Prompting: Are We Actuall...  2023-10-22  \n",
       "129  Satisfiability Aided Language Models Using Dec...  2023-10-22  \n",
       "130  Scalable Prompt Generation for Semi supervised...  2023-10-22  \n",
       "131      Scaling Instruction Finetuned Language Models  2023-10-22  \n",
       "132            Scaling Laws for Neural Language Models  2023-10-22  \n",
       "133  Self Consistency Improves Chain of Thought Rea...  2023-10-22  \n",
       "134  Self Critique Prompting with Large Language Mo...  2023-10-22  \n",
       "135  Self Refine: Iterative Refinement with Self Fe...  2023-10-22  \n",
       "136  Show Your Work: Scratchpads for Intermediate C...  2023-10-22  \n",
       "137  Skeleton of Thought: Large Language Models Can...  2023-10-22  \n",
       "138  Structure Pretraining and Prompt Tuning for Kn...  2023-10-22  \n",
       "139  Successive Prompting for Decomposing Complex Q...  2023-10-22  \n",
       "140  SwitchPrompt: Learning Domain Specific Gated S...  2023-10-22  \n",
       "141  Synthetic Prompting: Generating Chain of Thoug...  2023-10-22  \n",
       "142  TELeR: A General Taxonomy of LLM Prompts for B...  2023-10-22  \n",
       "143  Teaching Algorithmic Reasoning via In context ...  2023-10-22  \n",
       "144  The Capacity for Moral Self Correction in Larg...  2023-10-22  \n",
       "145  The Power of Scale for Parameter Efficient Pro...  2023-10-22  \n",
       "146  The Unreliability of Explanations in Few shot ...  2023-10-22  \n",
       "147  The Web Can Be Your Oyster for Improving Large...  2023-10-22  \n",
       "148  Toxicity Detection with Generative Prompt base...  2023-10-22  \n",
       "149  Training language models to follow instruction...  2023-10-22  \n",
       "150  Tree of Thoughts: Deliberate Problem Solving w...  2023-10-22  \n",
       "151  TreePrompt: Learning to Compose Tree Prompts f...  2023-10-22  \n",
       "152  UPRISE: Universal Prompt Retrieval for Improvi...  2023-10-22  \n",
       "153      Universality and Limitations of Prompt Tuning  2023-10-22  \n",
       "154  Visual Language Prompt Tuning with Knowledge g...  2023-10-22  \n",
       "155  What In Context Learning \"Learns\" In Context: ...  2023-10-22  \n",
       "156  Why think step by step? Reasoning emerges from...  2023-10-22  \n",
       "157  ZeroPrompt: Streaming Acoustic Encoders are Ze...  2023-10-22  \n",
       "158  kNN Prompting: Beyond Context Learning with Ca...  2023-10-22  \n",
       "159  Ã€ la carte Prompt Tuning (APT): Combining Dist...  2023-10-22  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_scholar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper title</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Structured Prompting: Scaling In-Context Learn...</td>\n",
       "      <td>Structured Prompting: Scaling In Context Learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Using Tree-of-Thought Prompting to boost ChatG...</td>\n",
       "      <td>Using Tree of Thought Prompting to boost ChatG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper title  \\\n",
       "0  Structured Prompting: Scaling In-Context Learn...   \n",
       "1  Using Tree-of-Thought Prompting to boost ChatG...   \n",
       "\n",
       "                                               query  \n",
       "0  Structured Prompting: Scaling In Context Learn...  \n",
       "1  Using Tree of Thought Prompting to boost ChatG...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output both files to Excel\n",
    "semantic_scholar_df.to_excel(\"Semantic Scholar Citations - First Pass.xlsx\", index=False)\n",
    "no_results_df.to_excel(\"No Results Semantic Scholar - First Pass.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
