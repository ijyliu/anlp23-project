"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"355F8MSY","preprint","2023","OpenAI","GPT-4 Technical Report","","","","","http://arxiv.org/abs/2303.08774","We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.","2023-03-27","2023-09-25 14:23:36","2023-10-22 05:13:34","2023-09-25 14:23:36","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2303.08774 [cs]","","C:\Users\ijyli\Zotero\storage\ZLQQGQUP\2303.html; C:\Users\ijyli\Zotero\storage\LM72BFL3\OpenAI - 2023 - GPT-4 Technical Report.pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2303.08774","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F37GLVE7","preprint","2023","Cheng, Liying; Li, Xingxuan; Bing, Lidong","Is GPT-4 a Good Data Analyst?","","","","","http://arxiv.org/abs/2305.15038","As large language models (LLMs) have demonstrated their powerful capabilities in plenty of domains and tasks, including context understanding, code generation, language generation, data storytelling, etc., many data analysts may raise concerns if their jobs will be replaced by AI. This controversial topic has drawn a lot of attention in public. However, we are still at a stage of divergent opinions without any definitive conclusion. Motivated by this, we raise the research question of ""is GPT-4 a good data analyst?"" in this work and aim to answer it by conducting head-to-head comparative studies. In detail, we regard GPT-4 as a data analyst to perform end-to-end data analysis with databases from a wide range of domains. We propose a framework to tackle the problems by carefully designing the prompts for GPT-4 to conduct experiments. We also design several task-specific evaluation metrics to systematically compare the performance between several professional human data analysts and GPT-4. Experimental results show that GPT-4 can achieve comparable performance to humans. We also provide in-depth discussions about our results to shed light on further studies before we reach the conclusion that GPT-4 can replace data analysts.","2023-05-24","2023-09-25 14:24:06","2023-09-25 14:24:06","2023-09-25 14:24:06","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2305.15038 [cs]","","C:\Users\ijyli\Zotero\storage\4N77GWHJ\2305.html; C:\Users\ijyli\Zotero\storage\QDTTIL6T\Cheng et al. - 2023 - Is GPT-4 a Good Data Analyst.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2305.15038","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65DI4GGM","newspaperArticle","2023","Roose, Kevin","A Conversation With Bing’s Chatbot Left Me Deeply Unsettled","The New York Times","","0362-4331","","https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html","A very strange conversation with the chatbot built into Microsoft’s search engine led to it declaring its love for me.","2023-02-16","2023-09-25 15:33:45","2023-09-25 15:33:45","2023-09-25 15:33:45","","","","","","","","","","","","","","en-US","","","","","NYTimes.com","","","","C:\Users\ijyli\Zotero\storage\XQCJKDEG\bing-chatbot-microsoft-chatgpt.html","","","Artificial Intelligence; ChatGPT; Computers and the Internet; Conversation; internal-sub-only; Microsoft Corp; OpenAI Labs; Search Engines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Technology","","","",""
"HLYY654Y","forumPost","2023","Ethan Mollick [@emollick]","I have a strong suspicion that “prompt engineering” is not going to be a big deal in the long-term & prompt engineer is not the job of the future AI gets easier. You can already see in Midjourney how basic prompts went from complex in v3 to easy in v4. Same with ChatGPT to Bing. https://t.co/BTtSN4oVF4","Twitter","","","","https://twitter.com/emollick/status/1627804798224580608","","2023-02-20","2023-09-26 02:53:27","2023-09-26 02:53:27","2023-09-26 02:53:27","","","","","","","","","","","","","","en","","Tweet","","","","","","","; C:\Users\ijyli\Zotero\storage\EUFKYTRM\1627804798224580608.html","https://t.co/BTtSN4oVF4","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H445H9N6","conferencePaper","2022","Wu, Tongshuang; Terry, Michael; Cai, Carrie Jun","AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts","CHI Conference on Human Factors in Computing Systems","978-1-4503-9157-3","","10.1145/3491102.3517582","https://dl.acm.org/doi/10.1145/3491102.3517582","","2022-04-29","2023-09-26 03:03:13","2023-09-26 03:03:13","2023-09-26 03:03:13","1-22","","","","","","AI Chains","","","","","ACM","New Orleans LA USA","en","","","","","DOI.org (Crossref)","","","","C:\Users\ijyli\Zotero\storage\G3NM64QK\Wu et al. - 2022 - AI Chains Transparent and Controllable Human-AI I.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CHI '22: CHI Conference on Human Factors in Computing Systems","","","","","","","","","","","","","","",""
"U6WJMRWZ","magazineArticle","2023","Acar, Oguz A.","AI Prompt Engineering Isn’t the Future","Harvard Business Review","","0017-8012","","https://hbr.org/2023/06/ai-prompt-engineering-isnt-the-future","Despite the buzz surrounding it, the prominence of prompt engineering may be fleeting. A more enduring and adaptable skill will keep enabling us to harness the potential of generative AI? It is called problem formulation — the ability to identify, analyze, and delineate problems.","2023-06-06","2023-09-26 03:14:17","2023-09-26 03:14:17","2023-09-26 03:14:17","","","","","","","","","","","","","","","","","","","hbr.org","","Section: Technology and analytics","","C:\Users\ijyli\Zotero\storage\I72G55WX\ai-prompt-engineering-isnt-the-future.html","","","AI and machine learning; Algorithms; Analytics and data science; Automation; Cybersecurity and digital privacy; Data management; Enterprise computing; Information management; Technology and analytics; Web-based technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5YYT9DF3","preprint","2023","Diao, Shizhe; Wang, Pengcheng; Lin, Yong; Zhang, Tong","Active Prompting with Chain-of-Thought for Large Language Models","","","","","http://arxiv.org/abs/2302.12246","The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs' ability to produce high-quality answers. In particular, an effective approach for complex question-and-answer tasks is example-based prompting with chain-of-thought (CoT) reasoning, which significantly improves the performance of LLMs. However, current CoT methods rely on a fixed set of human-annotated exemplars, which are not necessarily the most effective examples for different tasks. This paper proposes a new method, Active-Prompt, to adapt LLMs to different tasks with task-specific example prompts (annotated with human-designed CoT reasoning). For this purpose, we propose a solution to the key problem of determining which questions are the most important and helpful ones to annotate from a pool of task-specific queries. By borrowing ideas from the related problem of uncertainty-based active learning, we introduce several metrics to characterize the uncertainty so as to select the most uncertain questions for annotation. Experimental results demonstrate the superiority of our proposed method, achieving state-of-the-art on eight complex reasoning tasks. Further analyses of different uncertainty metrics, pool sizes, zero-shot learning, and accuracy-uncertainty relationship demonstrate the effectiveness of our method. Our code will be available at https://github.com/shizhediao/active-prompt.","2023-05-23","2023-09-26 03:15:01","2023-09-26 03:15:01","2023-09-26 03:15:01","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2302.12246 [cs]","","C:\Users\ijyli\Zotero\storage\WSCU8EX6\2302.html; C:\Users\ijyli\Zotero\storage\EZGKACIN\Diao et al. - 2023 - Active Prompting with Chain-of-Thought for Large L.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2302.12246","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BILARCH","webpage","","","PromptBase","","","","","https://promptbase.com","Search 100,000+ quality AI prompts from top prompt engineers. Produce better outputs, save on time & API costs, sell your own prompts.","","2023-09-26 03:15:17","2023-09-26 03:37:17","2023-09-26 03:15:17","","","","","","","PromptBase | Prompt Marketplace","","","","","","","en","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MI32YKHN","preprint","2023","Hebenstreit, Konstantin; Praas, Robert; Kiesewetter, Louis P.; Samwald, Matthias","An automatically discovered chain-of-thought prompt generalizes to novel models and datasets","","","","","http://arxiv.org/abs/2305.02897","Emergent chain-of-thought (CoT) reasoning capabilities promise to improve performance and explainability of large language models (LLMs). However, uncertainties remain about how reasoning strategies formulated for previous model generations generalize to new model generations and different datasets. In this small-scale study, we compare different reasoning strategies induced by zero-shot prompting across six recently released LLMs (davinci-002, davinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere command-xlarge) on a mixture of six question-answering datasets, including datasets from scientific and medical domains. Our findings demonstrate that while some variations in effectiveness occur, gains from CoT reasoning strategies remain robust across different models and datasets. GPT-4 has the most benefit from current state-of-the-art reasoning strategies and exhibits the best performance by applying a prompt previously discovered through automated discovery.","2023-08-03","2023-09-26 03:15:36","2023-09-26 03:15:36","2023-09-26 03:15:36","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2305.02897 [cs]","","C:\Users\ijyli\Zotero\storage\EZIPW94R\2305.html; C:\Users\ijyli\Zotero\storage\9DQ7M9VQ\Hebenstreit et al. - 2023 - An automatically discovered chain-of-thought promp.pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2305.02897","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBGCI5CT","journalArticle","","Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bosma, Maarten; Ichter, Brian; Xia, Fei; Chi, Ed H; Le, Quoc V; Zhou, Denny","Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","","","","","","We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.","","2023-09-26 03:15:52","2023-09-26 03:15:52","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\ijyli\Zotero\storage\8AG6AWPT\Wei et al. - Chain-of-Thought Prompting Elicits Reasoning in La.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LURSUVRC","preprint","2022","Zhang, Zhuosheng; Zhang, Aston; Li, Mu; Smola, Alex","Automatic Chain of Thought Prompting in Large Language Models","","","","","http://arxiv.org/abs/2210.03493","Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting. CoT prompting has two major paradigms. One leverages a simple prompt like ""Let's think step by step"" to facilitate step-by-step thinking before answering a question. The other uses a few manual demonstrations one by one, each composed of a question and a reasoning chain that leads to an answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific demonstrations one by one. We show that such manual efforts may be eliminated by leveraging LLMs with the ""Let's think step by step"" prompt to generate reasoning chains for demonstrations one by one, i.e., let's think not just step by step, but also one by one. However, these generated chains often come with mistakes. To mitigate the effect of such mistakes, we find that diversity matters for automatically constructing demonstrations. We propose an automatic CoT prompting method: Auto-CoT. It samples questions with diversity and generates reasoning chains to construct demonstrations. On ten public benchmark reasoning tasks with GPT-3, Auto-CoT consistently matches or exceeds the performance of the CoT paradigm that requires manual designs of demonstrations. Code is available at https://github.com/amazon-research/auto-cot","2022-10-07","2023-09-26 03:16:23","2023-09-26 03:16:23","2023-09-26 03:16:23","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2210.03493 [cs]","","C:\Users\ijyli\Zotero\storage\8TAIA3HA\2210.html; C:\Users\ijyli\Zotero\storage\BREVBII4\Zhang et al. - 2022 - Automatic Chain of Thought Prompting in Large Lang.pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2210.03493","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"46IQXEII","preprint","2023","Dhuliawala, Shehzaad; Komeili, Mojtaba; Xu, Jing; Raileanu, Roberta; Li, Xian; Celikyilmaz, Asli; Weston, Jason","Chain-of-Verification Reduces Hallucination in Large Language Models","","","","","http://arxiv.org/abs/2309.11495","Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.","2023-09-25","2023-09-26 03:16:47","2023-09-26 03:16:47","2023-09-26 03:16:47","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2309.11495 [cs]","","C:\Users\ijyli\Zotero\storage\6HVW7SMC\2309.html","","","Computer Science - Artificial Intelligence; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2309.11495","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3RXJ67P","preprint","2022","Liu, Jiacheng; Liu, Alisa; Lu, Ximing; Welleck, Sean; West, Peter; Bras, Ronan Le; Choi, Yejin; Hajishirzi, Hannaneh","Generated Knowledge Prompting for Commonsense Reasoning","","","","","http://arxiv.org/abs/2110.08387","It remains an open question whether incorporating external knowledge benefits commonsense reasoning while maintaining the flexibility of pretrained sequence models. To investigate this question, we develop generated knowledge prompting, which consists of generating knowledge from a language model, then providing the knowledge as additional input when answering a question. Our method does not require task-specific supervision for knowledge integration, or access to a structured knowledge base, yet it improves performance of large-scale, state-of-the-art models on four commonsense reasoning tasks, achieving state-of-the-art results on numerical commonsense (NumerSense), general commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks. Generated knowledge prompting highlights large-scale language models as flexible sources of external knowledge for improving commonsense reasoning. Our code is available at https://github.com/liujch1998/GKP","2022-09-28","2023-09-26 03:17:22","2023-09-26 03:17:22","2023-09-26 03:17:22","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2110.08387 [cs]","","C:\Users\ijyli\Zotero\storage\QWF7MR96\2110.html; C:\Users\ijyli\Zotero\storage\74ILI65I\Liu et al. - 2022 - Generated Knowledge Prompting for Commonsense Reas.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2110.08387","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PE8QEAAL","webpage","2023","Shackell, Cameron","Prompt engineering: is being an AI 'whisperer' the job of the future or a short-lived fad?","The Conversation","","","","http://theconversation.com/prompt-engineering-is-being-an-ai-whisperer-the-job-of-the-future-or-a-short-lived-fad-211833","Media articles and influencers have helped give the impression that prompt engineering could be a ticket to a six-figure salary. The reality, as always, is a different story.","2023-08-28","2023-09-26 03:29:08","2023-09-26 03:29:08","2023-09-26 03:29:08","","","","","","","Prompt engineering","","","","","","","en","","","","","","","","","C:\Users\ijyli\Zotero\storage\A6IN6CYE\prompt-engineering-is-being-an-ai-whisperer-the-job-of-the-future-or-a-short-lived-fad-211833.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CA6C7W8Q","webpage","2021","Martineau, Kim","What is prompt tuning?","IBM Research Blog","","","","https://research.ibm.com/blog/what-is-ai-prompt-tuning","It's an efficient, low-cost way of adapting a foundation model to new tasks without retraining the model.","2021-02-09","2023-09-26 03:34:21","2023-09-26 03:37:37","2023-09-26 03:34:21","","","","","","","","","","","","","","en-US","© Copyright IBM Corp. 2021","","","","","","","","C:\Users\ijyli\Zotero\storage\TLSRX94R\what-is-ai-prompt-tuning.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JB7XDT8","webpage","","Mann, Jyoti","Microsoft limits Bing chat exchanges and conversation lengths after 'creepy' interactions with some users","Business Insider","","","","https://www.businessinsider.com/microsoft-limits-bing-chat-exchanges-and-conversation-lengths-2023-2","Bing users will get a prompt to start a new topic once they hit the new limits imposed with the search engine's AI chatbot, Microsoft said.","","2023-09-26 04:11:31","2023-09-26 04:11:31","2023-09-26 04:11:31","","","","","","","","","","","","","","en-US","","","","","","","","","C:\Users\ijyli\Zotero\storage\MFSIBBQJ\microsoft-limits-bing-chat-exchanges-and-conversation-lengths-2023-2.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WP3MGPDG","conferencePaper","2022","Zhou, Yongchao; Muresanu, Andrei Ioan; Han, Ziwen; Paster, Keiran; Pitis, Silviu; Chan, Harris; Ba, Jimmy","Large Language Models are Human-Level Prompt Engineers","","","","","https://openreview.net/forum?id=92gvk82DE-","By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the ""program,"" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 21/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts.","2022-09-29","2023-09-26 05:39:03","2023-09-26 05:39:03","2023-09-26 05:39:03","","","","","","","","","","","","","","en","","","","","openreview.net","","","","C:\Users\ijyli\Zotero\storage\K2UC5R8B\Zhou et al. - 2022 - Large Language Models are Human-Level Prompt Engin.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The Eleventh International Conference on Learning Representations","","","","","","","","","","","","","","",""
"KCBUP4JK","computerProgram","2023","Hulbert, Dave","Using Tree-of-Thought Prompting to boost ChatGPT's reasoning","","","","","https://github.com/dave1010/tree-of-thought-prompting","Using Tree-of-Thought Prompting to boost ChatGPT's reasoning","2023-09-24","2023-09-26 05:46:18","2023-09-26 05:46:18","2023-09-26 05:46:18","","","","","","","","","","","","","","","MIT","","","","GitHub","","original-date: 2023-05-22T19:03:27Z","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUZTYUFC","preprint","2021","Chen, Mark; Tworek, Jerry; Jun, Heewoo; Yuan, Qiming; Pinto, Henrique Ponde de Oliveira; Kaplan, Jared; Edwards, Harri; Burda, Yuri; Joseph, Nicholas; Brockman, Greg; Ray, Alex; Puri, Raul; Krueger, Gretchen; Petrov, Michael; Khlaaf, Heidy; Sastry, Girish; Mishkin, Pamela; Chan, Brooke; Gray, Scott; Ryder, Nick; Pavlov, Mikhail; Power, Alethea; Kaiser, Lukasz; Bavarian, Mohammad; Winter, Clemens; Tillet, Philippe; Such, Felipe Petroski; Cummings, Dave; Plappert, Matthias; Chantzis, Fotios; Barnes, Elizabeth; Herbert-Voss, Ariel; Guss, William Hebgen; Nichol, Alex; Paino, Alex; Tezak, Nikolas; Tang, Jie; Babuschkin, Igor; Balaji, Suchir; Jain, Shantanu; Saunders, William; Hesse, Christopher; Carr, Andrew N.; Leike, Jan; Achiam, Josh; Misra, Vedant; Morikawa, Evan; Radford, Alec; Knight, Matthew; Brundage, Miles; Murati, Mira; Mayer, Katie; Welinder, Peter; McGrew, Bob; Amodei, Dario; McCandlish, Sam; Sutskever, Ilya; Zaremba, Wojciech","Evaluating Large Language Models Trained on Code","","","","","http://arxiv.org/abs/2107.03374","We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.","2021-07-14","2023-09-26 06:31:22","2023-09-26 06:31:22","2023-09-26 06:31:22","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2107.03374 [cs] version: 2","","C:\Users\ijyli\Zotero\storage\46D6JMMY\2107.html; C:\Users\ijyli\Zotero\storage\VTN24YRF\Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf","","","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2107.03374","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z87LTXAL","preprint","2022","Min, Sewon; Lyu, Xinxi; Holtzman, Ari; Artetxe, Mikel; Lewis, Mike; Hajishirzi, Hannaneh; Zettlemoyer, Luke","Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?","","","","","http://arxiv.org/abs/2202.12837","Large language models (LMs) are able to in-context learn -- perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required -- randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choce tasks, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of end task performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.","2022-10-20","2023-09-26 06:55:35","2023-09-26 06:55:35","2023-09-26 06:55:35","","","","","","","Rethinking the Role of Demonstrations","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2202.12837 [cs]","","C:\Users\ijyli\Zotero\storage\KNK3T7S7\2202.html; C:\Users\ijyli\Zotero\storage\S9E7MHMC\Min et al. - 2022 - Rethinking the Role of Demonstrations What Makes .pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2202.12837","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WB62ZY7S","preprint","2020","Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario","Language Models are Few-Shot Learners","","","","","http://arxiv.org/abs/2005.14165","Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.","2020-07-22","2023-09-26 07:05:43","2023-09-26 07:05:43","2023-09-26 07:05:43","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2005.14165 [cs]","","C:\Users\ijyli\Zotero\storage\FGWYX2HG\2005.html; C:\Users\ijyli\Zotero\storage\8TELU3ML\Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2005.14165","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PJH4SLP","webpage","2016","Flesch, Rudolf","How to Write Plain English","","","","","https://web.archive.org/web/20160712094308/http://www.mang.canterbury.ac.nz/writing_guide/writing/flesch.shtml","","2016-07-12","2023-09-26 17:47:09","2023-09-26 17:50:01","2023-09-26 17:47:09","","","","","","","","","","","","","","","","","","","","","","","C:\Users\ijyli\Zotero\storage\IIWNEDT4\flesch.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G6TVY4QN","computerProgram","","Aggarwal, Shivam Bansal, Chaitanya","textstat: Calculate statistical features from text","","","","","https://github.com/shivam5992/textstat","","","2023-09-26 17:52:06","2023-09-26 17:52:06","2023-09-26 17:52:06","","","","","","","textstat","","","","","","","","MIT","","","","PyPI","","","","C:\Users\ijyli\Zotero\storage\E4TZ4QDP\textstat.html","","","Text Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Python","0.7.3","","","","","","","",""
"LT4HAYH3","computerProgram","","Lacchia, Michele","radon: Code Metrics in Python","","","","","https://radon.readthedocs.org/","","","2023-09-26 19:45:27","2023-09-26 19:45:27","2023-09-26 19:45:27","","","","","","","radon","","","","","","","","MIT License","","","","PyPI","","","","C:\Users\ijyli\Zotero\storage\U3HJ4L9D\radon.html","","","analysis,; code,; complexity,; metrics; Software Development; Software Development - Libraries - Python Modules; Software Development - Quality Assurance; static,; Utilities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Python","6.0.1","OS Independent","","","","","","",""
"R5JINY9X","journalArticle","2014","Gardner, Dee; Davies, Mark","A New Academic Vocabulary List","Applied Linguistics","","0142-6001","10.1093/applin/amt015","https://doi.org/10.1093/applin/amt015","This article presents our new Academic Vocabulary List (AVL), derived from a 120-million-word academic subcorpus of the 425-million-word Corpus of Contemporary American English (COCA; Davies 2012). We first explore reasons why a new academic core list is warranted, and why such a list is still needed in English language education. We also provide a detailed description of the large academic corpus from which the AVL was derived, as well as the robust frequency and dispersion statistics used to identify the AVL. Our concluding case studies show that the AVL discriminates between academic and other materials, and that it covers ∼14% of academic materials in both COCA (120 million+ words) and the British National Corpus (33 million+ words). The article concludes with a discussion of how the AVL can be used in settings where academic English is the focus of instruction. In this discussion, we introduce a new web-based interface that can be used to learn AVL words, and to identify and interact with AVL words in any text entered in the search window.","2014-07-01","2023-09-26 19:58:34","2023-10-22 05:13:03","2023-09-26 19:58:34","305-327","","3","35","","Applied Linguistics","","","","","","","","","","","","","Silverchair","","","","C:\Users\ijyli\Zotero\storage\QWBXRZZF\Gardner and Davies - 2014 - A New Academic Vocabulary List.pdf; C:\Users\ijyli\Zotero\storage\V52UREL4\146569.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3CSSUL8","webpage","","","Semantic Scholar | AI-Powered Research Tool","","","","","https://www.semanticscholar.org/","Semantic Scholar uses groundbreaking AI and engineering to understand the semantics of scientific literature to help Scholars discover relevant research.","","2023-10-10 05:07:59","2023-10-10 05:07:59","2023-10-10 05:07:59","","","","","","","","","","","","","","en","","","","","","","","","C:\Users\ijyli\Zotero\storage\SU74PNWR\www.semanticscholar.org.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CY35X7AQ","preprint","2023","Gao, Andrew","Prompt Engineering for Large Language Models","","","","10.2139/ssrn.4504303","https://papers.ssrn.com/abstract=4504303","With the popularization of software like OpenAI’s ChatGPT and Google’s Bard, large language models (LLMs) have pervaded many aspects of life and work. For instance, ChatGPT can be used to provide customized recipes, suggesting substitutions for missing ingredients. It can be used to draft research proposals, write working code in many programming languages, translate text between languages, assist in policy making, and more (Gao 2023). Users interact with large language models through “prompts'', or natural language instructions. Carefully designed prompts can lead to significantly better outputs.In this review, common strategies for LLM prompt engineering will be explained. Additionally, considerations, recommended resources, and current directions of research on LLM prompt engineering will be discussed. Prompt engineering strategies based on finetuning will not be covered. The goal of this article is to introduce practical and validated prompt engineering techniques to a non-technical audience.","2023-07-08","2023-10-21 21:03:32","2023-10-22 05:13:56","2023-10-21 21:03:32","","","","","","","","","","","","","Rochester, NY","en","","SSRN Scholarly Paper","","","Social Science Research Network","","","","C:\Users\ijyli\Zotero\storage\LDEGTRGJ\Gao - 2023 - Prompt Engineering for Large Language Models.pdf","","","AI; artificial intelligence; chatgpt; large language model; prompt engineering","","","","","","","","","","","","","","","","","","","4504303","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAGSI2WP","preprint","2023","Fu, Yao; Peng, Hao; Sabharwal, Ashish; Clark, Peter; Khot, Tushar","Complexity-Based Prompting for Multi-Step Reasoning","","","","","http://arxiv.org/abs/2210.00720","We study the task of prompting large-scale language models to perform multi-step reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new reasoning chains and predict answers for new inputs. A central question is which reasoning examples make the most effective prompts. In this work, we propose complexity-based prompting, a simple and effective example selection scheme for multi-step reasoning. We show that prompts with higher reasoning complexity, i.e., chains with more reasoning steps, achieve substantially better performance on multi-step reasoning tasks over strong baselines. We further extend our complexity-based criteria from prompting (selecting inputs) to decoding (selecting outputs), where we sample multiple reasoning chains from the model, then choose the majority of generated answers from complex reasoning chains (over simple chains). When used to prompt GPT-3 and Codex, our approach substantially improves multi-step reasoning accuracy and achieves new state-of-the-art (SOTA) performance on three math benchmarks (GSM8K, MultiArith, and MathQA) and two BigBenchHard tasks (Date Understanding and Penguins), with an average +5.3 and up to +18 accuracy improvements. Compared with existing example selection schemes like manual tuning or retrieval-based selection, selection based on reasoning complexity is intuitive, easy to implement, and annotation-efficient. Further results demonstrate the robustness of performance gains from complex prompts under format perturbation and distribution shift.","2023-01-30","2023-10-22 05:06:58","2023-10-22 05:06:58","2023-10-22 05:06:58","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2210.00720 [cs]","","C:\Users\ijyli\Zotero\storage\PGYBJ363\2210.html; C:\Users\ijyli\Zotero\storage\LFZ8YNNV\Fu et al. - 2023 - Complexity-Based Prompting for Multi-Step Reasonin.pdf","","","Computer Science - Artificial Intelligence; Computer Science - Computation and Language; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2210.00720","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XCA83MMZ","preprint","2023","Shum, KaShun; Diao, Shizhe; Zhang, Tong","Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data","","","","","http://arxiv.org/abs/2302.12822","Chain-of-thought prompting (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in arithmetic, commonsense, and symbolic reasoning tasks. However, most CoT studies rely on carefully designed human-annotated rational chains to prompt the language model, which poses challenges for real-world applications where labeled training data is available without human-annotated rational chains. This creates barriers to applications of CoT prompting to these general tasks. This paper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoTs by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machine-generated rationale chains based on the labels. Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example in a black-box language model. Automate-CoT enables a quick adaptation of the CoT technique to different tasks. Experimental results demonstrate the effectiveness of our method, where state-of-the-art results are achieved on arithmetic reasoning (+2.7\%), commonsense reasoning (+3.4\%), symbolic reasoning (+3.2\%), and non-reasoning tasks (+2.5\%). Our code will be available at https://github.com/shizhediao/automate-cot.","2023-02-24","2023-10-22 05:08:27","2023-10-22 05:13:10","2023-10-22 05:08:27","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2302.12822 [cs]","","C:\Users\ijyli\Zotero\storage\JC3349S2\2302.html; C:\Users\ijyli\Zotero\storage\8VSI6DSX\Shum et al. - 2023 - Automatic Prompt Augmentation and Selection with C.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2302.12822","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPQDHPUF","preprint","2023","Adams, Griffin; Fabbri, Alexander; Ladhak, Faisal; Lehman, Eric; Elhadad, Noémie","From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting","","","","","http://arxiv.org/abs/2309.04269","Selecting the ``right'' amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain of Density'' (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between informativeness and readability. 500 annotated CoD summaries, as well as an extra 5,000 unannotated summaries, are freely available on HuggingFace (https://huggingface.co/datasets/griffin/chain_of_density).","2023-09-08","2023-10-22 05:09:04","2023-10-22 05:09:04","2023-10-22 05:09:04","","","","","","","From Sparse to Dense","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2309.04269 [cs]","","C:\Users\ijyli\Zotero\storage\QZMTMBS8\2309.html; C:\Users\ijyli\Zotero\storage\ZQW9FTMM\Adams et al. - 2023 - From Sparse to Dense GPT-4 Summarization with Cha.pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2309.04269","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HFMLMG8R","conferencePaper","2023","Pu, Dongqi; Demberg, Vera","ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)","","","10.18653/v1/2023.acl-srw.1","https://aclanthology.org/2023.acl-srw.1","Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style.","2023-07","2023-10-22 05:09:24","2023-10-22 05:09:24","2023-10-22 05:09:24","1–18","","","","","","ChatGPT vs Human-authored Text","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","ACLWeb","","","","C:\Users\ijyli\Zotero\storage\8WWZQWEK\Pu and Demberg - 2023 - ChatGPT vs Human-authored Text Insights into Cont.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q2G4VQCP","preprint","2023","Imperial, Joseph Marvin; Madabushi, Harish Tayyar","Flesch or Fumble? Evaluating Readability Standard Alignment of Instruction-Tuned Language Models","","","","","http://arxiv.org/abs/2309.05454","Readability metrics and standards such as Flesch Kincaid Grade Level (FKGL) and the Common European Framework of Reference for Languages (CEFR) exist to guide teachers and educators to properly assess the complexity of educational materials before administering them for classroom use. In this study, we select a diverse set of open and closed-source instruction-tuned language models and investigate their performances in writing story completions and simplifying narratives$-$tasks that teachers perform$-$using standard-guided prompts controlling text readability. Our extensive findings provide empirical proof of how globally recognized models like ChatGPT may be considered less effective and may require more refined prompts for these generative tasks compared to other open-sourced models such as BLOOMZ and FlanT5$-$which have shown promising results.","2023-09-11","2023-10-22 05:09:47","2023-10-22 05:09:47","2023-10-22 05:09:47","","","","","","","Flesch or Fumble?","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2309.05454 [cs]","","C:\Users\ijyli\Zotero\storage\77FB3SIU\2309.html; C:\Users\ijyli\Zotero\storage\5ELXLRI3\Imperial and Madabushi - 2023 - Flesch or Fumble Evaluating Readability Standard .pdf","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2309.05454","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TTZLM4K","conferencePaper","2023","Bhaskar, Adithya; Fabbri, Alex; Durrett, Greg","Prompted Opinion Summarization with GPT-3.5","Findings of the Association for Computational Linguistics: ACL 2023","","","10.18653/v1/2023.findings-acl.591","https://aclanthology.org/2023.findings-acl.591","Large language models have shown impressive performance across a wide variety of tasks, including text summarization. In this paper, we show that this strong performance extends to opinion summarization. We explore several pipeline methods for applying GPT-3.5 to summarize a large collection of user reviews in aprompted fashion. To handle arbitrarily large numbers of user reviews, we explore recursive summarization as well as methods for selecting salient content to summarize through supervised clustering or extraction. On two datasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and a generic summarization dataset of Amazon and Yelp reviews (FewSum), we show that GPT-3.5 models achieve very strong performance in human evaluation. We argue that standard evaluation metrics do not reflect this, and introduce three new metrics targeting faithfulness, factuality, and genericity to contrast these different methods.","2023-07","2023-10-22 05:11:03","2023-10-22 05:11:03","2023-10-22 05:11:03","9282–9300","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","ACLWeb","","","","C:\Users\ijyli\Zotero\storage\SSHKLZVA\Bhaskar et al. - 2023 - Prompted Opinion Summarization with GPT-3.5.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Findings 2023","","","","","","","","","","","","","","",""