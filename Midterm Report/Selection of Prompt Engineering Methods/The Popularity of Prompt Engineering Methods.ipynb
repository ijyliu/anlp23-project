{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Popularity of Prompt Engineering Methods\n",
    "\n",
    "This notebook produces statistics on Semantic Scholar citations per day for all of the prompt engineering approaches listed at \"https://www.promptingguide.ai/papers\" on October 10, 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\"><head><script charset=\"utf-8\" src=\"/_static/js/bundle-playback.js?v=1WaXNDFE\" type=\"text/javascript\"></script>\n",
      "<script charset=\"utf-8\" src=\"/_static/js/wombat.js?v=txqj7nKC\" type=\"text/javascript\"></script>\n",
      "<script>window.RufflePlayer=window.RufflePlayer||{};window.RufflePlayer.config={\"autoplay\":\"on\",\"unmuteOverlay\":\"hidden\"};</script>\n",
      "<script src=\"/_static/js/ruffle.js\" type=\"text/javascript\"></script>\n",
      "<script type=\"text/javascript\">\n",
      "  __wm.init(\"https://web.archive.org/web\");\n",
      "  __wm.wombat(\"https://www.promptingguide.ai/papers\",\"20231010055104\",\"https://web.archive.org/\",\"web\",\"/_static/\",\n",
      "\t      \"1696917064\");\n",
      "</script>\n",
      "<link href=\"/_static/css/banner-styles.css?v=S1zqJCYt\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"/_static/css/iconochive.css?v=qtvMKcIJ\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<!-- End Wayback Rewrite JS Include -->\n",
      "<meta charset=\"utf-8\"/><meta content=\"index,follow\" name=\"robots\"/><meta content=\"Papers – Nextra\" property=\"og:title\"/><meta content=\"#111\" media=\"(prefers-color-scheme: dark)\" name=\"theme-color\"/><style>\n",
      "        :root {\n",
      "          --nextra-primary-hue: 212deg;\n",
      "          --nextra-primary-saturation: 100%;\n",
      "          --nextra-navbar-height: 4rem;\n",
      "          --nextra-menu-height: 3.75rem;\n",
      "          --nextra-banner-height: 2.5rem;\n",
      "        }\n",
      "        \n",
      "        .dark {\n",
      "          --nextra-primary-hue: 204deg;\n",
      "          --nextra-primary-saturation: 100%;\n",
      "        }\n",
      "      </style><title>Papers | Prompt Engineering Guide<!-- --> </title><meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/><meta content=\"Prompt Engineering Guide\" property=\"og:title\"/><meta content=\"A Comprehensive Overview of Prompt Engineering\" property=\"og:description\"/><meta content=\"Papers | Prompt Engineering Guide\" name=\"og:title\"/><link href=\"/web/20231010055104im_/https://www.promptingguide.ai/144-favicon.svg\" rel=\"icon\" type=\"image/svg+xml\"/><link href=\"/web/20231010055104im_/https://www.promptingguide.ai/144-favicon-dark.svg\" media=\"(prefers-color-scheme: dark)\" rel=\"icon\" type=\"image/svg+xml\"/><meta content=\"12\" name=\"next-head-count\"/><link as=\"style\" href=\"/web/20231010055104/https://www.promptingguide.ai/_next/static/css/01662fb982270926.css\" rel=\"preload\"/><link data-n-g=\"\" href=\"/web/20231010055104cs_/https://www.promptingguide.ai/_next/static/css/01662fb982270926.css\" rel=\"stylesheet\"/><link as=\"style\" href=\"/web/20231010055104/https://www.promptingguide.ai/_next/static/css/78d4b83747a207ea.css\" rel=\"preload\"/><link data-n-p=\"\" href=\"/web/20231010055104cs_/https://www.promptingguide.ai/_next/static/css/78d4b83747a207ea.css\" rel=\"stylesheet\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/webpack-52f729f10091b61d.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/framework-c8e271832a0ddee4.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/main-ace3164b2260599b.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/pages/_app-0cb34192a0a0be90.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/14221-49164cdaced62cfa.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/chunks/pages/papers.en-ff6f70b957f16926.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/NiXWEo790ouuQU4aHl_Yr/_buildManifest.js\"></script><script defer=\"\" src=\"/web/20231010055104js_/https://www.promptingguide.ai/_next/static/NiXWEo790ouuQU4aHl_Yr/_ssgManifest.js\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div dir=\"ltr\"><script>document.documentElement.setAttribute('dir','ltr')</script><div class=\"nextra-nav-container nx-sticky nx-top-0 nx-z-20 nx-w-full nx-bg-transparent print:nx-hidden\"><div class=\"nextra-nav-container-blur nx-pointer-events-none nx-absolute nx-z-[-1] nx-h-full nx-w-full nx-bg-white dark:nx-bg-dark nx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] dark:nx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:nx-shadow-[0_0_0_1px_#000] contrast-more:dark:nx-shadow-[0_0_0_1px_#fff]\"></div><nav class=\"nx-mx-auto nx-flex nx-h-[var(--nextra-navbar-height)] nx-max-w-[90rem] nx-items-center nx-justify-end nx-gap-2 nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]\"><a class=\"nx-flex nx-items-center hover:nx-opacity-75 ltr:nx-mr-auto rtl:nx-ml-auto\" href=\"/web/20231010055104/https://www.promptingguide.ai/\"><svg fill=\"none\" height=\"24\" viewbox=\"0 0 206 246\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"40\" cy=\"40\" fill=\"currentColor\" r=\"40\"></circle><circle cx=\"40\" cy=\"206\" fill=\"currentColor\" r=\"40\"></circle><circle cx=\"166\" cy=\"120\" fill=\"currentColor\" r=\"40\"></circle></svg><span style=\"margin-left:.4em;font-weight:800\">Prompt Engineering Guide</span></a><a aria-current=\"false\" class=\"nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200\" href=\"/web/20231010055104/https://www.promptingguide.ai/course\"><span class=\"nx-absolute nx-inset-x-0 nx-text-center\">Prompt Engineering Course</span><span class=\"nx-invisible nx-font-medium\">Prompt Engineering Course</span></a><a aria-current=\"false\" class=\"nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200\" href=\"/web/20231010055104/https://www.promptingguide.ai/services\"><span class=\"nx-absolute nx-inset-x-0 nx-text-center\">Services</span><span class=\"nx-invisible nx-font-medium\">Services</span></a><a aria-current=\"false\" class=\"nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200\" href=\"/web/20231010055104/https://www.promptingguide.ai/about\"><span class=\"nx-absolute nx-inset-x-0 nx-text-center\">About</span><span class=\"nx-invisible nx-font-medium\">About</span></a><div class=\"nextra-search nx-relative md:nx-w-64 nx-hidden md:nx-inline-block mx-min-w-[200px]\"><div class=\"nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300\"><input class=\"nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current\" placeholder=\"Search...\" spellcheck=\"false\" type=\"search\" value=\"\"/></div></div><a class=\"nx-p-2 nx-text-current\" href=\"https://web.archive.org/web/20231010055104/https://github.com/dair-ai/Prompt-Engineering-Guide\" rel=\"noreferrer\" target=\"_blank\"><svg fill=\"currentColor\" height=\"24\" viewbox=\"3 3 18 18\" width=\"24\"><title>GitHub</title><path d=\"M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z\"></path></svg><span class=\"nx-sr-only\">GitHub</span><span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a><a class=\"nx-p-2 nx-text-current\" href=\"https://web.archive.org/web/20231010055104/https://discord.gg/FUyz9vPAwf\" rel=\"noreferrer\" target=\"_blank\"><svg fill=\"currentColor\" height=\"24\" viewbox=\"0 5 30.67 23.25\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\"><title>Discord</title><path d=\"M26.0015 6.9529C24.0021 6.03845 21.8787 5.37198 19.6623 5C19.3833 5.48048 19.0733 6.13144 18.8563 6.64292C16.4989 6.30193 14.1585 6.30193 11.8336 6.64292C11.6166 6.13144 11.2911 5.48048 11.0276 5C8.79575 5.37198 6.67235 6.03845 4.6869 6.9529C0.672601 12.8736 -0.41235 18.6548 0.130124 24.3585C2.79599 26.2959 5.36889 27.4739 7.89682 28.2489C8.51679 27.4119 9.07477 26.5129 9.55525 25.5675C8.64079 25.2265 7.77283 24.808 6.93587 24.312C7.15286 24.1571 7.36986 23.9866 7.57135 23.8161C12.6241 26.1255 18.0969 26.1255 23.0876 23.8161C23.3046 23.9866 23.5061 24.1571 23.7231 24.312C22.8861 24.808 22.0182 25.2265 21.1037 25.5675C21.5842 26.5129 22.1422 27.4119 22.7621 28.2489C25.2885 27.4739 27.8769 26.2959 30.5288 24.3585C31.1952 17.7559 29.4733 12.0212 26.0015 6.9529ZM10.2527 20.8402C8.73376 20.8402 7.49382 19.4608 7.49382 17.7714C7.49382 16.082 8.70276 14.7025 10.2527 14.7025C11.7871 14.7025 13.0425 16.082 13.0115 17.7714C13.0115 19.4608 11.7871 20.8402 10.2527 20.8402ZM20.4373 20.8402C18.9183 20.8402 17.6768 19.4608 17.6768 17.7714C17.6768 16.082 18.8873 14.7025 20.4373 14.7025C21.9717 14.7025 23.2271 16.082 23.1961 17.7714C23.1961 19.4608 21.9872 20.8402 20.4373 20.8402Z\"></path></svg><span class=\"nx-sr-only\">Discord</span><span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a><button aria-label=\"Menu\" class=\"nextra-hamburger -nx-mr-2 nx-rounded nx-p-2 active:nx-bg-gray-400/20 md:nx-hidden\" type=\"button\"><svg class=\"\" fill=\"none\" height=\"24\" stroke=\"currentColor\" viewbox=\"0 0 24 24\" width=\"24\"><g><path d=\"M4 6h16\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></g><path d=\"M4 12h16\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path><g><path d=\"M4 18h16\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></g></svg></button></nav></div><div class=\"nx-mx-auto nx-flex nx-max-w-[90rem]\"><div class=\"motion-reduce:nx-transition-none [transition:background-color_1.5s_ease] nx-bg-transparent\"></div><aside class=\"nextra-sidebar-container nx-flex nx-flex-col md:nx-top-16 md:nx-shrink-0 motion-reduce:nx-transform-none nx-transform-gpu nx-transition-all nx-ease-in-out print:nx-hidden md:nx-w-64 md:nx-sticky md:nx-self-start max-md:[transform:translate3d(0,-100%,0)]\"><div class=\"nx-px-4 nx-pt-4 md:nx-hidden\"><div class=\"nextra-search nx-relative md:nx-w-64\"><div class=\"nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300\"><input class=\"nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current\" placeholder=\"Search...\" spellcheck=\"false\" type=\"search\" value=\"\"/></div></div></div><div class=\"nx-overflow-y-auto nx-overflow-x-hidden nx-p-4 nx-grow md:nx-h-[calc(100vh-var(--nextra-navbar-height)-var(--nextra-menu-height))] nextra-scrollbar\"><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100\"><ul class=\"nx-flex nx-flex-col nx-gap-1 nextra-menu-desktop max-md:nx-hidden\"><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/\">Prompt Engineering</a></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/introduction\">Introduction<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/introduction/settings\">LLM Settings</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/introduction/basics\">Basics of Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/introduction/elements\">Prompt Elements</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/introduction/tips\">General Tips for Designing Prompts</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/introduction/examples\">Examples of Prompts</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques\">Techniques<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/zeroshot\">Zero-shot Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/fewshot\">Few-shot Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/cot\">Chain-of-Thought Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/consistency\">Self-Consistency</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/knowledge\">Generate Knowledge Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/tot\">Tree of Thoughts</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/rag\">Retrieval Augmented Generation</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/art\">Automatic Reasoning and Tool-use</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/ape\">Automatic Prompt Engineer</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/activeprompt\">Active-Prompt</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/dsp\">Directional Stimulus Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/react\">ReAct</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/multimodalcot\">Multimodal CoT</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/techniques/graph\">Graph Prompting</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications\">Applications<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/pal\">Program-Aided Language Models</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/generating\">Generating Data</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/synthetic_rag\">Generating Synthetic Dataset for RAG</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/generating_textbooks\">Tackling Generated Datasets Diversity</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/coding\">Generating Code</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/workplace_casestudy\">Graduate Job Classification Case Study</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/applications/pf\">Prompt Function</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/models\">Models<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/models/flan\">Flan</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/models/chatgpt\">ChatGPT</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/models/llama\">LLaMA</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/models/gpt-4\">GPT-4</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/models/collection\">LLM Collection</a></li></ul></div></div></li><li class=\"open\"><a class=\"nx-items-center nx-justify-between nx-gap-2 nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/risks\">Risks &amp; Misuses<svg class=\"nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path class=\"nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]\" d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a><div class=\"nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none\"><div class=\"nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1\"><ul class='nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[\"\"] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3'><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/risks/adversarial\">Adversarial Prompting</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/risks/factuality\">Factuality</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/risks/biases\">Biases</a></li></ul></div></div></li><li class=\"nx-flex nx-flex-col nx-gap-1 active\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-bg-primary-100 nx-font-semibold nx-text-primary-800 dark:nx-bg-primary-400/10 dark:nx-text-primary-600 contrast-more:nx-border-primary-500 contrast-more:dark:nx-border-primary-500\" href=\"/web/20231010055104/https://www.promptingguide.ai/papers\">Papers</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/tools\">Tools</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/notebooks\">Notebooks</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/datasets\">Datasets</a></li><li class=\"nx-flex nx-flex-col nx-gap-1\"><a class=\"nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50\" href=\"/web/20231010055104/https://www.promptingguide.ai/readings\">Additional Readings</a></li></ul></div></div></div><div class=\"nx-sticky nx-bottom-0 nx-bg-white dark:nx-bg-dark nx-mx-4 nx-py-4 nx-shadow-[0_-12px_16px_#fff] nx-flex nx-items-center nx-gap-2 dark:nx-border-neutral-800 dark:nx-shadow-[0_-12px_16px_#111] contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-shadow-none nx-justify-end nx-border-t\" data-toggle-animation=\"off\"><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 nx-grow\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R4v6pm:\" title=\"Change language\" type=\"button\"><span class=\"nx-flex nx-items-center nx-gap-2\"><svg fill=\"currentColor\" height=\"12\" viewbox=\"2 2 16 16\" width=\"12\"><path clip-rule=\"evenodd\" d=\"M4.083 9h1.946c.089-1.546.383-2.97.837-4.118A6.004 6.004 0 004.083 9zM10 2a8 8 0 100 16 8 8 0 000-16zm0 2c-.076 0-.232.032-.465.262-.238.234-.497.623-.737 1.182-.389.907-.673 2.142-.766 3.556h3.936c-.093-1.414-.377-2.649-.766-3.556-.24-.56-.5-.948-.737-1.182C10.232 4.032 10.076 4 10 4zm3.971 5c-.089-1.546-.383-2.97-.837-4.118A6.004 6.004 0 0115.917 9h-1.946zm-2.003 2H8.032c.093 1.414.377 2.649.766 3.556.24.56.5.948.737 1.182.233.23.389.262.465.262.076 0 .232-.032.465-.262.238-.234.498-.623.737-1.182.389-.907.673-2.142.766-3.556zm1.166 4.118c.454-1.147.748-2.572.837-4.118h1.946a6.004 6.004 0 01-2.783 4.118zm-6.268 0C6.412 13.97 6.118 12.546 6.03 11H4.083a6.004 6.004 0 002.783 4.118z\" fill-rule=\"evenodd\"></path></svg><span class=\"\">English</span></span></button><div class=\"\"><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R5f6pm:\" title=\"Change theme\" type=\"button\"><div class=\"nx-flex nx-items-center nx-gap-2 nx-capitalize\"><svg fill=\"none\" height=\"12\" stroke=\"currentColor\" viewbox=\"3 3 18 18\" width=\"12\"><path d=\"M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg><span class=\"md:nx-hidden\">Light</span></div></button></div></div></aside><nav aria-label=\"table of contents\" class=\"nextra-toc nx-order-last nx-hidden nx-w-64 nx-shrink-0 xl:nx-block print:nx-hidden nx-px-4\"><div class=\"nextra-scrollbar nx-sticky nx-top-16 nx-overflow-y-auto nx-pr-4 nx-pt-6 nx-text-sm [hyphens:auto] nx-max-h-[calc(100vh-var(--nextra-navbar-height)-env(safe-area-inset-bottom))] ltr:-nx-mr-4 rtl:-nx-ml-4\"><p class=\"nx-mb-4 nx-font-semibold nx-tracking-tight\">On This Page</p><ul><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#overviews\">Overviews</a></li><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#approaches\">Approaches</a></li><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#applications\">Applications</a></li><li class=\"nx-my-2 nx-scroll-my-6 nx-scroll-py-6\"><a class=\"nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words\" href=\"#collections\">Collections</a></li></ul><div class=\"nx-mt-8 nx-border-t nx-bg-white nx-pt-8 nx-shadow-[0_-12px_16px_white] dark:nx-bg-dark dark:nx-shadow-[0_-12px_16px_#111] nx-sticky nx-bottom-0 nx-flex nx-flex-col nx-items-start nx-gap-2 nx-pb-8 dark:nx-border-neutral-800 contrast-more:nx-border-t contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-border-neutral-400\"><a class=\"nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50\" href=\"https://web.archive.org/web/20231010055104/https://github.com/dair-ai/Prompt-Engineering-Guide/issues/new?title=Feedback%20for%20%E2%80%9CPapers%E2%80%9D&amp;labels=feedback\" rel=\"noreferrer\" target=\"_blank\">Question? Give us feedback →<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a><a class=\"nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50\" href=\"https://web.archive.org/web/20231010055104/https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/pages/papers.en.mdx\">Edit this page</a></div></div></nav><div id=\"reach-skip-nav\"></div><article class=\"nx-w-full nx-break-words nextra-content nx-flex nx-min-h-[calc(100vh-var(--nextra-navbar-height))] nx-min-w-0 nx-justify-center nx-pb-8 nx-pr-[calc(env(safe-area-inset-right)-1.5rem)]\"><main class=\"nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12\"><div class=\"nextra-breadcrumb nx-mt-1.5 nx-flex nx-items-center nx-gap-1 nx-overflow-hidden nx-text-sm nx-text-gray-500 dark:nx-text-gray-400 contrast-more:nx-text-current\"><div class=\"nx-whitespace-nowrap nx-transition-colors nx-font-medium nx-text-gray-700 contrast-more:nx-font-bold contrast-more:nx-text-current dark:nx-text-gray-100 contrast-more:dark:nx-text-current\" title=\"Papers\">Papers</div></div><h1 class=\"nx-mt-2 nx-text-4xl nx-font-bold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100\">Papers</h1>\n",
      "<p class=\"nx-mt-6 nx-leading-7 first:nx-mt-0\">The following are the latest papers (sorted by release date) on prompt engineering for large language models (LLMs). We update the list of papers on a daily/weekly basis.</p>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Overviews<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#overviews\" id=\"overviews\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.16938\" rel=\"noreferrer\" target=\"_blank\">Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13860\" rel=\"noreferrer\" target=\"_blank\">Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.13712\" rel=\"noreferrer\" target=\"_blank\">Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.08354\" rel=\"noreferrer\" target=\"_blank\">Tool Learning with Foundation Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.06488\" rel=\"noreferrer\" target=\"_blank\">One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.02020\" rel=\"noreferrer\" target=\"_blank\">A Bibliometric Review of Large Language Models Research from 2017 to 2023<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.18223\" rel=\"noreferrer\" target=\"_blank\">A Survey of Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.14725\" rel=\"noreferrer\" target=\"_blank\">Nature Language Reasoning, A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.07842\" rel=\"noreferrer\" target=\"_blank\">Augmented Language Models: a Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2301.00234\" rel=\"noreferrer\" target=\"_blank\">A Survey for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.10403\" rel=\"noreferrer\" target=\"_blank\">Towards Reasoning in Large Language Models: A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.09597\" rel=\"noreferrer\" target=\"_blank\">Reasoning with Language Model Prompting: A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2206.07682\" rel=\"noreferrer\" target=\"_blank\">Emergent Abilities of Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2204.13988\" rel=\"noreferrer\" target=\"_blank\">A Taxonomy of Prompt Modifiers for Text-To-Image Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2107.13586\" rel=\"noreferrer\" target=\"_blank\">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2021)</li>\n",
      "</ul>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Approaches<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#approaches\" id=\"approaches\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.11495\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Verification Reduces Hallucination in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08532\" rel=\"noreferrer\" target=\"_blank\">Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.04269\" rel=\"noreferrer\" target=\"_blank\">From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.06275\" rel=\"noreferrer\" target=\"_blank\">Re-Reading Improves Reasoning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.09687v2\" rel=\"noreferrer\" target=\"_blank\">Graph of Thoughts: Solving Elaborate Problems with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2307.15337\" rel=\"noreferrer\" target=\"_blank\">Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00369\" rel=\"noreferrer\" target=\"_blank\">Focused Prefix Tuning for Controllable Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19500\" rel=\"noreferrer\" target=\"_blank\">Exploring Lottery Prompts for Pre-trained Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19339\" rel=\"noreferrer\" target=\"_blank\">Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.20050\" rel=\"noreferrer\" target=\"_blank\">Let's Verify Step by Step<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.18787\" rel=\"noreferrer\" target=\"_blank\">Universality and Limitations of Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.16896\" rel=\"noreferrer\" target=\"_blank\">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14564v1\" rel=\"noreferrer\" target=\"_blank\">PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14992v1\" rel=\"noreferrer\" target=\"_blank\">Reasoning with Language Model is Planning with World Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13733\" rel=\"noreferrer\" target=\"_blank\">Self-Critique Prompting with Large Language Models for Inductive Instructions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14106\" rel=\"noreferrer\" target=\"_blank\">Better Zero-Shot Reasoning with Self-Adaptive Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14257\" rel=\"noreferrer\" target=\"_blank\">Hierarchical Prompting Assists Large Language Model on Web Navigation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13246\" rel=\"noreferrer\" target=\"_blank\">Interactive Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12740\" rel=\"noreferrer\" target=\"_blank\">Can We Edit Factual Knowledge by In-Context Learning?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12766\" rel=\"noreferrer\" target=\"_blank\">In-Context Learning of Large Language Models Explained as Kernel Regression<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.04091v3\" rel=\"noreferrer\" target=\"_blank\">Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12907\" rel=\"noreferrer\" target=\"_blank\">Meta-in-context learning in large language models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11860\" rel=\"noreferrer\" target=\"_blank\">Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11426\" rel=\"noreferrer\" target=\"_blank\">Post Hoc Explanations of Language Models Can Improve Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11186\" rel=\"noreferrer\" target=\"_blank\">Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11497\" rel=\"noreferrer\" target=\"_blank\">TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11430\" rel=\"noreferrer\" target=\"_blank\">TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11170\" rel=\"noreferrer\" target=\"_blank\">Efficient Prompting via Dynamic In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10998\" rel=\"noreferrer\" target=\"_blank\">The Web Can Be Your Oyster for Improving Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10713\" rel=\"noreferrer\" target=\"_blank\">Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10601\" rel=\"noreferrer\" target=\"_blank\">Tree of Thoughts: Deliberate Problem Solving with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10649\" rel=\"noreferrer\" target=\"_blank\">ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10276\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09955\" rel=\"noreferrer\" target=\"_blank\">CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09731\" rel=\"noreferrer\" target=\"_blank\">What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09993\" rel=\"noreferrer\" target=\"_blank\">Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09656\" rel=\"noreferrer\" target=\"_blank\">Satisfiability-Aided Language Models Using Declarative Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09137\" rel=\"noreferrer\" target=\"_blank\">Pre-Training to Learn in Context<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.05970\" rel=\"noreferrer\" target=\"_blank\">Boosted Prompt Ensembles for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.05642\" rel=\"noreferrer\" target=\"_blank\">Global Prompt Cell: A Portable Control Module for Effective Prompt<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.03843\" rel=\"noreferrer\" target=\"_blank\">Why think step-by-step? Reasoning emerges from the locality of experience<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.03609\" rel=\"noreferrer\" target=\"_blank\">Revisiting Automated Prompting: Are We Actually Doing Better?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.01904\" rel=\"noreferrer\" target=\"_blank\">REFINER: Reasoning Feedback on Intermediate Representations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.11366\" rel=\"noreferrer\" target=\"_blank\">Reflexion: an autonomous agent with dynamic memory and self-reflection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.17760\" rel=\"noreferrer\" target=\"_blank\">CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.17651v1\" rel=\"noreferrer\" target=\"_blank\">Self-Refine: Iterative Refinement with Self-Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.13824\" rel=\"noreferrer\" target=\"_blank\">kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.13283\" rel=\"noreferrer\" target=\"_blank\">Visual-Language Prompt Tuning with Knowledge-guided Context Optimization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.13217\" rel=\"noreferrer\" target=\"_blank\">Fairness-guided Few-shot Prompting for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.11315\" rel=\"noreferrer\" target=\"_blank\">Context-faithful Prompting for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.10475\" rel=\"noreferrer\" target=\"_blank\">Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.08518\" rel=\"noreferrer\" target=\"_blank\">UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.07320\" rel=\"noreferrer\" target=\"_blank\">Model-tuning Via Prompts Makes NLP Models Adversarially Robust<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.03922\" rel=\"noreferrer\" target=\"_blank\">Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.03628\" rel=\"noreferrer\" target=\"_blank\">CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.03846\" rel=\"noreferrer\" target=\"_blank\">Larger language models do in-context learning differently<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.02913\" rel=\"noreferrer\" target=\"_blank\">OpenICL: An Open-Source Framework for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.02909\" rel=\"noreferrer\" target=\"_blank\">Dynamic Prompting: A Unified Framework for Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.09014\" rel=\"noreferrer\" target=\"_blank\">ART: Automatic multi-step reasoning and tool-use for large language models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.02861\" rel=\"noreferrer\" target=\"_blank\">Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.02577\" rel=\"noreferrer\" target=\"_blank\">Effectiveness of Data Augmentation for Prefix Tuning with Limited Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.01580\" rel=\"noreferrer\" target=\"_blank\">Mixture of Soft Prompts for Controllable Data Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.02151\" rel=\"noreferrer\" target=\"_blank\">Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.00293\" rel=\"noreferrer\" target=\"_blank\">How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/pdf/2302.10198.pdf\" rel=\"noreferrer\" target=\"_blank\">Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.14838\" rel=\"noreferrer\" target=\"_blank\">EvoPrompting: Language Models for Code-Level Neural Architecture Search<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.14691\" rel=\"noreferrer\" target=\"_blank\">In-Context Instruction Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.02676\" rel=\"noreferrer\" target=\"_blank\">Chain of Hindsight Aligns Language Models with Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.14045\" rel=\"noreferrer\" target=\"_blank\">Language Is Not All You Need: Aligning Perception with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12822\" rel=\"noreferrer\" target=\"_blank\">Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12246\" rel=\"noreferrer\" target=\"_blank\">Active Prompting with Chain-of-Thought for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12173\" rel=\"noreferrer\" target=\"_blank\">More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.11382\" rel=\"noreferrer\" target=\"_blank\">A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.11520\" rel=\"noreferrer\" target=\"_blank\">Guiding Large Language Models via Directional Stimulus Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.11521\" rel=\"noreferrer\" target=\"_blank\">How Does In-Context Learning Help Prompt Tuning?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.09236\" rel=\"noreferrer\" target=\"_blank\">Scalable Prompt Generation for Semi-supervised Learning with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.09185\" rel=\"noreferrer\" target=\"_blank\">Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.07994\" rel=\"noreferrer\" target=\"_blank\">À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.08043\" rel=\"noreferrer\" target=\"_blank\">GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.07459\" rel=\"noreferrer\" target=\"_blank\">The Capacity for Moral Self-Correction in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.06868\" rel=\"noreferrer\" target=\"_blank\">SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.05619\" rel=\"noreferrer\" target=\"_blank\">Evaluating the Robustness of Discrete Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.05698\" rel=\"noreferrer\" target=\"_blank\">Compositional Exemplars for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.03668\" rel=\"noreferrer\" target=\"_blank\">Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.00923\" rel=\"noreferrer\" target=\"_blank\">Multimodal Chain-of-Thought Reasoning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.00093\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Can Be Easily Distracted by Irrelevant Context<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.00618\" rel=\"noreferrer\" target=\"_blank\">Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2301.12314\" rel=\"noreferrer\" target=\"_blank\">Progressive Prompts: Continual Learning for Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2301.08721\" rel=\"noreferrer\" target=\"_blank\">Batch Prompting: Efficient Inference with LLM APIs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.14024\" rel=\"noreferrer\" target=\"_blank\">Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.08061\" rel=\"noreferrer\" target=\"_blank\">On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.08073\" rel=\"noreferrer\" target=\"_blank\">Constitutional AI: Harmlessness from AI Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.04092\" rel=\"noreferrer\" target=\"_blank\">Successive Prompting for Decomposing Complex Questions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.09561v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are reasoners with Self-Verification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.09251\" rel=\"noreferrer\" target=\"_blank\">Discovering Language Model Behaviors with Model-Written Evaluations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.06713\" rel=\"noreferrer\" target=\"_blank\">Structured Prompting: Scaling In-Context Learning to 1,000 Examples<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2211.10435\" rel=\"noreferrer\" target=\"_blank\">PAL: Program-aided Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2211.01910\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Are Human-Level Prompt Engineers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2211.09527\" rel=\"noreferrer\" target=\"_blank\">Ignore Previous Prompt: Attack Techniques For Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.07321\" rel=\"noreferrer\" target=\"_blank\">Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2211.09066\" rel=\"noreferrer\" target=\"_blank\">Teaching Algorithmic Reasoning via In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2211.11875\" rel=\"noreferrer\" target=\"_blank\">Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for\" rel=\"noreferrer\" target=\"_blank\">Ask Me Anything: A simple strategy for prompting language models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.01296\" rel=\"noreferrer\" target=\"_blank\">Recitation-Augmented Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.03629\" rel=\"noreferrer\" target=\"_blank\">ReAct: Synergizing Reasoning and Acting in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.09150\" rel=\"noreferrer\" target=\"_blank\">Prompting GPT-3 To Be Reliable<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.02406\" rel=\"noreferrer\" target=\"_blank\">Decomposed Prompting: A Modular Approach for Solving Complex Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.03493\" rel=\"noreferrer\" target=\"_blank\">Automatic Chain of Thought Prompting in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.01240v3\" rel=\"noreferrer\" target=\"_blank\">Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2209.02128\" rel=\"noreferrer\" target=\"_blank\">Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2209.14610\" rel=\"noreferrer\" target=\"_blank\">Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2209.11755\" rel=\"noreferrer\" target=\"_blank\">Promptagator: Few-shot Dense Retrieval From 8 Examples<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2208.03299\" rel=\"noreferrer\" target=\"_blank\">Atlas: Few-shot Learning with Retrieval Augmented Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2207.05987\" rel=\"noreferrer\" target=\"_blank\">DocPrompting: Generating Code by Retrieving the Docs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2206.02336\" rel=\"noreferrer\" target=\"_blank\">On the Advance of Making Language Models Better Reasoners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2205.11916\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are Zero-Shot Reasoners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2205.11822\" rel=\"noreferrer\" target=\"_blank\">Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2205.00445\" rel=\"noreferrer\" target=\"_blank\">MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://aclanthology.org/2022.acl-long.576/\" rel=\"noreferrer\" target=\"_blank\">PPT: Pre-trained Prompt Tuning for Few-shot Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (Mqy 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2205.12390\" rel=\"noreferrer\" target=\"_blank\">Toxicity Detection with Generative Prompt-based Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2205.01543\" rel=\"noreferrer\" target=\"_blank\">Learning to Transfer Prompts for Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2205.03401\" rel=\"noreferrer\" target=\"_blank\">The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2204.13988\" rel=\"noreferrer\" target=\"_blank\">A Taxonomy of Prompt Modifiers for Text-To-Image Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2203.06566\" rel=\"noreferrer\" target=\"_blank\">PromptChainer: Chaining Large Language Model Prompts through Visual Programming<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2203.11171\" rel=\"noreferrer\" target=\"_blank\">Self-Consistency Improves Chain of Thought Reasoning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2203.02155\" rel=\"noreferrer\" target=\"_blank\">Training language models to follow instructions with human feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2202.12837\" rel=\"noreferrer\" target=\"_blank\">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2201.11903\" rel=\"noreferrer\" target=\"_blank\">Chain of Thought Prompting Elicits Reasoning in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2112.00114\" rel=\"noreferrer\" target=\"_blank\">Show Your Work: Scratchpads for Intermediate Computation with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2110.01691\" rel=\"noreferrer\" target=\"_blank\">AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2110.08387\" rel=\"noreferrer\" target=\"_blank\">Generated Knowledge Prompting for Commonsense Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2110.08207\" rel=\"noreferrer\" target=\"_blank\">Multitask Prompted Training Enables Zero-Shot Task Generalization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2109.07830\" rel=\"noreferrer\" target=\"_blank\">Reframing Instructional Prompts to GPTk's Language<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2109.06977\" rel=\"noreferrer\" target=\"_blank\">Design Guidelines for Prompt Engineering Text-to-Image Generative Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://aclanthology.org/2021.acl-long.295\" rel=\"noreferrer\" target=\"_blank\">Making Pre-trained Language Models Better Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2104.08786\" rel=\"noreferrer\" target=\"_blank\">Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://aclanthology.org/2021.eacl-main.316\" rel=\"noreferrer\" target=\"_blank\">BERTese: Learning to Speak to BERT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2104.08691\" rel=\"noreferrer\" target=\"_blank\">The Power of Scale for Parameter-Efficient Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2102.07350\" rel=\"noreferrer\" target=\"_blank\">Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2102.09690\" rel=\"noreferrer\" target=\"_blank\">Calibrate Before Use: Improving Few-Shot Performance of Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2101.00190\" rel=\"noreferrer\" target=\"_blank\">Prefix-Tuning: Optimizing Continuous Prompts for Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2101.00420\" rel=\"noreferrer\" target=\"_blank\">Learning to Generate Task-Specific Adapters from Task Description<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2021)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2012.15723\" rel=\"noreferrer\" target=\"_blank\">Making Pre-trained Language Models Better Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://aclanthology.org/2020.emnlp-main.105/\" rel=\"noreferrer\" target=\"_blank\">Learning from Task Descriptions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2010.15980\" rel=\"noreferrer\" target=\"_blank\">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2005.14165\" rel=\"noreferrer\" target=\"_blank\">Language Models are Few-Shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know\" rel=\"noreferrer\" target=\"_blank\">How Can We Know What Language Models Know?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2020)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2001.08361\" rel=\"noreferrer\" target=\"_blank\">Scaling Laws for Neural Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2020)</li>\n",
      "</ul>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Applications<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#applications\" id=\"applications\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.15427\" rel=\"noreferrer\" target=\"_blank\">Graph Neural Prompting with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.15025\" rel=\"noreferrer\" target=\"_blank\">Large Language Model Alignment: A Survey<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.13339\" rel=\"noreferrer\" target=\"_blank\">Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.13205\" rel=\"noreferrer\" target=\"_blank\">A Practical Survey on Zero-shot Prompt Design for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.10687\" rel=\"noreferrer\" target=\"_blank\">EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.10359\" rel=\"noreferrer\" target=\"_blank\">Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.10238\" rel=\"noreferrer\" target=\"_blank\">PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.09708\" rel=\"noreferrer\" target=\"_blank\">LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.09558\" rel=\"noreferrer\" target=\"_blank\">Summarization is (Almost) Dead<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.09444\" rel=\"noreferrer\" target=\"_blank\">Investigating Zero- and Few-shot Generalization in Fact Verification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.09338\" rel=\"noreferrer\" target=\"_blank\">Performance of the Pre-Trained Large Language Model GPT-4 on Automated Short Answer Grading<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.09117\" rel=\"noreferrer\" target=\"_blank\">Contrastive Decoding Improves Reasoning in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08963\" rel=\"noreferrer\" target=\"_blank\">Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08590\" rel=\"noreferrer\" target=\"_blank\">Neural Machine Translation Models Can Learn to be Few-shot Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08589\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Thought Reasoning is a Policy Improvement Operator<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08583\" rel=\"noreferrer\" target=\"_blank\">ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08541\" rel=\"noreferrer\" target=\"_blank\">When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08491\" rel=\"noreferrer\" target=\"_blank\">Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08303\" rel=\"noreferrer\" target=\"_blank\">Self-Consistent Narrative Prompts on Abductive Natural Language Inference<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08210\" rel=\"noreferrer\" target=\"_blank\">Investigating Answerability of LLMs for Long-Form Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08140\" rel=\"noreferrer\" target=\"_blank\">PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.08008\" rel=\"noreferrer\" target=\"_blank\">An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.07990\" rel=\"noreferrer\" target=\"_blank\">Leveraging Contextual Information for Effective Entity Salience Detection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.06135\" rel=\"noreferrer\" target=\"_blank\">Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.05833\" rel=\"noreferrer\" target=\"_blank\">PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.04269\" rel=\"noreferrer\" target=\"_blank\">From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.04461\" rel=\"noreferrer\" target=\"_blank\">Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.02654\" rel=\"noreferrer\" target=\"_blank\">Zero-Resource Hallucination Prevention for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.02772\" rel=\"noreferrer\" target=\"_blank\">Certifying LLM Safety against Adversarial Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2309.02772\" rel=\"noreferrer\" target=\"_blank\">Improving Code Generation by Dynamic Temperature Sampling<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.13479\" rel=\"noreferrer\" target=\"_blank\">Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.13032\" rel=\"noreferrer\" target=\"_blank\">Financial News Analytics Using Fine-Tuned Llama 2 GPT Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.10335\" rel=\"noreferrer\" target=\"_blank\">A Study on Robustness and Reliability of Large Language Model Code Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.12890\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Vote: Prompting for Rare Disease Identification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.09583\" rel=\"noreferrer\" target=\"_blank\">WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.09658\" rel=\"noreferrer\" target=\"_blank\">Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.09687\" rel=\"noreferrer\" target=\"_blank\">Graph of Thoughts: Solving Elaborate Problems with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.09662\" rel=\"noreferrer\" target=\"_blank\">Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.08614\" rel=\"noreferrer\" target=\"_blank\">Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.05596\" rel=\"noreferrer\" target=\"_blank\">You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2308.05481\" rel=\"noreferrer\" target=\"_blank\">LLM As DBA<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (August 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00784\" rel=\"noreferrer\" target=\"_blank\">Interpretable Math Word Problem Solution Generation Via Step-by-step Planning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00774\" rel=\"noreferrer\" target=\"_blank\">In-Context Learning User Simulators for Task-Oriented Dialog Systems<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00739\" rel=\"noreferrer\" target=\"_blank\">SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00618\" rel=\"noreferrer\" target=\"_blank\">Effective Structured Prompting by Meta-Learning and Representative Verbalizer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00526\" rel=\"noreferrer\" target=\"_blank\">Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2306.00550\" rel=\"noreferrer\" target=\"_blank\">Chain-Of-Thought Prompting Under Streaming Batch: A Case Study<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (June 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19713\" rel=\"noreferrer\" target=\"_blank\">Red Teaming Language Model Detectors with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://shishirpatil.github.io/gorilla/\" rel=\"noreferrer\" target=\"_blank\">Gorilla: Large Language Model Connected with Massive APIs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19835\" rel=\"noreferrer\" target=\"_blank\">Deliberate then Generate: Enhanced Prompting Framework for Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19597\" rel=\"noreferrer\" target=\"_blank\">What does the Failure to Reason with \"Respectively\" in Zero/Few-Shot Settings Tell Us about Language Models?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19426\" rel=\"noreferrer\" target=\"_blank\">ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19308\" rel=\"noreferrer\" target=\"_blank\">SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19234\" rel=\"noreferrer\" target=\"_blank\">Grammar Prompting for Domain-Specific Language Generation with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19148\" rel=\"noreferrer\" target=\"_blank\">Mitigating Label Biases for In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.18638\" rel=\"noreferrer\" target=\"_blank\">Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.19165\" rel=\"noreferrer\" target=\"_blank\">Strategic Reasoning with Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.18869\" rel=\"noreferrer\" target=\"_blank\">Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.18189\" rel=\"noreferrer\" target=\"_blank\">Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.18170\" rel=\"noreferrer\" target=\"_blank\">Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.18156\" rel=\"noreferrer\" target=\"_blank\">Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17826\" rel=\"noreferrer\" target=\"_blank\">NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17812\" rel=\"noreferrer\" target=\"_blank\">Tab-CoT: Zero-shot Tabular Chain of Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17680\" rel=\"noreferrer\" target=\"_blank\">Evaluating GPT-3 Generated Explanations for Hateful Content Moderation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17653\" rel=\"noreferrer\" target=\"_blank\">Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\">[Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning]<a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17373\" rel=\"noreferrer\" target=\"_blank\">https://arxiv.org/abs/2305.17373<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a>) (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17306\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17256\" rel=\"noreferrer\" target=\"_blank\">Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17147\" rel=\"noreferrer\" target=\"_blank\">Heterogeneous Value Evaluation for Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17104\" rel=\"noreferrer\" target=\"_blank\">PromptNER: Prompt Locating and Typing for Named Entity Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13514v1\" rel=\"noreferrer\" target=\"_blank\">Small Language Models Improve Giants by Rewriting Their Outputs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.15771v1\" rel=\"noreferrer\" target=\"_blank\">On the Planning Abilities of Large Language Models -- A Critical Investigation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.16582\" rel=\"noreferrer\" target=\"_blank\">Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12600v1\" rel=\"noreferrer\" target=\"_blank\">PRODIGY: Enabling In-context Learning Over Graphs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.15525v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are Few-Shot Health Learners<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.16367\" rel=\"noreferrer\" target=\"_blank\">Role-Play with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13299v1\" rel=\"noreferrer\" target=\"_blank\">Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12744v1\" rel=\"noreferrer\" target=\"_blank\">Fact-Checking Complex Claims with Program-Guided Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17126v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Models as Tool Makers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13016v2\" rel=\"noreferrer\" target=\"_blank\">Iterative Forward Tuning Boosts In-context Learning in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.17390v1\" rel=\"noreferrer\" target=\"_blank\">SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13246v1\" rel=\"noreferrer\" target=\"_blank\">Interactive Natural Language Processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.02897v1\" rel=\"noreferrer\" target=\"_blank\">An automatically discovered chain-of-thought prompt generalizes to novel models and datasets<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.08291v1\" rel=\"noreferrer\" target=\"_blank\">Large Language Model Guided Tree-of-Thought<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.06983v1\" rel=\"noreferrer\" target=\"_blank\">Active Retrieval Augmented Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12544v1\" rel=\"noreferrer\" target=\"_blank\">A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.02317v1\" rel=\"noreferrer\" target=\"_blank\">Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09800v1\" rel=\"noreferrer\" target=\"_blank\">Mirages: On Anthropomorphism in Dialogue Systems<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.15324v1\" rel=\"noreferrer\" target=\"_blank\">Model evaluation for extreme risks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.04388v1\" rel=\"noreferrer\" target=\"_blank\">Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.02466v1\" rel=\"noreferrer\" target=\"_blank\">Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13723\" rel=\"noreferrer\" target=\"_blank\">PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.04757v2\" rel=\"noreferrer\" target=\"_blank\">Augmented Large Language Models with Parametric Knowledge Guiding<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13735\" rel=\"noreferrer\" target=\"_blank\">Aligning Large Language Models through Synthetic Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13775\" rel=\"noreferrer\" target=\"_blank\">Concept-aware Training Improves In-context Learning Ability of Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.05176v1\" rel=\"noreferrer\" target=\"_blank\">FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13785\" rel=\"noreferrer\" target=\"_blank\">Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13817\" rel=\"noreferrer\" target=\"_blank\">Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13826\" rel=\"noreferrer\" target=\"_blank\">\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13903\" rel=\"noreferrer\" target=\"_blank\">Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13917\" rel=\"noreferrer\" target=\"_blank\">Generating Data for Symbolic Language with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13972\" rel=\"noreferrer\" target=\"_blank\">Make a Choice! Knowledge Base Question Answering with In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14002\" rel=\"noreferrer\" target=\"_blank\">Improving Language Models via Plug-and-Play Retrieval Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14006\" rel=\"noreferrer\" target=\"_blank\">Multi-Granularity Prompts for Topic Shift Detection in Dialogue<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14045\" rel=\"noreferrer\" target=\"_blank\">The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14057\" rel=\"noreferrer\" target=\"_blank\">Can Language Models Understand Physical Concepts?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14069\" rel=\"noreferrer\" target=\"_blank\">Evaluating Factual Consistency of Summaries with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14128\" rel=\"noreferrer\" target=\"_blank\">Dr.ICL: Demonstration-Retrieved In-context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14171\" rel=\"noreferrer\" target=\"_blank\">Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14210\" rel=\"noreferrer\" target=\"_blank\">Skill-Based Few-Shot Selection for In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14215\" rel=\"noreferrer\" target=\"_blank\">Exploring Chain-of-Thought Style Prompting for Text-to-SQL<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14233\" rel=\"noreferrer\" target=\"_blank\">Enhancing Chat Language Models by Scaling High-quality Instructional Conversations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14239\" rel=\"noreferrer\" target=\"_blank\">On Learning to Summarize with Large Language Models as References<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14259\" rel=\"noreferrer\" target=\"_blank\">Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14264\" rel=\"noreferrer\" target=\"_blank\">Active Learning Principles for In-Context Learning with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14279\" rel=\"noreferrer\" target=\"_blank\">Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14325\" rel=\"noreferrer\" target=\"_blank\">Improving Factuality and Reasoning in Language Models through Multiagent Debate<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14323\" rel=\"noreferrer\" target=\"_blank\">ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on\\ Chat-based Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14292\" rel=\"noreferrer\" target=\"_blank\">WikiChat: A Few-Shot LLM-Based Chatbot Grounded with Wikipedia<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.14283\" rel=\"noreferrer\" target=\"_blank\">Query Rewriting for Retrieval-Augmented Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13729\" rel=\"noreferrer\" target=\"_blank\">Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13412\" rel=\"noreferrer\" target=\"_blank\">Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13514\" rel=\"noreferrer\" target=\"_blank\">Small Language Models Improve Giants by Rewriting Their Outputs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13626\" rel=\"noreferrer\" target=\"_blank\">Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13660\" rel=\"noreferrer\" target=\"_blank\">Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13669\" rel=\"noreferrer\" target=\"_blank\">Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13068\" rel=\"noreferrer\" target=\"_blank\">Making Language Models Better Tool Learners with Execution Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13073\" rel=\"noreferrer\" target=\"_blank\">Text-to-SQL Error Correction with Language Models of Code<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13085\" rel=\"noreferrer\" target=\"_blank\">Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13235\" rel=\"noreferrer\" target=\"_blank\">SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13252\" rel=\"noreferrer\" target=\"_blank\">\"According to ...\" Prompting Language Models Improves Quoting from Pre-Training Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13264\" rel=\"noreferrer\" target=\"_blank\">Prompt-based methods may underestimate large language models' linguistic generalizations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13269\" rel=\"noreferrer\" target=\"_blank\">Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.13299\" rel=\"noreferrer\" target=\"_blank\">Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12576\" rel=\"noreferrer\" target=\"_blank\">Automated Few-shot Classification with Instruction-Finetuned Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12586\" rel=\"noreferrer\" target=\"_blank\">Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12627\" rel=\"noreferrer\" target=\"_blank\">MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12696\" rel=\"noreferrer\" target=\"_blank\">Learning Interpretable Style Embeddings via Prompting LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12723\" rel=\"noreferrer\" target=\"_blank\">Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12744\" rel=\"noreferrer\" target=\"_blank\">Fact-Checking Complex Claims with Program-Guided Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12749\" rel=\"noreferrer\" target=\"_blank\">A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12757\" rel=\"noreferrer\" target=\"_blank\">This Prompt is Measuring &lt;MASK&gt;: Evaluating Bias Evaluation in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12761\" rel=\"noreferrer\" target=\"_blank\">Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12900\" rel=\"noreferrer\" target=\"_blank\">Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12535\" rel=\"noreferrer\" target=\"_blank\">Explaining How Transformers Use Context to Build Predictions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12392\" rel=\"noreferrer\" target=\"_blank\">PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12217\" rel=\"noreferrer\" target=\"_blank\">PromptNER: A Prompting Method for Few-shot Named Entity Recognition via k Nearest Neighbor Search<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12295\" rel=\"noreferrer\" target=\"_blank\">Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11791\" rel=\"noreferrer\" target=\"_blank\">Enhancing Few-shot NER with Prompt Ordering based Data Augmentation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11792\" rel=\"noreferrer\" target=\"_blank\">Chain-of-thought prompting for responding to in-depth dialogue questions with LLM<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11853\" rel=\"noreferrer\" target=\"_blank\">How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11991\" rel=\"noreferrer\" target=\"_blank\">Evaluation of medium-large Language Models at zero-shot closed book generative question answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12077\" rel=\"noreferrer\" target=\"_blank\">Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.12096\" rel=\"noreferrer\" target=\"_blank\">Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11255\" rel=\"noreferrer\" target=\"_blank\">Reasoning Implicit Sentiment with Chain-of-Thought Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11334\" rel=\"noreferrer\" target=\"_blank\">Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11366\" rel=\"noreferrer\" target=\"_blank\">AutoTrial: Prompting Language Models for Clinical Trial Design<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11738\" rel=\"noreferrer\" target=\"_blank\">CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11759\" rel=\"noreferrer\" target=\"_blank\">Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11790\" rel=\"noreferrer\" target=\"_blank\">Prompting with Pseudo-Code Instructions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11171\" rel=\"noreferrer\" target=\"_blank\">TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11159\" rel=\"noreferrer\" target=\"_blank\">Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11140\" rel=\"noreferrer\" target=\"_blank\">Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11038\" rel=\"noreferrer\" target=\"_blank\">Learning In-context Learning for Named Entity Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10907\" rel=\"noreferrer\" target=\"_blank\">Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10866\" rel=\"noreferrer\" target=\"_blank\">TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10847\" rel=\"noreferrer\" target=\"_blank\">Large Language Models can be Guided to Evade AI-Generated Text Detection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10613\" rel=\"noreferrer\" target=\"_blank\">Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.11095\" rel=\"noreferrer\" target=\"_blank\">Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10679\" rel=\"noreferrer\" target=\"_blank\">Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.10142\" rel=\"noreferrer\" target=\"_blank\">Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09770\" rel=\"noreferrer\" target=\"_blank\">ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09645\" rel=\"noreferrer\" target=\"_blank\">StructGPT: A General Framework for Large Language Model to Reason over Structured Data<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09617\" rel=\"noreferrer\" target=\"_blank\">Towards Expert-Level Medical Question Answering with Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09612\" rel=\"noreferrer\" target=\"_blank\">Large Language Models are Built-in Autoregressive Search Engines<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09335\" rel=\"noreferrer\" target=\"_blank\">MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09312\" rel=\"noreferrer\" target=\"_blank\">Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09067\" rel=\"noreferrer\" target=\"_blank\">SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09333\" rel=\"noreferrer\" target=\"_blank\">Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2305.09025\" rel=\"noreferrer\" target=\"_blank\">Soft Prompt Decoding for Multilingual Dense Retrieval<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://ai.google/static/documents/palm2techreport.pdf\" rel=\"noreferrer\" target=\"_blank\">PaLM 2 Technical Report<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (May 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.06556\" rel=\"noreferrer\" target=\"_blank\">Are LLMs All You Need for Task-Oriented Dialogue?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.05973\" rel=\"noreferrer\" target=\"_blank\">HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.05253\" rel=\"noreferrer\" target=\"_blank\">Approximating Human Evaluation of Social Chatbots with Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.04616\" rel=\"noreferrer\" target=\"_blank\">Automated Reading Passage Generation with OpenAI's Large Language Model<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.04358\" rel=\"noreferrer\" target=\"_blank\">WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.04704\" rel=\"noreferrer\" target=\"_blank\">Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.02819\" rel=\"noreferrer\" target=\"_blank\">GPT detectors are biased against non-native English writers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.03153\" rel=\"noreferrer\" target=\"_blank\">Zero-Shot Next-Item Recommendation using Large Pretrained Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.02213\" rel=\"noreferrer\" target=\"_blank\">Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.01295\" rel=\"noreferrer\" target=\"_blank\">Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.01228\" rel=\"noreferrer\" target=\"_blank\">Better Language Models of Code through Self-Improvement<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.01209\" rel=\"noreferrer\" target=\"_blank\">PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\">Assessing Language Model Deployment with Risk Cards</a> (April 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2304.00116\" rel=\"noreferrer\" target=\"_blank\">Enhancing Large Language Models with Climate Resources<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.17564\" rel=\"noreferrer\" target=\"_blank\">BloombergGPT: A Large Language Model for Finance<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.17408\" rel=\"noreferrer\" target=\"_blank\">Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.15846\" rel=\"noreferrer\" target=\"_blank\">Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.16434\" rel=\"noreferrer\" target=\"_blank\">TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.16445\" rel=\"noreferrer\" target=\"_blank\">Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.15587\" rel=\"noreferrer\" target=\"_blank\">Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.14375\" rel=\"noreferrer\" target=\"_blank\">Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.15413\" rel=\"noreferrer\" target=\"_blank\">Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.15441\" rel=\"noreferrer\" target=\"_blank\">Zero-shot Model Diagnosis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.13592\" rel=\"noreferrer\" target=\"_blank\">Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.13035\" rel=\"noreferrer\" target=\"_blank\">SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.11455\" rel=\"noreferrer\" target=\"_blank\">Large Language Models and Simple, Stupid Bugs<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.09325\" rel=\"noreferrer\" target=\"_blank\">Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.08896\" rel=\"noreferrer\" target=\"_blank\">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.07142\" rel=\"noreferrer\" target=\"_blank\">Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.05063\" rel=\"noreferrer\" target=\"_blank\">ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.05398\" rel=\"noreferrer\" target=\"_blank\">MathPrompter: Mathematical Reasoning using Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.05400\" rel=\"noreferrer\" target=\"_blank\">Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.03199\" rel=\"noreferrer\" target=\"_blank\">Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.01903\" rel=\"noreferrer\" target=\"_blank\">Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.00815\" rel=\"noreferrer\" target=\"_blank\">Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2303.00733\" rel=\"noreferrer\" target=\"_blank\">SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (March 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.14233\" rel=\"noreferrer\" target=\"_blank\">Goal Driven Discovery of Distributional Differences via Language Descriptions<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.13439\" rel=\"noreferrer\" target=\"_blank\">Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.14169\" rel=\"noreferrer\" target=\"_blank\">TabGenie: A Toolkit for Table-to-Text Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12449\" rel=\"noreferrer\" target=\"_blank\">SGL-PT: A Strong Graph Learner with Graph Prompt Tuning<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12468\" rel=\"noreferrer\" target=\"_blank\">Few-Shot Table-to-Text Generation with Prompt-based Adapter<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12692\" rel=\"noreferrer\" target=\"_blank\">Language Models Are Few-shot Learners for Prognostic Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12784\" rel=\"noreferrer\" target=\"_blank\">STA: Self-controlled Text Augmentation for Improving Text Classifications<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.12813\" rel=\"noreferrer\" target=\"_blank\">Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.10916\" rel=\"noreferrer\" target=\"_blank\">How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.08961\" rel=\"noreferrer\" target=\"_blank\">Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.08068\" rel=\"noreferrer\" target=\"_blank\">LabelPrompt: Effective Prompt-based Learning for Relation Classification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.09236\" rel=\"noreferrer\" target=\"_blank\">Language Model Crossover: Variation through Few-Shot Prompting<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.08102\" rel=\"noreferrer\" target=\"_blank\">Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.07459\" rel=\"noreferrer\" target=\"_blank\">The Capacity for Moral Self-Correction in Large Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.04156\" rel=\"noreferrer\" target=\"_blank\">Prompting for Multimodal Hateful Meme Classification<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.03269\" rel=\"noreferrer\" target=\"_blank\">PLACES: Prompting Language Models for Social Conversation Synthesis<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.04761\" rel=\"noreferrer\" target=\"_blank\">Toolformer: Language Models Can Teach Themselves to Use Tools<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2302.01441\" rel=\"noreferrer\" target=\"_blank\">Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2301.12810\" rel=\"noreferrer\" target=\"_blank\">Crawling the Internal Knowledge-Base of Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (January 2023)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2212.02199\" rel=\"noreferrer\" target=\"_blank\">Legal Prompt Engineering for Multilingual Legal Judgement Prediction<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (December 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2211.15462\" rel=\"noreferrer\" target=\"_blank\">Investigating Prompt Engineering in Diffusion Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (November 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2209.09513v2\" rel=\"noreferrer\" target=\"_blank\">Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (September 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.15157\" rel=\"noreferrer\" target=\"_blank\">Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2210.14699\" rel=\"noreferrer\" target=\"_blank\">Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (October 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://aclanthology.org/2022.inlg-main.5\" rel=\"noreferrer\" target=\"_blank\">Plot Writing From Scratch Pre-Trained Language Models<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (July 2022)</li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://arxiv.org/abs/2202.03629\" rel=\"noreferrer\" target=\"_blank\">Survey of Hallucination in Natural Language Generation<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a> (February 2022)</li>\n",
      "</ul>\n",
      "<h2 class=\"nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400\">Collections<a aria-label=\"Permalink for this section\" class=\"subheading-anchor\" href=\"#collections\" id=\"collections\"></a></h2>\n",
      "<ul class=\"nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6\">\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://github.com/Timothyxxx/Chain-of-ThoughtsPapers\" rel=\"noreferrer\" target=\"_blank\">Chain-of-Thought Papers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://paperswithcode.com/task/prompt-engineering\" rel=\"noreferrer\" target=\"_blank\">Papers with Code<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "<li class=\"nx-my-2\"><a class=\"nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]\" href=\"https://web.archive.org/web/20231010055104/https://github.com/thunlp/PromptPapers#papers\" rel=\"noreferrer\" target=\"_blank\">Prompt Papers<span class=\"nx-sr-only nx-select-none\"> (opens in a new tab)</span></a></li>\n",
      "</ul><div class=\"nx-mt-16\"></div><div class=\"nx-mb-8 nx-flex nx-items-center nx-border-t nx-pt-8 dark:nx-border-neutral-800 contrast-more:nx-border-neutral-400 dark:contrast-more:nx-border-neutral-400 print:nx-hidden\"><a class=\"nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-pr-4 rtl:nx-pl-4\" href=\"/web/20231010055104/https://www.promptingguide.ai/risks/biases\" title=\"Biases\"><svg class=\"nx-inline nx-h-5 nx-shrink-0 ltr:nx-rotate-180\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg>Biases</a><a class=\"nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-ml-auto ltr:nx-pl-4 ltr:nx-text-right rtl:nx-mr-auto rtl:nx-pr-4 rtl:nx-text-left\" href=\"/web/20231010055104/https://www.promptingguide.ai/tools\" title=\"Tools\">Tools<svg class=\"nx-inline nx-h-5 nx-shrink-0 rtl:nx-rotate-180\" fill=\"none\" stroke=\"currentColor\" viewbox=\"0 0 24 24\"><path d=\"M9 5l7 7-7 7\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg></a></div></main></article></div><footer class=\"nx-bg-gray-100 nx-pb-[env(safe-area-inset-bottom)] dark:nx-bg-neutral-900 print:nx-bg-transparent\"><div class=\"nx-mx-auto nx-flex nx-max-w-[90rem] nx-gap-2 nx-py-2 nx-px-4 nx-hidden\"><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R4n9m:\" title=\"Change language\" type=\"button\"><span class=\"nx-flex nx-items-center nx-gap-2\"><svg fill=\"currentColor\" height=\"12\" viewbox=\"2 2 16 16\" width=\"12\"><path clip-rule=\"evenodd\" d=\"M4.083 9h1.946c.089-1.546.383-2.97.837-4.118A6.004 6.004 0 004.083 9zM10 2a8 8 0 100 16 8 8 0 000-16zm0 2c-.076 0-.232.032-.465.262-.238.234-.497.623-.737 1.182-.389.907-.673 2.142-.766 3.556h3.936c-.093-1.414-.377-2.649-.766-3.556-.24-.56-.5-.948-.737-1.182C10.232 4.032 10.076 4 10 4zm3.971 5c-.089-1.546-.383-2.97-.837-4.118A6.004 6.004 0 0115.917 9h-1.946zm-2.003 2H8.032c.093 1.414.377 2.649.766 3.556.24.56.5.948.737 1.182.233.23.389.262.465.262.076 0 .232-.032.465-.262.238-.234.498-.623.737-1.182.389-.907.673-2.142.766-3.556zm1.166 4.118c.454-1.147.748-2.572.837-4.118h1.946a6.004 6.004 0 01-2.783 4.118zm-6.268 0C6.412 13.97 6.118 12.546 6.03 11H4.083a6.004 6.004 0 002.783 4.118z\" fill-rule=\"evenodd\"></path></svg><span class=\"\">English</span></span></button><button aria-expanded=\"false\" aria-haspopup=\"listbox\" class=\"nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50\" data-headlessui-state=\"\" id=\"headlessui-listbox-button-:R579m:\" title=\"Change theme\" type=\"button\"><div class=\"nx-flex nx-items-center nx-gap-2 nx-capitalize\"><svg fill=\"none\" height=\"12\" stroke=\"currentColor\" viewbox=\"3 3 18 18\" width=\"12\"><path d=\"M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z\" fill=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\"></path></svg><span class=\"\">Light</span></div></button></div><hr class=\"dark:nx-border-neutral-800\"/><div class=\"nx-mx-auto nx-flex nx-max-w-[90rem] nx-justify-center nx-py-12 nx-text-gray-600 dark:nx-text-gray-400 md:nx-justify-start nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]\">Copyright © 2023 DAIR.AI</div></footer></div></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{}},\"page\":\"/papers.en\",\"query\":{},\"buildId\":\"NiXWEo790ouuQU4aHl_Yr\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false,\"locale\":\"en\",\"locales\":[\"en\",\"zh\",\"jp\",\"pt\",\"tr\",\"es\",\"it\",\"fr\",\"kr\",\"ca\",\"fi\",\"ru\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script></body></html><!--\n",
      "     FILE ARCHIVED ON 05:51:04 Oct 10, 2023 AND RETRIEVED FROM THE\n",
      "     INTERNET ARCHIVE ON 06:48:38 Oct 11, 2023.\n",
      "     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.\n",
      "\n",
      "     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.\n",
      "     SECTION 108(a)(3)).\n",
      "-->\n",
      "<!--\n",
      "playback timings (ms):\n",
      "  captures_list: 237.564\n",
      "  exclusion.robots: 0.137\n",
      "  exclusion.robots.policy: 0.127\n",
      "  cdx.remote: 0.056\n",
      "  esindex: 0.011\n",
      "  LoadShardBlock: 197.663 (3)\n",
      "  PetaboxLoader3.datanode: 206.17 (4)\n",
      "  load_resource: 50.824\n",
      "  PetaboxLoader3.resolve: 21.749\n",
      "-->\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape list of \"Approaches\" papers on \"https://www.promptingguide.ai/papers\"\n",
    "# I created an internet archive version of this page on October 10, 2023\n",
    "url = \"https://web.archive.org/web/20231010055104/https%3A%2F%2Fwww.promptingguide.ai%2Fpapers\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Papers | Prompt Engineering Guide Prompt Engineering GuidePrompt Engineering CoursePrompt Engineering CourseServicesServicesAboutAboutGitHubGitHub (opens in a new tab)DiscordDiscord (opens in a new tab)Prompt EngineeringIntroductionLLM SettingsBasics of PromptingPrompt ElementsGeneral Tips for Designing PromptsExamples of PromptsTechniquesZero-shot PromptingFew-shot PromptingChain-of-Thought PromptingSelf-ConsistencyGenerate Knowledge PromptingTree of ThoughtsRetrieval Augmented GenerationAutomatic Reasoning and Tool-useAutomatic Prompt EngineerActive-PromptDirectional Stimulus PromptingReActMultimodal CoTGraph PromptingApplicationsProgram-Aided Language ModelsGenerating DataGenerating Synthetic Dataset for RAGTackling Generated Datasets DiversityGenerating CodeGraduate Job Classification Case StudyPrompt FunctionModelsFlanChatGPTLLaMAGPT-4LLM CollectionRisks & MisusesAdversarial PromptingFactualityBiasesPapersToolsNotebooksDatasetsAdditional ReadingsEnglishLightOn This PageOverviewsApproachesApplicationsCollectionsQuestion? Give us feedback → (opens in a new tab)Edit this pagePapersPapers\n",
      "The following are the latest papers (sorted by release date) on prompt engineering for large language models (LLMs). We update the list of papers on a daily/weekly basis.\n",
      "Overviews\n",
      "\n",
      "Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation (opens in a new tab) (May 2023)\n",
      "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study (opens in a new tab) (May 2023)\n",
      "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond (opens in a new tab) (April 2023)\n",
      "Tool Learning with Foundation Models (opens in a new tab) (April 2023)\n",
      "One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era (opens in a new tab) (April 2023)\n",
      "A Bibliometric Review of Large Language Models Research from 2017 to 2023 (opens in a new tab) (April 2023)\n",
      "A Survey of Large Language Models (opens in a new tab) (April 2023)\n",
      "Nature Language Reasoning, A Survey (opens in a new tab) (March 2023)\n",
      "Augmented Language Models: a Survey (opens in a new tab) (February 2023)\n",
      "A Survey for In-context Learning (opens in a new tab) (December 2022)\n",
      "Towards Reasoning in Large Language Models: A Survey (opens in a new tab) (December 2022)\n",
      "Reasoning with Language Model Prompting: A Survey (opens in a new tab) (December 2022)\n",
      "Emergent Abilities of Large Language Models (opens in a new tab) (June 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing (opens in a new tab) (July 2021)\n",
      "\n",
      "Approaches\n",
      "\n",
      "Chain-of-Verification Reduces Hallucination in Large Language Models (opens in a new tab) (September 2023)\n",
      "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Re-Reading Improves Reasoning in Language Models (opens in a new tab) (September 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (opens in a new tab) (July 2023)\n",
      "Focused Prefix Tuning for Controllable Text Generation (opens in a new tab) (June 2023)\n",
      "Exploring Lottery Prompts for Pre-trained Language Models (opens in a new tab) (May 2023)\n",
      "Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses (opens in a new tab) (May 2023)\n",
      "Let's Verify Step by Step (opens in a new tab) (May 2023)\n",
      "Universality and Limitations of Prompt Tuning (opens in a new tab) (May 2023)\n",
      "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting (opens in a new tab) (May 2023)\n",
      "PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents (opens in a new tab) (May 2023)\n",
      "Reasoning with Language Model is Planning with World Model (opens in a new tab) (May 2023)\n",
      "Self-Critique Prompting with Large Language Models for Inductive Instructions (opens in a new tab) (May 2023)\n",
      "Better Zero-Shot Reasoning with Self-Adaptive Prompting (opens in a new tab) (May 2023)\n",
      "Hierarchical Prompting Assists Large Language Model on Web Navigation (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "Can We Edit Factual Knowledge by In-Context Learning? (opens in a new tab) (May 2023)\n",
      "In-Context Learning of Large Language Models Explained as Kernel Regression (opens in a new tab) (May 2023)\n",
      "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (opens in a new tab) (May 2023)\n",
      "Meta-in-context learning in large language models (opens in a new tab) (May 2023)\n",
      "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs (opens in a new tab) (May 2023)\n",
      "Post Hoc Explanations of Language Models Can Improve Language Models (opens in a new tab) (May 2023)\n",
      "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt (opens in a new tab) (May 2023)\n",
      "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding (opens in a new tab) (May 2023)\n",
      "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (opens in a new tab) (May 2023)\n",
      "Efficient Prompting via Dynamic In-Context Learning (opens in a new tab) (May 2023)\n",
      "The Web Can Be Your Oyster for Improving Large Language Models (opens in a new tab) (May 2023)\n",
      "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (opens in a new tab) (May 2023)\n",
      "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (opens in a new tab) (May 2023)\n",
      "ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs (opens in a new tab) (May 2023)\n",
      "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models (opens in a new tab) (May 2023)\n",
      "CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge (opens in a new tab) (May 2023)\n",
      "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning (opens in a new tab) (May 2023)\n",
      "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (opens in a new tab) (May 2023)\n",
      "Satisfiability-Aided Language Models Using Declarative Prompting (opens in a new tab) (May 2023)\n",
      "Pre-Training to Learn in Context (opens in a new tab) (May 2023)\n",
      "Boosted Prompt Ensembles for Large Language Models (opens in a new tab) (April 2023)\n",
      "Global Prompt Cell: A Portable Control Module for Effective Prompt (opens in a new tab) (April 2023)\n",
      "Why think step-by-step? Reasoning emerges from the locality of experience (opens in a new tab) (April 2023)\n",
      "Revisiting Automated Prompting: Are We Actually Doing Better? (opens in a new tab) (April 2023)\n",
      "REFINER: Reasoning Feedback on Intermediate Representations (opens in a new tab) (April 2023)\n",
      "Reflexion: an autonomous agent with dynamic memory and self-reflection (opens in a new tab) (March 2023)\n",
      "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society (opens in a new tab) (March 2023)\n",
      "Self-Refine: Iterative Refinement with Self-Feedback (opens in a new tab) (March 2023)\n",
      "kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference (opens in a new tab) (March 2023)\n",
      "Visual-Language Prompt Tuning with Knowledge-guided Context Optimization (opens in a new tab) (March 2023)\n",
      "Fairness-guided Few-shot Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Context-faithful Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning (opens in a new tab) (March 2023)\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (opens in a new tab) (March 2023)\n",
      "Model-tuning Via Prompts Makes NLP Models Adversarially Robust (opens in a new tab) (March 2023)\n",
      "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer (opens in a new tab) (March 2023)\n",
      "CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification (opens in a new tab) (March 2023)\n",
      "Larger language models do in-context learning differently (opens in a new tab) (March 2023)\n",
      "OpenICL: An Open-Source Framework for In-context Learning (opens in a new tab) (March 2023)\n",
      "Dynamic Prompting: A Unified Framework for Prompt Tuning (opens in a new tab) (March 2023)\n",
      "ART: Automatic multi-step reasoning and tool-use for large language models (opens in a new tab) (March 2023)\n",
      "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning (opens in a new tab) (March 2023)\n",
      "Effectiveness of Data Augmentation for Prefix Tuning with Limited Data (opens in a new tab) (March 2023)\n",
      "Mixture of Soft Prompts for Controllable Data Generation (opens in a new tab) (March 2023)\n",
      "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners (opens in a new tab) (March 2023)\n",
      "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks (opens in a new tab) (March 2023)\n",
      "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT (opens in a new tab) (February 2023)\n",
      "EvoPrompting: Language Models for Code-Level Neural Architecture Search (opens in a new tab) (February 2023)\n",
      "In-Context Instruction Learning (opens in a new tab) (February 2023)\n",
      "Chain of Hindsight Aligns Language Models with Feedback (opens in a new tab) (February 2023)\n",
      "Language Is Not All You Need: Aligning Perception with Language Models (opens in a new tab) (February 2023)\n",
      "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (opens in a new tab) (February 2023)\n",
      "Active Prompting with Chain-of-Thought for Large Language Models (opens in a new tab) (February 2023)\n",
      "More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models (opens in a new tab) (February 2023)\n",
      "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (opens in a new tab) (February 2023)\n",
      "Guiding Large Language Models via Directional Stimulus Prompting (opens in a new tab) (February 2023)\n",
      "How Does In-Context Learning Help Prompt Tuning? (opens in a new tab) (February 2023)\n",
      "Scalable Prompt Generation for Semi-supervised Learning with Language Models (opens in a new tab) (February 2023)\n",
      "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints (opens in a new tab) (February 2023)\n",
      "À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting (opens in a new tab) (February 2023)\n",
      "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains (opens in a new tab) (February 2023)\n",
      "Evaluating the Robustness of Discrete Prompts (opens in a new tab) (February 2023)\n",
      "Compositional Exemplars for In-context Learning (opens in a new tab) (February 2023)\n",
      "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (opens in a new tab) (February 2023)\n",
      "Multimodal Chain-of-Thought Reasoning in Language Models (opens in a new tab) (February 2023)\n",
      "Large Language Models Can Be Easily Distracted by Irrelevant Context (opens in a new tab) (February 2023)\n",
      "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models (opens in a new tab) (February 2023)\n",
      "Progressive Prompts: Continual Learning for Language Models (opens in a new tab) (January 2023)\n",
      "Batch Prompting: Efficient Inference with LLM APIs (opens in a new tab) (January 2023)\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (opens in a new tab) (December 2022)\n",
      "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning (opens in a new tab) (December 2022)\n",
      "Constitutional AI: Harmlessness from AI Feedback (opens in a new tab) (December 2022)\n",
      "Successive Prompting for Decomposing Complex Questions (opens in a new tab) (December 2022)\n",
      "Large Language Models are reasoners with Self-Verification (opens in a new tab) (December 2022)\n",
      "Discovering Language Model Behaviors with Model-Written Evaluations (opens in a new tab) (December 2022)\n",
      "Structured Prompting: Scaling In-Context Learning to 1,000 Examples (opens in a new tab) (December 2022)\n",
      "PAL: Program-aided Language Models (opens in a new tab) (November 2022)\n",
      "Large Language Models Are Human-Level Prompt Engineers (opens in a new tab) (November 2022)\n",
      "Ignore Previous Prompt: Attack Techniques For Language Models (opens in a new tab) (November 2022)\n",
      "Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods (opens in a new tab) (November 2022)\n",
      "Teaching Algorithmic Reasoning via In-context Learning (opens in a new tab) (November 2022)\n",
      "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference (opens in a new tab) (November 2022)\n",
      "Ask Me Anything: A simple strategy for prompting language models (opens in a new tab) (October 2022)\n",
      "Recitation-Augmented Language Models (opens in a new tab) (October 2022)\n",
      "ReAct: Synergizing Reasoning and Acting in Language Models (opens in a new tab) (October 2022)\n",
      "Prompting GPT-3 To Be Reliable (opens in a new tab) (October 2022)\n",
      "Decomposed Prompting: A Modular Approach for Solving Complex Tasks (opens in a new tab) (October 2022)\n",
      "Automatic Chain of Thought Prompting in Large Language Models (opens in a new tab) (October 2022)\n",
      "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought (opens in a new tab) (October 2022)\n",
      "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples (opens in a new tab) (September 2022)\n",
      "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning (opens in a new tab) (September 2022)\n",
      "Promptagator: Few-shot Dense Retrieval From 8 Examples (opens in a new tab) (September 2022)\n",
      "Atlas: Few-shot Learning with Retrieval Augmented Language Models (opens in a new tab) (November 2022)\n",
      "DocPrompting: Generating Code by Retrieving the Docs (opens in a new tab) (July 2022)\n",
      "On the Advance of Making Language Models Better Reasoners (opens in a new tab) (June 2022)\n",
      "Large Language Models are Zero-Shot Reasoners (opens in a new tab) (May 2022)\n",
      "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations (opens in a new tab) (May 2022)\n",
      "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (opens in a new tab) (May 2022)\n",
      "PPT: Pre-trained Prompt Tuning for Few-shot Learning (opens in a new tab) (Mqy 2022)\n",
      "Toxicity Detection with Generative Prompt-based Inference (opens in a new tab) (May 2022)\n",
      "Learning to Transfer Prompts for Text Generation (opens in a new tab) (May 2022)\n",
      "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (opens in a new tab) (May 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "PromptChainer: Chaining Large Language Model Prompts through Visual Programming (opens in a new tab) (March 2022)\n",
      "Self-Consistency Improves Chain of Thought Reasoning in Language Models (opens in a new tab) (March 2022)\n",
      "Training language models to follow instructions with human feedback (opens in a new tab)\n",
      "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (opens in a new tab) (February 2022)\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models (opens in a new tab) (January 2022)\n",
      "Show Your Work: Scratchpads for Intermediate Computation with Language Models (opens in a new tab) (November 2021)\n",
      "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts (opens in a new tab) (October 2021)\n",
      "Generated Knowledge Prompting for Commonsense Reasoning (opens in a new tab) (October 2021)\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization (opens in a new tab) (October 2021)\n",
      "Reframing Instructional Prompts to GPTk's Language (opens in a new tab) (September 2021)\n",
      "Design Guidelines for Prompt Engineering Text-to-Image Generative Models (opens in a new tab) (September 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (August 2021)\n",
      "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity (opens in a new tab) (April 2021)\n",
      "BERTese: Learning to Speak to BERT (opens in a new tab) (April 2021)\n",
      "The Power of Scale for Parameter-Efficient Prompt Tuning (opens in a new tab) (April 2021)\n",
      "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (opens in a new tab) (February 2021)\n",
      "Calibrate Before Use: Improving Few-Shot Performance of Language Models (opens in a new tab) (February 2021)\n",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation (opens in a new tab) (January 2021)\n",
      "Learning to Generate Task-Specific Adapters from Task Description (opens in a new tab) (January 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (December 2020)\n",
      "Learning from Task Descriptions (opens in a new tab) (November 2020)\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts (opens in a new tab) (October 2020)\n",
      "Language Models are Few-Shot Learners (opens in a new tab) (May 2020)\n",
      "How Can We Know What Language Models Know? (opens in a new tab) (July 2020)\n",
      "Scaling Laws for Neural Language Models (opens in a new tab) (January 2020)\n",
      "\n",
      "Applications\n",
      "\n",
      "Graph Neural Prompting with Large Language Models (opens in a new tab) (September 2023)\n",
      "Large Language Model Alignment: A Survey (opens in a new tab) (September 2023)\n",
      "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic (opens in a new tab) (September 2023)\n",
      "A Practical Survey on Zero-shot Prompt Design for In-context Learning (opens in a new tab) (September 2023)\n",
      "EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning (opens in a new tab) (September 2023)\n",
      "Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning (opens in a new tab) (September 2023)\n",
      "PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models (opens in a new tab) (September 2023)\n",
      "LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models (opens in a new tab) (September 2023)\n",
      "Summarization is (Almost) Dead (opens in a new tab) (September 2023)\n",
      "Investigating Zero- and Few-shot Generalization in Fact Verification (opens in a new tab) (September 2023)\n",
      "Performance of the Pre-Trained Large Language Model GPT-4 on Automated Short Answer Grading (opens in a new tab) (September 2023)\n",
      "Contrastive Decoding Improves Reasoning in Large Language Models (opens in a new tab) (September 2023)\n",
      "Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data? (opens in a new tab) (September 2023)\n",
      "Neural Machine Translation Models Can Learn to be Few-shot Learners (opens in a new tab) (September 2023)\n",
      "Chain-of-Thought Reasoning is a Policy Improvement Operator (opens in a new tab) (September 2023)\n",
      "ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer (opens in a new tab) (September 2023)\n",
      "When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets (opens in a new tab) (September 2023)\n",
      "Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata (opens in a new tab) (September 2023)\n",
      "Self-Consistent Narrative Prompts on Abductive Natural Language Inference (opens in a new tab) (September 2023)\n",
      "Investigating Answerability of LLMs for Long-Form Question Answering (opens in a new tab) (September 2023)\n",
      "PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions (opens in a new tab) (September 2023)\n",
      "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing (opens in a new tab) (September 2023)\n",
      "Leveraging Contextual Information for Effective Entity Salience Detection (opens in a new tab) (September 2023)\n",
      "Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts (opens in a new tab) (September 2023)\n",
      "PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models (opens in a new tab) (September 2023)\n",
      "Zero-Resource Hallucination Prevention for Large Language Models (opens in a new tab) (September 2023)\n",
      "Certifying LLM Safety against Adversarial Prompting (opens in a new tab) (September 2023)\n",
      "Improving Code Generation by Dynamic Temperature Sampling (opens in a new tab) (September 2023)\n",
      "Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages (opens in a new tab) (August 2023)\n",
      "Financial News Analytics Using Fine-Tuned Llama 2 GPT Model (opens in a new tab) (August 2023)\n",
      "A Study on Robustness and Reliability of Large Language Model Code Generation (opens in a new tab) (August 2023)\n",
      "Large Language Models Vote: Prompting for Rare Disease Identification (opens in a new tab) (August 2023)\n",
      "WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct (opens in a new tab) (August 2023)\n",
      "Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning (opens in a new tab) (August 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment (opens in a new tab) (August 2023)\n",
      "Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought (opens in a new tab) (August 2023)\n",
      "You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content (opens in a new tab) (August 2023)\n",
      "LLM As DBA (opens in a new tab) (August 2023)\n",
      "Interpretable Math Word Problem Solution Generation Via Step-by-step Planning (opens in a new tab) (June 2023)\n",
      "In-Context Learning User Simulators for Task-Oriented Dialog Systems (opens in a new tab) (June 2023)\n",
      "SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL (opens in a new tab) (June 2023)\n",
      "Effective Structured Prompting by Meta-Learning and Representative Verbalizer (opens in a new tab) (June 2023)\n",
      "Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering (opens in a new tab) (June 2023)\n",
      "Chain-Of-Thought Prompting Under Streaming Batch: A Case Study (opens in a new tab) (June 2023)\n",
      "Red Teaming Language Model Detectors with Language Models (opens in a new tab) (May 2023)\n",
      "Gorilla: Large Language Model Connected with Massive APIs (opens in a new tab) (May 2023)\n",
      "Deliberate then Generate: Enhanced Prompting Framework for Text Generation (opens in a new tab) (May 2023)\n",
      "What does the Failure to Reason with \"Respectively\" in Zero/Few-Shot Settings Tell Us about Language Models? (opens in a new tab) (May 2023)\n",
      "ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning (opens in a new tab) (May 2023)\n",
      "SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models (opens in a new tab) (May 2023)\n",
      "Grammar Prompting for Domain-Specific Language Generation with Large Language Models (opens in a new tab) (May 2023)\n",
      "Mitigating Label Biases for In-context Learning (opens in a new tab) (May 2023)\n",
      "Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model (opens in a new tab) (May 2023)\n",
      "Strategic Reasoning with Language Models (opens in a new tab) (May 2023)\n",
      "Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs (opens in a new tab) (May 2023)\n",
      "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models (opens in a new tab) (May 2023)\n",
      "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning (opens in a new tab) (May 2023)\n",
      "Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods (opens in a new tab) (May 2023)\n",
      "NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models (opens in a new tab) (May 2023)\n",
      "Tab-CoT: Zero-shot Tabular Chain of Thought (opens in a new tab) (May 2023)\n",
      "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation (opens in a new tab) (May 2023)\n",
      "Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks (opens in a new tab) (May 2023)\n",
      "[Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning]https://arxiv.org/abs/2305.17373 (opens in a new tab)) (May 2023)\n",
      "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance (opens in a new tab) (May 2023)\n",
      "Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning (opens in a new tab) (May 2023)\n",
      "Heterogeneous Value Evaluation for Large Language Models (opens in a new tab) (May 2023)\n",
      "PromptNER: Prompt Locating and Typing for Named Entity Recognition (opens in a new tab) (May 2023)\n",
      "Small Language Models Improve Giants by Rewriting Their Outputs (opens in a new tab) (May 2023)\n",
      "On the Planning Abilities of Large Language Models -- A Critical Investigation (opens in a new tab) (May 2023)\n",
      "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models (opens in a new tab) (May 2023)\n",
      "PRODIGY: Enabling In-context Learning Over Graphs (opens in a new tab) (May 2023)\n",
      "Large Language Models are Few-Shot Health Learners (opens in a new tab) (May 2023)\n",
      "Role-Play with Large Language Models (opens in a new tab) (May 2023)\n",
      "Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations (opens in a new tab) (May 2023)\n",
      "Fact-Checking Complex Claims with Program-Guided Reasoning (opens in a new tab) (May 2023)\n",
      "Large Language Models as Tool Makers (opens in a new tab) (May 2023)\n",
      "Iterative Forward Tuning Boosts In-context Learning in Language Models (opens in a new tab) (May 2023)\n",
      "SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "An automatically discovered chain-of-thought prompt generalizes to novel models and datasets (opens in a new tab) (May 2023)\n",
      "Large Language Model Guided Tree-of-Thought (opens in a new tab) (May 2023)\n",
      "Active Retrieval Augmented Generation (opens in a new tab) (May 2023)\n",
      "A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models (opens in a new tab) (May 2023)\n",
      "Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings (opens in a new tab) (May 2023)\n",
      "Mirages: On Anthropomorphism in Dialogue Systems (opens in a new tab) (May 2023)\n",
      "Model evaluation for extreme risks (opens in a new tab) (May 2023)\n",
      "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting (opens in a new tab) (May 2023)\n",
      "Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction (opens in a new tab) (May 2023)\n",
      "PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training (opens in a new tab) (May 2023)\n",
      "Augmented Large Language Models with Parametric Knowledge Guiding (opens in a new tab) (May 2023)\n",
      "Aligning Large Language Models through Synthetic Feedback (opens in a new tab) (May 2023)\n",
      "Concept-aware Training Improves In-context Learning Ability of Language Models (opens in a new tab) (May 2023)\n",
      "FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance (opens in a new tab) (May 2023)\n",
      "Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation (opens in a new tab) (May 2023)\n",
      "Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing (opens in a new tab) (May 2023)\n",
      "\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures (opens in a new tab) (May 2023)\n",
      "Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction (opens in a new tab) (May 2023)\n",
      "Generating Data for Symbolic Language with Large Language Models (opens in a new tab) (May 2023)\n",
      "Make a Choice! Knowledge Base Question Answering with In-Context Learning (opens in a new tab) (May 2023)\n",
      "Improving Language Models via Plug-and-Play Retrieval Feedback (opens in a new tab) (May 2023)\n",
      "Multi-Granularity Prompts for Topic Shift Detection in Dialogue (opens in a new tab) (May 2023)\n",
      "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning (opens in a new tab) (May 2023)\n",
      "Can Language Models Understand Physical Concepts? (opens in a new tab) (May 2023)\n",
      "Evaluating Factual Consistency of Summaries with Large Language Models (opens in a new tab) (May 2023)\n",
      "Dr.ICL: Demonstration-Retrieved In-context Learning (opens in a new tab) (May 2023)\n",
      "Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models (opens in a new tab) (May 2023)\n",
      "Skill-Based Few-Shot Selection for In-Context Learning (opens in a new tab) (May 2023)\n",
      "Exploring Chain-of-Thought Style Prompting for Text-to-SQL (opens in a new tab) (May 2023)\n",
      "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations (opens in a new tab) (May 2023)\n",
      "On Learning to Summarize with Large Language Models as References (opens in a new tab) (May 2023)\n",
      "Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery (opens in a new tab) (May 2023)\n",
      "Active Learning Principles for In-Context Learning with Large Language Models (opens in a new tab) (May 2023)\n",
      "Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs (opens in a new tab) (May 2023)\n",
      "Improving Factuality and Reasoning in Language Models through Multiagent Debate (opens in a new tab) (May 2023)\n",
      "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on\\ Chat-based Large Language Models (opens in a new tab) (May 2023)\n",
      "WikiChat: A Few-Shot LLM-Based Chatbot Grounded with Wikipedia (opens in a new tab) (May 2023)\n",
      "Query Rewriting for Retrieval-Augmented Large Language Models (opens in a new tab) (May 2023)\n",
      "Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker (opens in a new tab) (May 2023)\n",
      "Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method (opens in a new tab) (May 2023)\n",
      "Small Language Models Improve Giants by Rewriting Their Outputs (opens in a new tab) (May 2023)\n",
      "Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration (opens in a new tab) (May 2023)\n",
      "Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning (opens in a new tab) (May 2023)\n",
      "Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment (opens in a new tab) (May 2023)\n",
      "Making Language Models Better Tool Learners with Execution Feedback (opens in a new tab) (May 2023)\n",
      "Text-to-SQL Error Correction with Language Models of Code (opens in a new tab) (May 2023)\n",
      "Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models (opens in a new tab) (May 2023)\n",
      "SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations (opens in a new tab) (May 2023)\n",
      "\"According to ...\" Prompting Language Models Improves Quoting from Pre-Training Data (opens in a new tab) (May 2023)\n",
      "Prompt-based methods may underestimate large language models' linguistic generalizations (opens in a new tab) (May 2023)\n",
      "Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases (opens in a new tab) (May 2023)\n",
      "Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations (opens in a new tab) (May 2023)\n",
      "Automated Few-shot Classification with Instruction-Finetuned Language Models (opens in a new tab) (May 2023)\n",
      "Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies (opens in a new tab) (May 2023)\n",
      "MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction (opens in a new tab) (May 2023)\n",
      "Learning Interpretable Style Embeddings via Prompting LLMs (opens in a new tab) (May 2023)\n",
      "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting (opens in a new tab) (May 2023)\n",
      "Fact-Checking Complex Claims with Program-Guided Reasoning (opens in a new tab) (May 2023)\n",
      "A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches (opens in a new tab) (May 2023)\n",
      "This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language Models (opens in a new tab) (May 2023)\n",
      "Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer (opens in a new tab) (May 2023)\n",
      "Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph (opens in a new tab) (May 2023)\n",
      "Explaining How Transformers Use Context to Build Predictions (opens in a new tab) (May 2023)\n",
      "PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs (opens in a new tab) (May 2023)\n",
      "PromptNER: A Prompting Method for Few-shot Named Entity Recognition via k Nearest Neighbor Search (opens in a new tab) (May 2023)\n",
      "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning (opens in a new tab) (May 2023)\n",
      "Enhancing Few-shot NER with Prompt Ordering based Data Augmentation (opens in a new tab) (May 2023)\n",
      "Chain-of-thought prompting for responding to in-depth dialogue questions with LLM (opens in a new tab) (May 2023)\n",
      "How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings (opens in a new tab) (May 2023)\n",
      "Evaluation of medium-large Language Models at zero-shot closed book generative question answering (opens in a new tab) (May 2023)\n",
      "Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer (opens in a new tab) (May 2023)\n",
      "Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions? (opens in a new tab) (May 2023)\n",
      "Reasoning Implicit Sentiment with Chain-of-Thought Prompting (opens in a new tab) (May 2023)\n",
      "Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs (opens in a new tab) (May 2023)\n",
      "AutoTrial: Prompting Language Models for Clinical Trial Design (opens in a new tab) (May 2023)\n",
      "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing (opens in a new tab) (May 2023)\n",
      "Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning (opens in a new tab) (May 2023)\n",
      "Prompting with Pseudo-Code Instructions (opens in a new tab) (May 2023)\n",
      "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models (opens in a new tab) (May 2023)\n",
      "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors (opens in a new tab) (May 2023)\n",
      "Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model (opens in a new tab) (May 2023)\n",
      "Learning In-context Learning for Named Entity Recognition (opens in a new tab) (May 2023)\n",
      "Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation (opens in a new tab) (May 2023)\n",
      "TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition (opens in a new tab) (May 2023)\n",
      "Large Language Models can be Guided to Evade AI-Generated Text Detection (opens in a new tab) (May 2023)\n",
      "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning (opens in a new tab) (May 2023)\n",
      "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization (opens in a new tab) (May 2023)\n",
      "Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation (opens in a new tab) (May 2023)\n",
      "Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback (opens in a new tab) (May 2023)\n",
      "ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing (opens in a new tab) (May 2023)\n",
      "StructGPT: A General Framework for Large Language Model to Reason over Structured Data (opens in a new tab) (May 2023)\n",
      "Towards Expert-Level Medical Question Answering with Large Language Models (opens in a new tab) (May 2023)\n",
      "Large Language Models are Built-in Autoregressive Search Engines (opens in a new tab) (May 2023)\n",
      "MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection (opens in a new tab) (May 2023)\n",
      "Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation (opens in a new tab) (May 2023)\n",
      "SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting (opens in a new tab) (May 2023)\n",
      "Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image (opens in a new tab) (May 2023)\n",
      "Soft Prompt Decoding for Multilingual Dense Retrieval (opens in a new tab) (May 2023)\n",
      "PaLM 2 Technical Report (opens in a new tab) (May 2023)\n",
      "Are LLMs All You Need for Task-Oriented Dialogue? (opens in a new tab) (April 2023)\n",
      "HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting (opens in a new tab) (April 2023)\n",
      "Approximating Human Evaluation of Social Chatbots with Prompting (opens in a new tab) (April 2023)\n",
      "Automated Reading Passage Generation with OpenAI's Large Language Model (opens in a new tab) (April 2023)\n",
      "WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus (opens in a new tab) (April 2023)\n",
      "Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition (opens in a new tab) (April 2023)\n",
      "GPT detectors are biased against non-native English writers (opens in a new tab) (April 2023)\n",
      "Zero-Shot Next-Item Recommendation using Large Pretrained Language Models (opens in a new tab) (April 2023)\n",
      "Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT (opens in a new tab) (April 2023)\n",
      "Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning (opens in a new tab) (April 2023)\n",
      "Better Language Models of Code through Self-Improvement (opens in a new tab) (April 2023)\n",
      "PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction (opens in a new tab) (April 2023)\n",
      "Assessing Language Model Deployment with Risk Cards (April 2023)\n",
      "Enhancing Large Language Models with Climate Resources (opens in a new tab) (March 2023)\n",
      "BloombergGPT: A Large Language Model for Finance (opens in a new tab) (March 2023)\n",
      "Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts (opens in a new tab) (March 2023)\n",
      "Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes (opens in a new tab) (March 2023)\n",
      "TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs (opens in a new tab) (March 2023)\n",
      "Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning (opens in a new tab) (March 2023)\n",
      "Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses (opens in a new tab) (March 2023)\n",
      "Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning (opens in a new tab) (March 2023)\n",
      "Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation (opens in a new tab) (March 2023)\n",
      "Zero-shot Model Diagnosis (opens in a new tab) (March 2023)\n",
      "Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages (opens in a new tab) (March 2023)\n",
      "SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization (opens in a new tab) (March 2023)\n",
      "Large Language Models and Simple, Stupid Bugs (opens in a new tab) (March 2023)\n",
      "Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses? (opens in a new tab) (March 2023)\n",
      "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models (opens in a new tab) (March 2023)\n",
      "Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification (opens in a new tab) (March 2023)\n",
      "ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction (opens in a new tab) (March 2023)\n",
      "MathPrompter: Mathematical Reasoning using Large Language Models (opens in a new tab) (March 2023)\n",
      "Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums (opens in a new tab) (March 2023)\n",
      "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting (opens in a new tab) (March 2023)\n",
      "Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering (opens in a new tab) (March 2023)\n",
      "Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis (opens in a new tab) (March 2023)\n",
      "SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks (opens in a new tab) (March 2023)\n",
      "Goal Driven Discovery of Distributional Differences via Language Descriptions (opens in a new tab) (February 2023)\n",
      "Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models (opens in a new tab) (February 2023)\n",
      "TabGenie: A Toolkit for Table-to-Text Generation (opens in a new tab) (February 2023)\n",
      "SGL-PT: A Strong Graph Learner with Graph Prompt Tuning (opens in a new tab) (February 2023)\n",
      "Few-Shot Table-to-Text Generation with Prompt-based Adapter (opens in a new tab) (February 2023)\n",
      "Language Models Are Few-shot Learners for Prognostic Prediction (opens in a new tab) (February 2023)\n",
      "STA: Self-controlled Text Augmentation for Improving Text Classifications (opens in a new tab) (February 2023)\n",
      "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback (opens in a new tab) (February 2023)\n",
      "How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study (opens in a new tab) (February 2023)\n",
      "Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales (opens in a new tab) (February 2023)\n",
      "LabelPrompt: Effective Prompt-based Learning for Relation Classification (opens in a new tab) (February 2023)\n",
      "Language Model Crossover: Variation through Few-Shot Prompting (opens in a new tab) (February 2023)\n",
      "Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "Prompting for Multimodal Hateful Meme Classification (opens in a new tab) (February 2023)\n",
      "PLACES: Prompting Language Models for Social Conversation Synthesis (opens in a new tab) (February 2023)\n",
      "Toolformer: Language Models Can Teach Themselves to Use Tools (opens in a new tab) (February 2023)\n",
      "Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation (opens in a new tab) (February 2023)\n",
      "Crawling the Internal Knowledge-Base of Language Models (opens in a new tab) (January 2023)\n",
      "Legal Prompt Engineering for Multilingual Legal Judgement Prediction (opens in a new tab) (December 2022)\n",
      "Investigating Prompt Engineering in Diffusion Models (opens in a new tab) (November 2022)\n",
      "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering (opens in a new tab) (September 2022)\n",
      "Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language (opens in a new tab) (October 2022)\n",
      "Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic? (opens in a new tab) (October 2022)\n",
      "Plot Writing From Scratch Pre-Trained Language Models (opens in a new tab) (July 2022)\n",
      "Survey of Hallucination in Natural Language Generation (opens in a new tab) (February 2022)\n",
      "\n",
      "Collections\n",
      "\n",
      "Chain-of-Thought Papers (opens in a new tab)\n",
      "Papers with Code (opens in a new tab)\n",
      "Prompt Papers (opens in a new tab)\n",
      "BiasesToolsEnglishLightCopyright © 2023 DAIR.AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strip html tags\n",
    "no_tags = soup.get_text()\n",
    "print(no_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Chain-of-Verification Reduces Hallucination in Large Language Models (opens in a new tab) (September 2023)\n",
      "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Re-Reading Improves Reasoning in Language Models (opens in a new tab) (September 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (opens in a new tab) (July 2023)\n",
      "Focused Prefix Tuning for Controllable Text Generation (opens in a new tab) (June 2023)\n",
      "Exploring Lottery Prompts for Pre-trained Language Models (opens in a new tab) (May 2023)\n",
      "Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses (opens in a new tab) (May 2023)\n",
      "Let's Verify Step by Step (opens in a new tab) (May 2023)\n",
      "Universality and Limitations of Prompt Tuning (opens in a new tab) (May 2023)\n",
      "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting (opens in a new tab) (May 2023)\n",
      "PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents (opens in a new tab) (May 2023)\n",
      "Reasoning with Language Model is Planning with World Model (opens in a new tab) (May 2023)\n",
      "Self-Critique Prompting with Large Language Models for Inductive Instructions (opens in a new tab) (May 2023)\n",
      "Better Zero-Shot Reasoning with Self-Adaptive Prompting (opens in a new tab) (May 2023)\n",
      "Hierarchical Prompting Assists Large Language Model on Web Navigation (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "Can We Edit Factual Knowledge by In-Context Learning? (opens in a new tab) (May 2023)\n",
      "In-Context Learning of Large Language Models Explained as Kernel Regression (opens in a new tab) (May 2023)\n",
      "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (opens in a new tab) (May 2023)\n",
      "Meta-in-context learning in large language models (opens in a new tab) (May 2023)\n",
      "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs (opens in a new tab) (May 2023)\n",
      "Post Hoc Explanations of Language Models Can Improve Language Models (opens in a new tab) (May 2023)\n",
      "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt (opens in a new tab) (May 2023)\n",
      "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding (opens in a new tab) (May 2023)\n",
      "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (opens in a new tab) (May 2023)\n",
      "Efficient Prompting via Dynamic In-Context Learning (opens in a new tab) (May 2023)\n",
      "The Web Can Be Your Oyster for Improving Large Language Models (opens in a new tab) (May 2023)\n",
      "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (opens in a new tab) (May 2023)\n",
      "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (opens in a new tab) (May 2023)\n",
      "ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs (opens in a new tab) (May 2023)\n",
      "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models (opens in a new tab) (May 2023)\n",
      "CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge (opens in a new tab) (May 2023)\n",
      "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning (opens in a new tab) (May 2023)\n",
      "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (opens in a new tab) (May 2023)\n",
      "Satisfiability-Aided Language Models Using Declarative Prompting (opens in a new tab) (May 2023)\n",
      "Pre-Training to Learn in Context (opens in a new tab) (May 2023)\n",
      "Boosted Prompt Ensembles for Large Language Models (opens in a new tab) (April 2023)\n",
      "Global Prompt Cell: A Portable Control Module for Effective Prompt (opens in a new tab) (April 2023)\n",
      "Why think step-by-step? Reasoning emerges from the locality of experience (opens in a new tab) (April 2023)\n",
      "Revisiting Automated Prompting: Are We Actually Doing Better? (opens in a new tab) (April 2023)\n",
      "REFINER: Reasoning Feedback on Intermediate Representations (opens in a new tab) (April 2023)\n",
      "Reflexion: an autonomous agent with dynamic memory and self-reflection (opens in a new tab) (March 2023)\n",
      "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society (opens in a new tab) (March 2023)\n",
      "Self-Refine: Iterative Refinement with Self-Feedback (opens in a new tab) (March 2023)\n",
      "kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference (opens in a new tab) (March 2023)\n",
      "Visual-Language Prompt Tuning with Knowledge-guided Context Optimization (opens in a new tab) (March 2023)\n",
      "Fairness-guided Few-shot Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Context-faithful Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning (opens in a new tab) (March 2023)\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (opens in a new tab) (March 2023)\n",
      "Model-tuning Via Prompts Makes NLP Models Adversarially Robust (opens in a new tab) (March 2023)\n",
      "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer (opens in a new tab) (March 2023)\n",
      "CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification (opens in a new tab) (March 2023)\n",
      "Larger language models do in-context learning differently (opens in a new tab) (March 2023)\n",
      "OpenICL: An Open-Source Framework for In-context Learning (opens in a new tab) (March 2023)\n",
      "Dynamic Prompting: A Unified Framework for Prompt Tuning (opens in a new tab) (March 2023)\n",
      "ART: Automatic multi-step reasoning and tool-use for large language models (opens in a new tab) (March 2023)\n",
      "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning (opens in a new tab) (March 2023)\n",
      "Effectiveness of Data Augmentation for Prefix Tuning with Limited Data (opens in a new tab) (March 2023)\n",
      "Mixture of Soft Prompts for Controllable Data Generation (opens in a new tab) (March 2023)\n",
      "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners (opens in a new tab) (March 2023)\n",
      "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks (opens in a new tab) (March 2023)\n",
      "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT (opens in a new tab) (February 2023)\n",
      "EvoPrompting: Language Models for Code-Level Neural Architecture Search (opens in a new tab) (February 2023)\n",
      "In-Context Instruction Learning (opens in a new tab) (February 2023)\n",
      "Chain of Hindsight Aligns Language Models with Feedback (opens in a new tab) (February 2023)\n",
      "Language Is Not All You Need: Aligning Perception with Language Models (opens in a new tab) (February 2023)\n",
      "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (opens in a new tab) (February 2023)\n",
      "Active Prompting with Chain-of-Thought for Large Language Models (opens in a new tab) (February 2023)\n",
      "More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models (opens in a new tab) (February 2023)\n",
      "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (opens in a new tab) (February 2023)\n",
      "Guiding Large Language Models via Directional Stimulus Prompting (opens in a new tab) (February 2023)\n",
      "How Does In-Context Learning Help Prompt Tuning? (opens in a new tab) (February 2023)\n",
      "Scalable Prompt Generation for Semi-supervised Learning with Language Models (opens in a new tab) (February 2023)\n",
      "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints (opens in a new tab) (February 2023)\n",
      "À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting (opens in a new tab) (February 2023)\n",
      "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains (opens in a new tab) (February 2023)\n",
      "Evaluating the Robustness of Discrete Prompts (opens in a new tab) (February 2023)\n",
      "Compositional Exemplars for In-context Learning (opens in a new tab) (February 2023)\n",
      "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (opens in a new tab) (February 2023)\n",
      "Multimodal Chain-of-Thought Reasoning in Language Models (opens in a new tab) (February 2023)\n",
      "Large Language Models Can Be Easily Distracted by Irrelevant Context (opens in a new tab) (February 2023)\n",
      "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models (opens in a new tab) (February 2023)\n",
      "Progressive Prompts: Continual Learning for Language Models (opens in a new tab) (January 2023)\n",
      "Batch Prompting: Efficient Inference with LLM APIs (opens in a new tab) (January 2023)\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (opens in a new tab) (December 2022)\n",
      "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning (opens in a new tab) (December 2022)\n",
      "Constitutional AI: Harmlessness from AI Feedback (opens in a new tab) (December 2022)\n",
      "Successive Prompting for Decomposing Complex Questions (opens in a new tab) (December 2022)\n",
      "Large Language Models are reasoners with Self-Verification (opens in a new tab) (December 2022)\n",
      "Discovering Language Model Behaviors with Model-Written Evaluations (opens in a new tab) (December 2022)\n",
      "Structured Prompting: Scaling In-Context Learning to 1,000 Examples (opens in a new tab) (December 2022)\n",
      "PAL: Program-aided Language Models (opens in a new tab) (November 2022)\n",
      "Large Language Models Are Human-Level Prompt Engineers (opens in a new tab) (November 2022)\n",
      "Ignore Previous Prompt: Attack Techniques For Language Models (opens in a new tab) (November 2022)\n",
      "Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods (opens in a new tab) (November 2022)\n",
      "Teaching Algorithmic Reasoning via In-context Learning (opens in a new tab) (November 2022)\n",
      "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference (opens in a new tab) (November 2022)\n",
      "Ask Me Anything: A simple strategy for prompting language models (opens in a new tab) (October 2022)\n",
      "Recitation-Augmented Language Models (opens in a new tab) (October 2022)\n",
      "ReAct: Synergizing Reasoning and Acting in Language Models (opens in a new tab) (October 2022)\n",
      "Prompting GPT-3 To Be Reliable (opens in a new tab) (October 2022)\n",
      "Decomposed Prompting: A Modular Approach for Solving Complex Tasks (opens in a new tab) (October 2022)\n",
      "Automatic Chain of Thought Prompting in Large Language Models (opens in a new tab) (October 2022)\n",
      "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought (opens in a new tab) (October 2022)\n",
      "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples (opens in a new tab) (September 2022)\n",
      "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning (opens in a new tab) (September 2022)\n",
      "Promptagator: Few-shot Dense Retrieval From 8 Examples (opens in a new tab) (September 2022)\n",
      "Atlas: Few-shot Learning with Retrieval Augmented Language Models (opens in a new tab) (November 2022)\n",
      "DocPrompting: Generating Code by Retrieving the Docs (opens in a new tab) (July 2022)\n",
      "On the Advance of Making Language Models Better Reasoners (opens in a new tab) (June 2022)\n",
      "Large Language Models are Zero-Shot Reasoners (opens in a new tab) (May 2022)\n",
      "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations (opens in a new tab) (May 2022)\n",
      "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (opens in a new tab) (May 2022)\n",
      "PPT: Pre-trained Prompt Tuning for Few-shot Learning (opens in a new tab) (Mqy 2022)\n",
      "Toxicity Detection with Generative Prompt-based Inference (opens in a new tab) (May 2022)\n",
      "Learning to Transfer Prompts for Text Generation (opens in a new tab) (May 2022)\n",
      "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (opens in a new tab) (May 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "PromptChainer: Chaining Large Language Model Prompts through Visual Programming (opens in a new tab) (March 2022)\n",
      "Self-Consistency Improves Chain of Thought Reasoning in Language Models (opens in a new tab) (March 2022)\n",
      "Training language models to follow instructions with human feedback (opens in a new tab)\n",
      "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (opens in a new tab) (February 2022)\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models (opens in a new tab) (January 2022)\n",
      "Show Your Work: Scratchpads for Intermediate Computation with Language Models (opens in a new tab) (November 2021)\n",
      "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts (opens in a new tab) (October 2021)\n",
      "Generated Knowledge Prompting for Commonsense Reasoning (opens in a new tab) (October 2021)\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization (opens in a new tab) (October 2021)\n",
      "Reframing Instructional Prompts to GPTk's Language (opens in a new tab) (September 2021)\n",
      "Design Guidelines for Prompt Engineering Text-to-Image Generative Models (opens in a new tab) (September 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (August 2021)\n",
      "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity (opens in a new tab) (April 2021)\n",
      "BERTese: Learning to Speak to BERT (opens in a new tab) (April 2021)\n",
      "The Power of Scale for Parameter-Efficient Prompt Tuning (opens in a new tab) (April 2021)\n",
      "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (opens in a new tab) (February 2021)\n",
      "Calibrate Before Use: Improving Few-Shot Performance of Language Models (opens in a new tab) (February 2021)\n",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation (opens in a new tab) (January 2021)\n",
      "Learning to Generate Task-Specific Adapters from Task Description (opens in a new tab) (January 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (December 2020)\n",
      "Learning from Task Descriptions (opens in a new tab) (November 2020)\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts (opens in a new tab) (October 2020)\n",
      "Language Models are Few-Shot Learners (opens in a new tab) (May 2020)\n",
      "How Can We Know What Language Models Know? (opens in a new tab) (July 2020)\n",
      "Scaling Laws for Neural Language Models (opens in a new tab) (January 2020)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get approaches by taking text after the line \"Approaches\" and before the line \"Applications\"\n",
    "\n",
    "approaches = no_tags.split(\"\\nApproaches\")[1].split(\"\\nApplications\")[0]\n",
    "print(approaches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chain-of-Verification Reduces Hallucination in Large Language Models (opens in a new tab) (September 2023)\n",
      "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (opens in a new tab) (September 2023)\n",
      "From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (opens in a new tab) (September 2023)\n",
      "Re-Reading Improves Reasoning in Language Models (opens in a new tab) (September 2023)\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (opens in a new tab) (August 2023)\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (opens in a new tab) (July 2023)\n",
      "Focused Prefix Tuning for Controllable Text Generation (opens in a new tab) (June 2023)\n",
      "Exploring Lottery Prompts for Pre-trained Language Models (opens in a new tab) (May 2023)\n",
      "Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses (opens in a new tab) (May 2023)\n",
      "Let's Verify Step by Step (opens in a new tab) (May 2023)\n",
      "Universality and Limitations of Prompt Tuning (opens in a new tab) (May 2023)\n",
      "MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting (opens in a new tab) (May 2023)\n",
      "PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents (opens in a new tab) (May 2023)\n",
      "Reasoning with Language Model is Planning with World Model (opens in a new tab) (May 2023)\n",
      "Self-Critique Prompting with Large Language Models for Inductive Instructions (opens in a new tab) (May 2023)\n",
      "Better Zero-Shot Reasoning with Self-Adaptive Prompting (opens in a new tab) (May 2023)\n",
      "Hierarchical Prompting Assists Large Language Model on Web Navigation (opens in a new tab) (May 2023)\n",
      "Interactive Natural Language Processing (opens in a new tab) (May 2023)\n",
      "Can We Edit Factual Knowledge by In-Context Learning? (opens in a new tab) (May 2023)\n",
      "In-Context Learning of Large Language Models Explained as Kernel Regression (opens in a new tab) (May 2023)\n",
      "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (opens in a new tab) (May 2023)\n",
      "Meta-in-context learning in large language models (opens in a new tab) (May 2023)\n",
      "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs (opens in a new tab) (May 2023)\n",
      "Post Hoc Explanations of Language Models Can Improve Language Models (opens in a new tab) (May 2023)\n",
      "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt (opens in a new tab) (May 2023)\n",
      "TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding (opens in a new tab) (May 2023)\n",
      "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (opens in a new tab) (May 2023)\n",
      "Efficient Prompting via Dynamic In-Context Learning (opens in a new tab) (May 2023)\n",
      "The Web Can Be Your Oyster for Improving Large Language Models (opens in a new tab) (May 2023)\n",
      "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (opens in a new tab) (May 2023)\n",
      "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (opens in a new tab) (May 2023)\n",
      "ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs (opens in a new tab) (May 2023)\n",
      "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models (opens in a new tab) (May 2023)\n",
      "CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge (opens in a new tab) (May 2023)\n",
      "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning (opens in a new tab) (May 2023)\n",
      "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (opens in a new tab) (May 2023)\n",
      "Satisfiability-Aided Language Models Using Declarative Prompting (opens in a new tab) (May 2023)\n",
      "Pre-Training to Learn in Context (opens in a new tab) (May 2023)\n",
      "Boosted Prompt Ensembles for Large Language Models (opens in a new tab) (April 2023)\n",
      "Global Prompt Cell: A Portable Control Module for Effective Prompt (opens in a new tab) (April 2023)\n",
      "Why think step-by-step? Reasoning emerges from the locality of experience (opens in a new tab) (April 2023)\n",
      "Revisiting Automated Prompting: Are We Actually Doing Better? (opens in a new tab) (April 2023)\n",
      "REFINER: Reasoning Feedback on Intermediate Representations (opens in a new tab) (April 2023)\n",
      "Reflexion: an autonomous agent with dynamic memory and self-reflection (opens in a new tab) (March 2023)\n",
      "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society (opens in a new tab) (March 2023)\n",
      "Self-Refine: Iterative Refinement with Self-Feedback (opens in a new tab) (March 2023)\n",
      "kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference (opens in a new tab) (March 2023)\n",
      "Visual-Language Prompt Tuning with Knowledge-guided Context Optimization (opens in a new tab) (March 2023)\n",
      "Fairness-guided Few-shot Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Context-faithful Prompting for Large Language Models (opens in a new tab) (March 2023)\n",
      "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning (opens in a new tab) (March 2023)\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (opens in a new tab) (March 2023)\n",
      "Model-tuning Via Prompts Makes NLP Models Adversarially Robust (opens in a new tab) (March 2023)\n",
      "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer (opens in a new tab) (March 2023)\n",
      "CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification (opens in a new tab) (March 2023)\n",
      "Larger language models do in-context learning differently (opens in a new tab) (March 2023)\n",
      "OpenICL: An Open-Source Framework for In-context Learning (opens in a new tab) (March 2023)\n",
      "Dynamic Prompting: A Unified Framework for Prompt Tuning (opens in a new tab) (March 2023)\n",
      "ART: Automatic multi-step reasoning and tool-use for large language models (opens in a new tab) (March 2023)\n",
      "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning (opens in a new tab) (March 2023)\n",
      "Effectiveness of Data Augmentation for Prefix Tuning with Limited Data (opens in a new tab) (March 2023)\n",
      "Mixture of Soft Prompts for Controllable Data Generation (opens in a new tab) (March 2023)\n",
      "Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners (opens in a new tab) (March 2023)\n",
      "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks (opens in a new tab) (March 2023)\n",
      "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT (opens in a new tab) (February 2023)\n",
      "EvoPrompting: Language Models for Code-Level Neural Architecture Search (opens in a new tab) (February 2023)\n",
      "In-Context Instruction Learning (opens in a new tab) (February 2023)\n",
      "Chain of Hindsight Aligns Language Models with Feedback (opens in a new tab) (February 2023)\n",
      "Language Is Not All You Need: Aligning Perception with Language Models (opens in a new tab) (February 2023)\n",
      "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (opens in a new tab) (February 2023)\n",
      "Active Prompting with Chain-of-Thought for Large Language Models (opens in a new tab) (February 2023)\n",
      "More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models (opens in a new tab) (February 2023)\n",
      "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (opens in a new tab) (February 2023)\n",
      "Guiding Large Language Models via Directional Stimulus Prompting (opens in a new tab) (February 2023)\n",
      "How Does In-Context Learning Help Prompt Tuning? (opens in a new tab) (February 2023)\n",
      "Scalable Prompt Generation for Semi-supervised Learning with Language Models (opens in a new tab) (February 2023)\n",
      "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints (opens in a new tab) (February 2023)\n",
      "À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting (opens in a new tab) (February 2023)\n",
      "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks (opens in a new tab) (February 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (February 2023)\n",
      "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains (opens in a new tab) (February 2023)\n",
      "Evaluating the Robustness of Discrete Prompts (opens in a new tab) (February 2023)\n",
      "Compositional Exemplars for In-context Learning (opens in a new tab) (February 2023)\n",
      "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (opens in a new tab) (February 2023)\n",
      "Multimodal Chain-of-Thought Reasoning in Language Models (opens in a new tab) (February 2023)\n",
      "Large Language Models Can Be Easily Distracted by Irrelevant Context (opens in a new tab) (February 2023)\n",
      "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models (opens in a new tab) (February 2023)\n",
      "Progressive Prompts: Continual Learning for Language Models (opens in a new tab) (January 2023)\n",
      "Batch Prompting: Efficient Inference with LLM APIs (opens in a new tab) (January 2023)\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (opens in a new tab) (December 2022)\n",
      "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning (opens in a new tab) (December 2022)\n",
      "Constitutional AI: Harmlessness from AI Feedback (opens in a new tab) (December 2022)\n",
      "Successive Prompting for Decomposing Complex Questions (opens in a new tab) (December 2022)\n",
      "Large Language Models are reasoners with Self-Verification (opens in a new tab) (December 2022)\n",
      "Discovering Language Model Behaviors with Model-Written Evaluations (opens in a new tab) (December 2022)\n",
      "Structured Prompting: Scaling In-Context Learning to 1,000 Examples (opens in a new tab) (December 2022)\n",
      "PAL: Program-aided Language Models (opens in a new tab) (November 2022)\n",
      "Large Language Models Are Human-Level Prompt Engineers (opens in a new tab) (November 2022)\n",
      "Ignore Previous Prompt: Attack Techniques For Language Models (opens in a new tab) (November 2022)\n",
      "Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods (opens in a new tab) (November 2022)\n",
      "Teaching Algorithmic Reasoning via In-context Learning (opens in a new tab) (November 2022)\n",
      "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference (opens in a new tab) (November 2022)\n",
      "Ask Me Anything: A simple strategy for prompting language models (opens in a new tab) (October 2022)\n",
      "Recitation-Augmented Language Models (opens in a new tab) (October 2022)\n",
      "ReAct: Synergizing Reasoning and Acting in Language Models (opens in a new tab) (October 2022)\n",
      "Prompting GPT-3 To Be Reliable (opens in a new tab) (October 2022)\n",
      "Decomposed Prompting: A Modular Approach for Solving Complex Tasks (opens in a new tab) (October 2022)\n",
      "Automatic Chain of Thought Prompting in Large Language Models (opens in a new tab) (October 2022)\n",
      "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought (opens in a new tab) (October 2022)\n",
      "Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples (opens in a new tab) (September 2022)\n",
      "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning (opens in a new tab) (September 2022)\n",
      "Promptagator: Few-shot Dense Retrieval From 8 Examples (opens in a new tab) (September 2022)\n",
      "Atlas: Few-shot Learning with Retrieval Augmented Language Models (opens in a new tab) (November 2022)\n",
      "DocPrompting: Generating Code by Retrieving the Docs (opens in a new tab) (July 2022)\n",
      "On the Advance of Making Language Models Better Reasoners (opens in a new tab) (June 2022)\n",
      "Large Language Models are Zero-Shot Reasoners (opens in a new tab) (May 2022)\n",
      "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations (opens in a new tab) (May 2022)\n",
      "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (opens in a new tab) (May 2022)\n",
      "PPT: Pre-trained Prompt Tuning for Few-shot Learning (opens in a new tab) (Mqy 2022)\n",
      "Toxicity Detection with Generative Prompt-based Inference (opens in a new tab) (May 2022)\n",
      "Learning to Transfer Prompts for Text Generation (opens in a new tab) (May 2022)\n",
      "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (opens in a new tab) (May 2022)\n",
      "A Taxonomy of Prompt Modifiers for Text-To-Image Generation (opens in a new tab) (April 2022)\n",
      "PromptChainer: Chaining Large Language Model Prompts through Visual Programming (opens in a new tab) (March 2022)\n",
      "Self-Consistency Improves Chain of Thought Reasoning in Language Models (opens in a new tab) (March 2022)\n",
      "Training language models to follow instructions with human feedback (opens in a new tab)\n",
      "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (opens in a new tab) (February 2022)\n",
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models (opens in a new tab) (January 2022)\n",
      "Show Your Work: Scratchpads for Intermediate Computation with Language Models (opens in a new tab) (November 2021)\n",
      "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts (opens in a new tab) (October 2021)\n",
      "Generated Knowledge Prompting for Commonsense Reasoning (opens in a new tab) (October 2021)\n",
      "Multitask Prompted Training Enables Zero-Shot Task Generalization (opens in a new tab) (October 2021)\n",
      "Reframing Instructional Prompts to GPTk's Language (opens in a new tab) (September 2021)\n",
      "Design Guidelines for Prompt Engineering Text-to-Image Generative Models (opens in a new tab) (September 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (August 2021)\n",
      "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity (opens in a new tab) (April 2021)\n",
      "BERTese: Learning to Speak to BERT (opens in a new tab) (April 2021)\n",
      "The Power of Scale for Parameter-Efficient Prompt Tuning (opens in a new tab) (April 2021)\n",
      "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (opens in a new tab) (February 2021)\n",
      "Calibrate Before Use: Improving Few-Shot Performance of Language Models (opens in a new tab) (February 2021)\n",
      "Prefix-Tuning: Optimizing Continuous Prompts for Generation (opens in a new tab) (January 2021)\n",
      "Learning to Generate Task-Specific Adapters from Task Description (opens in a new tab) (January 2021)\n",
      "Making Pre-trained Language Models Better Few-shot Learners (opens in a new tab) (December 2020)\n",
      "Learning from Task Descriptions (opens in a new tab) (November 2020)\n",
      "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts (opens in a new tab) (October 2020)\n",
      "Language Models are Few-Shot Learners (opens in a new tab) (May 2020)\n",
      "How Can We Know What Language Models Know? (opens in a new tab) (July 2020)\n",
      "Scaling Laws for Neural Language Models (opens in a new tab) (January 2020)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove fully empty lines\n",
    "no_empty_lines = approaches.replace(\"\\n\\n\", \"\\n\")\n",
    "print(no_empty_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title              month\n",
      "0    Chain-of-Verification Reduces Hallucination in...   (September 2023)\n",
      "1    Connecting Large Language Models with Evolutio...   (September 2023)\n",
      "2    From Sparse to Dense: GPT-4 Summarization with...   (September 2023)\n",
      "3    Re-Reading Improves Reasoning in Language Models    (September 2023)\n",
      "4    Graph of Thoughts: Solving Elaborate Problems ...      (August 2023)\n",
      "..                                                 ...                ...\n",
      "143                   Learning from Task Descriptions     (November 2020)\n",
      "144  AutoPrompt: Eliciting Knowledge from Language ...     (October 2020)\n",
      "145             Language Models are Few-Shot Learners          (May 2020)\n",
      "146        How Can We Know What Language Models Know?         (July 2020)\n",
      "147           Scaling Laws for Neural Language Models      (January 2020)\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of approaches\n",
    "# First column is title (content before \"(opens in a new tab)\")\n",
    "# Second column is month (content after \"(opens in a new tab)\")\n",
    "\n",
    "approaches_papers = pd.DataFrame(columns=[\"title\", \"month\"])\n",
    "for line in no_empty_lines.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        title = line.split(\"(opens in a new tab)\")[0]\n",
    "        month = line.split(\"(opens in a new tab)\")[1]\n",
    "        new_record = pd.DataFrame([{\"title\": title, \"month\": month}])\n",
    "        approaches_papers = pd.concat([approaches_papers, new_record], ignore_index=True)\n",
    "\n",
    "print(approaches_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 50/148 [01:41<04:21,  2.67s/it]"
     ]
    }
   ],
   "source": [
    "# Semantic scholar dataframe\n",
    "semantic_scholar_df = pd.DataFrame()\n",
    "no_results_df = pd.DataFrame()\n",
    "\n",
    "# Loop over papers\n",
    "for paper_title in tqdm(approaches_papers[\"title\"]):\n",
    "    # Replace hyphens with a space (per documentation)\n",
    "    query = paper_title.replace(\"-\", \" \")\n",
    "    # Query semantic scholar\n",
    "    r = requests.get(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/search?query=' + query + '&fields=paperId,title,citationCount,publicationDate,year&limit=1'\n",
    "    )\n",
    "    # Attempt for a returned result\n",
    "    try:\n",
    "        paper_id = r.json()['data'][0]['paperId']\n",
    "        semantic_scholar_title = r.json()['data'][0]['title']\n",
    "        ss_publication_date = r.json()['data'][0]['publicationDate']\n",
    "        ss_year = r.json()['data'][0]['year']\n",
    "        # Citation count as of October 10, 2023\n",
    "        paper_ss_url = f'https://api.semanticscholar.org/v1/paper/{paper_id}'\n",
    "        response = requests.get(paper_ss_url)\n",
    "        paper_data = response.json()\n",
    "        citations = paper_data.get('citations', [])\n",
    "        # Get paper ids of citing papers\n",
    "        citing_paper_ids = [citation['paperId'] for citation in citations]\n",
    "        # Loop over citing papers. If citing paper was published before October 10, 2023, add to count\n",
    "        constructed_citation_count = 0\n",
    "        for citing_paper_id in citing_paper_ids:\n",
    "            paper_ss_url = f'https://api.semanticscholar.org/v1/paper/{citing_paper_id}'\n",
    "            response = requests.get(paper_ss_url)\n",
    "            citing_paper_data = response.json()\n",
    "            if paper_data['publicationDate'] <= '2023-10-10':\n",
    "                constructed_citation_count += 1\n",
    "        # Add on paper data\n",
    "        new_record = pd.DataFrame([{\"paper title\":paper_title, \"semantic scholar title\": semantic_scholar_title, \"ss_publication_date\": ss_publication_date, \"ss_year\": ss_year, \"citation_count\": constructed_citation_count, \"query\": query}])\n",
    "        semantic_scholar_df = pd.concat([semantic_scholar_df, new_record], ignore_index=True)\n",
    "    # Error catch for no results\n",
    "    except:\n",
    "        new_record = pd.DataFrame([{\"paper title\":paper_title, \"query\": query}])\n",
    "        no_results_df = pd.concat([no_results_df, new_record], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_scholar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['abstract', 'arxivId', 'authors', 'citationVelocity', 'citations', 'corpusId', 'doi', 'fieldsOfStudy', 'influentialCitationCount', 'isOpenAccess', 'isPublisherLicensed', 'is_open_access', 'is_publisher_licensed', 'numCitedBy', 'numCiting', 'paperId', 'references', 's2FieldsOfStudy', 'title', 'topics', 'url', 'venue', 'year'])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with the actual paper ID you are interested in\n",
    "paper_id = '8d5a41c94e01c10ed7baf7dd68a851790275a1e5'\n",
    "\n",
    "url = f'https://api.semanticscholar.org/v1/paper/{paper_id}'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    paper_data = response.json()\n",
    "    print(paper_data.keys())\n",
    "    #print(paper_data.get('publicationDate'))\n",
    "    citations = paper_data.get('citations', [])\n",
    "    # Get paper ids of citing papers\n",
    "    citing_paper_ids = [citation['paperId'] for citation in citations]\n",
    "    # Get publication dates of citing papers\n",
    "    response = requests.post('https://api.semanticscholar.org/graph/v1/paper', json={'ids': citing_paper_ids})\n",
    "    # Filter citations by date here\n",
    "    #print(citations)\n",
    "    #filtered_citations = [citation for citation in citations if citation['publicationDate'] <= '2021-10-10']\n",
    "    #print(filtered_citations)\n",
    "else:\n",
    "    print('Failed to retrieve data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"total\": 1196604,\n",
      "  \"offset\": 0,\n",
      "  \"next\": 10,\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"paperId\": \"8d5a41c94e01c10ed7baf7dd68a851790275a1e5\",\n",
      "      \"title\": \"The Impact of COVID Vaccination on Symptoms of Long COVID: An International Survey of People with Lived Experience of Long COVID\",\n",
      "      \"citationCount\": 33\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"e2fea94b98c5d3f9e5264569422c8250fd224476\",\n",
      "      \"title\": \"Long COVID Risk and Pre-COVID Vaccination: An EHR-Based Cohort Study from the RECOVER Program\",\n",
      "      \"citationCount\": 14\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"0f722d8d3882006980da6ddce74da5bcd8361fb0\",\n",
      "      \"title\": \"Bilateral optic neuritis after COVID vaccination\",\n",
      "      \"citationCount\": 10\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"dedb8621c013a1f6a07e6403f00af32b433e2a81\",\n",
      "      \"title\": \"COVID vaccination in older adults\",\n",
      "      \"citationCount\": 12\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"dca76137d55a9714f41c0b804546181611ff0ca8\",\n",
      "      \"title\": \"The Impact of COVID Vaccination on Symptoms of Long COVID. An International Survey of People with Lived Experience of Long COVID\",\n",
      "      \"citationCount\": 30\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"8d85e3b7cf3f35d9cfa09f08270740743bdce802\",\n",
      "      \"title\": \"The Challenge of Staging Breast Cancer With PET/CT in the Era of COVID Vaccination\",\n",
      "      \"citationCount\": 25\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"87fb9e503d1dde5aa168cdc30f55428e0ed04d22\",\n",
      "      \"title\": \"Herpes zoster after COVID vaccination\",\n",
      "      \"citationCount\": 48\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"9efc8549e939c6e49aa6fb44cce48c4befd45398\",\n",
      "      \"title\": \"Acantholytic Dyskeratosis Post-COVID Vaccination.\",\n",
      "      \"citationCount\": 5\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"b2b1d6225ebee4c23dfefd76266e3ab9d172434e\",\n",
      "      \"title\": \"Anti-COVID Vaccination for Adolescents: A Survey on Determinants of Vaccine Parental Hesitancy\",\n",
      "      \"citationCount\": 16\n",
      "    },\n",
      "    {\n",
      "      \"paperId\": \"942be051ae08c762fd9c195184d66d32a839f2f3\",\n",
      "      \"title\": \"Towards a GDPR-Compliant Blockchain-Based COVID Vaccination Passport\",\n",
      "      \"citationCount\": 18\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "r = requests.get(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/search?query=covid+vaccination&fields=title,citationCount'#,\n",
    "    #params={'query': 'Semantic'}\n",
    "    #params={'fields': 'referenceCount,citationCount,title'}#,\n",
    "    #json={\"ids\": [\"649def34f8be52c8b66281af98ae884c09aef38b\", \"ARXIV:2106.15928\"]}\n",
    ")\n",
    "#print(r)\n",
    "print(json.dumps(r.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language%20Models%20are%20Few-Shot%20Learners\n",
      "{'total': 3625, 'offset': 0, 'next': 10, 'data': [{'paperId': '6b85b63579a916f705a8e10a49bd8d849d91b1fc', 'title': 'Language Models are Few-Shot Learners', 'citationCount': 15624}, {'paperId': '236445f0a3b1e30b2542e5e64616ff6a8af7e3ea', 'title': 'Language Models are Few-shot Learners for Prognostic Prediction', 'citationCount': 21}, {'paperId': 'a6a83754a0d1e9a8e41c1e9bbdbca32d3b9d1fd3', 'title': 'It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners', 'citationCount': 618}, {'paperId': '85e7d63f75c0916bd350a229e040c5fbb1472e7a', 'title': 'Making Pre-trained Language Models Better Few-shot Learners', 'citationCount': 1037}, {'paperId': 'ff0b2681d7b05e16c46dfb71d980cc2f605907cd', 'title': 'Finetuned Language Models Are Zero-Shot Learners', 'citationCount': 1105}, {'paperId': '42fc019b2668c9d9d984154d4c57f6c6d5a91619', 'title': 'Language Models are Few-shot Multilingual Learners', 'citationCount': 64}, {'paperId': '6dd44624ac912fb50c21c691806ee52d27e73abb', 'title': 'Large Language Models are Few-Shot Health Learners', 'citationCount': 8}, {'paperId': '9405cc0d6169988371b2755e573cc28650d14dfe', 'title': 'Language Models are Unsupervised Multitask Learners', 'citationCount': 12110}, {'paperId': 'b65b7f480a61d3dd31d8117b349cabc87c8ccf6c', 'title': 'Bidirectional Language Models Are Also Few-shot Learners', 'citationCount': 14}, {'paperId': '86d0d3855f94105e25d81cab9f3d269c6062a9c4', 'title': 'Selective Annotation Makes Language Models Better Few-Shot Learners', 'citationCount': 68}]}\n"
     ]
    }
   ],
   "source": [
    "# Language Models are Few-Shot Learners\n",
    "q_string = \"Language Models are Few-Shot Learners\"\n",
    "# Put string in URL format\n",
    "import urllib.parse\n",
    "q_string_url = urllib.parse.quote(q_string)\n",
    "print(q_string_url)\n",
    "\n",
    "r = requests.get(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/search?query=' + q_string + '&fields=title,citationCount'\n",
    ")\n",
    "print(r.json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 3625, 'offset': 0, 'next': 10, 'data': [{'paperId': '6b85b63579a916f705a8e10a49bd8d849d91b1fc', 'title': 'Language Models are Few-Shot Learners', 'citationCount': 15624}, {'paperId': '236445f0a3b1e30b2542e5e64616ff6a8af7e3ea', 'title': 'Language Models are Few-shot Learners for Prognostic Prediction', 'citationCount': 21}, {'paperId': 'a6a83754a0d1e9a8e41c1e9bbdbca32d3b9d1fd3', 'title': 'It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners', 'citationCount': 618}, {'paperId': '85e7d63f75c0916bd350a229e040c5fbb1472e7a', 'title': 'Making Pre-trained Language Models Better Few-shot Learners', 'citationCount': 1037}, {'paperId': 'ff0b2681d7b05e16c46dfb71d980cc2f605907cd', 'title': 'Finetuned Language Models Are Zero-Shot Learners', 'citationCount': 1105}, {'paperId': '42fc019b2668c9d9d984154d4c57f6c6d5a91619', 'title': 'Language Models are Few-shot Multilingual Learners', 'citationCount': 64}, {'paperId': '6dd44624ac912fb50c21c691806ee52d27e73abb', 'title': 'Large Language Models are Few-Shot Health Learners', 'citationCount': 8}, {'paperId': '9405cc0d6169988371b2755e573cc28650d14dfe', 'title': 'Language Models are Unsupervised Multitask Learners', 'citationCount': 12110}, {'paperId': 'b65b7f480a61d3dd31d8117b349cabc87c8ccf6c', 'title': 'Bidirectional Language Models Are Also Few-shot Learners', 'citationCount': 14}, {'paperId': '86d0d3855f94105e25d81cab9f3d269c6062a9c4', 'title': 'Selective Annotation Makes Language Models Better Few-Shot Learners', 'citationCount': 68}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to dataframe\n",
    "import pandas as pd\n",
    "\n",
    "print(r.json()['data'][0]['title'])\n",
    "print(r.json()['data'][0]['citationCount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2023-09-20\n",
      "1     2023-09-15\n",
      "2     2023-09-08\n",
      "3     2023-09-12\n",
      "4     2023-08-18\n",
      "         ...    \n",
      "105   2021-01-01\n",
      "106   2020-11-01\n",
      "107   2020-10-29\n",
      "108   2020-05-28\n",
      "109   2019-11-28\n",
      "Name: ss_publication_date, Length: 110, dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper title</th>\n",
       "      <th>semantic scholar title</th>\n",
       "      <th>ss_publication_date</th>\n",
       "      <th>ss_year</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>query</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_from_pub_to_10_8_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Chain of Verification Reduces Hallucination in...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>2023-09-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>From Sparse to Dense: GPT 4 Summarization with...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Re Reading Improves Reasoning in Language Models</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>1037</td>\n",
       "      <td>Making Pre trained Language Models Better Few ...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>63</td>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>Eliciting Knowledge from Language Models Using...</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>15624</td>\n",
       "      <td>Language Models are Few Shot Learners</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>736</td>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1410.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper title  \\\n",
       "0    Chain-of-Verification Reduces Hallucination in...   \n",
       "1    Connecting Large Language Models with Evolutio...   \n",
       "2    From Sparse to Dense: GPT-4 Summarization with...   \n",
       "3    Re-Reading Improves Reasoning in Language Models    \n",
       "4    Graph of Thoughts: Solving Elaborate Problems ...   \n",
       "..                                                 ...   \n",
       "105  Making Pre-trained Language Models Better Few-...   \n",
       "106                   Learning from Task Descriptions    \n",
       "107  AutoPrompt: Eliciting Knowledge from Language ...   \n",
       "108             Language Models are Few-Shot Learners    \n",
       "109        How Can We Know What Language Models Know?    \n",
       "\n",
       "                                semantic scholar title ss_publication_date  \\\n",
       "0    Chain-of-Verification Reduces Hallucination in...          2023-09-20   \n",
       "1    Connecting Large Language Models with Evolutio...          2023-09-15   \n",
       "2    From Sparse to Dense: GPT-4 Summarization with...          2023-09-08   \n",
       "3     Re-Reading Improves Reasoning in Language Models          2023-09-12   \n",
       "4    Graph of Thoughts: Solving Elaborate Problems ...          2023-08-18   \n",
       "..                                                 ...                 ...   \n",
       "105  Making Pre-trained Language Models Better Few-...          2021-01-01   \n",
       "106                    Learning from Task Descriptions          2020-11-01   \n",
       "107  Eliciting Knowledge from Language Models Using...          2020-10-29   \n",
       "108              Language Models are Few-Shot Learners          2020-05-28   \n",
       "109         How Can We Know What Language Models Know?          2019-11-28   \n",
       "\n",
       "     ss_year  citation_count  \\\n",
       "0       2023               3   \n",
       "1       2023               5   \n",
       "2       2023               1   \n",
       "3       2023               1   \n",
       "4       2023              22   \n",
       "..       ...             ...   \n",
       "105     2021            1037   \n",
       "106     2020              63   \n",
       "107     2020             215   \n",
       "108     2020           15624   \n",
       "109     2019             736   \n",
       "\n",
       "                                                 query   end_date  \\\n",
       "0    Chain of Verification Reduces Hallucination in... 2023-10-08   \n",
       "1    Connecting Large Language Models with Evolutio... 2023-10-08   \n",
       "2    From Sparse to Dense: GPT 4 Summarization with... 2023-10-08   \n",
       "3    Re Reading Improves Reasoning in Language Models  2023-10-08   \n",
       "4    Graph of Thoughts: Solving Elaborate Problems ... 2023-10-08   \n",
       "..                                                 ...        ...   \n",
       "105  Making Pre trained Language Models Better Few ... 2023-10-08   \n",
       "106                   Learning from Task Descriptions  2023-10-08   \n",
       "107  AutoPrompt: Eliciting Knowledge from Language ... 2023-10-08   \n",
       "108             Language Models are Few Shot Learners  2023-10-08   \n",
       "109        How Can We Know What Language Models Know?  2023-10-08   \n",
       "\n",
       "     days_from_pub_to_10_8_2023  \n",
       "0                          18.0  \n",
       "1                          23.0  \n",
       "2                          30.0  \n",
       "3                          26.0  \n",
       "4                          51.0  \n",
       "..                          ...  \n",
       "105                      1010.0  \n",
       "106                      1071.0  \n",
       "107                      1074.0  \n",
       "108                      1228.0  \n",
       "109                      1410.0  \n",
       "\n",
       "[110 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add days between publication and October 8, 2023 as a column to semantic_scholar_df\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "\n",
    "# Convert publication date to datetime object\n",
    "semantic_scholar_df[\"ss_publication_date\"] = pd.to_datetime(semantic_scholar_df[\"ss_publication_date\"])\n",
    "\n",
    "print(semantic_scholar_df[\"ss_publication_date\"])\n",
    "\n",
    "# Column for October 8, 2023\n",
    "semantic_scholar_df[\"end_date\"] = datetime(2023, 10, 8)\n",
    "\n",
    "# Calculate days between publication and October 8, 2023\n",
    "semantic_scholar_df[\"days_from_pub_to_10_8_2023\"] = (semantic_scholar_df['end_date'] - semantic_scholar_df['ss_publication_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "semantic_scholar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper title</th>\n",
       "      <th>semantic scholar title</th>\n",
       "      <th>ss_publication_date</th>\n",
       "      <th>ss_year</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>query</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_from_pub_to_10_8_2023</th>\n",
       "      <th>citations_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in...</td>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Chain of Verification Reduces Hallucination in...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>2023-09-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Connecting Large Language Models with Evolutio...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>From Sparse to Dense: GPT-4 Summarization with...</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>From Sparse to Dense: GPT 4 Summarization with...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>Re-Reading Improves Reasoning in Language Models</td>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Re Reading Improves Reasoning in Language Models</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>Graph of Thoughts: Solving Elaborate Problems ...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.431373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>Making Pre-trained Language Models Better Few-...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>1037</td>\n",
       "      <td>Making Pre trained Language Models Better Few ...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1.026733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>63</td>\n",
       "      <td>Learning from Task Descriptions</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>Eliciting Knowledge from Language Models Using...</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoPrompt: Eliciting Knowledge from Language ...</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0.200186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>15624</td>\n",
       "      <td>Language Models are Few Shot Learners</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>12.723127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>2019</td>\n",
       "      <td>736</td>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>0.521986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper title  \\\n",
       "0    Chain-of-Verification Reduces Hallucination in...   \n",
       "1    Connecting Large Language Models with Evolutio...   \n",
       "2    From Sparse to Dense: GPT-4 Summarization with...   \n",
       "3    Re-Reading Improves Reasoning in Language Models    \n",
       "4    Graph of Thoughts: Solving Elaborate Problems ...   \n",
       "..                                                 ...   \n",
       "105  Making Pre-trained Language Models Better Few-...   \n",
       "106                   Learning from Task Descriptions    \n",
       "107  AutoPrompt: Eliciting Knowledge from Language ...   \n",
       "108             Language Models are Few-Shot Learners    \n",
       "109        How Can We Know What Language Models Know?    \n",
       "\n",
       "                                semantic scholar title ss_publication_date  \\\n",
       "0    Chain-of-Verification Reduces Hallucination in...          2023-09-20   \n",
       "1    Connecting Large Language Models with Evolutio...          2023-09-15   \n",
       "2    From Sparse to Dense: GPT-4 Summarization with...          2023-09-08   \n",
       "3     Re-Reading Improves Reasoning in Language Models          2023-09-12   \n",
       "4    Graph of Thoughts: Solving Elaborate Problems ...          2023-08-18   \n",
       "..                                                 ...                 ...   \n",
       "105  Making Pre-trained Language Models Better Few-...          2021-01-01   \n",
       "106                    Learning from Task Descriptions          2020-11-01   \n",
       "107  Eliciting Knowledge from Language Models Using...          2020-10-29   \n",
       "108              Language Models are Few-Shot Learners          2020-05-28   \n",
       "109         How Can We Know What Language Models Know?          2019-11-28   \n",
       "\n",
       "     ss_year  citation_count  \\\n",
       "0       2023               3   \n",
       "1       2023               5   \n",
       "2       2023               1   \n",
       "3       2023               1   \n",
       "4       2023              22   \n",
       "..       ...             ...   \n",
       "105     2021            1037   \n",
       "106     2020              63   \n",
       "107     2020             215   \n",
       "108     2020           15624   \n",
       "109     2019             736   \n",
       "\n",
       "                                                 query   end_date  \\\n",
       "0    Chain of Verification Reduces Hallucination in... 2023-10-08   \n",
       "1    Connecting Large Language Models with Evolutio... 2023-10-08   \n",
       "2    From Sparse to Dense: GPT 4 Summarization with... 2023-10-08   \n",
       "3    Re Reading Improves Reasoning in Language Models  2023-10-08   \n",
       "4    Graph of Thoughts: Solving Elaborate Problems ... 2023-10-08   \n",
       "..                                                 ...        ...   \n",
       "105  Making Pre trained Language Models Better Few ... 2023-10-08   \n",
       "106                   Learning from Task Descriptions  2023-10-08   \n",
       "107  AutoPrompt: Eliciting Knowledge from Language ... 2023-10-08   \n",
       "108             Language Models are Few Shot Learners  2023-10-08   \n",
       "109        How Can We Know What Language Models Know?  2023-10-08   \n",
       "\n",
       "     days_from_pub_to_10_8_2023  citations_per_day  \n",
       "0                          18.0           0.166667  \n",
       "1                          23.0           0.217391  \n",
       "2                          30.0           0.033333  \n",
       "3                          26.0           0.038462  \n",
       "4                          51.0           0.431373  \n",
       "..                          ...                ...  \n",
       "105                      1010.0           1.026733  \n",
       "106                      1071.0           0.058824  \n",
       "107                      1074.0           0.200186  \n",
       "108                      1228.0          12.723127  \n",
       "109                      1410.0           0.521986  \n",
       "\n",
       "[110 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column for citations per day\n",
    "semantic_scholar_df[\"citations_per_day\"] = semantic_scholar_df[\"citation_count\"] / semantic_scholar_df[\"days_from_pub_to_10_8_2023\"]\n",
    "\n",
    "semantic_scholar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by citations per day, descending\n",
    "semantic_scholar_df = semantic_scholar_df.sort_values(by=[\"citations_per_day\"], ascending=False)\n",
    "\n",
    "# Output to CSV\n",
    "semantic_scholar_df.to_csv(\"semantic_scholar_df.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
