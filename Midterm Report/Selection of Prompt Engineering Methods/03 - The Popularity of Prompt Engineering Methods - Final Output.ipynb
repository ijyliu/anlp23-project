{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Popularity of Prompt Engineering Methods\n",
    "\n",
    "This series of notebooks produces statistics on Semantic Scholar citations per day for all of the prompt engineering approaches listed at \"https://www.promptingguide.ai/papers\", \"https://en.wikipedia.org/wiki/Prompt_engineering#Text-to-text\", and the citations section for \"The Practicality of Prompt Engineering\".\n",
    "\n",
    "This file produces final Excel and LaTeX output from the citations per day data and hand-labelled supplementary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper title</th>\n",
       "      <th>semantic scholar title</th>\n",
       "      <th>ss_publication_date</th>\n",
       "      <th>ss_year</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>query</th>\n",
       "      <th>day_queried</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_from_pub_to_end_date</th>\n",
       "      <th>citations_per_day</th>\n",
       "      <th>Prompt Engineering Method</th>\n",
       "      <th>Generalizable?</th>\n",
       "      <th>Ease of Implementation? (1=easy, 5=hard)</th>\n",
       "      <th>Performance Gain - Rough Order of Magnitude</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>16440</td>\n",
       "      <td>Language Models are Few Shot Learners</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>1242.564615</td>\n",
       "      <td>13.230700</td>\n",
       "      <td>Few-shot Learning</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Original GPT-3 Paper</td>\n",
       "      <td>Various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>1529</td>\n",
       "      <td>GPT 4 Technical Report</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>221.564615</td>\n",
       "      <td>6.900921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original GPT-4 Paper</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training language models to follow instructions with human feedback</td>\n",
       "      <td>Training language models to follow instructions with human feedback</td>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>2022</td>\n",
       "      <td>3009</td>\n",
       "      <td>Training language models to follow instructions with human feedback</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>597.564615</td>\n",
       "      <td>5.035439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fine-tuning, introduces Instruct-GPT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning in Large Language Models</td>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning in Large Language Models</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>2022</td>\n",
       "      <td>2105</td>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning in Large Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>632.564615</td>\n",
       "      <td>3.327723</td>\n",
       "      <td>Chain-of-thought Prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Focuses on PaLM</td>\n",
       "      <td>GSM8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>Scaling Instruction-Finetuned Language Models</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>2022</td>\n",
       "      <td>823</td>\n",
       "      <td>Scaling Instruction Finetuned Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>367.564615</td>\n",
       "      <td>2.239062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fine-tuning, introduces Instruct-GPT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models</td>\n",
       "      <td>More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023</td>\n",
       "      <td>37</td>\n",
       "      <td>More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application Integrated Large Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>On the Advance of Making Language Models Better Reasoners</td>\n",
       "      <td>On the Advance of Making Language Models Better Reasoners</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>106</td>\n",
       "      <td>On the Advance of Making Language Models Better Reasoners</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Prefix-Tuning: Optimizing Continuous Prompts for Generation</td>\n",
       "      <td>Prefix-Tuning: Optimizing Continuous Prompts for Generation</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021</td>\n",
       "      <td>1682</td>\n",
       "      <td>Prefix Tuning: Optimizing Continuous Prompts for Generation</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Prompt Engineering for Large Language Models</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Reflexion: an autonomous agent with dynamic memory and self-reflection</td>\n",
       "      <td>Reflexion: an autonomous agent with dynamic memory and self-reflection</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023</td>\n",
       "      <td>105</td>\n",
       "      <td>Reflexion: an autonomous agent with dynamic memory and self reflection</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>2023-10-22 13:33:02.768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                paper title  \\\n",
       "0                                                                                                     Language Models are Few-Shot Learners   \n",
       "1                                                                                                                    GPT-4 Technical Report   \n",
       "2                                                                       Training language models to follow instructions with human feedback   \n",
       "3                                                                     Chain of Thought Prompting Elicits Reasoning in Large Language Models   \n",
       "4                                                                                             Scaling Instruction-Finetuned Language Models   \n",
       "..                                                                                                                                      ...   \n",
       "156  More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models   \n",
       "157                                                                               On the Advance of Making Language Models Better Reasoners   \n",
       "158                                                                             Prefix-Tuning: Optimizing Continuous Prompts for Generation   \n",
       "159                                                                                            Prompt Engineering for Large Language Models   \n",
       "160                                                                  Reflexion: an autonomous agent with dynamic memory and self-reflection   \n",
       "\n",
       "                                                                                                                     semantic scholar title  \\\n",
       "0                                                                                                     Language Models are Few-Shot Learners   \n",
       "1                                                                                                                    GPT-4 Technical Report   \n",
       "2                                                                       Training language models to follow instructions with human feedback   \n",
       "3                                                                     Chain of Thought Prompting Elicits Reasoning in Large Language Models   \n",
       "4                                                                                             Scaling Instruction-Finetuned Language Models   \n",
       "..                                                                                                                                      ...   \n",
       "156  More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models   \n",
       "157                                                                               On the Advance of Making Language Models Better Reasoners   \n",
       "158                                                                             Prefix-Tuning: Optimizing Continuous Prompts for Generation   \n",
       "159                                                                                            Prompt Engineering for Large Language Models   \n",
       "160                                                                  Reflexion: an autonomous agent with dynamic memory and self-reflection   \n",
       "\n",
       "    ss_publication_date  ss_year  citation_count  \\\n",
       "0            2020-05-28     2020           16440   \n",
       "1            2023-03-15     2023            1529   \n",
       "2            2022-03-04     2022            3009   \n",
       "3            2022-01-28     2022            2105   \n",
       "4            2022-10-20     2022             823   \n",
       "..                  ...      ...             ...   \n",
       "156                 NaT     2023              37   \n",
       "157                 NaT     2022             106   \n",
       "158                 NaT     2021            1682   \n",
       "159                 NaT     2023               3   \n",
       "160                 NaT     2023             105   \n",
       "\n",
       "                                                                                                                                      query  \\\n",
       "0                                                                                                     Language Models are Few Shot Learners   \n",
       "1                                                                                                                    GPT 4 Technical Report   \n",
       "2                                                                       Training language models to follow instructions with human feedback   \n",
       "3                                                                     Chain of Thought Prompting Elicits Reasoning in Large Language Models   \n",
       "4                                                                                             Scaling Instruction Finetuned Language Models   \n",
       "..                                                                                                                                      ...   \n",
       "156  More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application Integrated Large Language Models   \n",
       "157                                                                               On the Advance of Making Language Models Better Reasoners   \n",
       "158                                                                             Prefix Tuning: Optimizing Continuous Prompts for Generation   \n",
       "159                                                                                            Prompt Engineering for Large Language Models   \n",
       "160                                                                  Reflexion: an autonomous agent with dynamic memory and self reflection   \n",
       "\n",
       "    day_queried                end_date  days_from_pub_to_end_date  \\\n",
       "0    2023-10-22 2023-10-22 13:33:02.768                1242.564615   \n",
       "1    2023-10-22 2023-10-22 13:33:02.768                 221.564615   \n",
       "2    2023-10-22 2023-10-22 13:33:02.768                 597.564615   \n",
       "3    2023-10-22 2023-10-22 13:33:02.768                 632.564615   \n",
       "4    2023-10-22 2023-10-22 13:33:02.768                 367.564615   \n",
       "..          ...                     ...                        ...   \n",
       "156  2023-10-22 2023-10-22 13:33:02.768                        NaN   \n",
       "157  2023-10-22 2023-10-22 13:33:02.768                        NaN   \n",
       "158  2023-10-22 2023-10-22 13:33:02.768                        NaN   \n",
       "159  2023-10-22 2023-10-22 13:33:02.768                        NaN   \n",
       "160  2023-10-22 2023-10-22 13:33:02.768                        NaN   \n",
       "\n",
       "     citations_per_day   Prompt Engineering Method Generalizable?  \\\n",
       "0            13.230700           Few-shot Learning              Y   \n",
       "1             6.900921                         NaN            NaN   \n",
       "2             5.035439                         NaN            NaN   \n",
       "3             3.327723  Chain-of-thought Prompting              Y   \n",
       "4             2.239062                         NaN            NaN   \n",
       "..                 ...                         ...            ...   \n",
       "156                NaN                         NaN            NaN   \n",
       "157                NaN                         NaN            NaN   \n",
       "158                NaN                         NaN            NaN   \n",
       "159                NaN                         NaN            NaN   \n",
       "160                NaN                         NaN            NaN   \n",
       "\n",
       "     Ease of Implementation? (1=easy, 5=hard)  \\\n",
       "0                                         4.0   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         3.0   \n",
       "4                                         NaN   \n",
       "..                                        ...   \n",
       "156                                       NaN   \n",
       "157                                       NaN   \n",
       "158                                       NaN   \n",
       "159                                       NaN   \n",
       "160                                       NaN   \n",
       "\n",
       "    Performance Gain - Rough Order of Magnitude  \\\n",
       "0                                           0.1   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           0.4   \n",
       "4                                           NaN   \n",
       "..                                          ...   \n",
       "156                                         NaN   \n",
       "157                                         NaN   \n",
       "158                                         NaN   \n",
       "159                                         NaN   \n",
       "160                                         NaN   \n",
       "\n",
       "                                    Notes Datasets  \n",
       "0                    Original GPT-3 Paper  Various  \n",
       "1                    Original GPT-4 Paper      NaN  \n",
       "2    Fine-tuning, introduces Instruct-GPT      NaN  \n",
       "3                         Focuses on PaLM    GSM8K  \n",
       "4    Fine-tuning, introduces Instruct-GPT      NaN  \n",
       "..                                    ...      ...  \n",
       "156                                   NaN      NaN  \n",
       "157                                   NaN      NaN  \n",
       "158                                   NaN      NaN  \n",
       "159                                   NaN      NaN  \n",
       "160                                   NaN      NaN  \n",
       "\n",
       "[161 rows x 16 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input Excel file \"Hand-Labeled Method and Implementation Considerations.xlsx\"\n",
    "# Column \"Performance Gain - Rough Order of Magnitude\" should be a string\n",
    "df = pd.read_excel(\"Hand-Labeled Method and Implementation Considerations.xlsx\", converters={'Performance Gain - Rough Order of Magnitude':str})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper title</th>\n",
       "      <th>citations_per_day</th>\n",
       "      <th>Prompt Engineering Method</th>\n",
       "      <th>Generalizable?</th>\n",
       "      <th>Ease of Implementation? (1=easy, 5=hard)</th>\n",
       "      <th>Performance Gain - Rough Order of Magnitude</th>\n",
       "      <th>Datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>13.230700</td>\n",
       "      <td>Few-shot Learning</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chain of Thought Prompting Elicits Reasoning in Large Language Models</td>\n",
       "      <td>3.327723</td>\n",
       "      <td>Chain-of-thought Prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>GSM8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>1.707434</td>\n",
       "      <td>Zero-Shot Chain-of-thought</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>GSM8K, Last Letter, Coin Flip, Date Understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</td>\n",
       "      <td>1.431593</td>\n",
       "      <td>Tree-of-thought</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Game of 24, Creative Writing, Mini Crosswords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Making Pre-trained Language Models Better Few-shot Learners</td>\n",
       "      <td>1.056058</td>\n",
       "      <td>Better Few Shot Finetuning</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>GLUE, SNLI, MR, CR, MPQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Self-Refine: Iterative Refinement with Self-Feedback</td>\n",
       "      <td>0.973061</td>\n",
       "      <td>Self-refine</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>GSM8K, PIE, CommonGen, CodeNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ReAct: Synergizing Reasoning and Acting in Language Models</td>\n",
       "      <td>0.870102</td>\n",
       "      <td>ReAct</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10-34%</td>\n",
       "      <td>HotpotQA, Fever, ALFWorld, WebShop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Least-to-most prompting enables complex reasoning in large language models</td>\n",
       "      <td>0.710210</td>\n",
       "      <td>Least-to-most prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-15%</td>\n",
       "      <td>Last Letter, SCAN, GSM8K, DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PAL: Program-aided Language Models</td>\n",
       "      <td>0.584822</td>\n",
       "      <td>Program Aided Language Models</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Large Language Models Are Human-Level Prompt Engineers</td>\n",
       "      <td>0.548697</td>\n",
       "      <td>Automatic Prompt Engineer</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Big-Bench Instruction Induction (BBII), Big-Bench Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>How Can We Know What Language Models Know?</td>\n",
       "      <td>0.535602</td>\n",
       "      <td>Prompt Mining, Prompt Paraphrasing</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>LAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Automatic Chain of Thought Prompting in Large Language Models</td>\n",
       "      <td>0.528163</td>\n",
       "      <td>Automatic Chain of Thought Prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5-10%</td>\n",
       "      <td>MultiArith, GSM8K, CommonSenseQA, SVAMP, AQUA-RAT, StrategyQA, Last Letter, Coin Flip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Show Your Work: Scratchpads for Intermediate Computation with Language Models</td>\n",
       "      <td>0.455489</td>\n",
       "      <td>Scratchpads</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10-15%</td>\n",
       "      <td>Long addition, division, execution of arbitrary programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Multimodal Chain-of-Thought Reasoning in Language Models</td>\n",
       "      <td>0.346581</td>\n",
       "      <td>Multimodal CoT</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>ScienceQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm</td>\n",
       "      <td>0.323613</td>\n",
       "      <td>Metaprompt</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society</td>\n",
       "      <td>0.311338</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Chain-of-Verification Reduces Hallucination in Large Language Models</td>\n",
       "      <td>0.307082</td>\n",
       "      <td>Chain-of-Verification</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>Wikidata, QUEST, MultiSpanQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Complexity-Based Prompting for Multi-Step Reasoning</td>\n",
       "      <td>0.301640</td>\n",
       "      <td>Complexity-based prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5-20%</td>\n",
       "      <td>GSM8K, MultiArith, MathQA, Date Understanding, Penguins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decomposed Prompting: A Modular Approach for Solving Complex Tasks</td>\n",
       "      <td>0.271850</td>\n",
       "      <td>Decomposed Prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5-10%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models</td>\n",
       "      <td>0.271283</td>\n",
       "      <td>Plan-and-Solve Prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5-5%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Large Language Models Can Be Easily Distracted by Irrelevant Context</td>\n",
       "      <td>0.264586</td>\n",
       "      <td>Various, Instruction to Ignore Irrelevant Information</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>GSM-IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers</td>\n",
       "      <td>0.212966</td>\n",
       "      <td>EvoPrompt</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15-25%</td>\n",
       "      <td>SAMSum, ASSET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts</td>\n",
       "      <td>0.195040</td>\n",
       "      <td>Chaining</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peer review writing, flashcards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Prompting GPT-3 To Be Reliable</td>\n",
       "      <td>0.194298</td>\n",
       "      <td>Prompting for Reliability</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</td>\n",
       "      <td>0.190913</td>\n",
       "      <td>Demonstrate-Search-Predict</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40-300% relative gains</td>\n",
       "      <td>Open-SQuAD, HotPotQA, QReCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ART: Automatic multi-step reasoning and tool-use for large language models</td>\n",
       "      <td>0.176819</td>\n",
       "      <td>Automatic Reasoning and Tool-Use</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10-15%</td>\n",
       "      <td>GSM8K, AQUA-RATE, BigBench, MMLU, SQUAD, TriviaQA, SVAMP, MAWPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Promptagator: Few-shot Dense Retrieval From 8 Examples</td>\n",
       "      <td>0.167273</td>\n",
       "      <td>Few-shot Dense Retrieval</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Fever, SciFact, SciDocs, HotpotQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</td>\n",
       "      <td>0.166484</td>\n",
       "      <td>Maieutic Prompting</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Com2Sense, CommonSenseQA, CREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Reframing Instructional Prompts to GPTk's Language</td>\n",
       "      <td>0.157847</td>\n",
       "      <td>Reframing</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5-15%</td>\n",
       "      <td>MC-TACO, QASC, Quoref, WinoGrande, CosmosQA, MultiRC, Essential-Terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Generated Knowledge Prompting for Commonsense Reasoning</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>Generated Knowledge Prompting</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10-32%</td>\n",
       "      <td>NumerSense, CommonSenseQA, CommonSenseQA2, QASC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Teaching Algorithmic Reasoning via In-context Learning</td>\n",
       "      <td>0.152241</td>\n",
       "      <td>Algorithmic Prompting</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>GSM8K, GSM8K-Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery</td>\n",
       "      <td>0.147536</td>\n",
       "      <td>Gradient-Based Prompt Optimization</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-2%</td>\n",
       "      <td>SST, Amazon, AGNEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              paper title  \\\n",
       "0                                                                   Language Models are Few-Shot Learners   \n",
       "3                                   Chain of Thought Prompting Elicits Reasoning in Large Language Models   \n",
       "6                                                           Large Language Models are Zero-Shot Reasoners   \n",
       "8                                 Tree of Thoughts: Deliberate Problem Solving with Large Language Models   \n",
       "12                                            Making Pre-trained Language Models Better Few-shot Learners   \n",
       "14                                                   Self-Refine: Iterative Refinement with Self-Feedback   \n",
       "15                                             ReAct: Synergizing Reasoning and Acting in Language Models   \n",
       "18                             Least-to-most prompting enables complex reasoning in large language models   \n",
       "22                                                                     PAL: Program-aided Language Models   \n",
       "23                                                 Large Language Models Are Human-Level Prompt Engineers   \n",
       "24                                                             How Can We Know What Language Models Know?   \n",
       "26                                          Automatic Chain of Thought Prompting in Large Language Models   \n",
       "27                          Show Your Work: Scratchpads for Intermediate Computation with Language Models   \n",
       "32                                               Multimodal Chain-of-Thought Reasoning in Language Models   \n",
       "33                             Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm   \n",
       "34               CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society   \n",
       "35                                   Chain-of-Verification Reduces Hallucination in Large Language Models   \n",
       "37                                                    Complexity-Based Prompting for Multi-Step Reasoning   \n",
       "40                                     Decomposed Prompting: A Modular Approach for Solving Complex Tasks   \n",
       "41      Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models   \n",
       "42                                   Large Language Models Can Be Easily Distracted by Irrelevant Context   \n",
       "44        Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers   \n",
       "48  AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts   \n",
       "49                                                                         Prompting GPT-3 To Be Reliable   \n",
       "50        Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP   \n",
       "52                             ART: Automatic multi-step reasoning and tool-use for large language models   \n",
       "55                                                 Promptagator: Few-shot Dense Retrieval From 8 Examples   \n",
       "56                         Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations   \n",
       "58                                                     Reframing Instructional Prompts to GPTk's Language   \n",
       "59                                                Generated Knowledge Prompting for Commonsense Reasoning   \n",
       "60                                                 Teaching Algorithmic Reasoning via In-context Learning   \n",
       "62           Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery   \n",
       "\n",
       "    citations_per_day                              Prompt Engineering Method  \\\n",
       "0           13.230700                                      Few-shot Learning   \n",
       "3            3.327723                             Chain-of-thought Prompting   \n",
       "6            1.707434                             Zero-Shot Chain-of-thought   \n",
       "8            1.431593                                        Tree-of-thought   \n",
       "12           1.056058                             Better Few Shot Finetuning   \n",
       "14           0.973061                                            Self-refine   \n",
       "15           0.870102                                                  ReAct   \n",
       "18           0.710210                                Least-to-most prompting   \n",
       "22           0.584822                          Program Aided Language Models   \n",
       "23           0.548697                              Automatic Prompt Engineer   \n",
       "24           0.535602                     Prompt Mining, Prompt Paraphrasing   \n",
       "26           0.528163                   Automatic Chain of Thought Prompting   \n",
       "27           0.455489                                            Scratchpads   \n",
       "32           0.346581                                         Multimodal CoT   \n",
       "33           0.323613                                             Metaprompt   \n",
       "34           0.311338                                           Role-Playing   \n",
       "35           0.307082                                  Chain-of-Verification   \n",
       "37           0.301640                             Complexity-based prompting   \n",
       "40           0.271850                                   Decomposed Prompting   \n",
       "41           0.271283                               Plan-and-Solve Prompting   \n",
       "42           0.264586  Various, Instruction to Ignore Irrelevant Information   \n",
       "44           0.212966                                              EvoPrompt   \n",
       "48           0.195040                                               Chaining   \n",
       "49           0.194298                              Prompting for Reliability   \n",
       "50           0.190913                             Demonstrate-Search-Predict   \n",
       "52           0.176819                       Automatic Reasoning and Tool-Use   \n",
       "55           0.167273                               Few-shot Dense Retrieval   \n",
       "56           0.166484                                     Maieutic Prompting   \n",
       "58           0.157847                                              Reframing   \n",
       "59           0.154563                          Generated Knowledge Prompting   \n",
       "60           0.152241                                  Algorithmic Prompting   \n",
       "62           0.147536                     Gradient-Based Prompt Optimization   \n",
       "\n",
       "   Generalizable?  Ease of Implementation? (1=easy, 5=hard)  \\\n",
       "0               Y                                       4.0   \n",
       "3               Y                                       3.0   \n",
       "6               Y                                       1.0   \n",
       "8               Y                                       3.0   \n",
       "12              Y                                       4.0   \n",
       "14              Y                                       3.0   \n",
       "15              Y                                       4.0   \n",
       "18              Y                                       2.0   \n",
       "22              N                                       4.0   \n",
       "23              Y                                       4.0   \n",
       "24              N                                       4.0   \n",
       "26              Y                                       4.0   \n",
       "27              Y                                       4.0   \n",
       "32              N                                       4.0   \n",
       "33              Y                                       NaN   \n",
       "34              Y                                       4.0   \n",
       "35              Y                                       3.0   \n",
       "37              Y                                       3.0   \n",
       "40              Y                                       4.0   \n",
       "41              Y                                       2.0   \n",
       "42              N                                       2.0   \n",
       "44              Y                                       4.0   \n",
       "48          Maybe                                       4.0   \n",
       "49              Y                                       4.0   \n",
       "50              Y                                       4.0   \n",
       "52              Y                                       4.0   \n",
       "55              N                                       4.0   \n",
       "56              Y                                       4.0   \n",
       "58              Y                                       4.0   \n",
       "59          Maybe                                       3.0   \n",
       "60          Maybe                                       4.0   \n",
       "62              Y                                       4.0   \n",
       "\n",
       "   Performance Gain - Rough Order of Magnitude  \\\n",
       "0                                          0.1   \n",
       "3                                          0.4   \n",
       "6                                          0.3   \n",
       "8                                          0.7   \n",
       "12                                        0.11   \n",
       "14                                         0.2   \n",
       "15                                      10-34%   \n",
       "18                                       0-15%   \n",
       "22                                        0.15   \n",
       "23                                         0.1   \n",
       "24                                         0.1   \n",
       "26                                       5-10%   \n",
       "27                                      10-15%   \n",
       "32                                        0.16   \n",
       "33                                         NaN   \n",
       "34                                         NaN   \n",
       "35                                      20-30%   \n",
       "37                                       5-20%   \n",
       "40                                       5-10%   \n",
       "41                                      2.5-5%   \n",
       "42                                     Unclear   \n",
       "44                                      15-25%   \n",
       "48                                         NaN   \n",
       "49                                         NaN   \n",
       "50                      40-300% relative gains   \n",
       "52                                      10-15%   \n",
       "55                                        0.05   \n",
       "56                                         0.2   \n",
       "58                                       5-15%   \n",
       "59                                      10-32%   \n",
       "60                                         0.4   \n",
       "62                                        0-2%   \n",
       "\n",
       "                                                                                 Datasets  \n",
       "0                                                                                 Various  \n",
       "3                                                                                   GSM8K  \n",
       "6                                       GSM8K, Last Letter, Coin Flip, Date Understanding  \n",
       "8                                           Game of 24, Creative Writing, Mini Crosswords  \n",
       "12                                                               GLUE, SNLI, MR, CR, MPQA  \n",
       "14                                                         GSM8K, PIE, CommonGen, CodeNet  \n",
       "15                                                     HotpotQA, Fever, ALFWorld, WebShop  \n",
       "18                                                         Last Letter, SCAN, GSM8K, DROP  \n",
       "22                                                                                    NaN  \n",
       "23                                 Big-Bench Instruction Induction (BBII), Big-Bench Hard  \n",
       "24                                                                                   LAMA  \n",
       "26  MultiArith, GSM8K, CommonSenseQA, SVAMP, AQUA-RAT, StrategyQA, Last Letter, Coin Flip  \n",
       "27                               Long addition, division, execution of arbitrary programs  \n",
       "32                                                                              ScienceQA  \n",
       "33                                                                                    NaN  \n",
       "34                                                                                    NaN  \n",
       "35                                                           Wikidata, QUEST, MultiSpanQA  \n",
       "37                                GSM8K, MultiArith, MathQA, Date Understanding, Penguins  \n",
       "40                                                                                    NaN  \n",
       "41                                                                                    NaN  \n",
       "42                                                                                 GSM-IC  \n",
       "44                                                                          SAMSum, ASSET  \n",
       "48                                                        Peer review writing, flashcards  \n",
       "49                                                                                    NaN  \n",
       "50                                                            Open-SQuAD, HotPotQA, QReCC  \n",
       "52                        GSM8K, AQUA-RATE, BigBench, MMLU, SQUAD, TriviaQA, SVAMP, MAWPS  \n",
       "55                                                       Fever, SciFact, SciDocs, HotpotQ  \n",
       "56                                                        Com2Sense, CommonSenseQA, CREAK  \n",
       "58                  MC-TACO, QASC, Quoref, WinoGrande, CosmosQA, MultiRC, Essential-Terms  \n",
       "59                                        NumerSense, CommonSenseQA, CommonSenseQA2, QASC  \n",
       "60                                                                      GSM8K, GSM8K-Hard  \n",
       "62                                                                    SST, Amazon, AGNEWS  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Items with non-missing column \"Prompt Engineeering Method\" and \"Ease of Implementation? (1=easy, 5=hard)\" not 5\n",
    "limitations = df[(df[\"Prompt Engineering Method\"].notnull()) & (df[\"Ease of Implementation? (1=easy, 5=hard)\"] != 5)]\n",
    "\n",
    "# Drop irrelevant columns\n",
    "limitations = limitations.drop(df.columns[1:9], axis=1)\n",
    "\n",
    "# Drop \"Notes\" column\n",
    "limitations = limitations.drop(\"Notes\", axis=1)\n",
    "\n",
    "# Print full width\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "limitations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSM8K                              8\n",
       "Last Letter                        3\n",
       "CommonSenseQA                      3\n",
       "Coin Flip                          2\n",
       "Date Understanding                 2\n",
       "                                  ..\n",
       "execution of arbitrary programs    1\n",
       "ScienceQA                          1\n",
       "Wikidata                           1\n",
       "MultiSpanQA                        1\n",
       "AGNEWS                             1\n",
       "Name: count, Length: 72, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of column \"Datasets\"\n",
    "\n",
    "datasets = limitations[\"Datasets\"].unique()\n",
    "\n",
    "# Convert array to list\n",
    "datasets = datasets.tolist()\n",
    "\n",
    "# Split list items by comma\n",
    "ds_list = []\n",
    "for ds in datasets:\n",
    "    ds_list.append(str(ds).split(\", \"))\n",
    "\n",
    "# Flatten list of lists\n",
    "ds_list = [item for sublist in ds_list for item in sublist]\n",
    "\n",
    "# Frequency of list items\n",
    "ds_list = pd.Series(ds_list).value_counts()\n",
    "\n",
    "ds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Method'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ijyli\\repo\\anlp23-project\\Midterm Report\\Selection of Prompt Engineering Methods\\03 - The Popularity of Prompt Engineering Methods - Final Output.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Clean up columns for final LaTeX table\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Keep columns: 'paper title', 'citations per day', 'Method'\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m distributable_excel \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mpaper title\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcitations_per_day\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMethod\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Drop items missing 'paper title' or 'citations_per_day'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m distributable_excel \u001b[39m=\u001b[39m distributable_excel\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpaper title\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcitations_per_day\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\anaconda3\\envs\\anlp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Method'] not in index\""
     ]
    }
   ],
   "source": [
    "# Clean up columns for final LaTeX table\n",
    "\n",
    "# Keep columns: 'paper title', 'citations per day', 'Method'\n",
    "distributable_excel = df[['paper title', 'citations_per_day', 'Method']]\n",
    "\n",
    "# Drop items missing 'paper title' or 'citations_per_day'\n",
    "distributable_excel = distributable_excel.dropna(subset=['paper title', 'citations_per_day'])\n",
    "\n",
    "# Rename columns\n",
    "distributable_excel = distributable_excel.rename(columns={'paper title': 'Title', 'Method': 'Method', 'citations_per_day': 'Citations Per Day'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distributable_excel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ijyli\\repo\\anlp23-project\\Midterm Report\\Selection of Prompt Engineering Methods\\03 - The Popularity of Prompt Engineering Methods - Final Output.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Output distributable Excel file available on request\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ijyli/repo/anlp23-project/Midterm%20Report/Selection%20of%20Prompt%20Engineering%20Methods/03%20-%20The%20Popularity%20of%20Prompt%20Engineering%20Methods%20-%20Final%20Output.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m distributable_excel\u001b[39m.\u001b[39mto_excel(\u001b[39m'\u001b[39m\u001b[39mThe Popularity of Prompt Engineering Methods - Extended Data.xlsx\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'distributable_excel' is not defined"
     ]
    }
   ],
   "source": [
    "# Output distributable Excel file available on request\n",
    "distributable_excel.to_excel('The Popularity of Prompt Engineering Methods - Extended Data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output LaTeX table of top general methods\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
